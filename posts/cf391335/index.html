<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.0.0">
  <link rel="icon" type="image/png" sizes="32x32" href="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/theme/favicon.ico">
  <link rel="icon" type="image/png" sizes="16x16" href="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/theme/favicon.ico">
  <link rel="alternate" href="/atom.xml" title="Houmin" type="application/atom+xml">
  <meta name="google-site-verification" content="zdGhdEF7jHoJW58lsdN6l9JrQFjJFwakCIc7TbbosV0">
  <meta name="msvalidate.01" content="2F527B379ED5537861D0D38C2C754C2B">
  <meta name="baidu-site-verification" content="xAag2PqzKE">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/font-awesome@4/css/font-awesome.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/pace-js@1/themes/blue/pace-theme-minimal.css">
  <script src="//cdn.jsdelivr.net/npm/pace-js@1/pace.min.js"></script>


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '7.5.0',
    exturl: false,
    sidebar: {"position":"right","display":"post","offset":12,"onmobile":true},
    copycode: {"enable":true,"show_result":true,"style":"mac"},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":true},
    bookmark: {"enable":true,"color":"#222","save":"auto"},
    fancybox: true,
    mediumzoom: false,
    lazyload: true,
    pangu: false,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: 'search.xml',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: '复制',
      copy_success: '复制成功',
      copy_failure: '复制失败'
    },
    sidebarPadding: 40
  };
</script>

  <meta name="description" content="原生的 k8s 基于 Device Plugin 和 Extended Resource 机制实现了在容器中使用GPU，但是只支持GPU的独占使用，不允许在Pod间共享GPU，这大大降低了对集群中GPU的利用率。为了在集群层面共享GPU，我们需要实现GPU资源的隔离与调度，本文将依次介绍阿里的 GPUShare 与腾讯的 GPUManager，分析其实现机制。">
<meta name="keywords" content="k8s,device plugin,GPU,资源隔离,scheduler extender">
<meta property="og:type" content="article">
<meta property="og:title" content="【Kubernetes】GPU 共享">
<meta property="og:url" content="http://houmin.cc/posts/cf391335/index.html">
<meta property="og:site_name" content="Houmin">
<meta property="og:description" content="原生的 k8s 基于 Device Plugin 和 Extended Resource 机制实现了在容器中使用GPU，但是只支持GPU的独占使用，不允许在Pod间共享GPU，这大大降低了对集群中GPU的利用率。为了在集群层面共享GPU，我们需要实现GPU资源的隔离与调度，本文将依次介绍阿里的 GPUShare 与腾讯的 GPUManager，分析其实现机制。">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https://github.com/AliyunContainerService/gpushare-scheduler-extender/raw/master/docs/designs/arch.jpg">
<meta property="og:image" content="https://github.com/AliyunContainerService/gpushare-scheduler-extender/raw/master/docs/designs/filter.jpg">
<meta property="og:image" content="https://github.com/AliyunContainerService/gpushare-scheduler-extender/raw/master/docs/designs/bind.jpg">
<meta property="og:image" content="https://github.com/AliyunContainerService/gpushare-scheduler-extender/raw/master/docs/designs/sequence.jpg">
<meta property="og:image" content="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-11-19_gpu-manager.png">
<meta property="og:image" content="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-11-19_gpu-manager-predicate.png">
<meta property="og:updated_time" content="2020-11-23T13:06:17.421Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://github.com/AliyunContainerService/gpushare-scheduler-extender/raw/master/docs/designs/arch.jpg">

<link rel="canonical" href="http://houmin.cc/posts/cf391335/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true,
    isPage: false,
    isArchive: false
  };
</script>

  <title>【Kubernetes】GPU 共享 | Houmin</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>


  <script src="/js/photoswipe.min.js?v="></script>
  <script src="/js/photoswipe-ui-default.min.js?v="></script>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Houmin</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <h1 class="site-subtitle" itemprop="description">Yesterday You Said Tomorrow</h1>
      
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-album">

    <a href="/album" rel="section"><i class="fa fa-fw fa-camera"></i>相册</a>

  </li>
        <li class="menu-item menu-item-movies">

    <a href="/movies/" rel="section"><i class="fa fa-fw fa-film"></i>观影</a>

  </li>
        <li class="menu-item menu-item-books">

    <a href="/books/" rel="section"><i class="fa fa-fw fa-book"></i>阅读</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>关于</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="none" placeholder="搜索..." spellcheck="false" type="text" id="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result"></div>

</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://houmin.cc/posts/cf391335/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/theme/avatar.png">
      <meta itemprop="name" content="Houmin">
      <meta itemprop="description" content="丈夫拥书万卷，何假南面百城">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Houmin">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          【Kubernetes】GPU 共享
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-11-18 11:11:07" itemprop="dateCreated datePublished" datetime="2020-11-18T11:11:07+08:00">2020-11-18</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%AF%E4%B8%9A%E4%B8%93%E6%94%BB/" itemprop="url" rel="index">
                    <span itemprop="name">术业专攻</span>
                  </a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/posts/cf391335/#comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/posts/cf391335/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>13k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>23 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>原生的 k8s 基于 <code>Device Plugin</code> 和 <code>Extended Resource</code> 机制实现了在容器中使用GPU，但是只支持GPU的独占使用，不允许在Pod间共享GPU，这大大降低了对集群中GPU的利用率。为了在集群层面共享GPU，我们需要实现GPU资源的隔离与调度，本文将依次介绍阿里的 <a href="https://github.com/AliyunContainerService/gpushare-scheduler-extender" target="_blank" rel="external nofollow noopener noreferrer">GPUShare</a> 与腾讯的 <a href="https://github.com/tkestack/gpu-manager" target="_blank" rel="external nofollow noopener noreferrer">GPUManager</a>，分析其实现机制。</p>
<a id="more"></a>
<h2 id="阿里GPUShare"><a href="#阿里GPUShare" class="headerlink" title="阿里GPUShare"></a>阿里GPUShare</h2><p>阿里的 <a href="https://github.com/AliyunContainerService/gpushare-scheduler-extender" target="_blank" rel="external nofollow noopener noreferrer">GPUShare</a> 基于 <a href="https://github.com/NVIDIA/nvidia-docker" target="_blank" rel="external nofollow noopener noreferrer">Nvidia Docker2</a> 和他们的 <a href="https://docs.google.com/document/d/1ZgKH_K4SEfdiE_OfxQ836s4yQWxZfSjS288Tq9YIWCA/edit#heading=h.r88v2xgacqr" target="_blank" rel="external nofollow noopener noreferrer">gpu sharing design</a> 设计而实现的，为了使用阿里的GPUShare，首先需要配置Node上的 Docker Runtime 并安装 <code>NVIDIA Docker 2</code>，具体过程可以参考 <a href="../574111db">在Docker中使用GPU</a>。</p>
<h3 id="架构设计"><a href="#架构设计" class="headerlink" title="架构设计"></a>架构设计</h3><h4 id="设计原则"><a href="#设计原则" class="headerlink" title="设计原则"></a>设计原则</h4><ul>
<li>尽管GPU可以从 CUDA Cores 和 GPU Memory 两个维度来衡量GPU的能力，<strong>在推理的场景，我们可以假定CUDA core的数量和GPU  Memory的大小是成比例的</strong></li>
<li>设计仍然使用 Extended Resource，只是单位从 <code>number of GPUs</code> 变更为 <code>amount of GPU memory in MiB</code></li>
<li>在模型开发和推理的场景下，<strong>用户申请的GPU资源不超过1个GPU，也就是说 resource limit 是 一个GPU</strong></li>
<li>基于k8s原生的Scheduler Extender、Extended Resource、DevicePlugin机制来实现</li>
</ul>
<h4 id="核心组件"><a href="#核心组件" class="headerlink" title="核心组件"></a>核心组件</h4><p>设计里定义了两种扩展资源：</p>
<ul>
<li><code>gpu-mem</code>： 对应于GPU Memory，如果一个Node有多个GPU设备，这里计算的是总的GPU Memory</li>
<li><code>gpu-count</code>：对应于GPU 设备的数目</li>
</ul>
<p>下图是整个设计的核心组件：</p>
<ul>
<li>GPU Share Scheduler Extender：基于k8s scheduler extender机制，作用于调度过程的<code>Filter</code>和<code>Bind</code>阶段，用于决定某个Node上的一个GPU设备是否可以提供足够的GPU Memory，并将GPU分配的结果记录到Pod Spec 的 Annotation中</li>
<li>GPU Share Device Plugin：基于k8s device plugin机制，根据GPU Share Scheduler Extender记录在Pod Spec的Annotation，实现GPU 设备的 Allocation。</li>
</ul>
<p><img alt="GPU Share Design" data-src="https://github.com/AliyunContainerService/gpushare-scheduler-extender/raw/master/docs/designs/arch.jpg"></p>
<h3 id="具体过程"><a href="#具体过程" class="headerlink" title="具体过程"></a>具体过程</h3><h4 id="设备资源报告"><a href="#设备资源报告" class="headerlink" title="设备资源报告"></a>设备资源报告</h4><p><code>GPU Share Device Plugin</code> 基于 <code>nvml</code> 库来查询每个Node上GPU设备的数目和每个GPU设备的GPU Memory。</p>
<p>这些资源状况被通过 <code>ListAndWatch()</code> 汇报给 Kubelet，然后 kubelet 会上报给 APIServer，这时候执行 <code>kubectl get node</code> 可以看到在 <code>status</code> 看到相关的<code>Extended Resource</code>字段：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Node</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="number">10.0</span><span class="number">.0</span><span class="number">.4</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">gpushare:</span> <span class="string">"true"</span></span><br><span class="line">    <span class="string">...</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">podCIDR:</span> <span class="number">172.16</span><span class="number">.1</span><span class="number">.0</span><span class="string">/26</span></span><br><span class="line">  <span class="attr">podCIDRs:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="number">172.16</span><span class="number">.1</span><span class="number">.0</span><span class="string">/26</span></span><br><span class="line">  <span class="attr">providerID:</span> <span class="string">qcloud:///800002/ins-hsmsc4x9</span></span><br><span class="line"><span class="attr">status:</span></span><br><span class="line">  <span class="string">...</span></span><br><span class="line">  <span class="attr">allocatable:</span></span><br><span class="line">    <span class="attr">aliyun.com/gpu-count:</span> <span class="string">"1"</span></span><br><span class="line">    <span class="attr">aliyun.com/gpu-mem:</span> <span class="string">"22"</span></span><br><span class="line">    <span class="attr">cpu:</span> <span class="string">5926m</span></span><br><span class="line">    <span class="attr">ephemeral-storage:</span> <span class="string">"47438316671"</span></span><br><span class="line">    <span class="attr">hugepages-2Mi:</span> <span class="string">"0"</span></span><br><span class="line">    <span class="attr">memory:</span> <span class="string">54222084Ki</span></span><br><span class="line">    <span class="string">...</span></span><br><span class="line">  <span class="attr">capacity:</span></span><br><span class="line">    <span class="attr">aliyun.com/gpu-count:</span> <span class="string">"1"</span></span><br><span class="line">    <span class="attr">aliyun.com/gpu-mem:</span> <span class="string">"22"</span></span><br><span class="line">    <span class="attr">cpu:</span> <span class="string">"6"</span></span><br><span class="line">    <span class="attr">ephemeral-storage:</span> <span class="string">51473868Ki</span></span><br><span class="line">    <span class="attr">hugepages-2Mi:</span> <span class="string">"0"</span></span><br><span class="line">    <span class="attr">memory:</span> <span class="string">57448708Ki</span></span><br><span class="line">    <span class="string">...</span></span><br></pre></td></tr></table></figure>
<h4 id="调度"><a href="#调度" class="headerlink" title="调度"></a>调度</h4><p>用户申请GPU的时候，在 Extended Resource 中只填写 <code>gpu-mem</code>，下面部署一个单机版的Tensorflow：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span> </span><br><span class="line">  <span class="attr">name:</span> <span class="string">tensorflow</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">k8s-app:</span> <span class="string">tensorflow</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">k8s-app:</span> <span class="string">tensorflow</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">k8s-app:</span> <span class="string">tensorflow</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">tensorflow</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">tensorflow/tensorflow:2.2.1-gpu-py3-jupyter</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">8888</span></span><br><span class="line">        <span class="attr">resources:</span></span><br><span class="line">          <span class="attr">limits:</span></span><br><span class="line">            <span class="attr">cpu:</span> <span class="number">4</span></span><br><span class="line">            <span class="attr">memory:</span> <span class="string">2Gi</span></span><br><span class="line">            <span class="attr">aliyun.com/gpu-mem:</span> <span class="number">3</span></span><br><span class="line">          <span class="attr">requests:</span></span><br><span class="line">            <span class="attr">cpu:</span> <span class="number">2</span></span><br><span class="line">            <span class="attr">memory:</span> <span class="string">1Gi</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">jupyter-service</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">NodePort</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">8888</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">tensorflow</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">k8s-app:</span> <span class="string">tensorflow</span></span><br></pre></td></tr></table></figure>
<h5 id="Filter"><a href="#Filter" class="headerlink" title="Filter"></a>Filter</h5><p>当kube-scheduler运行完所有的Filter函数后，就会调用 <code>GPU Share Extender</code> 的 Filter 函数。在原生的过滤中，kube-scheduler会计算是否有足够的Extended Resource（算的是总共的GPU Memory），但是不能知道是否某个GPU设备有足够的资源，这时候就需要调度器插件来实现。以下图为例：</p>
<ul>
<li>用户申请了8138MiB的GPU Memory，对于原生调度器，N1节点只剩下  (16276 * 2 - 16276 - 12207 = 4069) 的GPU资源，不满足 Extended Resource可用的条件，N1节点被过滤掉</li>
<li>接下来的N2节点和N3节点剩余的总的资源数都有8138MiB，那么该选择哪一个呢</li>
<li>在 <code>GPU Share Extender</code> 的过滤中，他需要找到有单个GPU能够满足用户申请的资源，当检查到N2节点的时候，发现虽然总的GPU Memory有8138MiB，但是每个GPU设备都只剩4096MiB了，不能满足单设备8138的需求，所以N2被过滤掉</li>
<li>扫描到N3节点，发现GPU0满足8138MiB的需求，符合要求</li>
</ul>
<p><img alt data-src="https://github.com/AliyunContainerService/gpushare-scheduler-extender/raw/master/docs/designs/filter.jpg"></p>
<blockquote>
<p><strong>这里有一个问题：当一个Node上有多张卡的时候，Scheduler Extender是如何知道每张卡当前可用的Capacity的呢？</strong></p>
</blockquote>
<p>我们看一下Extender在 Filter 阶段执行的函数，对于要创建的Pod，当前Node检查自己拥有的所有可用GPU，一旦有一个GPU的可用显存大于申请的显存，那么当前Node是可以被调度的。</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// check if the pod can be allocated on the node</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(n *NodeInfo)</span> <span class="title">Assume</span><span class="params">(pod *v1.Pod)</span> <span class="params">(allocatable <span class="keyword">bool</span>)</span></span> &#123;</span><br><span class="line">	allocatable = <span class="literal">false</span></span><br><span class="line"></span><br><span class="line">	n.rwmu.RLock()</span><br><span class="line">	<span class="keyword">defer</span> n.rwmu.RUnlock()</span><br><span class="line"></span><br><span class="line">	availableGPUs := n.getAvailableGPUs()</span><br><span class="line">	reqGPU := <span class="keyword">uint</span>(utils.GetGPUMemoryFromPodResource(pod))</span><br><span class="line">	log.Printf(<span class="string">"debug: AvailableGPUs: %v in node %s"</span>, availableGPUs, n.name)</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span> <span class="built_in">len</span>(availableGPUs) &gt; <span class="number">0</span> &#123;</span><br><span class="line">		<span class="keyword">for</span> devID := <span class="number">0</span>; devID &lt; <span class="built_in">len</span>(n.devs); devID++ &#123;</span><br><span class="line">			availableGPU, ok := availableGPUs[devID]</span><br><span class="line">			<span class="keyword">if</span> ok &#123;</span><br><span class="line">				<span class="keyword">if</span> availableGPU &gt;= reqGPU &#123;</span><br><span class="line">					allocatable = <span class="literal">true</span></span><br><span class="line">					<span class="keyword">break</span></span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> allocatable</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>接下来的一个问题是，每个Node可用的GPU显存是如何得到的呢？我们进入到 <code>getAvailableGPUs</code> 继续看：</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(n *NodeInfo)</span> <span class="title">getAvailableGPUs</span><span class="params">()</span> <span class="params">(availableGPUs <span class="keyword">map</span>[<span class="keyword">int</span>]<span class="keyword">uint</span>)</span></span> &#123;</span><br><span class="line">	allGPUs := n.getAllGPUs()</span><br><span class="line">	usedGPUs := n.getUsedGPUs()</span><br><span class="line">	unhealthyGPUs := n.getUnhealthyGPUs()</span><br><span class="line">	availableGPUs = <span class="keyword">map</span>[<span class="keyword">int</span>]<span class="keyword">uint</span>&#123;&#125;</span><br><span class="line">	<span class="keyword">for</span> id, totalGPUMem := <span class="keyword">range</span> allGPUs &#123;</span><br><span class="line">		<span class="keyword">if</span> usedGPUMem, found := usedGPUs[id]; found &#123;</span><br><span class="line">			availableGPUs[id] = totalGPUMem - usedGPUMem</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	log.Printf(<span class="string">"info: available GPU list %v before removing unhealty GPUs"</span>, availableGPUs)</span><br><span class="line">	<span class="keyword">for</span> id, _ := <span class="keyword">range</span> unhealthyGPUs &#123;</span><br><span class="line">		log.Printf(<span class="string">"info: delete dev %d from availble GPU list"</span>, id)</span><br><span class="line">		<span class="built_in">delete</span>(availableGPUs, id)</span><br><span class="line">	&#125;</span><br><span class="line">	log.Printf(<span class="string">"info: available GPU list %v after removing unhealty GPUs"</span>, availableGPUs)</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> availableGPUs</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里可以看到，<code>Scheduler Extender</code> 内部维护了当前Node上所有的GPU显存状态和已经用了的GPU显存状态信息：</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// device index: gpu memory</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(n *NodeInfo)</span> <span class="title">getUsedGPUs</span><span class="params">()</span> <span class="params">(usedGPUs <span class="keyword">map</span>[<span class="keyword">int</span>]<span class="keyword">uint</span>)</span></span> &#123;</span><br><span class="line">	usedGPUs = <span class="keyword">map</span>[<span class="keyword">int</span>]<span class="keyword">uint</span>&#123;&#125;</span><br><span class="line">	<span class="keyword">for</span> _, dev := <span class="keyword">range</span> n.devs &#123;</span><br><span class="line">		usedGPUs[dev.idx] = dev.GetUsedGPUMemory()</span><br><span class="line">	&#125;</span><br><span class="line">	log.Printf(<span class="string">"info: getUsedGPUs: %v in node %s, and devs %v"</span>, usedGPUs, n.name, n.devs)</span><br><span class="line">	<span class="keyword">return</span> usedGPUs</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// device index: gpu memory</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(n *NodeInfo)</span> <span class="title">getAllGPUs</span><span class="params">()</span> <span class="params">(allGPUs <span class="keyword">map</span>[<span class="keyword">int</span>]<span class="keyword">uint</span>)</span></span> &#123;</span><br><span class="line">	allGPUs = <span class="keyword">map</span>[<span class="keyword">int</span>]<span class="keyword">uint</span>&#123;&#125;</span><br><span class="line">	<span class="keyword">for</span> _, dev := <span class="keyword">range</span> n.devs &#123;</span><br><span class="line">		allGPUs[dev.idx] = dev.totalGPUMem</span><br><span class="line">	&#125;</span><br><span class="line">	log.Printf(<span class="string">"info: getAllGPUs: %v in node %s, and dev %v"</span>, allGPUs, n.name, n.devs)</span><br><span class="line">	<span class="keyword">return</span> allGPUs</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>关于 <code>GetUsedGPUMemory</code>，是<code>Scheduler Extender</code> 内部维护的 <code>DeviceInfo</code> 所记录的，这里的 <code>d.podMap</code> 会在每次Extender执行 <code>Bind</code> 的时候，将对应的Pod添加到对应的Node上的 <code>DeviceInfo</code>中：</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(d *DeviceInfo)</span> <span class="title">GetUsedGPUMemory</span><span class="params">()</span> <span class="params">(gpuMem <span class="keyword">uint</span>)</span></span> &#123;</span><br><span class="line">	log.Printf(<span class="string">"debug: GetUsedGPUMemory() podMap %v, and its address is %p"</span>, d.podMap, d)</span><br><span class="line">	d.rwmu.RLock()</span><br><span class="line">	<span class="keyword">defer</span> d.rwmu.RUnlock()</span><br><span class="line">	<span class="keyword">for</span> _, pod := <span class="keyword">range</span> d.podMap &#123;</span><br><span class="line">		<span class="keyword">if</span> pod.Status.Phase == v1.PodSucceeded || pod.Status.Phase == v1.PodFailed &#123;</span><br><span class="line">			log.Printf(<span class="string">"debug: skip the pod %s in ns %s due to its status is %s"</span>, pod.Name, pod.Namespace, pod.Status.Phase)</span><br><span class="line">			<span class="keyword">continue</span></span><br><span class="line">		&#125;</span><br><span class="line">		<span class="comment">// gpuMem += utils.GetGPUMemoryFromPodEnv(pod)</span></span><br><span class="line">		gpuMem += utils.GetGPUMemoryFromPodAnnotation(pod)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> gpuMem</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>再总结总结，本质上是 <code>Scheduler Extender</code> 维护了一个 <code>devs</code> 这么一个数据结构，使得它可以知道当前Node上每个GPU设备的显存状态。</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// NodeInfo is node level aggregated information.</span></span><br><span class="line"><span class="keyword">type</span> NodeInfo <span class="keyword">struct</span> &#123;</span><br><span class="line">	name           <span class="keyword">string</span></span><br><span class="line">	node           *v1.Node</span><br><span class="line">	devs           <span class="keyword">map</span>[<span class="keyword">int</span>]*DeviceInfo</span><br><span class="line">	gpuCount       <span class="keyword">int</span></span><br><span class="line">	gpuTotalMemory <span class="keyword">int</span></span><br><span class="line">	rwmu           *sync.RWMutex</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>那么问题来了，我们通过ApiServer，只能知道对应Node上的 <code>gpuCount</code> 和 <code>gpuTotalMemory</code>，而不知道每张卡各自的显存的。这个 <code>devs</code> 是怎么初始化得到每张卡的显存信息呢的呢？继续看代码：</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Create Node Level</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">NewNodeInfo</span><span class="params">(node *v1.Node)</span> *<span class="title">NodeInfo</span></span> &#123;</span><br><span class="line">	log.Printf(<span class="string">"debug: NewNodeInfo() creates nodeInfo for %s"</span>, node.Name)</span><br><span class="line"></span><br><span class="line">	devMap := <span class="keyword">map</span>[<span class="keyword">int</span>]*DeviceInfo&#123;&#125;</span><br><span class="line">	<span class="keyword">for</span> i := <span class="number">0</span>; i &lt; utils.GetGPUCountInNode(node); i++ &#123;</span><br><span class="line">		devMap[i] = newDeviceInfo(i, <span class="keyword">uint</span>(utils.GetTotalGPUMemory(node)/utils.GetGPUCountInNode(node)))</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span> <span class="built_in">len</span>(devMap) == <span class="number">0</span> &#123;</span><br><span class="line">		log.Printf(<span class="string">"warn: node %s with nodeinfo %v has no devices"</span>,</span><br><span class="line">			node.Name,</span><br><span class="line">			node)</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> &amp;NodeInfo&#123;</span><br><span class="line">		name:           node.Name,</span><br><span class="line">		node:           node,</span><br><span class="line">		devs:           devMap,</span><br><span class="line">		gpuCount:       utils.GetGPUCountInNode(node),</span><br><span class="line">		gpuTotalMemory: utils.GetTotalGPUMemory(node),</span><br><span class="line">		rwmu:           <span class="built_in">new</span>(sync.RWMutex),</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可以看到，这里在初始化的时候，默认设定每张GPU卡的显存大小一样，通过平均得到每张卡的心存信息。</p>
<h5 id="Bind"><a href="#Bind" class="headerlink" title="Bind"></a>Bind</h5><ul>
<li>当调度器发现有Node符合要求，这时候会把Pod和Node Bind到一起，<code>GPU Share Extender</code> 需要做两件事情：<ul>
<li>根据 <code>binpack</code> 原则找到Node上对应的GPU设备，并将 GPU Device ID记录到 Pod的 Annotation中 <code>ALIYUN_GPU_ID</code>。他也会将Pod使用的GPU Memory记录到Pod Annotation中：<code>ALIYUN_COM_GPU_MEM_POD</code> 和 <code>ALIYUN_COM_GPU_MEM_ASSUME_TIME</code></li>
<li>Bind the Node and Pod with kubernetes API</li>
</ul>
</li>
<li>如果没有找到合适的Node符合要求，那么就不会做Bind操作</li>
</ul>
<p>以下图为例，N1中有4个GPU，其中GPU0（12207），GPU1（8138）、GPU2（4069）和GPU3（16276）, GPU2因为资源不够被过滤掉，剩下的3个GPU根据 Binpack 原则，我们选用GPU1（图里面 Annotation错了，不是0，而是1）</p>
<p><img alt data-src="https://github.com/AliyunContainerService/gpushare-scheduler-extender/raw/master/docs/designs/bind.jpg"></p>
<p>我们看一看在找GPU设备的时候是如何操作的，可以看到这里通过 <code>candidateGPUMemory &gt; availableGPU</code> 这里实现了 <code>binpack</code>。</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// allocate the GPU ID to the pod</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(n *NodeInfo)</span> <span class="title">allocateGPUID</span><span class="params">(pod *v1.Pod)</span> <span class="params">(candidateDevID <span class="keyword">int</span>, found <span class="keyword">bool</span>)</span></span> &#123;</span><br><span class="line"></span><br><span class="line">	reqGPU := <span class="keyword">uint</span>(<span class="number">0</span>)</span><br><span class="line">	found = <span class="literal">false</span></span><br><span class="line">	candidateDevID = <span class="number">-1</span></span><br><span class="line">	candidateGPUMemory := <span class="keyword">uint</span>(<span class="number">0</span>)</span><br><span class="line">	availableGPUs := n.getAvailableGPUs()</span><br><span class="line"></span><br><span class="line">	reqGPU = <span class="keyword">uint</span>(utils.GetGPUMemoryFromPodResource(pod))</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span> reqGPU &gt; <span class="keyword">uint</span>(<span class="number">0</span>) &#123;</span><br><span class="line">		log.Printf(<span class="string">"info: reqGPU for pod %s in ns %s: %d"</span>, pod.Name, pod.Namespace, reqGPU)</span><br><span class="line">		log.Printf(<span class="string">"info: AvailableGPUs: %v in node %s"</span>, availableGPUs, n.name)</span><br><span class="line">		<span class="keyword">if</span> <span class="built_in">len</span>(availableGPUs) &gt; <span class="number">0</span> &#123;</span><br><span class="line">			<span class="keyword">for</span> devID := <span class="number">0</span>; devID &lt; <span class="built_in">len</span>(n.devs); devID++ &#123;</span><br><span class="line">				availableGPU, ok := availableGPUs[devID]</span><br><span class="line">				<span class="keyword">if</span> ok &#123;</span><br><span class="line">					<span class="keyword">if</span> availableGPU &gt;= reqGPU &#123;</span><br><span class="line">						<span class="keyword">if</span> candidateDevID == <span class="number">-1</span> || candidateGPUMemory &gt; availableGPU &#123;</span><br><span class="line">							candidateDevID = devID</span><br><span class="line">							candidateGPUMemory = availableGPU</span><br><span class="line">						&#125;</span><br><span class="line"></span><br><span class="line">						found = <span class="literal">true</span></span><br><span class="line">					&#125;</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		<span class="keyword">if</span> found &#123;</span><br><span class="line">			log.Printf(<span class="string">"info: Find candidate dev id %d for pod %s in ns %s successfully."</span>,</span><br><span class="line">				candidateDevID,</span><br><span class="line">				pod.Name,</span><br><span class="line">				pod.Namespace)</span><br><span class="line">		&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">			log.Printf(<span class="string">"warn: Failed to find available GPUs %d for the pod %s in the namespace %s"</span>,</span><br><span class="line">				reqGPU,</span><br><span class="line">				pod.Name,</span><br><span class="line">				pod.Namespace)</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> candidateDevID, found</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="在Node上运行Deployment"><a href="#在Node上运行Deployment" class="headerlink" title="在Node上运行Deployment"></a>在Node上运行Deployment</h4><p>接下来由Kubelet在创建container前调用 <code>GPU Share Device Plugin</code> 的 <code>Allocate</code> 函数，参数是申请的GPU Memory的数量。</p>
<p>Pod运行成功后，执行 <code>kubectl get pod</code> 可以看到：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">annotations:</span></span><br><span class="line">    <span class="attr">ALIYUN_COM_GPU_MEM_ASSIGNED:</span> <span class="string">"true"</span></span><br><span class="line">    <span class="attr">ALIYUN_COM_GPU_MEM_ASSUME_TIME:</span> <span class="string">"1606125285243248618"</span></span><br><span class="line">    <span class="attr">ALIYUN_COM_GPU_MEM_DEV:</span> <span class="string">"22"</span></span><br><span class="line">    <span class="attr">ALIYUN_COM_GPU_MEM_IDX:</span> <span class="string">"0"</span></span><br><span class="line">    <span class="attr">ALIYUN_COM_GPU_MEM_POD:</span> <span class="string">"3"</span></span><br><span class="line">  <span class="string">...</span></span><br></pre></td></tr></table></figure>
<ul>
<li><p>Device Plugin 从 k8s apiserver 拿到所有Pending的Pod中属于GPU Share的Pod，并且按照 AssumedTimestamp排序</p>
</li>
<li><p>选择符合Allocation传入的GPU Memory的Pod，如果有多个，选择最早的那个Pod</p>
</li>
<li><p>标记 <code>ALIYUN_COM_GPU_MEM_ASSIGNED</code> 为 True</p>
</li>
<li><p>把 DeviceID 作为下NVIDIA_VISIBLE_DEVICES环境变量告诉 Nvidia Docker2，并且创建容器</p>
</li>
</ul>
<p><img alt data-src="https://github.com/AliyunContainerService/gpushare-scheduler-extender/raw/master/docs/designs/sequence.jpg"></p>
<blockquote>
<p><strong>这里问题是device plugin的allocate接口参数是什么，是否包含pod信息，是否包含pod annotation？</strong></p>
</blockquote>
<p>查看 Device Plugin 的代码，这一个申请的GPU Memory的数量让我很疑惑，为何要这么算？</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> _, req := <span class="keyword">range</span> reqs.ContainerRequests &#123;</span><br><span class="line">	podReqGPU += <span class="keyword">uint</span>(<span class="built_in">len</span>(req.DevicesIDs))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>继续看 <code>Device Plugin</code> 的 <code>DeviceIDs</code> 是如何生成的。这里调用了 <code>nvml library</code> 可以探测到本Node上拥有的GPU有多少个，每个显存是多少。接下来 <code>Device Plugin</code> 会创建一系列的 <code>FakeDeviceID</code>，并将这个DeviceIDs返回给 Kubelet，这就解释了为什么要通过上面的方法计算申请的 GPU Memory，这里的Memory以MiB为单位。</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">getDevices</span><span class="params">()</span> <span class="params">([]*pluginapi.Device, <span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">uint</span>)</span></span> &#123;</span><br><span class="line">	n, err := nvml.GetDeviceCount()</span><br><span class="line">	check(err)</span><br><span class="line"></span><br><span class="line">	<span class="keyword">var</span> devs []*pluginapi.Device</span><br><span class="line">	realDevNames := <span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">uint</span>&#123;&#125;</span><br><span class="line">	<span class="keyword">for</span> i := <span class="keyword">uint</span>(<span class="number">0</span>); i &lt; n; i++ &#123;</span><br><span class="line">		d, err := nvml.NewDevice(i)</span><br><span class="line">		check(err)</span><br><span class="line">		<span class="comment">// realDevNames = append(realDevNames, d.UUID)</span></span><br><span class="line">		<span class="keyword">var</span> id <span class="keyword">uint</span></span><br><span class="line">		log.Infof(<span class="string">"Deivce %s's Path is %s"</span>, d.UUID, d.Path)</span><br><span class="line">		_, err = fmt.Sscanf(d.Path, <span class="string">"/dev/nvidia%d"</span>, &amp;id)</span><br><span class="line">		check(err)</span><br><span class="line">		realDevNames[d.UUID] = id</span><br><span class="line">		<span class="comment">// var KiB uint64 = 1024</span></span><br><span class="line">		log.Infof(<span class="string">"# device Memory: %d"</span>, <span class="keyword">uint</span>(*d.Memory))</span><br><span class="line">		<span class="keyword">if</span> getGPUMemory() == <span class="keyword">uint</span>(<span class="number">0</span>) &#123;</span><br><span class="line">			setGPUMemory(<span class="keyword">uint</span>(*d.Memory))</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">for</span> j := <span class="keyword">uint</span>(<span class="number">0</span>); j &lt; getGPUMemory(); j++ &#123;</span><br><span class="line">			fakeID := generateFakeDeviceID(d.UUID, j)</span><br><span class="line">			<span class="keyword">if</span> j == <span class="number">0</span> &#123;</span><br><span class="line">				log.Infoln(<span class="string">"# Add first device ID: "</span> + fakeID)</span><br><span class="line">			&#125;</span><br><span class="line">			<span class="keyword">if</span> j == getGPUMemory()<span class="number">-1</span> &#123;</span><br><span class="line">				log.Infoln(<span class="string">"# Add last device ID: "</span> + fakeID)</span><br><span class="line">			&#125;</span><br><span class="line">			devs = <span class="built_in">append</span>(devs, &amp;pluginapi.Device&#123;</span><br><span class="line">				ID:     fakeID,</span><br><span class="line">				Health: pluginapi.Healthy,</span><br><span class="line">			&#125;)</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> devs, realDevNames</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>我们看一下 <code>Device Plugin</code> 是如何找到对应的Pod的，可以看到一旦碰到有Pod申请的GPU显存与Kubelet传入的显存大小一致，那么则找到对应的Pod了。</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">pods, err := getCandidatePods()</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">   log.Infof(<span class="string">"invalid allocation requst: Failed to find candidate pods due to %v"</span>, err)</span><br><span class="line">   <span class="keyword">return</span> buildErrResponse(reqs, podReqGPU), <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> _, pod := <span class="keyword">range</span> pods &#123;</span><br><span class="line">   <span class="keyword">if</span> getGPUMemoryFromPodResource(pod) == podReqGPU &#123;</span><br><span class="line">      log.Infof(<span class="string">"Found Assumed GPU shared Pod %s in ns %s with GPU Memory %d"</span>,</span><br><span class="line">         pod.Name,</span><br><span class="line">         pod.Namespace,</span><br><span class="line">         podReqGPU)</span><br><span class="line">      assumePod = pod</span><br><span class="line">      found = <span class="literal">true</span></span><br><span class="line">      <span class="keyword">break</span></span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里的 <code>getCandidatePods</code>就是List所有Pending的Pod中 Assume Memory的，并且按照时间排序：</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// pick up the gpushare pod with assigned status is false, and</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">getCandidatePods</span><span class="params">()</span> <span class="params">([]*v1.Pod, error)</span></span> &#123;</span><br><span class="line">	candidatePods := []*v1.Pod&#123;&#125;</span><br><span class="line">	allPods, err := getPendingPodsInNode()</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> candidatePods, err</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">for</span> _, pod := <span class="keyword">range</span> allPods &#123;</span><br><span class="line">		current := pod</span><br><span class="line">		<span class="keyword">if</span> isGPUMemoryAssumedPod(&amp;current) &#123;</span><br><span class="line">			candidatePods = <span class="built_in">append</span>(candidatePods, &amp;current)</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">  ...</span><br><span class="line">	<span class="keyword">return</span> makePodOrderdByAge(candidatePods), <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="腾讯GPUManager"><a href="#腾讯GPUManager" class="headerlink" title="腾讯GPUManager"></a>腾讯GPUManager</h2><p>GPU Manager 提供一个 All-in-One 的 GPU 管理器，基于 Kubernetes DevicePlugin 插件系统实现，该管理器提供了分配并共享 GPU、GPU 指标查询、容器运行前的 GPU 相关设备准备等功能，支持用户在 Kubernetes 集群中使用 GPU 设备。</p>
<ul>
<li><strong>拓扑分配</strong>：提供基于 GPU 拓扑分配功能，当用户分配超过1张 GPU 卡的应用，可以选择拓扑连接最快的方式分配 GPU 设备。</li>
<li><strong>GPU 共享</strong>：允许用户提交小于1张卡资源的任务，并提供 QoS 保证。</li>
<li><strong>应用 GPU 指标的查询</strong>：用户可以访问主机端口（默认为 5678）的 <code>/metrics</code> 路径，可以为 Prometheus 提供 GPU 指标的收集功能，访问 <code>/usage</code> 路径可以进行可读性的容器状况查询。</li>
</ul>
<h3 id="架构设计-1"><a href="#架构设计-1" class="headerlink" title="架构设计"></a>架构设计</h3><h3 id="核心组件-1"><a href="#核心组件-1" class="headerlink" title="核心组件"></a>核心组件</h3><p>GPUManager 主要由两个部分组成：</p>
<ul>
<li><code>gpu-quota-admission</code> ：调度器插件，提供GPU的调度相关的增强功能</li>
<li><code>gpu-manager-daemonset</code> ： DevicePlugin 插件，提供容器使用GPU相关的功能</li>
</ul>
<p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-11-19_gpu-manager.png"></p>
<h4 id="gpu-quota-admission"><a href="#gpu-quota-admission" class="headerlink" title="gpu-quota-admission"></a>gpu-quota-admission</h4><p>该组件为调度器插件, 用于提供GPU的调度相关的增强功能. 增强功能包含:</p>
<ul>
<li>根据用户卡型号以及资源池的quota配置提供调度准入功能</li>
</ul>
<p>用户可以在原来的quota维度下划分更细致的调度准入维度, 例如用户有10张卡的配额, 那么在此基础上可以更细致的划分为P系列3张卡, M系列5张卡, K系列2张卡。通过用户配置一个Configmap, <code>card quota controller</code>就可以计算出每个namespace下使用了各种型号的GPU设备的数量, 在调度的时候就可以实现按照资源池及GPU型号进行策略调度. 例如</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"A"</span>: &#123;</span><br><span class="line">    <span class="attr">"pool"</span>: [</span><br><span class="line">      <span class="string">"public"</span></span><br><span class="line">    ],</span><br><span class="line">    <span class="attr">"quota"</span>: &#123;</span><br><span class="line">      <span class="attr">"M40"</span>: <span class="number">2</span>,</span><br><span class="line">      <span class="attr">"P100"</span>: <span class="number">3</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"B"</span>: &#123;</span><br><span class="line">    <span class="attr">"pool"</span>: [</span><br><span class="line">      <span class="string">"wx"</span></span><br><span class="line">    ],</span><br><span class="line">    <span class="attr">"quota"</span>: &#123;</span><br><span class="line">      <span class="attr">"M40"</span>: <span class="number">8</span>,</span><br><span class="line">      <span class="attr">"P100"</span>: <span class="number">2</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>GPU共享的调度</li>
</ul>
<p>默认的Kubernetes的GPU使用最小粒度为1张卡, 配合GPU Manager组件, 可以为集群提供更小粒度的GPU资源使用调度策略。为此我们增加了GPU predicate controller来尽可能的降低系统默认调度策略带来的碎片化问题。</p>
<p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-11-19_gpu-manager-predicate.png"></p>
<h4 id><a href="#" class="headerlink" title=" "></a> </h4><h4 id="gpu-manager-daemonset"><a href="#gpu-manager-daemonset" class="headerlink" title="gpu-manager-daemonset"></a>gpu-manager-daemonset</h4><p>该组件为DevicePlugin的一种GPU插件, 提供容器使用GPU相关的功能：</p>
<ul>
<li><p>拓扑感知分配</p>
<p>拓扑感知分配, 用于用户单机多卡时, 分配通信代价最小的GPU卡, 避免由于通信开销导致的计算能力下降</p>
</li>
<li><p>多容器GPU共享</p>
<p>该功能用于提供多个容器在同一张卡运行的能力, 同时保证各个容器的QoS, 并且支持使用率的动态调整</p>
</li>
<li><p>容器内指标查询与收集</p>
<p>该功能提供Prometheus的GPU相关指标(利用率,显存使用大小), 方便用户指标展示以及使用基于指标的自动扩缩容功能</p>
</li>
<li><p>GPU相关的特殊设备使用(RDMA等)</p>
<p>该功能可以提供GPU容器使用RDMA等设备的挂载</p>
</li>
</ul>
<p>GPUManager使用了原生的<code>runc</code>，但是Nvidia使用了自己的<code>runc</code>。</p>
<h5 id="topology-awareness-allocator"><a href="#topology-awareness-allocator" class="headerlink" title="topology awareness allocator"></a>topology awareness allocator</h5><p>该模块提供基于GPU拓扑分配的一个功能, 因为GPU设备的特殊性, GPU之间的通信需要经过不同的switch或者socket-level link。不同的GPU选择会对单机多卡程序peer to peer的数据拷贝带来延迟, <code>Topology awareness allocator</code>通过2种不同的分配算法来尽可能的减少这种延迟。</p>
<h5 id="visualization-manager"><a href="#visualization-manager" class="headerlink" title="visualization manager"></a>visualization manager</h5><p>GaiaStack 的 GPU 共享提供的是不同于NVIDIA的vGPU(高隔离)和MPS(低隔离)的一种设计, 并且本身提供一个QoS保障, 因此需要一个特殊的管理器来管理使用共享功能的GPU容器。</p>
<h5 id="driver-volume-manager"><a href="#driver-volume-manager" class="headerlink" title="driver volume manager"></a>driver volume manager</h5><p>该管理器用来提供GPU容器运行时需要的底层CUDA Driver, 这个管理器我们借鉴的是<code>nvidia-docker</code> 1.0中的volume的设计. Kubernetes DevicePlugin的接口说明允许给容器增加可挂载的Volume和环境变量, 因此管理器通过在Allocate阶段给GPU容器配置一个volume挂载点来提供CUDA Driver以及配置环境变量LD_LIBRARY_PATH告诉应用哪里去search CUDA Driver</p>
<h4 id="vCUDA-controller"><a href="#vCUDA-controller" class="headerlink" title="vCUDA controller"></a>vCUDA controller</h4><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul>
<li><a href="https://github.com/AliyunContainerService/gpushare-scheduler-extender/blob/master/docs/designs/designs.md" target="_blank" rel="external nofollow noopener noreferrer">阿里GPUShare设计文档</a></li>
<li><a href="https://www.alibabacloud.com/help/zh/doc-detail/163994.htm" target="_blank" rel="external nofollow noopener noreferrer">阿里共享调度</a></li>
<li><a href="http://km.oa.com/group/597/articles/show/388457" target="_blank" rel="external nofollow noopener noreferrer">Gaia GPUManager介绍</a></li>
</ul>

    </div>

    
    
    
      
  <div class="popular-posts-header">相关文章推荐</div>
  <ul class="popular-posts">
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="/posts/3f069334/" rel="bookmark">【Kubernetes】Device Plugin</a></div>
    </li>
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="/posts/574111db/" rel="bookmark">【Kubernetes】在Docker中使用GPU</a></div>
    </li>
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="/posts/d8b96fe4/" rel="bookmark">【Kubernetes】开篇</a></div>
    </li>
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="/posts/83a17de0/" rel="bookmark">【Kubernetes】Scheduling Framework</a></div>
    </li>
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="/posts/fb705539/" rel="bookmark">【Kubernetes】Kubelet</a></div>
    </li>
  </ul>

      
        <div class="reward-container">
  <div></div>
  <button disable="enable" onclick="var qr = document.getElementById(&quot;qr&quot;); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    打赏
  </button>
  <div id="qr" style="display: none;">
      
      <div style="display: inline-block;">
        <img src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/theme/wechatpay.png" alt="Houmin 微信支付">
        <p>微信支付</p>
      </div>
      
      <div style="display: inline-block;">
        <img src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/theme/alipay.jpg" alt="Houmin 支付宝">
        <p>支付宝</p>
      </div>

  </div>
</div>

        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>Houmin
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="http://houmin.cc/posts/cf391335/" title="【Kubernetes】GPU 共享">http://houmin.cc/posts/cf391335/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/null" rel="external nofollow noopener noreferrer" target="_blank"><i class="fa fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>


      <footer class="post-footer">
          
          <div class="post-tags">
              <a href="/tags/k8s/" rel="tag"><i class="fa fa-tag"></i> k8s</a>
              <a href="/tags/device-plugin/" rel="tag"><i class="fa fa-tag"></i> device plugin</a>
              <a href="/tags/GPU/" rel="tag"><i class="fa fa-tag"></i> GPU</a>
              <a href="/tags/%E8%B5%84%E6%BA%90%E9%9A%94%E7%A6%BB/" rel="tag"><i class="fa fa-tag"></i> 资源隔离</a>
              <a href="/tags/scheduler-extender/" rel="tag"><i class="fa fa-tag"></i> scheduler extender</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-next post-nav-item">
                <a href="/posts/574111db/" rel="next" title="【Kubernetes】在Docker中使用GPU">
                  <i class="fa fa-chevron-left"></i> 【Kubernetes】在Docker中使用GPU
                </a>
            </div>

            <span class="post-nav-divider"></span>

            <div class="post-nav-prev post-nav-item">
            </div>
          </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          
    <div class="comments" id="comments"></div>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#阿里GPUShare"><span class="nav-number">1.</span> <span class="nav-text">阿里GPUShare</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#架构设计"><span class="nav-number">1.1.</span> <span class="nav-text">架构设计</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#设计原则"><span class="nav-number">1.1.1.</span> <span class="nav-text">设计原则</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#核心组件"><span class="nav-number">1.1.2.</span> <span class="nav-text">核心组件</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#具体过程"><span class="nav-number">1.2.</span> <span class="nav-text">具体过程</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#设备资源报告"><span class="nav-number">1.2.1.</span> <span class="nav-text">设备资源报告</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#调度"><span class="nav-number">1.2.2.</span> <span class="nav-text">调度</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Filter"><span class="nav-number">1.2.2.1.</span> <span class="nav-text">Filter</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Bind"><span class="nav-number">1.2.2.2.</span> <span class="nav-text">Bind</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#在Node上运行Deployment"><span class="nav-number">1.2.3.</span> <span class="nav-text">在Node上运行Deployment</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#腾讯GPUManager"><span class="nav-number">2.</span> <span class="nav-text">腾讯GPUManager</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#架构设计-1"><span class="nav-number">2.1.</span> <span class="nav-text">架构设计</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#核心组件-1"><span class="nav-number">2.2.</span> <span class="nav-text">核心组件</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#gpu-quota-admission"><span class="nav-number">2.2.1.</span> <span class="nav-text">gpu-quota-admission</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#null"><span class="nav-number">2.2.2.</span> <span class="nav-text"> </span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#gpu-manager-daemonset"><span class="nav-number">2.2.3.</span> <span class="nav-text">gpu-manager-daemonset</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#topology-awareness-allocator"><span class="nav-number">2.2.3.1.</span> <span class="nav-text">topology awareness allocator</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#visualization-manager"><span class="nav-number">2.2.3.2.</span> <span class="nav-text">visualization manager</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#driver-volume-manager"><span class="nav-number">2.2.3.3.</span> <span class="nav-text">driver volume manager</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#vCUDA-controller"><span class="nav-number">2.2.4.</span> <span class="nav-text">vCUDA controller</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#参考资料"><span class="nav-number">3.</span> <span class="nav-text">参考资料</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <img class="site-author-image" itemprop="image" alt="Houmin" src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/theme/avatar.png">
  <p class="site-author-name" itemprop="name">Houmin</p>
  <div class="site-description" itemprop="description">丈夫拥书万卷，何假南面百城</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">114</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
        <span class="site-state-item-count">9</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">175</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="feed-link motion-element">
    <a href="/atom.xml" rel="alternate">
      <i class="fa fa-rss"></i>RSS
    </a>
  </div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/SimpCosm" title="GitHub &amp;rarr; https:&#x2F;&#x2F;github.com&#x2F;SimpCosm" rel="external nofollow noopener noreferrer" target="_blank"><i class="fa fa-fw fa-github"></i></a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:weihoumin@gmail.com" title="E-Mail &amp;rarr; mailto:weihoumin@gmail.com" rel="external nofollow noopener noreferrer" target="_blank"><i class="fa fa-fw fa-envelope"></i></a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        
  <div class="hitokoto">
    <!-- hitokoto -->
    <div id="hito-expression">:D 获取中...</div>

    <script src="https://cdn.jsdelivr.net/npm/bluebird@3/js/browser/bluebird.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/whatwg-fetch@2.0.3/fetch.min.js"></script>
    <script>
      fetch('https://v1.hitokoto.cn')
        .then(function (res){
          return res.json();
        })
        .then(function (data) {
          var hitokoto = document.getElementById('hito-expression');
          hitokoto.innerText = data.hitokoto + '——【' + data.from + '】';
        })
        .catch(function (err) {
          console.error(err);
        })
    </script>
  </div>

<div class="copyright">
  
  &copy; 2019 – 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heartbeat"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Houmin</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
      <span class="post-meta-item-text">站点总字数：</span>
    <span title="站点总字数">1.1m</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span class="post-meta-item-text">站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">32:38</span>
</div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>












        
      </div>
    </footer>
  </div>



  
  <script src="//cdn.jsdelivr.net/npm/animejs@3.1.0/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>
  <script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/lozad@1/dist/lozad.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script>
<script src="/js/schemes/muse.js"></script>
<script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script>



  




  <script src="/js/local-search.js"></script>








<script>
if (document.querySelectorAll('div.pdf').length) {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/pdfobject@2/pdfobject.min.js', () => {
    document.querySelectorAll('div.pdf').forEach(element => {
      PDFObject.embed(element.getAttribute('target'), element, {
        pdfOpenParams: {
          navpanes: 0,
          toolbar: 0,
          statusbar: 0,
          pagemode: 'thumbs',
          view: 'FitH'
        },
        PDFJS_URL: '/lib/pdf/web/viewer.html',
        height: element.getAttribute('height') || '800px'
      });
    });
  }, window.PDFObject);
}
</script>


<script>
if (document.querySelectorAll('pre.mermaid').length) {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mermaid@8/dist/mermaid.min.js', () => {
    mermaid.initialize({
      theme: 'forest',
      logLevel: 3,
      flowchart: { curve: 'linear' },
      gantt: { axisFormat: '%m/%d/%Y' },
      sequence: { actorMargin: 50 }
    });
  }, window.mermaid);
}
</script>



  

  

  


<script>
NexT.utils.getScript('//cdn.jsdelivr.net/npm/valine@1/dist/Valine.min.js', () => {
  var GUEST = ['nick', 'mail', 'link'];
  var guest = 'nick,mail,link';
  guest = guest.split(',').filter(item => {
    return GUEST.includes(item);
  });
  new Valine({
    el: '#comments',
    verify: false,
    notify: false,
    appId: 'iEBFuhVyk4tuhVYctQ265uid-gzGzoHsz',
    appKey: 'KGjOktrtgSEWK1v9DYA3T3Az',
    placeholder: "Just go go",
    avatar: 'retro',
    meta: guest,
    pageSize: '10' || 10,
    visitor: false,
    lang: 'zh-cn' || 'zh-cn',
    path: location.pathname,
    recordIP: true,
    serverURLs: ''
  });
}, window.Valine);
</script>

</body>
</html>
