<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Houmin</title>
  
  <subtitle>Yesterday You Said Tomorrow</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://houmin.cc/"/>
  <updated>2021-01-26T09:23:38.887Z</updated>
  <id>http://houmin.cc/</id>
  
  <author>
    <name>Houmin</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Systemd 新一代 Init 进程</title>
    <link href="http://houmin.cc/posts/fee24f7a/"/>
    <id>http://houmin.cc/posts/fee24f7a/</id>
    <published>2021-01-26T08:08:13.000Z</published>
    <updated>2021-01-26T09:23:38.887Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>在 <a href="https://houmin.cc/posts/e27e5d75/">Linux 启动过程</a> 中我们介绍了 Linux 启动中关键的一步：Init 进程启动系统。作为操作系统的 1 号进程，Init 是一个由内核启动的用户级进程，完成系统引导。早期 Linux 系统的 Init 进程是著名的 <a href="https://wiki.archlinux.org/index.php/SysVinit" target="_blank" rel="external nofollow noopener noreferrer"> <code>SysV Init</code></a> ，然而由于 SysVInit 进程是串行启动用户程序，启动时间长，而且启动事件复杂，已经慢慢开始退出历史舞台。目前广泛被各大 Linux 发行版采用的 Init 进程是 Systemd。Systemd 作为系统启动和管理的一整套解决方案，取代了 <code>initd</code>，成为系统的 1 号进程，其他的进程都是其子进程，本文将介绍 Systemd 的设计与使用。</p><a id="more"></a><h2 id="系统管理"><a href="#系统管理" class="headerlink" title="系统管理"></a>系统管理</h2><p>Systemd 并不是一个命令，而是一组命令，涉及到系统管理的方方面面。</p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2021-01-26_systemd.png"></p><h3 id="systemctl"><a href="#systemctl" class="headerlink" title="systemctl"></a>systemctl</h3><p><code>systemctl</code>是 Systemd 的主命令，用于管理系统。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 重启系统</span></span><br><span class="line">$ sudo systemctl reboot</span><br><span class="line"></span><br><span class="line"><span class="comment"># 关闭系统，切断电源</span></span><br><span class="line">$ sudo systemctl poweroff</span><br><span class="line"></span><br><span class="line"><span class="comment"># CPU停止工作</span></span><br><span class="line">$ sudo systemctl halt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 暂停系统</span></span><br><span class="line">$ sudo systemctl <span class="built_in">suspend</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 让系统进入冬眠状态</span></span><br><span class="line">$ sudo systemctl hibernate</span><br><span class="line"></span><br><span class="line"><span class="comment"># 让系统进入交互式休眠状态</span></span><br><span class="line">$ sudo systemctl hybrid-sleep</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动进入救援状态（单用户状态）</span></span><br><span class="line">$ sudo systemctl rescue</span><br></pre></td></tr></table></figure><h3 id="systemd-analyze"><a href="#systemd-analyze" class="headerlink" title="systemd-analyze"></a>systemd-analyze</h3><p><code>systemd-analyze</code>命令用于查看启动耗时。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看启动耗时</span></span><br><span class="line">$ systemd-analyze                                                                                       </span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看每个服务的启动耗时</span></span><br><span class="line">$ systemd-analyze blame</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示瀑布状的启动过程流</span></span><br><span class="line">$ systemd-analyze critical-chain</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示指定服务的启动流</span></span><br><span class="line">$ systemd-analyze critical-chain atd.service</span><br></pre></td></tr></table></figure><h3 id="hostnamectl"><a href="#hostnamectl" class="headerlink" title="hostnamectl"></a>hostnamectl</h3><p><code>hostnamectl</code>命令用于查看当前主机的信息。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 显示当前主机的信息</span></span><br><span class="line">$ hostnamectl</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置主机名。</span></span><br><span class="line">$ sudo hostnamectl <span class="built_in">set</span>-hostname rhel7</span><br></pre></td></tr></table></figure><h3 id="localectl"><a href="#localectl" class="headerlink" title="localectl"></a>localectl</h3><p><code>localectl</code>命令用于查看本地化设置。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看本地化设置</span></span><br><span class="line">$ localectl</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置本地化参数。</span></span><br><span class="line">$ sudo localectl <span class="built_in">set</span>-locale LANG=en_GB.utf8</span><br><span class="line">$ sudo localectl <span class="built_in">set</span>-keymap en_GB</span><br></pre></td></tr></table></figure><h3 id="timedatectl"><a href="#timedatectl" class="headerlink" title="timedatectl"></a>timedatectl</h3><p><code>timedatectl</code>命令用于查看当前时区设置。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看当前时区设置</span></span><br><span class="line">$ timedatectl</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示所有可用的时区</span></span><br><span class="line">$ timedatectl list-timezones                                                                                   </span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置当前时区</span></span><br><span class="line">$ sudo timedatectl <span class="built_in">set</span>-timezone America/New_York</span><br><span class="line">$ sudo timedatectl <span class="built_in">set</span>-time YYYY-MM-DD</span><br><span class="line">$ sudo timedatectl <span class="built_in">set</span>-time HH:MM:SS</span><br></pre></td></tr></table></figure><h3 id="loginctl"><a href="#loginctl" class="headerlink" title="loginctl"></a>loginctl</h3><p><code>loginctl</code>命令用于查看当前登录的用户。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 列出当前session</span></span><br><span class="line">$ loginctl list-sessions</span><br><span class="line"></span><br><span class="line"><span class="comment"># 列出当前登录用户</span></span><br><span class="line">$ loginctl list-users</span><br><span class="line"></span><br><span class="line"><span class="comment"># 列出显示指定用户的信息</span></span><br><span class="line">$ loginctl show-user ruanyf</span><br></pre></td></tr></table></figure><h2 id="关键概念"><a href="#关键概念" class="headerlink" title="关键概念"></a>关键概念</h2><h3 id="Unit"><a href="#Unit" class="headerlink" title="Unit"></a>Unit</h3><p>Systemd 可以管理所有系统资源，不同的资源统称为 Unit（单位），Unit 一共分成12种。</p><ul><li>Service unit：系统服务</li><li>Target unit：多个 Unit 构成的一个组</li><li>Device Unit：硬件设备</li><li>Mount Unit：文件系统的挂载点</li><li>Automount Unit：自动挂载点</li><li>Path Unit：文件或路径</li><li>Scope Unit：不是由 Systemd 启动的外部进程</li><li>Slice Unit：进程组</li><li>Snapshot Unit：Systemd 快照，可以切回某个快照</li><li>Socket Unit：进程间通信的 socket</li><li>Swap Unit：swap 文件</li><li>Timer Unit：定时器</li></ul><p><code>systemctl list-units</code>命令可以查看当前系统的所有 Unit 。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 列出正在运行的 Unit</span></span><br><span class="line">$ systemctl list-units</span><br><span class="line"></span><br><span class="line"><span class="comment"># 列出所有Unit，包括没有找到配置文件的或者启动失败的</span></span><br><span class="line">$ systemctl list-units --all</span><br><span class="line"></span><br><span class="line"><span class="comment"># 列出所有没有运行的 Unit</span></span><br><span class="line">$ systemctl list-units --all --state=inactive</span><br><span class="line"></span><br><span class="line"><span class="comment"># 列出所有加载失败的 Unit</span></span><br><span class="line">$ systemctl list-units --failed</span><br><span class="line"></span><br><span class="line"><span class="comment"># 列出所有正在运行的、类型为 service 的 Unit</span></span><br><span class="line">$ systemctl list-units --<span class="built_in">type</span>=service</span><br></pre></td></tr></table></figure><h4 id="Unit-状态"><a href="#Unit-状态" class="headerlink" title="Unit 状态"></a>Unit 状态</h4><p><code>systemctl status</code>命令用于查看系统状态和单个 Unit 的状态。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 显示系统状态</span></span><br><span class="line">$ systemctl status</span><br><span class="line">● VM-0-29-tlinux</span><br><span class="line">    State: running</span><br><span class="line">     Jobs: 0 queued</span><br><span class="line">   Failed: 0 units</span><br><span class="line">    Since: Tue 2021-01-26 14:40:53 CST; 2h 14min ago</span><br><span class="line">   CGroup: /</span><br><span class="line">           ├─1 /usr/lib/systemd/systemd --switched-root --system --deserialize 22</span><br><span class="line">           ├─kubepods</span><br><span class="line">           │ ├─burstable</span><br><span class="line">           │ │ └─pod03d6d352-2913-4785-a12e-32e3d9ce400b</span><br><span class="line">           │ │   ├─ccd2fce847cfde2f71388f857443b6566e16f1cff6579242f3fa8139c0f35ce3</span><br><span class="line">           │ │   │ └─11624 /pause</span><br><span class="line">           │ │   └─083081f9958f1ad85cdab4e7bd1fbe7e71e98a08acaf2899b3c544d11cd2d469</span><br><span class="line">           │ │     └─11858 /coredns -conf /etc/coredns/Corefile</span><br><span class="line">           │ └─besteffort</span><br><span class="line">           │   ├─podbbc08e2b-14f4-4be9-969f-10bde919ff72</span><br><span class="line">           │   │ ├─cd8f27bc035ebdefdcffd0c8da2009e7d1fd38d9539122371e5faf80982a51a8</span><br><span class="line">           │   │ │ └─10744 /pause</span><br><span class="line">           │   │ └─52aa86bce27df9cc665819b0d65d667a8cbc7ffb4dd3dddc24d7cc2a361dad30</span><br><span class="line">           │   │   └─11246 kube-proxy --kubeconfig=/var/lib</span><br><span class="line">           ...</span><br><span class="line">           </span><br><span class="line"><span class="comment"># 显示单个 Unit 的状态</span></span><br><span class="line">$ systemctl status kubelet.service</span><br><span class="line">● kubelet.service - kubelet</span><br><span class="line">   Loaded: loaded (/usr/lib/systemd/system/kubelet.service; enabled; vendor preset: disabled)</span><br><span class="line">   Active: active (running) since Tue 2021-01-26 14:45:12 CST; 2h 9min ago</span><br><span class="line"> Main PID: 10446 (kubelet)</span><br><span class="line">    Tasks: 13</span><br><span class="line">   Memory: 97.8M</span><br><span class="line">   CGroup: /system.slice/kubelet.service</span><br><span class="line">           └─10446 /usr/bin/kubelet --serialize-image-pulls=<span class="literal">false</span> --register-schedulable=<span class="literal">true</span> --v=2 --cloud-provider=qcloud --fail-swap-on=<span class="literal">false</span> --authorization-mode=W...</span><br><span class="line"></span><br><span class="line">Jan 26 16:30:14 VM-0-29-tlinux kubelet[10446]: I0126 16:30:14.441801   10446 client.go:135] MetaDataClient send resource public-ipv4  url http://metadata.ten...ublic-ipv4</span><br><span class="line">Jan 26 16:30:14 VM-0-29-tlinux kubelet[10446]: I0126 16:30:14.469511   10446 client.go:147] MetaDataClient resource public-ipv4 StatusCode 200</span><br><span class="line">Jan 26 16:30:14 VM-0-29-tlinux kubelet[10446]: I0126 16:30:14.470560   10446 client.go:159] MetaDataClient resource public-ipv4 send data 154.8.149.172</span><br><span class="line">Jan 26 16:35:14 VM-0-29-tlinux kubelet[10446]: I0126 16:35:14.356159   10446 container_manager_linux.go:470] [ContainerManager]: Discovered runtime cgroups n...rd.service</span><br><span class="line">Jan 26 16:40:14 VM-0-29-tlinux kubelet[10446]: I0126 16:40:14.357373   10446 container_manager_linux.go:470] [ContainerManager]: Discovered runtime cgroups n...rd.service</span><br><span class="line">Jan 26 16:45:14 VM-0-29-tlinux kubelet[10446]: I0126 16:45:14.358655   10446 container_manager_linux.go:470] [ContainerManager]: Discovered runtime cgroups n...rd.service</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示远程主机的某个 Unit 的状态</span></span><br><span class="line">$ systemctl -H root@rhel7.example.com status httpd.service</span><br></pre></td></tr></table></figure><p>除了<code>status</code>命令，<code>systemctl</code>还提供了三个查询状态的简单方法，主要供脚本内部的判断语句使用。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 显示某个 Unit 是否正在运行</span></span><br><span class="line">$ systemctl is-active application.service</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示某个 Unit 是否处于启动失败状态</span></span><br><span class="line">$ systemctl is-failed application.service</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示某个 Unit 服务是否建立了启动链接</span></span><br><span class="line">$ systemctl is-enabled application.service</span><br></pre></td></tr></table></figure><h4 id="Unit-管理"><a href="#Unit-管理" class="headerlink" title="Unit 管理"></a>Unit 管理</h4><p>对于用户来说，最常用的是下面这些命令，用于启动和停止 Unit（主要是 service）。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 立即启动一个服务</span></span><br><span class="line">$ sudo systemctl start apache.service</span><br><span class="line"></span><br><span class="line"><span class="comment"># 立即停止一个服务</span></span><br><span class="line">$ sudo systemctl stop apache.service</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重启一个服务</span></span><br><span class="line">$ sudo systemctl restart apache.service</span><br><span class="line"></span><br><span class="line"><span class="comment"># 杀死一个服务的所有子进程</span></span><br><span class="line">$ sudo systemctl <span class="built_in">kill</span> apache.service</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重新加载一个服务的配置文件</span></span><br><span class="line">$ sudo systemctl reload apache.service</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重载所有修改过的配置文件</span></span><br><span class="line">$ sudo systemctl daemon-reload</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示某个 Unit 的所有底层参数</span></span><br><span class="line">$ systemctl show httpd.service</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示某个 Unit 的指定属性的值</span></span><br><span class="line">$ systemctl show -p CPUShares httpd.service</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置某个 Unit 的指定属性</span></span><br><span class="line">$ sudo systemctl <span class="built_in">set</span>-property httpd.service CPUShares=500</span><br></pre></td></tr></table></figure><h4 id="依赖关系"><a href="#依赖关系" class="headerlink" title="依赖关系"></a>依赖关系</h4><p>Unit 之间存在依赖关系：A 依赖于 B，就意味着 Systemd 在启动 A 的时候，同时会去启动 B。<code>systemctl list-dependencies</code>命令列出一个 Unit 的所有依赖。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">$ systemctl list-dependencies kubelet.service</span><br><span class="line">kubelet.service</span><br><span class="line">● ├─system.slice</span><br><span class="line">● └─basic.target</span><br><span class="line">●   ├─microcode.service</span><br><span class="line">●   ├─rhel-dmesg.service</span><br><span class="line">●   ├─selinux-policy-migrate-local-changes@targeted.service</span><br><span class="line">●   ├─paths.target</span><br><span class="line">●   ├─slices.target</span><br><span class="line">●   │ ├─-.slice</span><br><span class="line">●   │ └─system.slice</span><br><span class="line">●   ├─sockets.target</span><br><span class="line">●   │ ├─avahi-daemon.socket</span><br><span class="line">●   │ ├─dbus.socket</span><br><span class="line">●   │ ├─dm-event.socket</span><br><span class="line">●   │ ├─iscsid.socket</span><br><span class="line">●   │ ├─iscsiuio.socket</span><br><span class="line">●   │ ├─systemd-initctl.socket</span><br><span class="line">●   │ ├─systemd-journald.socket</span><br><span class="line">●   │ ├─systemd-shutdownd.socket</span><br><span class="line">●   │ ├─systemd-udevd-control.socket</span><br><span class="line">●   │ └─systemd-udevd-kernel.socket</span><br><span class="line">●   ├─sysinit.target</span><br><span class="line">●   │ ├─dev-hugepages.mount</span><br><span class="line">●   │ ├─dev-mqueue.mount</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>上面命令的输出结果之中，有些依赖是 Target 类型，默认不会展开显示。如果要展开 Target，就需要使用<code>--all</code>参数。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">$ systemctl list-dependencies --all kubelet.service</span><br><span class="line">kubelet.service</span><br><span class="line">● ├─system.slice</span><br><span class="line">● │ ├─-.slice</span><br><span class="line">● │ └─-.slice</span><br><span class="line">● └─basic.target</span><br><span class="line">●   ├─microcode.service</span><br><span class="line">●   │ ├─system.slice</span><br><span class="line">●   │ │ ├─-.slice</span><br><span class="line">●   │ │ └─-.slice</span><br><span class="line">  │   └─...</span><br><span class="line">●   ├─rhel-dmesg.service</span><br><span class="line">●   │ ├─system.slice</span><br><span class="line">●   │ │ ├─-.slice</span><br><span class="line">●   │ │ └─-.slice</span><br><span class="line">  │   └─...</span><br><span class="line">●   ├─selinux-policy-migrate-local-changes@targeted.service</span><br><span class="line">●   │ ├─system-selinux\x2dpolicy\x2dmigrate\x2dlocal\x2dchanges.slice</span><br><span class="line">●   │ │ └─system.slice</span><br><span class="line">●   │ │   ├─-.slice</span><br><span class="line">●   │ │   └─-.slice</span><br><span class="line">●   │ └─<span class="built_in">local</span>-fs.target</span><br><span class="line">...</span><br></pre></td></tr></table></figure><h3 id="Target"><a href="#Target" class="headerlink" title="Target"></a>Target</h3><p>启动计算机的时候，需要启动大量的 Unit。如果每一次启动，都要一一写明本次启动需要哪些 Unit，显然非常不方便，Systemd 的解决方案就是 Target。</p><p>简单说，Target 就是一个 Unit 组，包含许多相关的 Unit 。启动某个 Target 的时候，Systemd 就会启动里面所有的 Unit。从这个意义上说，Target 这个概念类似于 <code>状态点</code>，启动某个 Target 就好比启动到某种状态。传统的<code>init</code>启动模式里面，有 RunLevel 的概念，跟 Target 的作用很类似。不同的是，RunLevel 是互斥的，不可能多个 RunLevel 同时启动，但是多个 Target 可以同时启动。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看当前系统的所有 Target</span></span><br><span class="line">$ systemctl list-unit-files --<span class="built_in">type</span>=target</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看一个 Target 包含的所有 Unit</span></span><br><span class="line">$ systemctl list-dependencies multi-user.target</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看启动时的默认 Target</span></span><br><span class="line">$ systemctl get-default</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置启动时的默认 Target</span></span><br><span class="line">$ sudo systemctl <span class="built_in">set</span>-default multi-user.target</span><br><span class="line"></span><br><span class="line"><span class="comment"># 切换 Target 时，默认不关闭前一个 Target 启动的进程，</span></span><br><span class="line"><span class="comment"># systemctl isolate 命令改变这种行为，</span></span><br><span class="line"><span class="comment"># 关闭前一个 Target 里面所有不属于后一个 Target 的进程</span></span><br><span class="line">$ sudo systemctl isolate multi-user.target</span><br></pre></td></tr></table></figure><p>Target 与 传统 RunLevel 的对应关系如下。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Traditional runlevel      New target name     Symbolically linked to...</span><br><span class="line"></span><br><span class="line">Runlevel 0           |    runlevel0.target -poweroff.target</span><br><span class="line">Runlevel 1           |    runlevel1.target -rescue.target</span><br><span class="line">Runlevel 2           |    runlevel2.target -multi-user.target</span><br><span class="line">Runlevel 3           |    runlevel3.target -multi-user.target</span><br><span class="line">Runlevel 4           |    runlevel4.target -multi-user.target</span><br><span class="line">Runlevel 5           |    runlevel5.target -graphical.target</span><br><span class="line">Runlevel 6           |    runlevel6.target -reboot.target</span><br></pre></td></tr></table></figure><p>它与<code>init</code>进程的主要差别如下。</p><ul><li><strong>默认的 RunLevel</strong>（在<code>/etc/inittab</code>文件设置）现在被默认的 Target 取代，位置是<code>/etc/systemd/system/default.target</code>，通常符号链接到<code>graphical.target</code>（图形界面）或者<code>multi-user.target</code>（多用户命令行）。</li><li><strong>启动脚本的位置</strong>，以前是<code>/etc/init.d</code>目录，符号链接到不同的 RunLevel 目录 （比如<code>/etc/rc3.d</code>、<code>/etc/rc5.d</code>等），现在则存放在<code>/lib/systemd/system</code>和<code>/etc/systemd/system</code>目录。</li><li><strong>配置文件的位置</strong>，以前<code>init</code>进程的配置文件是<code>/etc/inittab</code>，各种服务的配置文件存放在<code>/etc/sysconfig</code>目录。现在的配置文件主要存放在<code>/lib/systemd</code>目录，在<code>/etc/systemd</code>目录里面的修改可以覆盖原始设置。</li></ul><h2 id="日志管理"><a href="#日志管理" class="headerlink" title="日志管理"></a>日志管理</h2><p>Systemd 统一管理所有 Unit 的启动日志。带来的好处就是，可以只用<code>journalctl</code>一个命令，查看所有日志（内核日志和应用日志）。日志的配置文件是<code>/etc/systemd/journald.conf</code>。</p><p><code>journalctl</code>功能强大，用法非常多。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看所有日志（默认情况下 ，只保存本次启动的日志）</span></span><br><span class="line">$ sudo journalctl</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看内核日志（不显示应用日志）</span></span><br><span class="line">$ sudo journalctl -k</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看系统本次启动的日志</span></span><br><span class="line">$ sudo journalctl -b</span><br><span class="line">$ sudo journalctl -b -0</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看上一次启动的日志（需更改设置）</span></span><br><span class="line">$ sudo journalctl -b -1</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看指定时间的日志</span></span><br><span class="line">$ sudo journalctl --since=<span class="string">"2012-10-30 18:17:16"</span></span><br><span class="line">$ sudo journalctl --since <span class="string">"20 min ago"</span></span><br><span class="line">$ sudo journalctl --since yesterday</span><br><span class="line">$ sudo journalctl --since <span class="string">"2015-01-10"</span> --until <span class="string">"2015-01-11 03:00"</span></span><br><span class="line">$ sudo journalctl --since 09:00 --until <span class="string">"1 hour ago"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示尾部的最新10行日志</span></span><br><span class="line">$ sudo journalctl -n</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示尾部指定行数的日志</span></span><br><span class="line">$ sudo journalctl -n 20</span><br><span class="line"></span><br><span class="line"><span class="comment"># 实时滚动显示最新日志</span></span><br><span class="line">$ sudo journalctl -f</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看指定服务的日志</span></span><br><span class="line">$ sudo journalctl /usr/lib/systemd/systemd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看指定进程的日志</span></span><br><span class="line">$ sudo journalctl _PID=1</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看某个路径的脚本的日志</span></span><br><span class="line">$ sudo journalctl /usr/bin/bash</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看指定用户的日志</span></span><br><span class="line">$ sudo journalctl _UID=33 --since today</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看某个 Unit 的日志</span></span><br><span class="line">$ sudo journalctl -u nginx.service</span><br><span class="line">$ sudo journalctl -u nginx.service --since today</span><br><span class="line"></span><br><span class="line"><span class="comment"># 实时滚动显示某个 Unit 的最新日志</span></span><br><span class="line">$ sudo journalctl -u nginx.service -f</span><br><span class="line"></span><br><span class="line"><span class="comment"># 合并显示多个 Unit 的日志</span></span><br><span class="line">$ journalctl -u nginx.service -u php-fpm.service --since today</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看指定优先级（及其以上级别）的日志，共有8级</span></span><br><span class="line"><span class="comment"># 0: emerg</span></span><br><span class="line"><span class="comment"># 1: alert</span></span><br><span class="line"><span class="comment"># 2: crit</span></span><br><span class="line"><span class="comment"># 3: err</span></span><br><span class="line"><span class="comment"># 4: warning</span></span><br><span class="line"><span class="comment"># 5: notice</span></span><br><span class="line"><span class="comment"># 6: info</span></span><br><span class="line"><span class="comment"># 7: debug</span></span><br><span class="line">$ sudo journalctl -p err -b</span><br><span class="line"></span><br><span class="line"><span class="comment"># 日志默认分页输出，--no-pager 改为正常的标准输出</span></span><br><span class="line">$ sudo journalctl --no-pager</span><br><span class="line"></span><br><span class="line"><span class="comment"># 以 JSON 格式（单行）输出</span></span><br><span class="line">$ sudo journalctl -b -u nginx.service -o json</span><br><span class="line"></span><br><span class="line"><span class="comment"># 以 JSON 格式（多行）输出，可读性更好</span></span><br><span class="line">$ sudo journalctl -b -u nginx.serviceqq</span><br><span class="line"> -o json-pretty</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示日志占据的硬盘空间</span></span><br><span class="line">$ sudo journalctl --disk-usage</span><br><span class="line"></span><br><span class="line"><span class="comment"># 指定日志文件占据的最大空间</span></span><br><span class="line">$ sudo journalctl --vacuum-size=1G</span><br><span class="line"></span><br><span class="line"><span class="comment"># 指定日志文件保存多久</span></span><br><span class="line">$ sudo journalctl --vacuum-time=1years</span><br></pre></td></tr></table></figure><h2 id="配置管理"><a href="#配置管理" class="headerlink" title="配置管理"></a>配置管理</h2><p>每一个 Unit 都有一个配置文件，告诉 Systemd 怎么启动这个 Unit 。</p><p>Systemd 默认从目录<code>/etc/systemd/system/</code>读取配置文件。但是，里面存放的大部分文件都是符号链接，指向目录<code>/usr/lib/systemd/system/</code>，真正的配置文件存放在那个目录。</p><p><code>systemctl enable</code>命令用于在上面两个目录之间，建立符号链接关系。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ sudo systemctl <span class="built_in">enable</span> clamd@scan.service</span><br><span class="line"><span class="comment"># 等同于</span></span><br><span class="line">$ sudo ln -s <span class="string">'/usr/lib/systemd/system/clamd@scan.service'</span> <span class="string">'/etc/systemd/system/multi-user.target.wants/clamd@scan.service'</span></span><br></pre></td></tr></table></figure><p>如果配置文件里面设置了开机启动，<code>systemctl enable</code>命令相当于激活开机启动。</p><p>与之对应的，<code>systemctl disable</code>命令用于在两个目录之间，撤销符号链接关系，相当于撤销开机启动。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo systemctl <span class="built_in">disable</span> clamd@scan.service</span><br></pre></td></tr></table></figure><p>配置文件的后缀名，就是该 Unit 的种类，比如<code>sshd.socket</code>。如果省略，Systemd 默认后缀名为<code>.service</code>，所以<code>sshd</code>会被理解成<code>sshd.service</code>。</p><h3 id="配置文件的状态"><a href="#配置文件的状态" class="headerlink" title="配置文件的状态"></a>配置文件的状态</h3><p><code>systemctl list-unit-files</code> 命令用于列出所有配置文件。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 列出所有配置文件</span></span><br><span class="line">$ systemctl list-unit-files</span><br><span class="line"></span><br><span class="line"><span class="comment"># 列出指定类型的配置文件</span></span><br><span class="line">$ systemctl list-unit-files --<span class="built_in">type</span>=service</span><br></pre></td></tr></table></figure><p>这个命令会输出一个列表。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ systemctl list-unit-files</span><br><span class="line"></span><br><span class="line">UNIT FILE              STATE</span><br><span class="line">chronyd.service        enabled</span><br><span class="line">clamd@.service         static</span><br><span class="line">clamd@scan.service     disabled</span><br></pre></td></tr></table></figure><p>这个列表显示每个配置文件的状态，一共有四种。</p><ul><li>enabled：已建立启动链接</li><li>disabled：没建立启动链接</li><li>static：该配置文件没有<code>[Install]</code>部分（无法执行），只能作为其他配置文件的依赖</li><li>masked：该配置文件被禁止建立启动链接</li></ul><p>注意，从配置文件的状态无法看出，该 Unit 是否正在运行。这必须执行前面提到的<code>systemctl status</code>命令。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ systemctl status bluetooth.service</span><br></pre></td></tr></table></figure><p>一旦修改配置文件，就要让 SystemD 重新加载配置文件，然后重新启动，否则修改不会生效。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ sudo systemctl daemon-reload</span><br><span class="line">$ sudo systemctl restart httpd.service</span><br></pre></td></tr></table></figure><h3 id="配置文件的格式"><a href="#配置文件的格式" class="headerlink" title="配置文件的格式"></a>配置文件的格式</h3><p>配置文件就是普通的文本文件，可以用文本编辑器打开。<code>systemctl cat</code>命令可以查看配置文件的内容。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">$ systemctl cat kubelet.service</span><br><span class="line"><span class="comment"># /usr/lib/systemd/system/kubelet.service</span></span><br><span class="line">[Unit]</span><br><span class="line">Description=kubelet</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">EnvironmentFile=-/etc/kubernetes/kubelet</span><br><span class="line">ExecStart=/usr/bin/kubelet <span class="variable">$&#123;SERIALIZE_IMAGE_PULLS&#125;</span> <span class="variable">$&#123;REGISTER_SCHEDULABLE&#125;</span> <span class="variable">$&#123;V&#125;</span> <span class="variable">$&#123;CLOUD_PROVIDER&#125;</span> <span class="variable">$&#123;FAIL_SWAP_ON&#125;</span> <span class="variable">$&#123;AUTHORIZATION_MODE&#125;</span> <span class="variable">$&#123;CLOUD_CONFIG&#125;</span> <span class="variable">$&#123;CLUSTER_DNS&#125;</span> $&#123;</span><br><span class="line">ExecStartPost=-/bin/bash /etc/kubernetes/deny-tcp-port-10250.sh</span><br><span class="line">Restart=always</span><br><span class="line">RestartSec=10</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure><p>从上面的输出可以看到，配置文件分成几个区块。每个区块的第一行，是用方括号表示的区别名，比如<code>[Unit]</code>。注意，配置文件的区块名和字段名，都是大小写敏感的。每个区块内部是一些等号连接的键值对。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[Section]</span><br><span class="line">Directive1=value</span><br><span class="line">Directive2=value</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>注意，键值对的等号两侧不能有空格。</p><h3 id="配置文件的区块"><a href="#配置文件的区块" class="headerlink" title="配置文件的区块"></a>配置文件的区块</h3><h4 id="Unit-区块"><a href="#Unit-区块" class="headerlink" title="Unit 区块"></a>Unit 区块</h4><p><code>[Unit]</code>区块通常是配置文件的第一个区块，用来定义 Unit 的元数据，以及配置与其他 Unit 的关系。它的主要字段如下。</p><ul><li><code>Description</code>：简短描述</li><li><code>Documentation</code>：文档地址</li><li><code>Requires</code>：当前 Unit 依赖的其他 Unit，如果它们没有运行，当前 Unit 会启动失败</li><li><code>Wants</code>：与当前 Unit 配合的其他 Unit，如果它们没有运行，当前 Unit 不会启动失败，<strong>弱依赖</strong></li><li><code>BindsTo</code>：与<code>Requires</code>类似，它指定的 Unit 如果退出，会导致当前 Unit 停止运行，<strong>强依赖</strong></li><li><code>Before</code>：如果该字段指定的 Unit 也要启动，那么必须在当前 Unit 之后启动</li><li><code>After</code>：如果该字段指定的 Unit 也要启动，那么必须在当前 Unit 之前启动</li><li><code>Conflicts</code>：这里指定的 Unit 不能与当前 Unit 同时运行</li><li><code>Condition...</code>：当前 Unit 运行必须满足的条件，否则不会运行</li><li><code>Assert...</code>：当前 Unit 运行必须满足的条件，否则会报启动失败</li></ul><blockquote><p>注意，<code>Wants</code>字段与<code>Requires</code>字段只涉及依赖关系，与启动顺序无关，默认情况下是同时启动的。</p><p>注意，<code>After</code>和<code>Before</code>字段只涉及启动顺序，不涉及依赖关系。</p></blockquote><h4 id="Install-区块"><a href="#Install-区块" class="headerlink" title="Install 区块"></a>Install 区块</h4><p><code>[Install]</code>通常是配置文件的最后一个区块，用来定义如何启动，以及是否开机启动，它的主要字段如下。</p><ul><li><code>WantedBy</code>：它的值是一个或多个 Target，当前 Unit 激活时（enable）符号链接会放入<code>/etc/systemd/system</code>目录下面以 Target 名 + <code>.wants</code>后缀构成的子目录中。<code>Target</code>的含义是服务组，表示一组服务。<code>WantedBy=multi-user.target</code>指的是，sshd 所在的 Target 是<code>multi-user.target</code>。这个设置非常重要，因为执行<code>systemctl enable sshd.service</code>命令时，<code>sshd.service</code>的一个符号链接，就会放在<code>/etc/systemd/system</code>目录下面的<code>multi-user.target.wants</code>子目录之中。</li><li><code>RequiredBy</code>：它的值是一个或多个 Target，当前 Unit 激活时，符号链接会放入<code>/etc/systemd/system</code>目录下面以 Target 名 + <code>.required</code>后缀构成的子目录中</li><li><code>Alias</code>：当前 Unit 可用于启动的别名</li><li><code>Also</code>：当前 Unit 激活（enable）时，会被同时激活的其他 Unit</li></ul><p>上面的结果表示，默认的启动 Target 是<code>multi-user.target</code>。在这个组里的所有服务，都将开机启动。这就是为什么<code>systemctl enable</code>命令能设置开机启动的原因。使用 Target 的时候，<code>systemctl list-dependencies</code>命令和<code>systemctl isolate</code>命令也很有用。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看 multi-user.target 包含的所有服务</span></span><br><span class="line">$ systemctl list-dependencies multi-user.target</span><br><span class="line"></span><br><span class="line"><span class="comment"># 切换到另一个 target</span></span><br><span class="line"><span class="comment"># shutdown.target 就是关机状态</span></span><br><span class="line">$ sudo systemctl isolate shutdown.target</span><br></pre></td></tr></table></figure><p>一般来说，常用的 Target 有两个：一个是<code>multi-user.target</code>，表示多用户命令行状态；另一个是<code>graphical.target</code>，表示图形用户状态，它依赖于<code>multi-user.target</code>。官方文档有一张非常清晰的 <a href="https://www.freedesktop.org/software/systemd/man/bootup.html#System Manager Bootup" target="_blank" rel="external nofollow noopener noreferrer">Target 依赖关系图</a>。</p><h4 id="Service-区块"><a href="#Service-区块" class="headerlink" title="Service 区块"></a>Service 区块</h4><p><code>[Service]</code>区块用来 Service 的配置，只有 Service 类型的 Unit 才有这个区块。它的主要字段如下。</p><h5 id="启动命令"><a href="#启动命令" class="headerlink" title="启动命令"></a>启动命令</h5><ul><li><code>EnvironmentFile</code>：指定当前服务的环境参数文件。该文件内部的<code>key=value</code>键值对，可以用<code>$key</code>的形式，在当前配置文件中获取。</li><li><code>Environment</code>：指定环境变量</li><li><code>ExecStart</code>：定义启动进程时执行的命令。</li><li><code>ExecStartPre</code>：启动当前服务之前执行的命令</li><li><code>ExecStartPost</code>：启动当前服务之后执行的命令</li><li><code>ExecReload</code>：重启当前服务时执行的命令</li><li><code>ExecStop</code>：停止当前服务时执行的命令</li><li><code>ExecStopPost</code>：停止当其服务之后执行的命令</li><li><code>TimeoutSec</code>：定义 Systemd 停止当前服务之前等待的秒数</li></ul><p>上面的例子中，启动<code>sshd</code>，执行的命令是<code>/usr/sbin/sshd -D $OPTIONS</code>，其中的变量<code>$OPTIONS</code>就来自<code>EnvironmentFile</code>字段指定的环境参数文件。</p><p>请看下面的例子：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[Service]</span><br><span class="line">ExecStart=/bin/<span class="built_in">echo</span> execstart1</span><br><span class="line">ExecStart=</span><br><span class="line">ExecStart=/bin/<span class="built_in">echo</span> execstart2</span><br><span class="line">ExecStartPost=/bin/<span class="built_in">echo</span> post1</span><br><span class="line">ExecStartPost=/bin/<span class="built_in">echo</span> post2</span><br></pre></td></tr></table></figure><p>上面这个配置文件，第二行<code>ExecStart</code>设为空值，等于取消了第一行的设置，运行结果如下。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">execstart2</span><br><span class="line">post1</span><br><span class="line">post2</span><br></pre></td></tr></table></figure><p>所有的启动设置之前，都可以加上一个连词号（<code>-</code>），表示”抑制错误”，即发生错误的时候，不影响其他命令的执行。比如，<code>EnvironmentFile=-/etc/sysconfig/sshd</code>（注意等号后面的那个连词号），就表示即使<code>/etc/sysconfig/sshd</code>文件不存在，也不会抛出错误。</p><h5 id="启动类型"><a href="#启动类型" class="headerlink" title="启动类型"></a>启动类型</h5><p><code>Type</code>字段定义启动类型，它可以设置的值如下。</p><ul><li><code>Type=simple</code>：默认值，执行<code>ExecStart</code>指定的命令，启动主进程</li><li><code>Type=forking</code>：以 fork 方式从父进程创建子进程，创建后父进程会立即退出</li><li><code>Type=oneshot</code>：一次性进程，Systemd 会等当前服务退出，再继续往下执行</li><li><code>Type=dbus</code>：当前服务通过D-Bus启动</li><li><code>Type=notify</code>：当前服务启动完毕，会通知<code>Systemd</code>，再继续往下执行</li><li><code>Type=idle</code>：若有其他任务执行完毕，当前服务才会运行</li></ul><p>下面是一个<code>oneshot</code>的例子，笔记本电脑启动时，要把触摸板关掉，配置文件可以这样写。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[Unit]</span><br><span class="line">Description=Switch-off Touchpad</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=oneshot</span><br><span class="line">ExecStart=/usr/bin/touchpad-off</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure><p>上面的配置文件，启动类型设为<code>oneshot</code>，就表明这个服务只要运行一次就够了，不需要长期运行。</p><p>如果关闭以后，将来某个时候还想打开，配置文件修改如下。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[Unit]</span><br><span class="line">Description=Switch-off Touchpad</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=oneshot</span><br><span class="line">ExecStart=/usr/bin/touchpad-off start</span><br><span class="line">ExecStop=/usr/bin/touchpad-off stop</span><br><span class="line">RemainAfterExit=yes</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure><p>上面配置文件中，<code>RemainAfterExit</code>字段设为<code>yes</code>，表示进程退出以后，服务仍然保持执行。这样的话，一旦使用<code>systemctl stop</code>命令停止服务，<code>ExecStop</code>指定的命令就会执行，从而重新开启触摸板。</p><h5 id="重启行为"><a href="#重启行为" class="headerlink" title="重启行为"></a>重启行为</h5><p><code>Service</code>区块有一些字段，定义了重启行为。</p><p><code>KillMode</code>字段：定义 Systemd 如何停止 sshd 服务。</p><p>上面这个例子中，将<code>KillMode</code>设为<code>process</code>，表示只停止主进程，不停止任何sshd 子进程，即子进程打开的 SSH session 仍然保持连接。这个设置不太常见，但对 sshd 很重要，否则你停止服务的时候，会连自己打开的 SSH session 一起杀掉。</p><p><code>KillMode</code>字段可以设置的值如下。</p><ul><li>control-group（默认值）：当前控制组里面的所有子进程，都会被杀掉</li><li>process：只杀主进程</li><li>mixed：主进程将收到 SIGTERM 信号，子进程收到 SIGKILL 信号</li><li>none：没有进程会被杀掉，只是执行服务的 stop 命令。</li></ul><p>接下来是<code>Restart</code>字段。</p><p><code>Restart</code>字段：定义了 sshd 退出后，Systemd 的重启方式。</p><p>上面的例子中，<code>Restart</code>设为<code>on-failure</code>，表示任何意外的失败，就将重启sshd。如果 sshd 正常停止（比如执行<code>systemctl stop</code>命令），它就不会重启。</p><p><code>Restart</code>字段可以设置的值如下。</p><ul><li>no（默认值）：退出后不会重启</li><li>on-success：只有正常退出时（退出状态码为0），才会重启</li><li>on-failure：非正常退出时（退出状态码非0），包括被信号终止和超时，才会重启</li><li>on-abnormal：只有被信号终止和超时，才会重启</li><li>on-abort：只有在收到没有捕捉到的信号终止时，才会重启</li><li>on-watchdog：超时退出，才会重启</li><li>always：不管是什么退出原因，总是重启</li></ul><p>对于守护进程，推荐设为<code>on-failure</code>。对于那些允许发生错误退出的服务，可以设为<code>on-abnormal</code>。</p><p>最后是<code>RestartSec</code>字段。</p><p><code>RestartSec</code>字段：表示 Systemd 重启服务之前，需要等待的秒数。上面的例子设为等待42秒。</p><h3 id="Target-的配置文件"><a href="#Target-的配置文件" class="headerlink" title="Target 的配置文件"></a>Target 的配置文件</h3><p>Target 也有自己的配置文件。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ systemctl cat multi-user.target</span><br><span class="line"></span><br><span class="line">[Unit]</span><br><span class="line">Description=Multi-User System</span><br><span class="line">Documentation=man:systemd.special(7)</span><br><span class="line">Requires=basic.target</span><br><span class="line">Conflicts=rescue.service rescue.target</span><br><span class="line">After=basic.target rescue.service rescue.target</span><br><span class="line">AllowIsolate=yes</span><br></pre></td></tr></table></figure><p>注意，Target 配置文件里面没有启动命令。</p><p>上面输出结果中，主要字段含义如下。</p><ul><li><code>Requires</code>字段：要求<code>basic.target</code>一起运行。</li><li><code>Conflicts</code>字段：冲突字段。如果<code>rescue.service</code>或<code>rescue.target</code>正在运行，<code>multi-user.target</code>就不能运行，反之亦然。</li><li><code>After</code>：表示<code>multi-user.target</code>在<code>basic.target</code> 、 <code>rescue.service</code>、 <code>rescue.target</code>之后启动，如果它们有启动的话。</li><li><code>AllowIsolate</code>：允许使用<code>systemctl isolate</code>命令切换到<code>multi-user.target</code>。</li></ul><h3 id="修改配置文件后重启"><a href="#修改配置文件后重启" class="headerlink" title="修改配置文件后重启"></a>修改配置文件后重启</h3><p>修改配置文件以后，需要重新加载配置文件，然后重新启动相关服务。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 重新加载配置文件</span></span><br><span class="line">$ sudo systemctl daemon-reload</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重启相关服务</span></span><br><span class="line">$ sudo systemctl restart foobar</span><br></pre></td></tr></table></figure><h2 id="功能实战"><a href="#功能实战" class="headerlink" title="功能实战"></a>功能实战</h2><h3 id="开机启动"><a href="#开机启动" class="headerlink" title="开机启动"></a>开机启动</h3><p>对于那些支持 Systemd 的软件，安装的时候，会自动在<code>/usr/lib/systemd/system</code>目录添加一个配置文件。</p><p>如果你想让该软件开机启动，就执行下面的命令（以<code>httpd.service</code>为例）。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo systemctl <span class="built_in">enable</span> httpd</span><br></pre></td></tr></table></figure><p>上面的命令相当于在<code>/etc/systemd/system</code>目录添加一个符号链接，指向<code>/usr/lib/systemd/system</code>里面的<code>httpd.service</code>文件。</p><p>这是因为开机时，<code>Systemd</code>只执行<code>/etc/systemd/system</code>目录里面的配置文件。这也意味着，如果把修改后的配置文件放在该目录，就可以达到覆盖原始配置的效果。</p><h3 id="启动服务"><a href="#启动服务" class="headerlink" title="启动服务"></a>启动服务</h3><p>设置开机启动以后，软件并不会立即启动，必须等到下一次开机。如果想现在就运行该软件，那么要执行<code>systemctl start</code>命令。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo systemctl start httpd</span><br></pre></td></tr></table></figure><p>执行上面的命令以后，有可能启动失败，因此要用<code>systemctl status</code>命令查看一下该服务的状态。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">$ sudo systemctl status httpd</span><br><span class="line"></span><br><span class="line">httpd.service - The Apache HTTP Server</span><br><span class="line">   Loaded: loaded (/usr/lib/systemd/system/httpd.service; enabled)</span><br><span class="line">   Active: active (running) since 金 2014-12-05 12:18:22 JST; 7min ago</span><br><span class="line"> Main PID: 4349 (httpd)</span><br><span class="line">   Status: <span class="string">"Total requests: 1; Current requests/sec: 0; Current traffic:   0 B/sec"</span></span><br><span class="line">   CGroup: /system.slice/httpd.service</span><br><span class="line">           ├─4349 /usr/sbin/httpd -DFOREGROUND</span><br><span class="line">           ├─4350 /usr/sbin/httpd -DFOREGROUND</span><br><span class="line">           ├─4351 /usr/sbin/httpd -DFOREGROUND</span><br><span class="line">           ├─4352 /usr/sbin/httpd -DFOREGROUND</span><br><span class="line">           ├─4353 /usr/sbin/httpd -DFOREGROUND</span><br><span class="line">           └─4354 /usr/sbin/httpd -DFOREGROUND</span><br><span class="line"></span><br><span class="line">12月 05 12:18:22 localhost.localdomain systemd[1]: Starting The Apache HTTP Server...</span><br><span class="line">12月 05 12:18:22 localhost.localdomain systemd[1]: Started The Apache HTTP Server.</span><br><span class="line">12月 05 12:22:40 localhost.localdomain systemd[1]: Started The Apache HTTP Server.</span><br></pre></td></tr></table></figure><p>上面的输出结果含义如下。</p><ul><li><code>Loaded</code>行：配置文件的位置，是否设为开机启动</li><li><code>Active</code>行：表示正在运行</li><li><code>Main PID</code>行：主进程ID</li><li><code>Status</code>行：由应用本身（这里是 httpd ）提供的软件当前状态</li><li><code>CGroup</code>块：应用的所有子进程</li><li>日志块：应用的日志</li></ul><h3 id="停止服务"><a href="#停止服务" class="headerlink" title="停止服务"></a>停止服务</h3><p>终止正在运行的服务，需要执行<code>systemctl stop</code>命令。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo systemctl stop httpd.service</span><br></pre></td></tr></table></figure><p>有时候，该命令可能没有响应，服务停不下来。这时候就不得不”杀进程”了，向正在运行的进程发出<code>kill</code>信号。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo systemctl <span class="built_in">kill</span> httpd.service</span><br></pre></td></tr></table></figure><p>此外，重启服务要执行<code>systemctl restart</code>命令。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo systemctl restart httpd.service</span><br></pre></td></tr></table></figure><h2 id="社区争议"><a href="#社区争议" class="headerlink" title="社区争议"></a>社区争议</h2><p>Systemd 的优点是功能强大，使用方便，缺点是体系庞大，非常复杂。事实上，现在还有很多人反对使用 Systemd，理由就是它过于复杂，与操作系统的其他部分强耦合，违反 <code>keep simple, keep stupid</code> 的 Unix 哲学。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="http://www.ruanyifeng.com/blog/2016/03/systemd-tutorial-commands.html" target="_blank" rel="external nofollow noopener noreferrer">Systemd 入门教程</a></li><li><a href="https://www.freedesktop.org/software/systemd/man/bootup.html#System Manager Bootup" target="_blank" rel="external nofollow noopener noreferrer">Target 依赖关系图</a></li><li><a href="https://www.freedesktop.org/software/systemd/man/systemd.unit.html" target="_blank" rel="external nofollow noopener noreferrer">Unit 配置官方文档</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在 &lt;a href=&quot;https://houmin.cc/posts/e27e5d75/&quot;&gt;Linux 启动过程&lt;/a&gt; 中我们介绍了 Linux 启动中关键的一步：Init 进程启动系统。作为操作系统的 1 号进程，Init 是一个由内核启动的用户级进程，完成系统引导。早期 Linux 系统的 Init 进程是著名的 &lt;a href=&quot;https://wiki.archlinux.org/index.php/SysVinit&quot; target=&quot;_blank&quot; rel=&quot;external nofollow noopener noreferrer&quot;&gt; &lt;code&gt;SysV Init&lt;/code&gt;&lt;/a&gt; ，然而由于 SysVInit 进程是串行启动用户程序，启动时间长，而且启动事件复杂，已经慢慢开始退出历史舞台。目前广泛被各大 Linux 发行版采用的 Init 进程是 Systemd。Systemd 作为系统启动和管理的一整套解决方案，取代了 &lt;code&gt;initd&lt;/code&gt;，成为系统的 1 号进程，其他的进程都是其子进程，本文将介绍 Systemd 的设计与使用。&lt;/p&gt;
    
    </summary>
    
    <content src="http://houmin.cc/https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2021-01-26_systemd.png" type="image" />
    
    
      <category term="术业专攻" scheme="http://houmin.cc/categories/%E6%9C%AF%E4%B8%9A%E4%B8%93%E6%94%BB/"/>
    
    
  </entry>
  
  <entry>
    <title>【异构计算】NVIDIA XID Message</title>
    <link href="http://houmin.cc/posts/feaa4605/"/>
    <id>http://houmin.cc/posts/feaa4605/</id>
    <published>2021-01-21T06:19:26.000Z</published>
    <updated>2021-01-21T07:01:02.487Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p><code>Xid Message</code> 由 NVIDIA 驱动报告的错误信息，一般卸载操作系统的内核日志或者是事件日志中。Xid消息表明发生了一般的GPU错误，通常是由于驱动程序对GPU的编程不正确或发送给GPU的命令损坏所致。这些消息可能表示硬件问题、NVIDIA软件问题或用户应用程序问题。</p><a id="more"></a><p>Xid Message 的产生可能有以下三种：</p><ul><li>Hardware Problem</li><li>NVIDIA Software Problem</li><li>User Application Problem</li></ul><p>Xid Message 可以用作错误诊断，辅助调试报告的错误。在所有不同版本的NVIDIA驱动中，Xid Message 的含义保持一致。</p><h2 id="查看-Xid-Errors"><a href="#查看-Xid-Errors" class="headerlink" title="查看 Xid Errors"></a>查看 Xid Errors</h2><p>在 Linux 中，Xid Error 的信息在 <code>/var/log/messages</code> 中，可以看到错误信息。下图展示的是 XID 14 的错误信息：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ grep <span class="string">"NVRM: Xid"</span> /var/<span class="built_in">log</span>/messages</span><br><span class="line">[…] NVRM: GPU at 0000:03:00: GPU-b850f46d-d5ea-c752-ddf3-c4453e44d3f7 </span><br><span class="line">[…] NVRM: Xid (0000:03:00): 14, Channel 00000001</span><br></pre></td></tr></table></figure><p>在 NVIDIA 提供的 NVML 库中可以监听 GPU 的 Xid Error，下面是 Go 监听的示例代码：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">eventSet := nvml.NewEventSet()</span><br><span class="line"><span class="keyword">defer</span> nvml.DeleteEventSet(eventSet)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> _, gpu := <span class="keyword">range</span> devices &#123;</span><br><span class="line">err = nvml.RegisterEventForDevice(eventSet, nvml.XidCriticalError, gpu)</span><br><span class="line"><span class="comment">// ...</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> &#123;</span><br><span class="line"><span class="keyword">select</span> &#123;</span><br><span class="line"><span class="keyword">case</span> &lt;-stop:</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line"><span class="keyword">default</span>:</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">e, err := nvml.WaitForEvent(eventSet, <span class="number">5000</span>)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &amp;&amp; e.Etype != nvml.XidCriticalError &#123;</span><br><span class="line"><span class="keyword">continue</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// <span class="doctag">FIXME:</span> formalize the full list and document it.</span></span><br><span class="line"><span class="comment">// http://docs.nvidia.com/deploy/xid-errors/index.html#topic_4</span></span><br><span class="line"><span class="comment">// Application errors: the GPU should still be healthy</span></span><br><span class="line"><span class="keyword">if</span> e.Edata == <span class="number">31</span> || e.Edata == <span class="number">43</span> || e.Edata == <span class="number">45</span> &#123;</span><br><span class="line"><span class="keyword">continue</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> e.UUID == <span class="literal">nil</span> || <span class="built_in">len</span>(*e.UUID) == <span class="number">0</span> &#123;</span><br><span class="line"><span class="comment">// All devices are unhealthy</span></span><br><span class="line">log.Printf(<span class="string">"XidCriticalError: Xid=%d, All devices will go unhealthy."</span>, e.Edata)</span><br><span class="line"><span class="keyword">for</span> _, d := <span class="keyword">range</span> devices &#123;</span><br><span class="line">unhealthy &lt;- d</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">continue</span></span><br><span class="line">&#125;</span><br><span class="line">   <span class="comment">//...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Common-Xid-Errors"><a href="#Common-Xid-Errors" class="headerlink" title="Common Xid Errors"></a>Common Xid Errors</h2><h3 id="XID-13：GR-SW-Notify-Error"><a href="#XID-13：GR-SW-Notify-Error" class="headerlink" title="XID 13：GR: SW Notify Error"></a>XID 13：GR: SW Notify Error</h3><p>XID 13 号错误是通用的用户进程的错误，一般是用户访问数组越界、或者非法指令、非法寄存器的问题。这种问题在很少的情况下才会是硬件问题或者内核驱动的问题，基本上是用户进程的问题。</p><p>当这种问题发生时，NVIDIA 推荐如下步骤：</p><ol><li>Run the application in cuda-gdb or cuda-memcheck , or</li><li>Run the application with CUDA_DEVICE_WAITS_ON_EXCEPTION=1 and then attach later with cuda-gdb, or</li><li>File a bug if the previous two come back inconclusive to eliminate potential NVIDIA driver or hardware bug.</li></ol><h3 id="XID-31-Fifo-MMU-Error"><a href="#XID-31-Fifo-MMU-Error" class="headerlink" title="XID 31: Fifo: MMU Error"></a>XID 31: Fifo: MMU Error</h3><p>XID 31 号错误是由 MMU 报告的错误，比如当一个用户进程对一个非法地址访问的时候。一般来说，这是用户程序级别的bug，也有可能是驱动或者硬件bug。</p><p>当这种问题发生时，NVIDIA 推荐如下步骤：</p><ol><li>Run the application in cuda-gdb or cuda-memcheck , or</li><li>Run the application with CUDA_DEVICE_WAITS_ON_EXCEPTION=1 and then attach later with cuda-gdb, or</li><li>File a bug if the previous two come back inconclusive to eliminate potential NVIDIA driver or hardware bug.</li></ol><h3 id="XID-32-PBDMA-Error"><a href="#XID-32-PBDMA-Error" class="headerlink" title="XID 32: PBDMA Error"></a>XID 32: PBDMA Error</h3><p>XID 32 号错误是由 DMA Controller 上报的，DMA Controller 负责在 NVIDIA 驱动和 GPU之前通过 PCIe总线进行通信。</p><p>一般来说，这种问题是由 PCI 的质量问题导致，一般也不是由用户程序造成的。</p><h3 id="XID-43-Reset-Channel-VERIF-Error"><a href="#XID-43-Reset-Channel-VERIF-Error" class="headerlink" title="XID 43: Reset Channel VERIF Error"></a>XID 43: Reset Channel VERIF Error</h3><p>XID 43 号错误发生在当探测到用户程序可能因此故障，这时候必须终止用户程序。这种情况下，GPU还是处于健康的状态。</p><p>在大多数情况，这种问题是用户进程导致的，而不是驱动的bug</p><h3 id="XID-45-OS-Preemptive-Channel-Removal"><a href="#XID-45-OS-Preemptive-Channel-Removal" class="headerlink" title="XID 45: OS: Preemptive Channel Removal"></a>XID 45: OS: Preemptive Channel Removal</h3><p>XID 45 号错误发生在 用户进程 Abort 了，这时候内核驱动需要终止在GPU上运行的GPU Application。<code>Ctrl-C</code>、CPU Reset、Sigkill 都是这种场景。</p><p>大多数情况下，这种问题是用户进程导致的，而不是驱动的bug</p><h3 id="XID-48-DBE-Double-Bit-Error-ECC-Error"><a href="#XID-48-DBE-Double-Bit-Error-ECC-Error" class="headerlink" title="XID 48: DBE(Double Bit Error) ECC Error"></a>XID 48: DBE(Double Bit Error) ECC Error</h3><p>XID 48 号错误发生在当 GPU 探测到GPU上有一个不可纠正的错误，这个错误也会报告给用户进程。这种情况下，可要 GPU Reset 或者 Node 重启来修复这个问题。<code>nvidia-smi</code> 工具会提供一个ECC错误的总结。</p><h2 id="Xid-Error-Listing"><a href="#Xid-Error-Listing" class="headerlink" title="Xid Error Listing"></a>Xid Error Listing</h2><p>下表展示了所有的Xid Error信息：</p><div class="table-container"><table><thead><tr><th>XID</th><th>Failure</th><th>Causes</th><th></th><th></th><th></th><th></th><th></th><th></th></tr></thead><tbody><tr><td></td><td></td><td>HW Error</td><td>Driver Error</td><td>User App Error</td><td>System Memory Corruption</td><td>Bus Error</td><td>Thermal Issue</td><td>FB Corruption</td></tr><tr><td>1</td><td>Invalid or corrupted push buffer stream</td><td></td><td>X</td><td></td><td>X</td><td>X</td><td></td><td>X</td></tr><tr><td>2</td><td>Invalid or corrupted push buffer stream</td><td></td><td>X</td><td></td><td>X</td><td>X</td><td></td><td>X</td></tr><tr><td>3</td><td>Invalid or corrupted push buffer stream</td><td></td><td>X</td><td></td><td>X</td><td>X</td><td></td><td>X</td></tr><tr><td>4</td><td>Invalid or corrupted push buffer stream</td><td></td><td>X</td><td></td><td>X</td><td>X</td><td></td><td>X</td></tr><tr><td></td><td>GPU semaphore timeout</td><td></td><td>X</td><td>X</td><td>X</td><td>X</td><td></td><td>X</td></tr><tr><td>5</td><td>Unused</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>6</td><td>Invalid or corrupted push buffer stream</td><td></td><td>X</td><td></td><td>X</td><td>X</td><td></td><td>X</td></tr><tr><td>7</td><td>Invalid or corrupted push buffer address</td><td></td><td>X</td><td></td><td></td><td>X</td><td></td><td>X</td></tr><tr><td>8</td><td>GPU stopped processing</td><td></td><td>X</td><td>X</td><td></td><td>X</td><td>X</td><td></td></tr><tr><td>9</td><td>Driver error programming GPU</td><td></td><td>X</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>10</td><td>Unused</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>11</td><td>Invalid or corrupted push buffer stream</td><td></td><td>X</td><td></td><td>X</td><td>X</td><td></td><td>X</td></tr><tr><td>12</td><td>Driver error handling GPU exception</td><td></td><td>X</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>13</td><td>Graphics Engine Exception</td><td></td><td>X</td><td>X</td><td>X</td><td>X</td><td>X</td><td>X</td></tr><tr><td>14</td><td>Unused</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>15</td><td>Unused</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>16</td><td>Display engine hung</td><td></td><td>X</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>17</td><td>Unused</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>18</td><td>Bus mastering disabled in PCI Config Space</td><td></td><td>X</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>19</td><td>Display Engine error</td><td></td><td>X</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>20</td><td>Invalid or corrupted Mpeg push buffer</td><td></td><td>X</td><td></td><td>X</td><td>X</td><td></td><td>X</td></tr><tr><td>21</td><td>Invalid or corrupted Motion Estimation push buffer</td><td></td><td>X</td><td></td><td>X</td><td>X</td><td></td><td>X</td></tr><tr><td>22</td><td>Invalid or corrupted Video Processor push buffer</td><td></td><td>X</td><td></td><td>X</td><td>X</td><td></td><td>X</td></tr><tr><td>23</td><td>Unused</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>24</td><td>GPU semaphore timeout</td><td></td><td>X</td><td>X</td><td>X</td><td>X</td><td>X</td><td>X</td></tr><tr><td>25</td><td>Invalid or illegal push buffer stream</td><td></td><td>X</td><td>X</td><td>X</td><td>X</td><td></td><td>X</td></tr><tr><td>26</td><td>Framebuffer timeout</td><td></td><td>X</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>27</td><td>Video processor exception</td><td></td><td>X</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>28</td><td>Video processor exception</td><td></td><td>X</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>29</td><td>Video processor exception</td><td></td><td>X</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>30</td><td>GPU semaphore access error</td><td></td><td>X</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>31</td><td>GPU memory page fault</td><td></td><td>X</td><td>X</td><td></td><td></td><td></td><td></td></tr><tr><td>32</td><td>Invalid or corrupted push buffer stream</td><td></td><td>X</td><td></td><td>X</td><td>X</td><td>X</td><td>X</td></tr><tr><td>33</td><td>Internal micro-controller error</td><td></td><td>X</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>34</td><td>Video processor exception</td><td></td><td>X</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>35</td><td>Video processor exception</td><td></td><td>X</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>36</td><td>Video processor exception</td><td></td><td>X</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>37</td><td>Driver firmware error</td><td></td><td>X</td><td></td><td>X</td><td>X</td><td></td><td></td></tr><tr><td>38</td><td>Driver firmware error</td><td></td><td>X</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>39</td><td>Unused</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>40</td><td>Unused</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>41</td><td>Unused</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>42</td><td>Video processor exception</td><td></td><td>X</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>43</td><td>GPU stopped processing</td><td></td><td>X</td><td>X</td><td></td><td></td><td></td><td></td></tr><tr><td>44</td><td>Graphics Engine fault during context switch</td><td></td><td>X</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>45</td><td>Preemptive cleanup, due to previous errors — Most likely to see when running multiple cuda applications and hitting a DBE</td><td></td><td>X</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>46</td><td>GPU stopped processing</td><td></td><td>X</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>47</td><td>Video processor exception</td><td></td><td>X</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>48</td><td>Double Bit ECC Error</td><td>X</td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>49</td><td>Unused</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>50</td><td>Unused</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>51</td><td>Unused</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>52</td><td>Unused</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>53</td><td>Unused</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>54</td><td>Auxiliary power is not connected to the GPU board</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>55</td><td>Unused</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>56</td><td>Display Engine error</td><td>X</td><td>X</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>57</td><td>Error programming video memory interface</td><td>X</td><td>X</td><td></td><td></td><td></td><td></td><td>X</td></tr><tr><td>58</td><td>Unstable video memory interface detected</td><td>X</td><td>X</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td>EDC error – clarified in printout</td><td>X</td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>59</td><td>Internal micro-controller error(older drivers)</td><td></td><td>X</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>60</td><td>Video processor exception</td><td></td><td>X</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>61</td><td>Internal micro-controller breakpoint/warning(newer drivers)</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>62</td><td>Internal micro-controller halt(newer drivers)</td><td>X</td><td>X</td><td></td><td></td><td></td><td>X</td><td></td></tr><tr><td>63</td><td>ECC page retirement recording event</td><td>X</td><td>X</td><td></td><td></td><td></td><td></td><td>X</td></tr><tr><td>64</td><td>ECC page retirement recording failure</td><td>X</td><td>X</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>65</td><td>Video processor exception</td><td>X</td><td>X</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>66</td><td>Illegal access by driver</td><td></td><td>X</td><td>X</td><td></td><td></td><td></td><td></td></tr><tr><td>67</td><td>Illegal access by driver</td><td></td><td>X</td><td>X</td><td></td><td></td><td></td><td></td></tr><tr><td>68</td><td>Video processor exception</td><td>X</td><td>X</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>69</td><td>Graphics Engine class error</td><td>X</td><td>X</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>70</td><td>CE3: Unknown Error</td><td>X</td><td>X</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>71</td><td>CE4: Unknown Error</td><td>X</td><td>X</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>72</td><td>CE5: Unknown Error</td><td>X</td><td>X</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>73</td><td>NVENC2 Error</td><td>X</td><td>X</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>74</td><td>NVLINK Error</td><td>X</td><td>X</td><td></td><td></td><td>X</td><td></td><td></td></tr><tr><td>75</td><td>Reserved</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>76</td><td>Reserved</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>77</td><td>Reserved</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>78</td><td>vGPU Start Error</td><td></td><td>X</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>79</td><td>GPU has fallen off the bus</td><td>X</td><td>X</td><td></td><td>X</td><td>X</td><td>X</td><td></td></tr><tr><td>80</td><td>Corrupted data sent to GPU</td><td>X</td><td>X</td><td></td><td>X</td><td>X</td><td></td><td>X</td></tr><tr><td>81</td><td>VGA Subsystem Error</td><td>X</td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>82</td><td>Reserved</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>83</td><td>Reserved</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>84</td><td>Reserved</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>85</td><td>Reserved</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>86</td><td>Reserved</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>87</td><td>Reserved</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>88</td><td>Reserved</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>89</td><td>Reserved</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>90</td><td>Reserved</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>91</td><td>Reserved</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>92</td><td>High single-bit ECC error rate</td><td>X</td><td>X</td><td></td><td></td><td></td><td></td></tr></tbody></table></div><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://docs.nvidia.com/deploy/xid-errors/index.html" target="_blank" rel="external nofollow noopener noreferrer">NVIDIA XID Errors</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;code&gt;Xid Message&lt;/code&gt; 由 NVIDIA 驱动报告的错误信息，一般卸载操作系统的内核日志或者是事件日志中。Xid消息表明发生了一般的GPU错误，通常是由于驱动程序对GPU的编程不正确或发送给GPU的命令损坏所致。这些消息可能表示硬件问题、NVIDIA软件问题或用户应用程序问题。&lt;/p&gt;
    
    </summary>
    
    
      <category term="术业专攻" scheme="http://houmin.cc/categories/%E6%9C%AF%E4%B8%9A%E4%B8%93%E6%94%BB/"/>
    
    
      <category term="GPU" scheme="http://houmin.cc/tags/GPU/"/>
    
      <category term="NVIDIA" scheme="http://houmin.cc/tags/NVIDIA/"/>
    
      <category term="XID" scheme="http://houmin.cc/tags/XID/"/>
    
  </entry>
  
  <entry>
    <title>从「纸牌屋」看美国政治生态</title>
    <link href="http://houmin.cc/posts/c2e89645/"/>
    <id>http://houmin.cc/posts/c2e89645/</id>
    <published>2021-01-10T05:06:17.000Z</published>
    <updated>2021-01-17T14:47:08.130Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>「阅读光影」是在2021年新推出的栏目，涉及到阅读与光影，主要用于记录阅读和观影中的感悟与笔记，作为内容输入的输出管道。在今年的后续时间里，将按照2021的 <a href="https://www.douban.com/doulist/133636602/" target="_blank" rel="external nofollow noopener noreferrer">阅读计划</a> 和 <a href="https://www.douban.com/doulist/133864290/" target="_blank" rel="external nofollow noopener noreferrer">观影计划</a>，对所读所看的内容进行记录与总结。</p><p>这里是2021年「阅读光影」第一期：<code>从「纸牌屋」看美国政治生态</code>，将以纸牌屋为起点，介绍美国政治的宏观图景。在拜登总统即将就职的当下，在特朗普总统遭到历史上首次的第二次弹劾的当下，在美国国会遭遇两百年来的首次占领的当下，美国的政治图景开始在眼前越发的生动立体。</p>    <div id="aplayer-IGflgVCK" class="aplayer aplayer-tag-marker meting-tag-marker" data-id="26238376" data-server="netease" data-type="song" data-mode="circulation" data-autoplay="false" data-mutex="true" data-listmaxheight="340px" data-preload="auto" data-theme="#555"></div><a id="more"></a><h2 id="三权分立"><a href="#三权分立" class="headerlink" title="三权分立"></a>三权分立</h2><p>首先我们来到「纸牌屋」这场大戏上演的主要地点：美国首都——华盛顿哥伦比亚特区。在下面的地图中，你可以看到 白宫 <code>The White House</code>、国会山 <code>Capitol Hill</code>，在国会山上你可以看到美国国会大厦 <code>United States Capitol</code>、美国最高法院 <code>Supreme Court of the United States</code>。</p><iframe src="https://www.google.com/maps/embed?pb=!1m18!1m12!1m3!1d99370.36297142891!2d-77.08461552967614!3d38.89370913932197!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x89b7c6de5af6e45b%3A0xc2524522d4885d2a!2z5ZOl5Lym5q-U5Lqa5Yy65Y2O55ub6aG_5ZOl5Lym5q-U5Lqa54m55Yy6!5e0!3m2!1szh-CN!2sus!4v1610869187028!5m2!1szh-CN!2sus" width="1200" height="750" frameborder="0" style="border:0;" allowfullscreen aria-hidden="false" tabindex="0"></iframe><p>这三个建筑即代表着美国的三权分立：</p><ul><li><strong>立法权力</strong>归<strong>美国国会</strong></li><li><strong>行政权力</strong>归<strong>美国总统</strong></li><li><strong>司法权力</strong>归<strong>美国最高法院</strong></li></ul><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-01-17_usa-seperation-of-power.png"></p><p>如果我们把地图缩小，在更大的尺度看 <a href="https://en.wikipedia.org/wiki/Washington,_D.C." target="_blank" rel="external nofollow noopener noreferrer">华盛顿</a>，我们可以看到实际上 <code>Washington</code>距离美国东海岸很近，实际上是处于 <code>Virginia</code> 和 <code>Maryland</code> 之间的一块很小的地方。关于美国首都的故事你们也许听过，这是一个美国联邦政府与南北方地方政府权力斗争与妥协的过程。</p><p>在 1775 年美国独立战争打响时，当时美国最大的城市是位于宾夕法尼亚州的 <a href="https://en.wikipedia.org/wiki/Philadelphia" target="_blank" rel="external nofollow noopener noreferrer"><strong>费城</strong>，<code>Philadelphia</code></a>，1776年7月4日签署的「独立宣言」的联邦会议也是在费城举办。除了因为独立战争战况紧急，到1783年前联邦议会基本都是在费城办公。1783年的 <a href="https://en.wikipedia.org/wiki/Pennsylvania_Mutiny_of_1783" target="_blank" rel="external nofollow noopener noreferrer"><code>费城兵变</code></a> 使得联邦议会将办公场所从费城迁到了纽约。这次兵变起因是经历了独立战争的民兵要求联邦政府支付他们在美国独立战争期间的兵役酬劳，但是联邦议会既没有财权满足士兵要求，也没有兵权弹压哗变，而宾夕法尼亚州政府也不施加援手，联邦国会议员只得仓皇逃离费城。</p><p>费城兵变将联邦「弱政府」的弊端暴露无疑，国会要求从各州管辖范围中划拨出一块独立的联邦直属辖区作为首都，这样一旦再出现类似之前宾州兵变的情况，国会便可绕过州政府、直接动用警力弹压。这时候南方蓄奴州与北方自由州之间的严重对立，使得双方都不能接受未来的永久首都落在对方的「势力范围」内，北方希望将首都定在纽约或者费城；而南方希望将首都定于南方。最终美国南北双方协商，各作让步，在美国南方离北方不远的地方新建一个城市作为美国的首都，这即是华盛顿哥伦比亚特区。</p><p><img alt data-src="https://upload.wikimedia.org/wikipedia/commons/7/78/Washington%2C_D.C._locator_map.svg"></p><p>OK，关于美国首都的讨论暂时到这，在进一步介绍美国三权分立各部门前，这里先熟悉下美国行政区划：从最初独立战争时期建国十三州，到现在星条旗上的五十个州，美国扩张历史可以参考<a href="https://www.bilibili.com/video/BV1Ht4y1Q7qJ" target="_blank" rel="external nofollow noopener noreferrer">这里</a>。</p><p><img alt data-src="https://upload.wikimedia.org/wikipedia/commons/9/92/Map_of_USA_with_state_names_2.svg"></p><h3 id="国会"><a href="#国会" class="headerlink" title="国会"></a>国会</h3><p>美国国会是宪法规定的最高立法机构，其采用两院制，是 <a href="https://en.wikipedia.org/wiki/Connecticut_Compromise" target="_blank" rel="external nofollow noopener noreferrer"><strong>1787 Connecticut Compromise</strong></a> 的结果：</p><ul><li><a href="https://zh.wikipedia.org/wiki/弗吉尼亚方案" target="_blank" rel="external nofollow noopener noreferrer">弗吉尼亚方案</a>：两院制，各州国会两院议员的数目与其人口总数成正比，对人口数较大的州更友好</li><li><a href="https://zh.wikipedia.org/wiki/新泽西方案" target="_blank" rel="external nofollow noopener noreferrer">新泽西方案</a>：一院制，所有的州无论大小，其代表权完全相同，对小州相对更友好</li></ul><p>在<a href="https://en.wikipedia.org/wiki/Constitutional_Convention_(United_States" target="_blank" rel="external nofollow noopener noreferrer">1787年联邦会议</a>)，经过激烈的争吵与讨论，最终确定国会采用两院制，两院之间并无从属关系：</p><ul><li>上议院为参议院 Senate：每个州都有两名参议员，与人口数无关，任期为6年，更少有党派气氛，不太受大众情绪干扰</li><li>下议院为众议院 House of Representatives：每个州在众议院中拥有的席位比例以人口为基准，更具党派氛围，贴近民意公论</li></ul><h4 id="参议院"><a href="#参议院" class="headerlink" title="参议院"></a>参议院</h4><p>参议院的总票数为100票，50个州每周两票，与各州人口无关。参议员任期为六年，相互交错，每隔两年改选约三分之一的席位。</p><p>作为美国上议院，参议院主要指责如下：</p><ul><li>批准或拒绝批准条约、解除已签署条约</li><li>确认内阁成员、最高法院大法官、联邦法官、军队负责人、监管机构、大使等</li><li>如果没有副总统候选人获得美国选举人投票的过半数，则由参议院负责从获得选举人票数最多的两人中选出一人担任该职务</li><li>参议院对被众议院弹劾的人进行审判</li></ul><p>参议院议长和主持会议的是美国副总统。在副总统缺席时，传统上由拥有多数席位党派的资深成员担任<strong>参议院临时议长</strong>，主持参议院工作。</p><p>当前参议院领导层如下：</p><ul><li>多数党领袖：多数党参议院一把手，现在是米奇·麦康奈尔，对内代表本党利益，对外则代表参议院。</li><li>多数党党鞭：多数党参议院二把手，确保本党议员按党的路线和原则投票，并建议本党领袖对未按要求投票的议员进行处罚。</li><li>少数党领袖：少数党参议院一把手，维护本党团结，增强凝聚力，推进本党立法议程。</li><li>少数党党鞭：少数党参议院二把手，确保本党议员按党的路线和原则投票，并建议本党领袖对未按要求投票的议员进行处罚。</li></ul><p><img alt data-src="https://upload.wikimedia.org/wikipedia/commons/d/d7/117th_United_States_Senate.svg"></p><h4 id="众议院"><a href="#众议院" class="headerlink" title="众议院"></a>众议院</h4><p>全国众议员票数为435票，众议院席位之分配以各州人口数作基础，以每10年举行一次的人口普查为依据，但各州至少要有一名代表。下图是按照2010年人口普查统计分配每州的众议员人数，可以看到加州、德州和佛州是三个人口大州，票数也更多。</p><p><img alt data-src="https://upload.wikimedia.org/wikipedia/commons/b/b9/2010_census_reapportionment.jpg"></p><p>众议员任期为2年，无连任限制。众议院的职责包括：</p><ul><li>提出和财政有关的动议、宣战权、终战权（又称撤兵权）</li><li>在总统选举中没有候选人获得多数选票时选择总统和副总统</li><li>弹劾总统、首席大法官及主要官员。</li></ul><p><img alt data-src="https://upload.wikimedia.org/wikipedia/commons/2/25/%28117th%29_US_House_of_Representatives.svg"></p><p>下面介绍下众议院中关键的领导人：众议院议长(The Speaker)、多数派领袖、多数派党鞭、少数派领袖、少数派党鞭。</p><p>众议院议长：</p><ul><li>众议员选举产生，传统上为多数党领导人。众议院议长继任总统之顺序仅次于兼任参议院议长的美国副总统，为政坛上第三重要的领袖人物。</li><li>当在总统职位与国会由不同政党掌握的情况下，众议院议长成为事实上的<strong>反对党领袖</strong>。</li><li>在 <a href="https://zh.wikipedia.org/wiki/2016%E5%B9%B4%E7%BE%8E%E5%9C%8B%E7%9C%BE%E8%AD%B0%E9%99%A2%E9%81%B8%E8%88%89" target="_blank" rel="external nofollow noopener noreferrer">2016年众议院选举</a>中，共和党在众议院取得多数席位 241 席，众议院为共和党领袖<a href="https://zh.wikipedia.org/wiki/保羅·萊恩" target="_blank" rel="external nofollow noopener noreferrer">保罗·莱恩</a></li><li>在 <a href="https://zh.wikipedia.org/wiki/2018%E5%B9%B4%E7%BE%8E%E5%9B%BD%E4%BC%97%E8%AE%AE%E9%99%A2%E9%80%89%E4%B8%BE" target="_blank" rel="external nofollow noopener noreferrer">2018年众议院选举</a>中，也即是特朗普总统的中期选举中，民主党重新赢得多数席位<strong>235</strong>席，众议院议长为民主党领袖<a href="https://zh.wikipedia.org/wiki/蘭希·佩洛西" target="_blank" rel="external nofollow noopener noreferrer">兰希·佩洛西</a></li><li>在 <a href="https://zh.wikipedia.org/wiki/2020%E5%B9%B4%E7%BE%8E%E5%9C%8B%E7%9C%BE%E8%AD%B0%E9%99%A2%E9%81%B8%E8%88%89" target="_blank" rel="external nofollow noopener noreferrer">2020年众议院选举</a>中，民主党继续保持多数席位<strong>222</strong>席，共和党获得212席，众议院议长仍然为民主党领袖<strong>佩洛西</strong></li></ul><p>美国总统每年都会在年初前往国会山发表 <a href="https://zh.wikipedia.org/wiki/%E5%9B%BD%E6%83%85%E5%92%A8%E6%96%87" target="_blank" rel="external nofollow noopener noreferrer">国情咨文 State of the Union address</a>，位于其身后的即是美国参议院议长和众议院议长。这里有几张有意思的图片：</p><p><img alt="2007年国情咨文，时任总统小布什为共和党人，众议院当时为民主党多数派，议长为佩洛西" data-src="https://upload.wikimedia.org/wikipedia/commons/a/a4/SOU2007.jpg"></p><p><img alt="2016年国情咨文，时任奥巴马总统为民主党人，众议院当时为共和党多数派，议长为Paul Ryan" data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2021-01-17_state-of-the-union-address-2016.jpg"></p><p><img alt="2020年国情咨文，时任总统特朗普为共和党人，众议院当时为民主党多数派，议长为佩洛西" data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2021-01-17_state-of-the-union-address-2020.jpg"></p><p>Emmm，特朗普发表演讲后佩洛西就将其国情咨文讲稿给撕了，开始演讲前佩洛西给特朗普打招呼也没反应，总之就很尴尬，具体的视频可以看<a href="https://www.youtube.com/watch?v=fvJkcCRyVSI" target="_blank" rel="external nofollow noopener noreferrer">这里</a>。</p><p>除了众议院议长外，接下来就是 <a href="https://en.wikipedia.org/wiki/Party_leaders_of_the_United_States_House_of_Representatives" target="_blank" rel="external nofollow noopener noreferrer">House Party Leader</a> ：</p><ul><li>多数派领袖：多数党的党内二号领导人</li><li>多数派党鞭：多数党的党内三号领导人，Frank Underwood 即是作为民主党党鞭，试图确保本党议员参与议会议事并按本党意志投票。按照「纸牌屋」里面表现的，最关键的事情就是数票数，确保某项法案得以在众议院通过。</li><li>少数派领袖：少数党的党内一号领导人</li><li>少数派党鞭：少数党的党内二号领导人</li></ul><p>与参议员相比，众议员较依赖所属政党，并通常会依照政党领袖意向来投票。政党领袖选择委员会主席的权力可激励议员们合作。其结果是，众议院中的领导地位较参议院中重要，众议院中的氛围被认为更具党派之见。</p><h3 id="内阁"><a href="#内阁" class="headerlink" title="内阁"></a>内阁</h3><p>大选结束后，当选总统可以自己组建内阁，自己向参议院提名候选人，经参议院审批和同意后，任命大使、公使及领事、最高法院的法官等各种行政部门领导人。从法理上说，美国总统从是美国的联邦政府行政分支的领导人和负责人，而内阁不过是总统的辅助结构和下属，没有宪法上的独立地位和法人代表权。</p><p>下面对于美国内阁关键角色进行介绍，参考 <a href="https://en.wikipedia.org/wiki/Cabinet_of_the_United_States" target="_blank" rel="external nofollow noopener noreferrer">美国内阁</a>：</p><h4 id="Vice-President"><a href="#Vice-President" class="headerlink" title="Vice President"></a>Vice President</h4><p>副总统和总统一同由选举产生，他既是美国行政分支的第二位领导人，也是立法分支参议院的议长。一旦总统于任内死亡、辞职或被撤职，副总统会立刻继任。</p><ul><li>1963年，美国总统约翰 · 肯尼迪遇刺身亡，时任副总统 林登 · 约翰逊继任美国总统</li><li>1974年，美国总统尼克松因为水门事件遭遇弹劾，尼克松主动请辞，杰拉尔德·福特继任美国总统</li><li>拜登政府的副总统位哈里斯，是为美国首任女性副总统。</li></ul><h4 id="Secretary-of-State"><a href="#Secretary-of-State" class="headerlink" title="Secretary of State"></a>Secretary of State</h4><p>国务卿，是美国内阁中所有成员的首席，主管外交事务，相当于其他国家的外交部长。</p><p>按照美国总统继任顺序，国务卿排在第四位，排在美国副总统、众议院议长、参议院临时议长之后。而副总统和参议院临时议长更多具有象征意义，美国政治权力当中，国务卿的真正实权相比副总统和参议院临时议长还要大，故国务卿的真正权力仅次于总统和美国众议院议长。</p><ul><li>基辛格曾任尼克松的国务卿</li><li>希拉里曾任奥巴马的国务卿</li></ul><h4 id="Secretary-of-the-Treasury"><a href="#Secretary-of-the-Treasury" class="headerlink" title="Secretary of the Treasury"></a>Secretary of the Treasury</h4><p>财政部长，负责财政和金融事务。财政部长是美国总统的<strong>主要经济顾问</strong>，是政府经济和<strong>财政政策</strong>的关键制定者，负责国内和国际金融、经济和财税政策的阐叙，管理国债，监督财政部执法机关的执法行为等事务，并担任美国政府的财务代理人。</p><p>按照美国总统继任顺序，国务卿排在第五位，排在国务卿之后。</p><ul><li>汉密尔顿是美国首任财政部部长，建立了美国中央银行，奠定了美国经济体系的基本框架</li><li><a href="https://zh.wikipedia.org/wiki/亨利·保尔森" target="_blank" rel="external nofollow noopener noreferrer">亨利·保尔森</a> 是2008年金融危机期间的财政部长，其在08年金融危机中的应对措施至今仍充满争议</li><li>拜登政府的财政部长为<strong><a href="https://en.wikipedia.org/wiki/Janet_Yellen" target="_blank" rel="external nofollow noopener noreferrer">Janet Yellen</a></strong> ，其曾在2014年到2018年担任美联储主席</li></ul><h4 id="Secretary-of-Defense"><a href="#Secretary-of-Defense" class="headerlink" title="Secretary of Defense"></a>Secretary of Defense</h4><p>国防部长</p><h4 id="Attorney-General"><a href="#Attorney-General" class="headerlink" title="Attorney General"></a>Attorney General</h4><p>司法部长</p><p>除此之外，还有一些内阁级别的官员</p><h4 id="White-House-Chief-of-Staff"><a href="#White-House-Chief-of-Staff" class="headerlink" title="White House Chief of Staff"></a>White House Chief of Staff</h4><p>白宫办公厅主任，也称作白宫幕僚长。</p><h3 id="最高法院"><a href="#最高法院" class="headerlink" title="最高法院"></a>最高法院</h3><p>美国最高法院通常由一名首席大法官和八名大法官组成。大法官均有美国总统提名，并在美国参议院投票通过后方可任命。一旦获参议院确认任命，法官享有终身任期，他们就无需再服从其原先的政党、总统、参议院的意志来审判。法官保留他们的职位直到去世、辞职、退休或弹劾（不过至今未出现法官被罢免的情况）</p><p>当前首席大法官为罗伯茨，下图是2020年9月18日前美国九大大法官合照，罗伯茨处于最中间。在其两次分别是托马斯大法官和金斯伯格大法官。2020年9月18日，金斯伯格 (RBG) 大法官去世，之后特朗普提名 <strong><a href="https://zh.wikipedia.org/wiki/艾米·康尼·巴雷特" target="_blank" rel="external nofollow noopener noreferrer">艾米·康尼·巴雷特</a></strong> 进入最高法院。</p><p>在金斯伯格大法官去世前，首席大法官罗伯茨被认为是法院的中位数大法官（处于意识形态光谱的中间，有四位大法官比他更自由，四位大法官比他更保守），使他成为法院的意识形态中心。金斯伯格大法官去世后，美国最高法院越加保守。</p><p><img alt="罗伯茨法院，2018.10.06-2020.09.18" data-src="https://upload.wikimedia.org/wikipedia/commons/c/c7/Supreme_Court_of_the_United_States_-_Roberts_Court_2018.jpg"></p><h2 id="选举总统"><a href="#选举总统" class="headerlink" title="选举总统"></a>选举总统</h2><h3 id="党内初选"><a href="#党内初选" class="headerlink" title="党内初选"></a>党内初选</h3><h3 id="总统大选"><a href="#总统大选" class="headerlink" title="总统大选"></a>总统大选</h3><h2 id="媒体监督"><a href="#媒体监督" class="headerlink" title="媒体监督"></a>媒体监督</h2>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;「阅读光影」是在2021年新推出的栏目，涉及到阅读与光影，主要用于记录阅读和观影中的感悟与笔记，作为内容输入的输出管道。在今年的后续时间里，将按照2021的 &lt;a href=&quot;https://www.douban.com/doulist/133636602/&quot; target=&quot;_blank&quot; rel=&quot;external nofollow noopener noreferrer&quot;&gt;阅读计划&lt;/a&gt; 和 &lt;a href=&quot;https://www.douban.com/doulist/133864290/&quot; target=&quot;_blank&quot; rel=&quot;external nofollow noopener noreferrer&quot;&gt;观影计划&lt;/a&gt;，对所读所看的内容进行记录与总结。&lt;/p&gt;
&lt;p&gt;这里是2021年「阅读光影」第一期：&lt;code&gt;从「纸牌屋」看美国政治生态&lt;/code&gt;，将以纸牌屋为起点，介绍美国政治的宏观图景。在拜登总统即将就职的当下，在特朗普总统遭到历史上首次的第二次弹劾的当下，在美国国会遭遇两百年来的首次占领的当下，美国的政治图景开始在眼前越发的生动立体。&lt;/p&gt;

    &lt;div id=&quot;aplayer-IGflgVCK&quot; class=&quot;aplayer aplayer-tag-marker meting-tag-marker&quot; data-id=&quot;26238376&quot; data-server=&quot;netease&quot; data-type=&quot;song&quot; data-mode=&quot;circulation&quot; data-autoplay=&quot;false&quot; data-mutex=&quot;true&quot; data-listmaxheight=&quot;340px&quot; data-preload=&quot;auto&quot; data-theme=&quot;#555&quot;&gt;&lt;/div&gt;
    
    </summary>
    
    <content src="http://houmin.cc/https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2021-01-10_house-of-cards.jpeg" type="image" />
    
    
      <category term="阅读光影" scheme="http://houmin.cc/categories/%E9%98%85%E8%AF%BB%E5%85%89%E5%BD%B1/"/>
    
    
      <category term="美国" scheme="http://houmin.cc/tags/%E7%BE%8E%E5%9B%BD/"/>
    
      <category term="政治" scheme="http://houmin.cc/tags/%E6%94%BF%E6%B2%BB/"/>
    
  </entry>
  
  <entry>
    <title>【系统监控】GPU 监控</title>
    <link href="http://houmin.cc/posts/b4058e1b/"/>
    <id>http://houmin.cc/posts/b4058e1b/</id>
    <published>2021-01-06T03:01:35.000Z</published>
    <updated>2021-01-07T08:47:52.346Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2 id="问题背景"><a href="#问题背景" class="headerlink" title="问题背景"></a>问题背景</h2><p>在使用GPU进行深度学习相关的训练与推理时，需要查看当前集群中GPU的使用情况：</p><ul><li>需要通过当前GPU设备资源使用情况判断是否可以再部署新的应用，判断集群是否需要扩容，为GPU服务提供对齐CPU的容量保障服务，补齐容量保障中的GPU短板</li><li>需要通过当前GPU设备资源使用情况分析使用中存在的瓶颈和短板，推进优化，提高资源利用率和服务性能</li></ul><a id="more"></a><p>为了获得GPU的监控数据，NVIDIA 提供了以下三种方法：</p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2021-01-06_nvidia-managing-tools.png"></p><ul><li><a href="https://developer.nvidia.com/nvidia-management-library-nvml" target="_blank" rel="external nofollow noopener noreferrer">NVML</a>：NVIDIA Management Library，基于C进行监控和管理GPU的库，<code>nvidia-smi</code> 命令即是基于此实现的</li><li><a href="https://developer.nvidia.com/dcgm" target="_blank" rel="external nofollow noopener noreferrer">DCGM</a>：Data Center GPU Manager，基于NVML和CUDA实现的一整套GPU的监控和管理工具</li><li>第三方工具：基于 DCGM 或者 NVML 开发的第三方监控工具，可以与Prometheus等工具结合，提供数据库、UI等工具</li></ul><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2021-01-06_nvidia-dcgm.png"></p><p>对比这三种工具的特点：</p><ul><li>NVML<ul><li>无状态的查询，只支持查询当前数据</li><li>属于低级别控制GPU的API</li><li>基于NVML库开发的管理工具运行成本低，开发成本高</li><li>基于NVML库开发的管理工具必须与GPU运行在同一个节点</li></ul></li><li>DCGM<ul><li>可以查询几个小时的数据指标</li><li>提供了GPU的健康检查和诊断</li><li>可以对一组GPU进行批量查询</li><li>允许以 <code>remote/local</code> 两种方式运行</li></ul></li><li>第三方工具<ul><li>提供了database、graphs和好看的UI</li></ul></li></ul><p>本文后续将主要介绍 DCGM。</p><h2 id="DCGM"><a href="#DCGM" class="headerlink" title="DCGM"></a>DCGM</h2><p>下图展示了 <code>DCGM</code> 在集群中运行的方式，<code>DCGM</code> 以 Agent 的形式部署在计算节点上，管理节点上的工具可以通过 <code>DCGM</code> 提供的API管理和监控GPU。</p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2021-01-06_nvidia-dcgm-icon.png"></p><p><code>DCGM</code> 提供了一下四种关键特性：</p><ul><li><strong>Active Health Monitoring</strong></li><li><strong>GPU Diagnostics</strong></li><li><strong>Policy and Alerting</strong></li><li><strong>Configuration Managerment</strong></li></ul><h3 id="安装部署"><a href="#安装部署" class="headerlink" title="安装部署"></a>安装部署</h3><p>DCGM 需要单独下载安装，在NVIDIA官网<a href="https://developer.nvidia.com/dcgm#Downloads" target="_blank" rel="external nofollow noopener noreferrer">NVIDIA</a>下载对应的安装包，这里选择下载rpm包即可，下载完成后：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 卸载可能已安装的旧版本DCGM</span></span><br><span class="line">$ yum remove datacenter-gpu-manager</span><br><span class="line"><span class="comment"># 安装</span></span><br><span class="line">$ rpm -ivh datacenter-gpu-manager-2.0.13-1-x86_64.rpm</span><br></pre></td></tr></table></figure><ul><li>DCGM的动态链接库会被安装到<code>/usr/lib64</code>目录</li><li>Python库会被安装到<code>/usr/local/dcgm/bindings</code>目录</li></ul><p>DCGM 是一个面向集群管理的工具，所以在实际使用前，需要先在目标机器启动一个agent，<code>nv-hostengine</code>，具体启动命令如下</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动 nv-hostengine</span></span><br><span class="line">$ nv-hostengine --port 39999 --<span class="built_in">bind</span>-interface 127.0.0.1</span><br><span class="line">Host Engine Listener Started</span><br><span class="line">Started host engine version 2.0.13 using port number: 39999</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看设备列表</span></span><br><span class="line">$ dcgmi discovery --host 127.0.0.1:39999 -l</span><br><span class="line">4 GPUs found.</span><br><span class="line">+--------+----------------------------------------------------------------------+</span><br><span class="line">| GPU ID | Device Information                                                   |</span><br><span class="line">+--------+----------------------------------------------------------------------+</span><br><span class="line">| 0      | Name: Tesla T4                                                       |</span><br><span class="line">|        | PCI Bus ID: 00000000:00:08.0                                         |</span><br><span class="line">|        | Device UUID: GPU-0bf43c76-0f1a-f49f-a362-92d5b9bbbc9f                |</span><br><span class="line">+--------+----------------------------------------------------------------------+</span><br><span class="line">| 1      | Name: Tesla T4                                                       |</span><br><span class="line">|        | PCI Bus ID: 00000000:00:09.0                                         |</span><br><span class="line">|        | Device UUID: GPU-c55a4e5e-47dd-48c2-99d0-2630042bf619                |</span><br><span class="line">+--------+----------------------------------------------------------------------+</span><br><span class="line">| 2      | Name: Tesla T4                                                       |</span><br><span class="line">|        | PCI Bus ID: 00000000:00:0A.0                                         |</span><br><span class="line">|        | Device UUID: GPU-95e5fe58-f03d-815e-c871-65637b623aca                |</span><br><span class="line">+--------+----------------------------------------------------------------------+</span><br><span class="line">| 3      | Name: Tesla T4                                                       |</span><br><span class="line">|        | PCI Bus ID: 00000000:00:0B.0                                         |</span><br><span class="line">|        | Device UUID: GPU-70747d1b-2b7a-9895-29f5-485608c1742e                |</span><br><span class="line">+--------+----------------------------------------------------------------------+</span><br><span class="line">0 NvSwitches found.</span><br><span class="line">+-----------+</span><br><span class="line">| Switch ID |</span><br><span class="line">+-----------+</span><br><span class="line">+-----------+</span><br><span class="line"></span><br><span class="line"><span class="comment"># 关闭 nv-hostengine，这里作演示用，后续的过程还要继续打开</span></span><br><span class="line">$ nv-hostengine –t</span><br><span class="line">Host engine successfully terminated.</span><br></pre></td></tr></table></figure><p>其中，<code>--port</code> <code>--bind-interface</code> 两个参数分别用来设置监听的端口和绑定的IP地址。同时也支持使用 <code>UNIX_SOCKET</code> 通信</p><p>在启动 <code>nv-hostengine</code> 之后，我们就可以使用 <code>dcgmi</code> 来操作</p><h3 id="组操作"><a href="#组操作" class="headerlink" title="组操作"></a>组操作</h3><p>和NVML不同，DCGM 的大部分功能都是面向组的，所以在使用DCGM之前，首先需要创建组，然后才能使用DCGM提供的各种功能。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 获取设备列表后，可以用如下命令创建组</span></span><br><span class="line"><span class="comment"># 创建成功后，该命令会输出如下，返回设备的组ID，后续的操作中都会用到组ID，例如下面的组ID 2</span></span><br><span class="line">$ dcgmi group --host 127.0.0.1:39999 -c GPU_GROUP</span><br><span class="line">Successfully created group <span class="string">"GPU_GROUP"</span> with a group ID of 2</span><br><span class="line"></span><br><span class="line">$ dcgmi group --host 127.0.0.1:39999 -l</span><br><span class="line">+-------------------+----------------------------------------------------------+</span><br><span class="line">| GROUPS                                                                       |</span><br><span class="line">| 1 group found.                                                               |</span><br><span class="line">+===================+==========================================================+</span><br><span class="line">| Groups            |                                                          |</span><br><span class="line">| -&gt; 2              |                                                          |</span><br><span class="line">|    -&gt; Group ID    | 2                                                        |</span><br><span class="line">|    -&gt; Group Name  | GPU_GROUP                                                |</span><br><span class="line">|    -&gt; Entities    | None                                                     |</span><br><span class="line">+-------------------+----------------------------------------------------------+</span><br><span class="line"></span><br><span class="line">$ dcgmi discovery --host 127.0.0.1:39999 -l </span><br><span class="line">4 GPUs found.</span><br><span class="line">+--------+----------------------------------------------------------------------+</span><br><span class="line">| GPU ID | Device Information                                                   |</span><br><span class="line">+--------+----------------------------------------------------------------------+</span><br><span class="line">| 0      | Name: Tesla T4                                                       |</span><br><span class="line">|        | PCI Bus ID: 00000000:00:08.0                                         |</span><br><span class="line">|        | Device UUID: GPU-0bf43c76-0f1a-f49f-a362-92d5b9bbbc9f                |</span><br><span class="line">+--------+----------------------------------------------------------------------+</span><br><span class="line">| 1      | Name: Tesla T4                                                       |</span><br><span class="line">|        | PCI Bus ID: 00000000:00:09.0                                         |</span><br><span class="line">|        | Device UUID: GPU-c55a4e5e-47dd-48c2-99d0-2630042bf619                |</span><br><span class="line">+--------+----------------------------------------------------------------------+</span><br><span class="line">| 2      | Name: Tesla T4                                                       |</span><br><span class="line">|        | PCI Bus ID: 00000000:00:0A.0                                         |</span><br><span class="line">|        | Device UUID: GPU-95e5fe58-f03d-815e-c871-65637b623aca                |</span><br><span class="line">+--------+----------------------------------------------------------------------+</span><br><span class="line">| 3      | Name: Tesla T4                                                       |</span><br><span class="line">|        | PCI Bus ID: 00000000:00:0B.0                                         |</span><br><span class="line">|        | Device UUID: GPU-70747d1b-2b7a-9895-29f5-485608c1742e                |</span><br><span class="line">+--------+----------------------------------------------------------------------+</span><br><span class="line">0 NvSwitches found.</span><br><span class="line">+-----------+</span><br><span class="line">| Switch ID |</span><br><span class="line">+-----------+</span><br><span class="line">+-----------+</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建组后可以用如下命令给组中添加设备</span></span><br><span class="line">$ dcgmi group --host 127.0.0.1:39999 -g 2 -a 0,1</span><br><span class="line">Add to group operation successful.</span><br><span class="line"></span><br><span class="line">$ dcgmi group --host 127.0.0.1:39999 -g 2 -i</span><br><span class="line">+-------------------+----------------------------------------------------------+</span><br><span class="line">| GROUP INFO                                                                   |</span><br><span class="line">+===================+==========================================================+</span><br><span class="line">| 2                 |                                                          |</span><br><span class="line">| -&gt; Group ID       | 2                                                        |</span><br><span class="line">| -&gt; Group Name     | GPU_GROUP                                                |</span><br><span class="line">| -&gt; Entities       | GPU 0, GPU 1                                             |</span><br><span class="line">+-------------------+----------------------------------------------------------+</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用如下命令可以从组中删除设备</span></span><br><span class="line">$ dcgmi group --host 127.0.0.1:39999 -g 2 -r 0,1</span><br><span class="line">Remove from group operation successful.</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用如下命令可以从删除组</span></span><br><span class="line">$ dcgmi group --host 127.0.0.1:39999 -d 2</span><br></pre></td></tr></table></figure><blockquote><p>注意：group和设备之间是多对多关系</p></blockquote><h3 id="Job-Statistics"><a href="#Job-Statistics" class="headerlink" title="Job Statistics"></a>Job Statistics</h3><p>当有一个Job需要通过GPU加速计算的时候，我们想知道：</p><ul><li>我的Job运行在哪个GPU上</li><li>我的Job使用了多少GPU</li><li>在我的Job运行过程中是否有任何的错误和Warning</li><li>系统的GPU是否都健康并且准备好了下一个Job的计算</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 当前 Group 3 如下</span></span><br><span class="line">$ dcgmi group --host 127.0.0.1:39999 -g 3 -i</span><br><span class="line">+-------------------+----------------------------------------------------------+</span><br><span class="line">| GROUP INFO                                                                   |</span><br><span class="line">+===================+==========================================================+</span><br><span class="line">| 3                 |                                                          |</span><br><span class="line">| -&gt; Group ID       | 3                                                        |</span><br><span class="line">| -&gt; Group Name     | GPU_GROUP                                                |</span><br><span class="line">| -&gt; Entities       | GPU 0, GPU 1, GPU 2, GPU 3                               |</span><br><span class="line">+-------------------+----------------------------------------------------------+</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在使用dcgmi获取GPU统计数据，需要先打开数据分析功能，具体命令如下</span></span><br><span class="line">$ dcgmi stats --host 127.0.0.1:39999 -g 3 --<span class="built_in">enable</span></span><br><span class="line">Successfully started process watches.</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打开数据分析功能后，可以使用如下命令查看具体的进程的统计信息</span></span><br><span class="line"><span class="comment"># 假设这里启动了一个CUDA应用进程正在使用GPU进行计算</span></span><br><span class="line">$ dcgmi stats --host 127.0.0.1:39999 -g 3 -p 41861 -v</span><br><span class="line">Successfully retrieved process info <span class="keyword">for</span> PID: 41861. Process ran on 1 GPUs.</span><br><span class="line">+------------------------------------------------------------------------------+</span><br><span class="line">| GPU ID: 3                                                                    |</span><br><span class="line">+====================================+=========================================+</span><br><span class="line">|-----  Execution Stats  ------------+-----------------------------------------|</span><br><span class="line">| Start Time                     *   | Wed Jan  6 16:54:16 2021                |</span><br><span class="line">| End Time                       *   | Still Running                           |</span><br><span class="line">| Total Execution Time (sec)     *   | Still Running                           |</span><br><span class="line">| No. of Conflicting Processes   *   | 0                                       |</span><br><span class="line">+-----  Performance Stats  ----------+-----------------------------------------+</span><br><span class="line">| Energy Consumed (Joules)           | 2985                                    |</span><br><span class="line">| Max GPU Memory Used (bytes)    *   | 12107907072                             |</span><br><span class="line">| SM Clock (MHz)                     | Avg: 1590, Max: 1590, Min: 1590         |</span><br><span class="line">| Memory Clock (MHz)                 | Avg: 5000, Max: 5000, Min: 5000         |</span><br><span class="line">| SM Utilization (%)                 | Avg: 100, Max: 100, Min: 100            |</span><br><span class="line">| Memory Utilization (%)             | Avg: 5, Max: 5, Min: 5                  |</span><br><span class="line">| PCIe Rx Bandwidth (megabytes)      | Avg: N/A, Max: N/A, Min: N/A            |</span><br><span class="line">| PCIe Tx Bandwidth (megabytes)      | Avg: N/A, Max: N/A, Min: N/A            |</span><br><span class="line">+-----  Event Stats  ----------------+-----------------------------------------+</span><br><span class="line">| Double Bit ECC Errors              | 0                                       |</span><br><span class="line">| PCIe Replay Warnings               | 0                                       |</span><br><span class="line">| Critical XID Errors                | 0                                       |</span><br><span class="line">+-----  Slowdown Stats  -------------+-----------------------------------------+</span><br><span class="line">| Due to - Power (%)                 | 0                                       |</span><br><span class="line">|        - Thermal (%)               | 0                                       |</span><br><span class="line">|        - Reliability (%)           | 0                                       |</span><br><span class="line">|        - Board Limit (%)           | 0                                       |</span><br><span class="line">|        - Low Utilization (%)       | 0                                       |</span><br><span class="line">|        - Sync Boost (%)            | 0                                       |</span><br><span class="line">+-----  Process Utilization  --------+-----------------------------------------+</span><br><span class="line">| PID                                | 41861                                   |</span><br><span class="line">|     Avg SM Utilization (%)         | 99                                      |</span><br><span class="line">|     Avg Memory Utilization (%)     | 3                                       |</span><br><span class="line">+-----  Overall Health  -------------+-----------------------------------------+</span><br><span class="line">| Overall Health                     | Healthy                                 |</span><br><span class="line">+------------------------------------+-----------------------------------------+</span><br><span class="line"></span><br><span class="line">(*) Represents a process statistic. Otherwise device statistic during</span><br><span class="line">    process lifetime listed.</span><br></pre></td></tr></table></figure><h3 id="Configuration-Managerment"><a href="#Configuration-Managerment" class="headerlink" title="Configuration Managerment"></a>Configuration Managerment</h3><p>DCGM 可以更改GPU设置, 具体支持的设置项如下，查看原有设置：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">$ dcgmi config  --host 127.0.0.1:39999 -g 3 --get</span><br><span class="line">+------------------------------+------------------------------+------------------------------+</span><br><span class="line">| GPU_GROUP                                                                                  |</span><br><span class="line">| Group of 4 GPUs                                                                            |</span><br><span class="line">+==============================+==============================+==============================+</span><br><span class="line">| Field                        | Target                       | Current                      |</span><br><span class="line">+------------------------------+------------------------------+------------------------------+</span><br><span class="line">| Compute Mode                 | Not Specified                | Unrestricted                 |</span><br><span class="line">| ECC Mode                     | Not Specified                | Enabled                      |</span><br><span class="line">| Sync Boost                   | Not Specified                | Not Supported                |</span><br><span class="line">| Memory Application Clock     | Not Specified                | 5001                         |</span><br><span class="line">| SM Application Clock         | Not Specified                | 585                          |</span><br><span class="line">| Power Limit                  | Not Specified                | 70                           |</span><br><span class="line">+------------------------------+------------------------------+------------------------------+</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 具体参数说明</span></span><br><span class="line">$ dcgmi config -h</span><br><span class="line"></span><br><span class="line"> config -- Used to configure settings <span class="keyword">for</span> groups of GPUs.</span><br><span class="line"></span><br><span class="line">Usage: dcgmi config</span><br><span class="line">   dcgmi config [--host &lt;IP/FQDN&gt;] [-g &lt;groupId&gt;] --enforce</span><br><span class="line">   dcgmi config [--host &lt;IP/FQDN&gt;] [-g &lt;groupId&gt;] --get [-v] [-j]</span><br><span class="line">   dcgmi config [--host &lt;IP/FQDN&gt;] [-g &lt;groupId&gt;] --<span class="built_in">set</span> [-e &lt;0/1&gt;] [-s</span><br><span class="line">        &lt;0/1&gt;] [-a &lt;mem,proc&gt;] [-P &lt;<span class="built_in">limit</span>&gt;] [-c &lt;mode&gt;]</span><br><span class="line">  </span><br><span class="line">  ...</span><br><span class="line">  -c  --compmode   mode       Configure Compute Mode. Can be any of the</span><br><span class="line">                               following:</span><br><span class="line">                               0 - Unrestricted</span><br><span class="line">                               1 - Prohibited</span><br><span class="line">                               2 - Exclusive Process</span><br><span class="line">  -P  --powerlimit <span class="built_in">limit</span>      Configure Power Limit (Watts).</span><br><span class="line">  -a  --appclocks  mem,proc   Configure Application Clocks. Must use memory,proc</span><br><span class="line">                               clocks (csv) format(MHz).</span><br><span class="line">  -s  --syncboost  0/1        Configure Syncboost. (1 to Enable, 0 to Disable)</span><br><span class="line">  -e  --eccmode    0/1        Configure Ecc mode. (1 to Enable, 0 to Disable)</span><br><span class="line">  </span><br><span class="line"><span class="comment"># 更改设置</span></span><br><span class="line">$ dcgmi config  --host 127.0.0.1:39999 -g 3 --<span class="built_in">set</span> -c 2</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查询结果</span></span><br><span class="line">$ dcgmi config  --host 127.0.0.1:39999 -g 3 --get</span><br><span class="line">+------------------------------+------------------------------+------------------------------+</span><br><span class="line">| GPU_GROUP                                                                                  |</span><br><span class="line">| Group of 4 GPUs                                                                            |</span><br><span class="line">+==============================+==============================+==============================+</span><br><span class="line">| Field                        | Target                       | Current                      |</span><br><span class="line">+------------------------------+------------------------------+------------------------------+</span><br><span class="line">| Compute Mode                 | E. Process                   | E. Process                   |</span><br><span class="line">| ECC Mode                     | Not Specified                | Enabled                      |</span><br><span class="line">| Sync Boost                   | Not Specified                | Not Supported                |</span><br><span class="line">| Memory Application Clock     | Not Specified                | 5001                         |</span><br><span class="line">| SM Application Clock         | Not Specified                | 585                          |</span><br><span class="line">| Power Limit                  | Not Specified                | 70                           |</span><br><span class="line">+------------------------------+------------------------------+------------------------------+</span><br></pre></td></tr></table></figure><blockquote><p>注意，使用DCGM更改设置时，运作模式是一种面向声明的模式，用户通过dcgmi指定需要的目标设置，同时nv-hostengine自动调整设置，使当前设置对齐目标设置</p></blockquote><h3 id="Policy-and-Alerting"><a href="#Policy-and-Alerting" class="headerlink" title="Policy and Alerting"></a>Policy and Alerting</h3><p>dcgm 的提供了policy 功能，policy 本质上是类似于一种Watch机制，首先设定一个<code>违反</code>条件，然后可以根据<code>违反</code>条件设置对应的处理策略。一般而言，可以设置一个条件，然后注册listener，等待dcgm通知。</p><p><img alt data-src="https://developer-blogs.nvidia.com/wp-content/uploads/2016/08/image01-300x125.png"></p><p>例如</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过如下命令设置最大温度50度的条件</span></span><br><span class="line">$ dcgmi policy --host 127.0.0.1:39999 -g 3 --<span class="built_in">set</span> 0,0 -T 50</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置后的policy，通过如下命令查询</span></span><br><span class="line">$ dcgmi policy --host 127.0.0.1:39999 -g 2 --get</span><br><span class="line">Policy information</span><br><span class="line">+-----------------------------+------------------------------------------------+</span><br><span class="line">| Policy Information                                                           |</span><br><span class="line">| GPU_GROUP                                                                    |</span><br><span class="line">+=============================+================================================+</span><br><span class="line">| Violation conditions        | Max temperature threshold - 50                 |</span><br><span class="line">| Isolation mode              | Manual                                         |</span><br><span class="line">| Action on violation         | None                                           |</span><br><span class="line">| Validation after action     | None                                           |</span><br><span class="line">| Validation failure action   | None                                           |</span><br><span class="line">+-----------------------------+------------------------------------------------+</span><br><span class="line"></span><br><span class="line">$ dcgmi policy --host 127.0.0.1:39999 -g 2 --reg</span><br><span class="line">Timestamp: Wed Jan  6 17:02:27 2021</span><br><span class="line">The maximum thermal <span class="built_in">limit</span> has violated policy manager values.</span><br><span class="line">Temperature: 65</span><br><span class="line">Listening <span class="keyword">for</span> violations.</span><br><span class="line">Timestamp: Wed Jan  6 17:02:37 2021</span><br><span class="line">The maximum thermal <span class="built_in">limit</span> has violated policy manager values.</span><br><span class="line">Temperature: 65</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>参数设置</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"> --<span class="built_in">set</span>        actn,val   (OR required)  Set the current violation policy.</span><br><span class="line">                             Use csv action,validation (ie. 1,2)</span><br><span class="line">                             -----</span><br><span class="line">                             Action to take when any of the violations</span><br><span class="line">                             specified occur.</span><br><span class="line">                             0 - None</span><br><span class="line">                             1 - GPU Reset</span><br><span class="line">                             -----</span><br><span class="line">                             Validation to take after the violation action has</span><br><span class="line">                             been performed.</span><br><span class="line">                             0 - None</span><br><span class="line">                             1 - System Validation (short)</span><br><span class="line">                             2 - System Validation (medium)</span><br><span class="line">                             3 - System Validation (long)</span><br><span class="line">-x  --xiderrors             Add XID errors to the policy conditions.</span><br><span class="line">-n  --nvlinkerrors           Add NVLink errors to the policy conditions.</span><br><span class="line">-p  --pcierrors             Add PCIe replay errors to the policy conditions.</span><br><span class="line">-e  --eccerrors             Add ECC double bit errors to the policy</span><br><span class="line">                             conditions.</span><br><span class="line">-P  --maxpower   max        Specify the maximum power a group<span class="string">'s GPUs can reach</span></span><br><span class="line"><span class="string">                             before triggering a violation.</span></span><br><span class="line"><span class="string">-T  --maxtemp    max        Specify the maximum temperature a group'</span>s GPUs can</span><br><span class="line">                             reach before triggering a violation.</span><br><span class="line">-M  --maxpages   max        Specify the maximum number of retired pages that</span><br><span class="line">                             will trigger a violation.</span><br></pre></td></tr></table></figure><h3 id="Health-check"><a href="#Health-check" class="headerlink" title="Health check"></a>Health check</h3><p><code>DCGM</code> 的健康检查是无侵入式的检查，提供了实时监控和聚合的健康数据，其运行机制是</p><ol><li>打开健康检查，设置需要检查的项</li><li>DCGM在后台运行，根据设置监控对应组件状态</li><li>用户通过<code>dcgmi health</code>命令查询当前发现的错误</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">$ dcgmi health --check -g 1</span><br><span class="line">Health Monitor Report</span><br><span class="line">+------------------+---------------------------------------------------------+</span><br><span class="line">| Overall Health:   Healthy                                                  |</span><br><span class="line">+==================+=========================================================+</span><br><span class="line"></span><br><span class="line">$ dcgmi health --check -g 1 </span><br><span class="line">Health Monitor Report</span><br><span class="line">+----------------------------------------------------------------------+</span><br><span class="line">| Group 1       | Overall Health: Warning                              |</span><br><span class="line">+==================+===================================================+</span><br><span class="line">| GPU ID: 0     | Warning                                              |</span><br><span class="line">|               | PCIe system: Warning - Detected more than 8 PCIe     |</span><br><span class="line">|               | replays per minute <span class="keyword">for</span> GPU 0: 13                     |</span><br><span class="line">+---------------+------------------------------------------------------+</span><br><span class="line">| GPU ID: 1     | Warning                                              |</span><br><span class="line">|               | InfoROM system: Warning - A corrupt InfoROM has been |</span><br><span class="line">|               | detected <span class="keyword">in</span> GPU 1.                                   |</span><br><span class="line">+---------------+------------------------------------------------------+</span><br></pre></td></tr></table></figure><h3 id="GPU-Diagnostics"><a href="#GPU-Diagnostics" class="headerlink" title="GPU Diagnostics"></a>GPU Diagnostics</h3><p>诊断是主动检查的模式，提供了三个级别的检查，每次运行时会根据运行级别，运行对应的测试程序，来发现问题。</p><p>运行命令如下</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">$ dcgmi diag --host 127.0.0.1:39999 -g 3 -r 1</span><br><span class="line">Successfully ran diagnostic <span class="keyword">for</span> group.</span><br><span class="line">+---------------------------+------------------------------------------------+</span><br><span class="line">| Diagnostic                | Result                                         |</span><br><span class="line">+===========================+================================================+</span><br><span class="line">|-----  Deployment  --------+------------------------------------------------|</span><br><span class="line">| Blacklist                 | Pass                                           |</span><br><span class="line">| NVML Library              | Pass                                           |</span><br><span class="line">| CUDA Main Library         | Pass                                           |</span><br><span class="line">| Permissions and OS Blocks | Pass                                           |</span><br><span class="line">| Persistence Mode          | Pass                                           |</span><br><span class="line">| Environment Variables     | Pass                                           |</span><br><span class="line">| Page Retirement           | Pass                                           |</span><br><span class="line">| Graphics Processes        | Pass                                           |</span><br><span class="line">| Inforom                   | Pass                                           |</span><br><span class="line">+---------------------------+------------------------------------------------+</span><br></pre></td></tr></table></figure><h3 id="Profile"><a href="#Profile" class="headerlink" title="Profile"></a>Profile</h3><p>profile功能可以用较小的性能消耗获取GPU卡的利用率数据以及进程的性能数据，profile功能对于驱动版本和卡的类型有一些强制要求，具体是</p><ol><li>DCGM 版本大于1.7</li><li>驱动版本大于418.43</li><li>nv-hostengine 以root身份启动</li><li>目前只支持Tesla V100、Tesla T4卡</li></ol><p>可以获取的性能指标有</p><div class="table-container"><table><thead><tr><th style="text-align:left">指标</th><th style="text-align:left">说明</th><th style="text-align:left">FIELD_NAME</th></tr></thead><tbody><tr><td style="text-align:left">Graphics Engine Activity</td><td style="text-align:left">Ratio of time the graphics engine is active. The graphics engine is active if a graphics/compute context is bound and the graphics pipe or compute pipe is busy. PROF_GR_ENGINE_ACTIVE (ID: 1001)</td><td style="text-align:left"></td></tr><tr><td style="text-align:left">SM Activity</td><td style="text-align:left">The ratio of cycles an SM has at least 1 warp assigned (computed from the number of cycles and elapsed cycles)</td><td style="text-align:left">PROF_SM_ACTIVE (ID: 1002)</td></tr><tr><td style="text-align:left">SM Occupancy</td><td style="text-align:left">The ratio of number of warps resident on an SM. (number of resident warps as a percentage of the theoretical maximum number of warps per elapsed cycle)</td><td style="text-align:left">PROF_SM_OCCUPANCY (ID: 1003)</td></tr><tr><td style="text-align:left">Tensor Activity</td><td style="text-align:left">The ratio of cycles the tensor (HMMA) pipe is active (off the peak sustained elapsed cycles)</td><td style="text-align:left">PROF_PIPE_TENSOR_ACTIVE (ID: 1004)</td></tr><tr><td style="text-align:left">Memory BW Utilization</td><td style="text-align:left">The ratio of cycles the device memory interface is active sending or receiving data.</td><td style="text-align:left">PROF_DRAM_ACTIVE (ID: 1005)</td></tr><tr><td style="text-align:left">Engine Activity</td><td style="text-align:left">Ratio of cycles the fp64 /fp32 / fp16 / HMMA / IMMA pipes are active.</td><td style="text-align:left">PROF_PIPE_FPXY_ACTIVE (ID: 1006 (FP64); 1007 (FP32); 1008 (FP16))</td></tr><tr><td style="text-align:left">NVLink Activity</td><td style="text-align:left">The number of bytes of active NVLink rx or tx data including both header and payload.</td><td style="text-align:left">DEV_NVLINK_BANDWIDTH_L0</td></tr><tr><td style="text-align:left">PCIe Bandwidth pci<em>_bytes</em>{rx, tx}</td><td style="text-align:left">The number of bytes of active pcie rx or tx data including both header and payload.</td><td style="text-align:left">PROF<em>PCIE</em>[TR]X_BYTES (ID: 1009 (TX); 1010 (RX))</td></tr></tbody></table></div><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2021-01-06_dcgm-modularity.png"></p><h2 id="在-k8s-中集成-GPU-Telemetry"><a href="#在-k8s-中集成-GPU-Telemetry" class="headerlink" title="在 k8s 中集成 GPU Telemetry"></a>在 k8s 中集成 GPU Telemetry</h2><p>系统监控通常需要有以下几个组件：</p><ul><li>数据收集组件：collector，作为数据来源</li><li>时序数据库组件：存储收集到的metrics</li><li>可视化组件：将收集到的数据以可视化的界面友好地展示出来</li></ul><p>Prometheus 作为云原生时代优秀的解决方案，其结合 Grafana 和 Alert Manager 等组件实现了 k8s 集群的系统监控，下面是其组件架构，更多内容可以参考我的<a href="https://houmin.cc/posts/18c039ab/">另一篇博文</a>。</p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-09-16_prometheus-architecture.png"></p><p>同样，为了获得 GPU 的监控数据，NVIDIA 推出了 <a href="https://github.com/NVIDIA/gpu-monitoring-tools" target="_blank" rel="external nofollow noopener noreferrer"><code>dcgm-exporter</code></a>，它封装了 <code>DCGM</code>，类似于 <code>node-exporter</code> 将 GPU 的数据暴露给 Prometheus：</p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2021-01-06_nvidia-gpu-telemetry.png"></p><h3 id="部署-dcgm-exporter"><a href="#部署-dcgm-exporter" class="headerlink" title="部署 dcgm-exporter"></a>部署 dcgm-exporter</h3><p><code>dcgm-exporter</code> 作为 <code>DaemonSet</code> 运行在每一个装有GPU的Node上，为了使得 Prometheus 能够采集到它收集的数据，同时创建了 <code>Service</code>。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">DaemonSet</span></span><br><span class="line"><span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">"dcgm-exporter"</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/name:</span> <span class="string">"dcgm-exporter"</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/version:</span> <span class="string">"2.1.1"</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">updateStrategy:</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">RollingUpdate</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app.kubernetes.io/name:</span> <span class="string">"dcgm-exporter"</span></span><br><span class="line">      <span class="attr">app.kubernetes.io/version:</span> <span class="string">"2.1.1"</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app.kubernetes.io/name:</span> <span class="string">"dcgm-exporter"</span></span><br><span class="line">        <span class="attr">app.kubernetes.io/version:</span> <span class="string">"2.1.1"</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">"dcgm-exporter"</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">"nvidia/dcgm-exporter:2.0.13-2.1.1-ubuntu18.04"</span></span><br><span class="line">        <span class="attr">env:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">"DCGM_EXPORTER_LISTEN"</span></span><br><span class="line">          <span class="attr">value:</span> <span class="string">":9400"</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">"DCGM_EXPORTER_KUBERNETES"</span></span><br><span class="line">          <span class="attr">value:</span> <span class="string">"true"</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">"dcgm-exporter"</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">"metrics"</span></span><br><span class="line">          <span class="attr">containerPort:</span> <span class="number">9400</span></span><br><span class="line">        <span class="attr">securityContext:</span></span><br><span class="line">          <span class="attr">runAsNonRoot:</span> <span class="literal">false</span></span><br><span class="line">          <span class="attr">runAsUser:</span> <span class="number">0</span></span><br><span class="line">        <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">"pod-gpu-resources"</span></span><br><span class="line">          <span class="attr">readOnly:</span> <span class="literal">true</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">"/var/lib/kubelet/pod-resources"</span></span><br><span class="line">      <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">"pod-gpu-resources"</span></span><br><span class="line">        <span class="attr">hostPath:</span></span><br><span class="line">          <span class="attr">path:</span> <span class="string">"/var/lib/kubelet/pod-resources"</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">"dcgm-exporter"</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/name:</span> <span class="string">"dcgm-exporter"</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/version:</span> <span class="string">"2.1.1"</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/name:</span> <span class="string">"dcgm-exporter"</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/version:</span> <span class="string">"2.1.1"</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">"metrics"</span></span><br><span class="line">    <span class="attr">port:</span> <span class="number">9400</span></span><br></pre></td></tr></table></figure><p>这一步之后，可以获取每个Node上的 Metrics：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>部署完成后，需要在Prometheus的配置中，给 <code>scrape_configs</code>添加 <code>gpu-metrics</code> 的 job，通过 <code>kubernetes_sd_configs</code> 的服务发现机制找到 <code>dcgm-exporter</code> 对应的服务。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">gpu-metrics</span></span><br><span class="line">  <span class="attr">scrape_interval:</span> <span class="string">1s</span></span><br><span class="line">  <span class="attr">metrics_path:</span> <span class="string">/metrics</span></span><br><span class="line">  <span class="attr">scheme:</span> <span class="string">http</span></span><br><span class="line">  <span class="attr">kubernetes_sd_configs:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">role:</span> <span class="string">endpoints</span></span><br><span class="line">    <span class="attr">namespaces:</span></span><br><span class="line">      <span class="attr">names:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">kube-system</span></span><br><span class="line">    <span class="attr">selectors:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">role:</span> <span class="string">pod</span></span><br><span class="line">          <span class="attr">label:</span> <span class="string">"app.kubernetes.io/name:dcgm-exporter"</span></span><br><span class="line">  <span class="attr">relabel_configs:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">source_labels:</span> <span class="string">[__meta_kubernetes_pod_node_name]</span></span><br><span class="line">    <span class="attr">action:</span> <span class="string">replace</span></span><br><span class="line">    <span class="attr">target_label:</span> <span class="string">kubernetes_node</span></span><br></pre></td></tr></table></figure><h3 id="使用-grafana-监控"><a href="#使用-grafana-监控" class="headerlink" title="使用 grafana 监控"></a>使用 grafana 监控</h3><p>NVIDIA 提供了专用于 <a href="https://grafana.com/grafana/dashboards/12239" target="_blank" rel="external nofollow noopener noreferrer">GPU 监控的 Grafana 面板</a> ，在Grafana 导入面板后，即可看到对应的GPU监控面板：</p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2021-01-06_nvidia-dcgm-grafana.png"></p><h2 id="OpenFalcon-GPU-监控插件"><a href="#OpenFalcon-GPU-监控插件" class="headerlink" title="OpenFalcon GPU 监控插件"></a>OpenFalcon GPU 监控插件</h2><p>OpenFalcon 是小米开源的一套监控系统解决方案，其架构如下图所示。在每个节点上会有一个 <code>falcon-agent</code> 的 daemon 进程，负责对每个节点进行数据采集。</p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2021-01-07_falcon-arch.png"></p><p>为了支持GPU监控，OpenFalcon 有专门的 <a href="https://github.com/open-falcon/gpu-mon" target="_blank" rel="external nofollow noopener noreferrer">GPU 监控插件</a>，它依赖于 <code>DCGM</code> 获得监控指标，下面是一些常用的指标：</p><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">GPUUtils</span>             <span class="string">GPU 使用率 (%)</span></span><br><span class="line"><span class="attr">MemUtils</span>             <span class="string">GPU 显存使用率(%)</span></span><br><span class="line"><span class="attr">FBUsed</span>               <span class="string">GPU 的显存占用(MB)</span></span><br><span class="line"><span class="attr">Performance</span>          <span class="string">GPU 的性能状态(0-15, 其中0表示最高)</span></span><br><span class="line"><span class="attr">DeviceTemperature</span>    <span class="string">当前GPU设备温度(℃)</span></span><br><span class="line"><span class="attr">PowerUsed</span>            <span class="string">GPU的功率使用</span></span><br><span class="line"><span class="attr">SingleBitError</span>       <span class="string">全部累积的单精度ECC错误</span></span><br><span class="line"><span class="attr">DoubleBitError</span>       <span class="string">全部累积的双精度ECC错误</span></span><br></pre></td></tr></table></figure><h2 id="GPU-Manager-监控数据分析"><a href="#GPU-Manager-监控数据分析" class="headerlink" title="GPU Manager 监控数据分析"></a>GPU Manager 监控数据分析</h2><p>与 <code>OpenFalcon</code> 不同，GPU Manager 使用的是 <code>NVML</code> 库开发，获得对于 GPU Pod 级的监控数据。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(disp *Display)</span> <span class="title">getDeviceUsage</span><span class="params">(pidsInCont []<span class="keyword">int</span>, deviceIdx <span class="keyword">int</span>)</span> *<span class="title">displayapi</span>.<span class="title">DeviceInfo</span></span> &#123;</span><br><span class="line">nvml.Init()</span><br><span class="line"><span class="keyword">defer</span> nvml.Shutdown()</span><br><span class="line"></span><br><span class="line">dev, err := nvml.DeviceGetHandleByIndex(<span class="keyword">uint</span>(deviceIdx))</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">klog.Warningf(<span class="string">"can't find device %d, error %s"</span>, deviceIdx, err)</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">processSamples, err := dev.DeviceGetProcessUtilization(<span class="number">1024</span>, time.Second)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">klog.Warningf(<span class="string">"can't get processes utilization from device %d, error %s"</span>, deviceIdx, err)</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">processOnDevices, err := dev.DeviceGetComputeRunningProcesses(<span class="number">1024</span>)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">klog.Warningf(<span class="string">"can't get processes info from device %d, error %s"</span>, deviceIdx, err)</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">busID, err := dev.DeviceGetPciInfo()</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">klog.Warningf(<span class="string">"can't get pci info from device %d, error %s"</span>, deviceIdx, err)</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">sort.Slice(pidsInCont, <span class="function"><span class="keyword">func</span><span class="params">(i, j <span class="keyword">int</span>)</span> <span class="title">bool</span></span> &#123;</span><br><span class="line"><span class="keyword">return</span> pidsInCont[i] &lt; pidsInCont[j]</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line">usedMemory := <span class="keyword">uint64</span>(<span class="number">0</span>)</span><br><span class="line">usedPids := <span class="built_in">make</span>([]<span class="keyword">int32</span>, <span class="number">0</span>)</span><br><span class="line">usedGPU := <span class="keyword">uint</span>(<span class="number">0</span>)</span><br><span class="line"><span class="keyword">for</span> _, info := <span class="keyword">range</span> processOnDevices &#123;</span><br><span class="line">idx := sort.Search(<span class="built_in">len</span>(pidsInCont), <span class="function"><span class="keyword">func</span><span class="params">(pivot <span class="keyword">int</span>)</span> <span class="title">bool</span></span> &#123;</span><br><span class="line"><span class="keyword">return</span> pidsInCont[pivot] &gt;= <span class="keyword">int</span>(info.Pid)</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> idx &lt; <span class="built_in">len</span>(pidsInCont) &amp;&amp; pidsInCont[idx] == <span class="keyword">int</span>(info.Pid) &#123;</span><br><span class="line">usedPids = <span class="built_in">append</span>(usedPids, <span class="keyword">int32</span>(pidsInCont[idx]))</span><br><span class="line">usedMemory += info.UsedGPUMemory</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> _, sample := <span class="keyword">range</span> processSamples &#123;</span><br><span class="line">idx := sort.Search(<span class="built_in">len</span>(pidsInCont), <span class="function"><span class="keyword">func</span><span class="params">(pivot <span class="keyword">int</span>)</span> <span class="title">bool</span></span> &#123;</span><br><span class="line"><span class="keyword">return</span> pidsInCont[pivot] &gt;= <span class="keyword">int</span>(sample.Pid)</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> idx &lt; <span class="built_in">len</span>(pidsInCont) &amp;&amp; pidsInCont[idx] == <span class="keyword">int</span>(sample.Pid) &#123;</span><br><span class="line">usedGPU += sample.SmUtil</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> &amp;displayapi.DeviceInfo&#123;</span><br><span class="line">Id:      busID.BusID,</span><br><span class="line">CardIdx: fmt.Sprintf(<span class="string">"%d"</span>, deviceIdx),</span><br><span class="line">Gpu:     <span class="keyword">float32</span>(usedGPU),</span><br><span class="line">Mem:     <span class="keyword">float32</span>(usedMemory &gt;&gt; <span class="number">20</span>),</span><br><span class="line">Pids:    usedPids,</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="GPU-监控指标探讨"><a href="#GPU-监控指标探讨" class="headerlink" title="GPU 监控指标探讨"></a>GPU 监控指标探讨</h2><p>对于 k8s 的 GPU 监控，我们到底需要那些指标：</p><ul><li>集群级别<ul><li>整个集群有多少GPU，各种GPU的型号是怎样的</li><li>集群级别GPU算力使用量（绝对值），算力使用率（相对值）</li><li>集群级别GPU显存使用量（绝对值），显存使用率（相对值）</li></ul></li><li>单机级别<ul><li>Node上有多少GPU，各种GPU的型号是怎样的</li><li>单机级别GPU算力使用量（绝对值），算力使用率（相对值）</li><li>单机级别GPU显存使用量（绝对值），显存使用率（相对值）</li></ul></li><li>Pod级别<ul><li>Pod 运行在哪个GPU上</li><li>Pod级别GPU算力使用量（绝对值），算力使用率（相对值）</li><li>Pod级别GPU显存使用量（绝对值），显存使用率（相对值）</li></ul></li><li>其他相关统计数据<ul><li>GPU的功率、温度、主频、FAN转速等</li></ul></li></ul><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://github.com/NVIDIA/gpu-monitoring-tools" target="_blank" rel="external nofollow noopener noreferrer">NVIDIA GPU Monitoring Tools</a></li><li><a href="https://developer.nvidia.com/blog/monitoring-gpus-in-kubernetes-with-dcgm/" target="_blank" rel="external nofollow noopener noreferrer">Monitoring GPUs in Kubernetes with DCGM</a></li><li><a href="https://docs.nvidia.com/datacenter/cloud-native/kubernetes/dcgme2e.html" target="_blank" rel="external nofollow noopener noreferrer">Integrating GPU Telemetry into Kubernetes</a></li><li><a href="http://on-demand.gputechconf.com/gtc/2018/presentation/s8505-gpu-monitoring-and-management-with-nvidia-data-center-gpu-manager-dcgm-v2.pdf" target="_blank" rel="external nofollow noopener noreferrer">GTC 2018 Talk: GPU Monitoring and Management with NVIDIA Data Center GPU Manager</a></li><li><a href="https://book.open-falcon.org/zh_0_2/" target="_blank" rel="external nofollow noopener noreferrer">OpenFalcon 说明书</a></li><li><a href="https://github.com/open-falcon/gpu-mon" target="_blank" rel="external nofollow noopener noreferrer">OpenFalcon GPU监控插件</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot; class=&quot;aplayer-secondary-script-marker&quot;&gt;&lt;/script&gt;&lt;script class=&quot;meting-secondary-script-marker&quot; src=&quot;/assets/js/Meting.min.js&quot;&gt;&lt;/script&gt;&lt;h2 id=&quot;问题背景&quot;&gt;&lt;a href=&quot;#问题背景&quot; class=&quot;headerlink&quot; title=&quot;问题背景&quot;&gt;&lt;/a&gt;问题背景&lt;/h2&gt;&lt;p&gt;在使用GPU进行深度学习相关的训练与推理时，需要查看当前集群中GPU的使用情况：&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;需要通过当前GPU设备资源使用情况判断是否可以再部署新的应用，判断集群是否需要扩容，为GPU服务提供对齐CPU的容量保障服务，补齐容量保障中的GPU短板&lt;/li&gt;
&lt;li&gt;需要通过当前GPU设备资源使用情况分析使用中存在的瓶颈和短板，推进优化，提高资源利用率和服务性能&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    <content src="http://houmin.cc/https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2021-01-06_dcgm-modularity.png" type="image" />
    
    
      <category term="术业专攻" scheme="http://houmin.cc/categories/%E6%9C%AF%E4%B8%9A%E4%B8%93%E6%94%BB/"/>
    
    
      <category term="监控" scheme="http://houmin.cc/tags/%E7%9B%91%E6%8E%A7/"/>
    
      <category term="GPU" scheme="http://houmin.cc/tags/GPU/"/>
    
  </entry>
  
  <entry>
    <title>2020 渺小</title>
    <link href="http://houmin.cc/posts/9d4b744a/"/>
    <id>http://houmin.cc/posts/9d4b744a/</id>
    <published>2020-12-31T14:47:19.000Z</published>
    <updated>2021-01-17T07:40:45.073Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>当写下 <a href="https://houmin.cc/posts/2ecc368">2019 未来へ</a> 的时候，我没有意识到2020年将会发生什么。那时的我是轻松惬意的，文字里透露着面向未来的自信，期冀着能够做出自己的改变。一年过去了，咻的一下，很快，生活中的种种已经发生了改变。2020 年发生的种种让我更加意识到到自身的渺小与浅陋，绝大多数时候你改变不了什么，你能确定改变的只能是自己，尽管这并不简单。</p><p>这里是 「岁末围炉」系列的第二篇 <code>2020 渺小</code>，主题曲选择的是田馥甄的渺小，封面图来自冬日的雍和宫。 2020 年结束了，渺小的我依然在构建自己的框架，向着生命，向着未来。</p>    <div id="aplayer-bMSGKtKr" class="aplayer aplayer-tag-marker meting-tag-marker" data-id="27968284" data-server="netease" data-type="song" data-mode="circulation" data-autoplay="false" data-mutex="true" data-listmaxheight="340px" data-preload="auto" data-theme="#555"></div><a id="more"></a><h2 id="世界你好"><a href="#世界你好" class="headerlink" title="世界你好"></a>世界你好</h2><p>有人说，2020 年是这些年来最糟糕的一年，2020年是见证历史的一年，正如时代周刊在年底的一期杂志封面所提到的一样：</p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-12-14_time-2020-cover.jpg"></p><ul><li>年初，美军定点清除伊朗名将之花苏莱曼尼，美伊爆发克制性冲突，伊朗导弹误击乌克兰民航客机，176人死亡</li><li>年初，新冠疫情在武汉爆发，李文亮之死引发全国震动，武汉封城，全国驰援下湖北控制住疫情，中国控制住疫情</li><li>然而，疫情继续在全球爆发，截止2020年底全球累计确诊人数到达8000万人，累计死亡人数180万人，东京奥运会延期</li><li>因为新冠疫情的爆发，全球经济衰退，年初美股四次熔断，历史罕见负油价，在美联储持续降息放水下，美股在下半年一路长红</li><li>美国黑人佛洛伊德被警察跪杀，引发美国几十年来规模最大的反种族歧视、反暴力执法抗议，BLM运动下，众多历史雕像被摧毁</li><li>美国2020年大选跌宕起伏，拜登最终赢得大选，但特朗普所代表的群众依然广泛，美国党派冲突、阶层冲突矛盾进一步激化</li><li>中美贸易冲突进一步加剧，美国封杀TikTok、微信等企业，中美互关总领事馆</li><li>互联网行业整治监管趋紧，蚂蚁金服暂停上市，阿里、腾讯、顺丰被罚，巨头入局社区团购引发争议，蛋壳公寓暴雷</li><li>……</li></ul><p>所有的这些事件中，新冠疫情是影响最大的因素。事实证明，与非典不同，我们已经不能指望它在夏天凭空消失，我们所能依靠的只有疫苗。尽管在国内疫情已经得到了控制，但是全球疫情仍然严重，在未来的两年里，它仍将一直围绕着我们，各国之间仍然不能自由通航，以前的那种人员自由流动已经成为一种奢望。伴随着疫情，全球经济持续衰退，有可能造成甚于2008年的全球经济大危机，贫富差距加大，阶层矛盾进一步激化，民粹主义进一步发展。</p><p>显而易见的是，这个世界的情况没有在变好，而在过去十年间进一步恶化，08年以来的次贷危机和欧债危机造成的负面影响至今都还没有完全释放。在没有新的技术革新发生的情况下，未来的环境还会更差，战争的发生不是没有可能。所以，在天灾、疫情、战争带来的威胁下，我们能够做什么呢？我们什么都做不了，在这些面前我们只是渺小的蝼蚁。我们能够做的，就是尝试去理解世界，完善自己。</p><h2 id="行为框架"><a href="#行为框架" class="headerlink" title="行为框架"></a>行为框架</h2><p>在过去的一年，我一直在尝试去更好地理解自己的行为模式，去记录数据，去分析数据，去更新自己的模型。尽管还没有达到我想要的效果，但是我明显地感觉到，<code>I&#39;m on my way</code>。这种记录与分析里最重要的一种表达方式，就是我给自己建立的这个站点，或者也可以说是我的个人博客。虽然除了个人博客，我还想在这个站点记录更多的东西，不过不管怎么样我们可以慢慢来。如你所见，在<a href="https://houmin.cc/about/"> <code>houmin.cc</code></a>，我创建了几个不同的栏目用于定期的去总结、去梳理生活与学习工作中碰到的问题。</p><p>除了一年一度的 <a href="https://houmin.cc/categories/岁末围炉">岁末围炉</a>，另一个重要的专栏就是 <a href="https://houmin.cc/categories/朝花夕拾">朝花夕拾</a> 了。「朝花夕拾」是我给自己安排的每周总结，2020年第一期是 <a href="https://houmin.cc/posts/3e030bdb/">Carpe Diem</a>，最后一期是 <a href="https://houmin.cc/posts/64c2f65e">十字路口</a>。尽管号称每周更新，期间不乏拖更与断更，下面是2020年的「朝花夕拾」发布记录。可以看到，到2020年结束，朝花夕拾总共发布了29期。如果每周按照正常发布的节奏（以及排除年终/生日那周），总计应该有50期。尽管只是刚刚超过预期的一半，令我高兴的是整个「朝花夕拾」的框架已经建立。</p><div id="echarts9082" style="width: 100%;height: 600px;margin: 0 auto"></div><script type="text/javascript" src="https://cdn.bootcss.com/echarts/4.2.0-rc.2/echarts.min.js"></script><script type="text/javascript" src="http://gallery.echartsjs.com/dep/echarts/map/js/china.js"></script><script type="text/javascript">  // 基于准备好的dom，初始化echarts实例  var myChart = echarts.init(document.getElementById('echarts9082'));  // 指定图表的配置项和数据  option = {    title: {        text: '朝花夕拾'    },    tooltip: {        trigger: 'axis',        axisPointer: {            type: 'cross',            crossStyle: {                color: '#999'            }        }    },    toolbox: {        feature: {            dataView: {show: true, readOnly: false},            magicType: {show: true, type: ['line', 'bar']},            restore: {show: true},            saveAsImage: {show: true}        }    },    legend: {        data: ['单月发布', '累计发布']    },    xAxis: [        {            type: 'category',            data:  ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sept', 'Oct', 'Nov', 'Dec'],            axisPointer: {                type: 'shadow'            }        }    ],    yAxis: [        {            type: 'value',            name: '单月发布',            min: 0,            max: 4,            interval: 4,            axisLabel: {                formatter: '{value} 篇'            }        },        {            type: 'value',            name: '累计发布',            min: 0,            max: 50,            interval: 4,            axisLabel: {                formatter: '{value} 篇'            }        }    ],    series: [        {            name: '单月发布',            type: 'bar',            data: [3, 4, 4, 4, 1, 1, 4, 1, 0, 0, 4, 3],        },        {            name: '累计发布',            type: 'line',            yAxisIndex: 1,            data: [3, 7, 11, 15, 16, 17, 21, 22, 22, 22, 26, 29],        }    ]};  // 使用刚指定的配置项和数据显示图表。  myChart.setOption(option);</script><p>看看那些没能够定期发布的时间段，我依稀还能想到当时发生了什么。五月和六月，因为面临毕业论文答辩，没有花太多的时间在博客上，7月份入职后，在八月、九月和十月基本上都在消化吸收工作中涉及到的知识点，你可以看到那段时间我在 「术业专攻」中发布了很多专业内容的笔记。如果没有十一月的回归正常发布，今年的曲线将会很难看。</p><p>按照我多年来新年计划失效的经验（如果说这次朝花夕拾没能够完全按期发布也算是一次失败经验的话），如果没有定期的回顾与总结，一旦某段时间放松自己，偏离目标，就会因为破窗效应索性放弃了整个一年的计划。一方面是缺少定期的回顾，另外一方面是自己设定的计划完成时间粒度太粗，一旦某段时间放弃则全盘放弃，正如我年初在 <a href="https://houmin.cc/posts/c924112f">Do You Want To Build A Snowman?</a> 这篇博文中提到的一样。</p><p>现在回过头看，非常庆幸自己在2019年底有一段空闲时间给自己建立了一个框架，并在后续的日子里能够坚持实践。也许没有完全达到我期待中的效果，至少框架已经初具模型。事实上，早在16年的时候我就创建过自己的个人网站，也比较早的意识到博客系统可能会对我产生的帮助。然而（按照我现在的理解），正是因为没有建立一个好的可以执行下去的框架，导致当年创建的博客两次中断，在后续的日子里也没有留下多少有价值的记录。我也曾经建立过自己的 wiki 平台，但是因为项目维护和数据的获取更新等问题没有坚持下去。现在的这种框架对于我来说是最好的方式。</p><p>建立框架对于知识体系的构建产生帮助的最为典型的一个例子是，「术业专攻」这个栏目的建立与文章发布。在年初的时候，我在  <a href="https://houmin.cc/posts/c924112f">Do You Want To Build A Snowman?</a> 这篇博文讨论过个人知识管理的话题，当时得到的几个明确结论是：</p><ul><li>Data、Information、Knowledge、Wisdom这几个概念之间有着明显的区别，看到数据并不等于获取信息，阅读博客和书籍并不等同于学会了知识，知道了知识并不等同于掌握了智慧</li><li>提高知识获取效率最好的方法是主动去搜索资料，而不是被动的在信息流中流于表面的学习</li><li>只靠搜索不能内化知识，虽然可能在某个地方能够看到这些知识，但他们永远不是你的</li><li>只靠把知识存储在文件夹或笔记中，而不去花时间整理它们不能内化知识，你需要通过自己的整理去建立索引，方便以后更好的调用这些知识</li><li>图像、思维导图、定期回顾复习、向他人表述能够更好的帮助知识内化</li></ul><p>结合这几个结论，当前我的博客系统就是我最好的知识管理工具，也是我自己的笔记系统。截止2020年底，我在「术业专攻」总共发布了90篇博文，其中大部分是我在专业内容上的笔记总结。目前原创性的内容还比较少，更多的是在做笔记、做梳理、做总结。通过在发布博文的过程中，我会去结合自身的理解去消化吸收这些内容，在我的知识体系中构建自己的索引。在这个过程中，我越发体会到自己的浅陋，除了发布的这些博文，还有很多那些还没来得及被消化和发布的内容存在我的草稿箱中。在过去的一年中，我还剩下 300+ 的博文没有发布，这需要大量的时间去消化吸收。</p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-12-19_hexo-drafts.png"></p><p>这是一个动态增长的过程，每每在工作中碰到一些新的知识点，我会去搜索相关的资料并保存于草稿箱中。保存于草稿箱并不等同于我消化吸收了对应的内容，我还需要去按照自己的思维脉络，整理出属于自己的文章。之后再碰到对应的问题后，我就可以很好的在自己的知识体系中定位问题，索引出相关知识点。即使短暂的不记住了，我也可以再来博客系统来回顾。</p><p>除了专业相关的内容，我还根据自己的兴趣点，建立了 <a href="https://houmin.cc/categories/资本不眠">「资本不眠」</a>、<a href="https://houmin.cc/categories/好奇计划">「好奇计划」</a> 等栏目，用于记录专业内容之外的那些有意思的内容，并且可能还会去进一步扩展更多的栏目。记录、消化、总结、思考、时间、提高，是获取知识、创造新知识的最好办法，而 <code>houmin.cc</code> 就是我在这上面最好的框架与平台。</p><p>根据我前面一以贯之的理念，为了更好的成长，我们需要用数据去量化成长的指标，从而进一步反思与优化自己的行为模式。对于我这个系统最基础的框架也是一样，我们也需要数据去衡量这个框架的进步与效果。也就是说，你如何反映出你的框架在实际work，你如何知道自己的产出是否有实际意义，作为一个网站，我给他最明确的指标就是网站搜索与访问量。</p><p>听起来有点像运营微信微博等新媒体账号，对于你运营的网站，你期待的指标就是他的点击量和访问量获得显著提升。但是，与微信微博稍微有点不同的是，我的网站将完全基于搜索获取流量，而不是依赖于社交网络的传播。一方面我不得不承认，我现在网站中的很多内容还很粗浅，还不足以吸引人们在社交网络中传播它；另一方面，与我前面提到的知识管理理念相匹配，应该是人找信息，而不是信息找人，我们才是信息获取的发起方，通过搜索得到的内容将发挥更大的作用。</p><p>下图是 <code>houmin.cc</code> 在过去一年来的搜索数据，尽管目前网站的日均访问量仍然很小很小，但是已经可以看到相比于2019年的日均访问量已经有了一个量级的提高。未来的一年，给自己定下的一个目标是，要进一步修正和完善这个框架，创作更多有价值的内容。当我们实现这个目标后，可以看到的一个效果是，这个站点的日均访问量将进一步提升一个量级。</p><iframe src="https://www.google.com/maps/embed?pb=!1m18!1m12!1m3!1d99370.36297142891!2d-77.08461552967614!3d38.89370913932197!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x89b7c6de5af6e45b%3A0xc2524522d4885d2a!2z5ZOl5Lym5q-U5Lqa5Yy65Y2O55ub6aG_5ZOl5Lym5q-U5Lqa54m55Yy6!5e0!3m2!1szh-CN!2sus!4v1610869187028!5m2!1szh-CN!2sus" width="600" height="450" frameborder="0" style="border:0;" allowfullscreen aria-hidden="false" tabindex="0"></iframe><p>虽然在这里对访问量提出了一定的指标，更关键的是要提高自己网站内容的质量，输出有价值的内容，提高自己的影响力。这里提出这样的目标，源自于之前在网络上搜索问题时，碰见的那些 <a href="https://houmin.cc/links">有意思的站点</a> 。他们的博客记录着他们的思考，记录着那些有价值的内容，是我想要实现的目标。</p><h2 id="好好工作"><a href="#好好工作" class="headerlink" title="好好工作"></a>好好工作</h2><p>2020年7月，我从学校进入职场，开始了正式的职场生活。半年的工作让我对自己未来的期待，对当前的不足有了更加清晰的认识。经过几段实习经历和半年的工作经历，你已经见证了各种各样的前辈，你也看到了作为一个专业的技术工程师应该具备的能力。2021年，继续好好工作，扩展自己的深度和广度，加油！</p><div class="table-container"><table><thead><tr><th>考察指标</th><th>具体指标</th><th>实践改进方式</th></tr></thead><tbody><tr><td>技术实力</td><td>掌握扎实的底层技术原理，包括 kubernetes、linux、网络、Go语言等方面</td><td>「术业专攻」博客更新</td></tr><tr><td>业界动态</td><td>洞悉业界动态，知道大家现在都在做什么，未来的趋势在哪里，我们可以做的事情有哪些</td><td>创建「业界动态」专栏</td></tr><tr><td>开源影响力</td><td>积极参与开源社区贡献，在社区构建自己的影响力</td><td>成为k8s社区Member</td></tr><tr><td>产品思维</td><td>在公司内部积极完成leader下发的任务，并能够从产品和业务的角度去更好的思考问题</td><td>公司影响力提升</td></tr></tbody></table></div><h2 id="阅读光影"><a href="#阅读光影" class="headerlink" title="阅读光影"></a>阅读光影</h2><p>和2019年一样，2020年我并没有阅读多少书籍，豆瓣上标记的只有3本，但是我仍然愿意在这里花上一段篇幅来讨论它。从2014年注册豆瓣以来，下面是我每年在豆瓣读书上标记的阅读数，可以看到，本科时期是我阅读热情的高峰，尤其是大二和大三的时候，基本上每年阅读数能够达到50本。可是，读研之后，阅读的书就越来越少了，甚至在19年毫无所获。</p><div id="echarts5800" style="width: 100%;height: 600px;margin: 0 auto"></div><script type="text/javascript" src="https://cdn.bootcss.com/echarts/4.2.0-rc.2/echarts.min.js"></script><script type="text/javascript" src="http://gallery.echartsjs.com/dep/echarts/map/js/china.js"></script><script type="text/javascript">  // 基于准备好的dom，初始化echarts实例  var myChart = echarts.init(document.getElementById('echarts5800'));  // 指定图表的配置项和数据  option = {    title: {        text: '豆瓣阅读数据'    },    tooltip: {        trigger: 'axis',        axisPointer: {            type: 'cross',            crossStyle: {                color: '#999'            }        }    },    toolbox: {        feature: {            dataView: {show: true, readOnly: false},            magicType: {show: true, type: ['line', 'bar']},            restore: {show: true},            saveAsImage: {show: true}        }    },    legend: {        data: ['阅读统计']    },    xAxis: [        {            type: 'category',            data:  ['2014', '2015', '2016', '2017', '2018', '2019', '2020'],            axisPointer: {                type: 'shadow'            }        }    ],    yAxis: [        {            type: 'value',            name: '阅读统计',            min: 0,            max: 60,            interval: 5,            axisLabel: {                formatter: '{value}'            }        }    ],    series: [        {            name: '阅读统计',            type: 'bar',            data: [25, 55, 49, 6, 6, 0, 3]        }    ]};  // 使用刚指定的配置项和数据显示图表。  myChart.setOption(option);</script><p>2020年的上半年也是基本如此，没有阅读什么书籍。没有人会否认阅读的重要性，相对于从公众号或者知乎里面获取的零碎知识，阅读书籍是一种更加体系化的知识获取方式。在本科时期，我对于历史和小说比较感兴趣，这些领域的阅读都相对轻松。那个时候我经常会很快地扫读，也很少去写一些阅读笔记和书评，很多书籍看完之后就丢在一边，导致阅读的相对收益并不高。</p><p>双十一之后，我从PT那里拿来了 Kindle，开始构建自己的阅读系统，构建主题阅读的方法论：</p><ul><li>问题意识。为什么要读一本书，是因为你心中对于某个主题包含着困惑（小说等书除外），你是抱着解答这些问题的期待翻开一本书的。我给自己建立了一个<a href="https://www.douban.com/doulist/133636602/" target="_blank" rel="external nofollow noopener noreferrer">2021阅读清单</a>，这是一个很实用主义的书单，涉及到各种经济学的原理与实践、涉及到行为模式的构建、涉及到专业知识的深化，我希望通过阅读这些书去解决这些问题。</li><li>整理书籍的知识框架。一本书的精髓在于作者的框架逻辑，而不在于其遣词造句，读书最重要读的是其知识框架。</li><li>交叉阅读验证知识框架。同一个主题往往不止一本书籍，阅读同一主题中的不同书籍可以交叉验证之前总结的知识框架。</li><li>将书籍的知识框架打入到你的知识体系，将内化的知识表达出来。这个过程中，读书笔记是第一步，通过读书笔记，可以实现对书籍的二次精读，更加关注知识的整体架构，获取的知识才是成体系的，而不是碎片化的信息。</li></ul><p>以此方法论为基础，我将2020年阅读的三本书籍分别写下了阅读笔记，列次如下：</p><ul><li><a href="https://houmin.cc">【读书笔记】如何阅读一本书</a></li><li><a href="https://houmin.cc">【读书笔记】光变</a></li><li><a href="https://houmin.cc">【读书笔记】褚时健传</a></li></ul><p>与阅读相同，希望新的一年观影也能够感受更多的东西。在年初的时候，当时对 2008 年的经济危机十分感兴趣，看了好几部关于次贷危机的纪录片与电影，并以 <a href="https://houmin.cc/posts/787197ce/">The Big Short</a> 的形式总结发布出来。</p><p>新的一年，我也给自己建立了一个 <a href="https://www.douban.com/doulist/133864290/" target="_blank" rel="external nofollow noopener noreferrer">2021观影清单</a>，观影的同时，希望有更多的文章发布。</p><h2 id="资本不眠"><a href="#资本不眠" class="headerlink" title="资本不眠"></a>资本不眠</h2><p>2019 年初，给自己定下的一个目标是股市收益超过20个点，最好能够达到40个点。得益于今年不错的行情，再一次达到了这个目标，最终收益率达到了 <code>35%</code>，稍稍跑赢沪深300。不得不说，在投资方面我仍然没有入门，这是这两年来的股市行情向好，才没有亏钱。</p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-12-31_invest-return.jpg"></p><p>对于股票投资，我现在最大的问题在于，我不知道为什么要买一只股票。对于一只真正好的股票，股票涨了一些的时候我能不能拿得住，股票跌的时候我会不会害怕。这家公司身处什么行业，其主营业务是什么，它的管理层是一些怎样的人，它在过去几年的业绩怎么样，公司和行业的发展怎么样？现在处于经济周期的哪个阶段？股票建仓的策略如何？你对这只股票预期的收益是多少？</p><p>上面的种种问题，我心里都没有底。今年最大的一个遗憾是新能源，看看下面来自我账户的两张图：</p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-12-31_gwm.jpg"></p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-12-31_byd.jpg"></p><p>对的，这两只在今年大涨了4倍的股票我在他们起飞之前都已经关注过。这还不算，19年初就已经关注起新能源汽车行业，并且在 2020 年初还专门写了篇 <a href="https://houmin.cc/posts/8082c63c/">聊聊行业：以新能源汽车为例</a>  的文章，作为行业研究的入门笔记。然而，我还是错过了这一切：）</p><p>为什么？想想当初买这两只股票的逻辑：哟，长城汽车最高价到过16块，现在才七八块，绝对便宜啊，而且听说长城哈弗卖的挺不错的，不亏。然后我在长城处于7块到10块震荡的时候一直在做T，到10块后稍微跌了跌就清仓了。嗯，也能够赚点钱，但是 ：）比亚迪也基本是这样很早就卖了。</p><p>说实话，真的很心痛，要是没有卖该多好：）不过说起来，没能拿住，本质上就是自己认知思维没打开，整个投资框架没有建立起来，这笔钱还不属于我。2020年的下半年，我完全没有操作，一方面因为这两只股票的教训已经从认知上更倾向于长期投资，不太喜欢这种短期波动获取的收益；另一方面因为工作原因，没有太多的时间去研究其他的股票，也就没有去操作。</p><p>新的一年，在投资方面还是要去建立自己的投资框架，熟悉了解财经相关的知识，现在对财经方面的兴趣越来越强了（不愧是个俗人：）在2021年，希望至少完成5篇财经方面书籍的阅读，并且整理相关阅读笔记并发布。另外，除了A股投资，也要给自己开一个美股和港股的账户，毕竟那边有很多很好的标的；除了现在的股票投资，明年应该开始指数基金定投计划。</p><p>还是那句话，希望明年整体投资收益超过20%，最好能够到40%，加油。</p><h2 id="旅行影像"><a href="#旅行影像" class="headerlink" title="旅行影像"></a>旅行影像</h2><p>因为疫情，原来的旅行计划被迫放弃。令人开心的是，随着国内疫情的控制，今年还是除了北京，还是走了走杭州和西北，我将所看到的记录在了这些文章里。</p><ul><li><a href="https://houmin.cc/posts/2f653e3b/">西湖印象</a>：初夏到达杭州姐姐家，盛夏回到北京，杭州很美</li><li><a href="https://houmin.cc/posts/2561fdfd/">26：一个人的北京</a>：国庆去了趟大西北，真美</li></ul><p>2020 年我仍然在记录着，除了旅行中的光影，我也记录着身边的影像，你可以在 <a href="https://houmin.cc/tags/摄影">这里</a> 看到。越来越觉得，除了奇美的自然景观，人的影像有时候会更加生动。新的一年，希望自己能够更多的走出去，希望自己的镜头下能够记录更多更美的时刻。</p><h2 id="我与其他"><a href="#我与其他" class="headerlink" title="我与其他"></a>我与其他</h2><ul><li>2020年，我重新捡起了跑步，断断续续着，希望新的一年能够找回大四时跑步的状态，并参加一次马拉松</li><li>2020年，我开始审视自己的睡眠，并开始抓取自己的睡眠数据，希望新的一年能够将这一数据回归到正常</li><li>2020年，卡林巴琴最终没有坚持下来，可是我仍然记得音乐带来的放松，希望以后能够掌握一门乐器，也许吉他</li><li>2020年，「朝花夕拾」开始每周更多的记录，希望新的一年能够开拓数据收集的范围，记录世界纪录自己</li><li>2020年，我开始高密度的听起了播客，喜欢下班路上听着播客的放松状态，希望以后我也能够做一档自己的播客</li><li>2020年，我依旧是单身一个人，工作后能够投入到感情上面的时间越发减少，希望新的一年自己能够更加主动</li><li>2020年结束了，可以确定的是，我们以后会不止一次地回忆起这不平凡的一年，下面是来自「声东击西」记录2020的声音</li></ul><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="1500" height="80" src="//music.163.com/outchain/player?type=3&id=2071218639&auto=1&height=66"></iframe><hr><p>再见，2020</p><p>你好，2021</p><p>新年快乐！</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;当写下 &lt;a href=&quot;https://houmin.cc/posts/2ecc368&quot;&gt;2019 未来へ&lt;/a&gt; 的时候，我没有意识到2020年将会发生什么。那时的我是轻松惬意的，文字里透露着面向未来的自信，期冀着能够做出自己的改变。一年过去了，咻的一下，很快，生活中的种种已经发生了改变。2020 年发生的种种让我更加意识到到自身的渺小与浅陋，绝大多数时候你改变不了什么，你能确定改变的只能是自己，尽管这并不简单。&lt;/p&gt;
&lt;p&gt;这里是 「岁末围炉」系列的第二篇 &lt;code&gt;2020 渺小&lt;/code&gt;，主题曲选择的是田馥甄的渺小，封面图来自冬日的雍和宫。 2020 年结束了，渺小的我依然在构建自己的框架，向着生命，向着未来。&lt;/p&gt;

    &lt;div id=&quot;aplayer-bMSGKtKr&quot; class=&quot;aplayer aplayer-tag-marker meting-tag-marker&quot; data-id=&quot;27968284&quot; data-server=&quot;netease&quot; data-type=&quot;song&quot; data-mode=&quot;circulation&quot; data-autoplay=&quot;false&quot; data-mutex=&quot;true&quot; data-listmaxheight=&quot;340px&quot; data-preload=&quot;auto&quot; data-theme=&quot;#555&quot;&gt;&lt;/div&gt;
    
    </summary>
    
    <content src="http://houmin.cc/https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-12-20_temple.png" type="image" />
    
    
      <category term="岁末围炉" scheme="http://houmin.cc/categories/%E5%B2%81%E6%9C%AB%E5%9B%B4%E7%82%89/"/>
    
    
      <category term="年终总结" scheme="http://houmin.cc/tags/%E5%B9%B4%E7%BB%88%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
  <entry>
    <title>【深度学习】TensorFlow2</title>
    <link href="http://houmin.cc/posts/fcd0bf09/"/>
    <id>http://houmin.cc/posts/fcd0bf09/</id>
    <published>2020-12-21T06:17:24.000Z</published>
    <updated>2021-01-05T11:52:47.395Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>近年来，深度神经网络技术被大规模地使用在搜索、推荐、广告、翻译、语音、图像和视频等领域。与此同时，深度学习也在推动一些人类最重大的工程挑战，比如自动驾驶技术、医疗诊断和预测、个性化学习、加速科学发展（比如天文发现）、跨语言的自由交流（比如实时翻译），更通用的人工智能系统（比如 AlphaGo）等。</p><p>TensorFlow 是开源的端到端的机器学习平台，提供了丰富的工具链，推动了机器学习的前沿研究，支撑了大规模生产使用，支持多平台灵活部署。2019年10月，谷歌正式发布TensorFlow 2.0，相比于TensorFlow 1.0，TensorFlow 2 重点关注易用性，默认推荐使用 Keras 作为高阶 API，同时兼具可扩展性和高性能，默认为动态图方式执行。本文作为 Tensorflow2 学习笔记，主要参考<a href="https://github.com/lyhue1991/eat_tensorflow2_in_30_days" target="_blank" rel="external nofollow noopener noreferrer">eat_tensorflow2_in_30_days</a>，对照着原教程在Docker环境下对于TensorFlow2进行学习，感谢原作者的贡献。</p><a id="more"></a><h2 id="搭建环境"><a href="#搭建环境" class="headerlink" title="搭建环境"></a>搭建环境</h2><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">tensorflow</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">k8s-app:</span> <span class="string">tensorflow</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">k8s-app:</span> <span class="string">tensorflow</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">k8s-app:</span> <span class="string">tensorflow</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">tensorflow</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">unicosmos/tensorflow:2.4.0-gpu-jupyter</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">8888</span></span><br><span class="line">        <span class="attr">resources:</span></span><br><span class="line">          <span class="attr">limits:</span></span><br><span class="line">            <span class="attr">nvidia.com/gpu:</span> <span class="number">1</span></span><br><span class="line">        <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/tf/data</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">data-volume</span></span><br><span class="line">      <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">data-volume</span></span><br><span class="line">        <span class="attr">hostPath:</span></span><br><span class="line">          <span class="attr">path:</span> <span class="string">/root/data</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">jupyter-service</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">NodePort</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">8888</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">tensorflow</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">k8s-app:</span> <span class="string">tensorflow</span></span><br></pre></td></tr></table></figure><h2 id="模块与架构"><a href="#模块与架构" class="headerlink" title="模块与架构"></a>模块与架构</h2><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-12-21_tensorflow-model.png"></p><h2 id="数据流图"><a href="#数据流图" class="headerlink" title="数据流图"></a>数据流图</h2><p>TensorFlow最基本的一次计算流程通常是这样的：首先它接受n个固定格式的数据输入，通过特定的函数，将其转化为n个张量（Tensor）格式的输出。</p><p>一般来说，某次计算的输出很可能是下一次计算的（全部或部分）输入。整个计算过程其实是一个个Tensor 数据的流动过程。在这其中，TensorFlow将这一系列的计算流程抽象为了一张数据流图（Data Flow Graph）。简单来说，数据流图，就是在逻辑上描述一次机器学习计算的过程。下面我们以图11-26为例，来说明TensorFlow的几个重要概念。</p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-12-21_tensorflow-dataflow-graph.png"></p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-12-21_tensorflow-dataflow.png"></p><p>Tensorflow 变量 <code>Variable</code> 的主要总用是维护特定节点的状态，如深度学习或机器学习的模型参数。<code>tf.Variable</code> 的方法是 <code>Operation</code>，返回值是 <code>Tensor</code>。通过 <code>tf.Varaible</code> 方法创建的变量，与张量一样，可以作为操作的输入和输出。不同之处在于：</p><ul><li>张量的生命周期通常随依赖的计算完成而结束，内存也随之释放</li><li>变量则常驻内存，在每一步训练时不断更新其值，以实现模型参数的更新</li></ul><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-12-21_tensorflow-variable.png"></p><p>下面是在代码中使用 <code>tf.Varaible</code> 的方法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建变量</span></span><br><span class="line">w = tf.Variable(&lt;initial-value&gt;, name=&lt;optional-name&gt;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将变量作为操作的输入</span></span><br><span class="line">y = tf.matmul(w, ...another variable <span class="keyword">or</span> tensor...)</span><br><span class="line">z = tf.sigmoid(w + y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用 assign 或 assign_xxx 方法重新给变量赋值</span></span><br><span class="line">w.assign(w + <span class="number">1.0</span>)</span><br><span class="line">w.assign_add(<span class="number">1.0</span>)</span><br></pre></td></tr></table></figure><p>Tensorflow 用数据流图表示算法模型，数据流图由节点和有向边组成，每个节点均对应一个具体的操作 <code>Operation</code>。因此，<code>Operation</code> 是模型功能的实际载体。数据流图中的节点按照功能不同可以分为3种：</p><ul><li><strong>存储节点</strong>：有状态的变量操作，通常用来存储模型参数</li><li><strong>计算节点</strong>：无状态的计算或控制操作，主要负责算法逻辑表达或流程控制</li><li><strong>数据节点</strong>：数据的占位符操作，用于描述图外输入数据的属性</li></ul><p><strong>操作的输入和输出是张量或者操作（函数式编程）</strong></p><p>Tensorflow 的典型计算和控制操作如下：</p><div class="table-container"><table><thead><tr><th>操作类型</th><th></th></tr></thead><tbody><tr><td>基础算术</td><td>add/multiply/mod/sqrt/sin/trace/fft/argmin</td></tr><tr><td>数组运算</td><td>size/rank/split/reverse/cast/one_hot/quantize</td></tr><tr><td>梯度裁剪</td><td>clip_by_value/clip_by_norm/clip_by_global_norm</td></tr><tr><td>逻辑控制和调试</td><td>identity/logical_and/equal/less/is_finite/is_nan</td></tr><tr><td>数据流控制</td><td>enqueue/dequeue/size/take_grad/apply_grad</td></tr><tr><td>初始化操作</td><td>zeros_initilizer/random_normal_initializer/orthogonal_intializer</td></tr><tr><td>神经网络运算</td><td>convolution/pool/bias_add/softmax/dropout/erision2d</td></tr><tr><td>随机计算</td><td>random_normal/random_shuffle/multinomial/random_gramma</td></tr><tr><td>字符串运算</td><td>string_to_hash_bucket/reduce_join/substr/encode_base 64</td></tr><tr><td>图像处理运算</td><td>encode_png/resize_images/rot90/hsv_to_rgb/adjust_gamma</td></tr></tbody></table></div><p>TensorFlow 使用 <code>占位符操作</code> 表示图外输入的数据，如训练和测试数据。TensorFlow 数据流图描述了算法模型的计算拓扑，其中的各个操作（节点）都是抽象的函数映射或数学表达式。换句话说，数据流图本身是一个具有计算拓扑和内部结构的壳，在用户向数据流图填充数据前，途中并没有真正执行任何运算。</p><h2 id="建模流程"><a href="#建模流程" class="headerlink" title="建模流程"></a>建模流程</h2><p>尽管TensorFlow设计上足够灵活，可以用于进行各种复杂的数值计算。但通常人们使用TensorFlow来实现机器学习模型，尤其常用于实现神经网络模型。从原理上说可以使用张量构建计算图来定义神经网络，并通过自动微分机制训练模型。但为简洁起见，一般推荐使用TensorFlow的高层次keras接口来实现神经网络网模型。使用TensorFlow实现神经网络模型的一般流程包括：</p><ul><li>准备数据</li><li>定义模型</li><li>训练模型</li><li>评估模型</li><li>使用模型</li><li>保存模型</li></ul><p><strong>对新手来说，其中最困难的部分实际上是准备数据过程。</strong></p><p>我们在实践中通常会遇到的数据类型包括结构化数据，图片数据，文本数据，时间序列数据。</p><p>我们将分别以titanic生存预测问题，cifar2图片分类问题，imdb电影评论分类问题，国内新冠疫情结束时间预测问题为例，演示应用tensorflow对这四类数据的建模方法。</p><h3 id="结构化数据建模"><a href="#结构化数据建模" class="headerlink" title="结构化数据建模"></a>结构化数据建模</h3><h4 id="准备数据"><a href="#准备数据" class="headerlink" title="准备数据"></a>准备数据</h4><p>titanic数据集的目标是根据乘客信息预测他们在Titanic号撞击冰山沉没后能否生存。</p><p>结构化数据一般会使用Pandas中的DataFrame进行预处理。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf </span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> models,layers</span><br><span class="line"></span><br><span class="line">dftrain_raw = pd.read_csv(<span class="string">'./data/titanic/train.csv'</span>)</span><br><span class="line">dftest_raw = pd.read_csv(<span class="string">'./data/titanic/test.csv'</span>)</span><br><span class="line">dftrain_raw.head(<span class="number">10</span>)</span><br></pre></td></tr></table></figure><p><img alt data-src="https://github.com/SimpCosm/eat_tensorflow2_in_30_days_ipynbs/raw/master/data/1-1-AUC曲线.jpg"></p><p>字段说明：</p><ul><li>Survived:0代表死亡，1代表存活【y标签】</li><li>Pclass:乘客所持票类，有三种值(1,2,3) 【转换成onehot编码】</li><li>Name:乘客姓名 【舍去】</li><li>Sex:乘客性别 【转换成bool特征】</li><li>Age:乘客年龄(有缺失) 【数值特征，添加“年龄是否缺失”作为辅助特征】</li><li>SibSp:乘客兄弟姐妹/配偶的个数(整数值) 【数值特征】</li><li>Parch:乘客父母/孩子的个数(整数值)【数值特征】</li><li>Ticket:票号(字符串)【舍去】</li><li>Fare:乘客所持票的价格(浮点数，0-500不等) 【数值特征】</li><li>Cabin:乘客所在船舱(有缺失) 【添加“所在船舱是否缺失”作为辅助特征】</li><li>Embarked:乘客登船港口:S、C、Q(有缺失)【转换成onehot编码，四维度 S,C,Q,nan】</li></ul><p>利用Pandas的数据可视化功能我们可以简单地进行探索性数据分析EDA（Exploratory Data Analysis）。</p><p>label分布情况</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line">%config InlineBackend.figure_format = <span class="string">'png'</span></span><br><span class="line">ax = dftrain_raw[<span class="string">'Survived'</span>].value_counts().plot(kind = <span class="string">'bar'</span>,</span><br><span class="line">     figsize = (<span class="number">12</span>,<span class="number">8</span>),fontsize=<span class="number">15</span>,rot = <span class="number">0</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">'Counts'</span>,fontsize = <span class="number">15</span>)</span><br><span class="line">ax.set_xlabel(<span class="string">'Survived'</span>,fontsize = <span class="number">15</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img alt data-src="https://github.com/SimpCosm/eat_tensorflow2_in_30_days_ipynbs/blob/master/data/1-1-Label分布.jpg"></p><p>年龄分布情况</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line">%config InlineBackend.figure_format = <span class="string">'png'</span></span><br><span class="line">ax = dftrain_raw[<span class="string">'Age'</span>].plot(kind = <span class="string">'hist'</span>,bins = <span class="number">20</span>,color= <span class="string">'purple'</span>,</span><br><span class="line">                    figsize = (<span class="number">12</span>,<span class="number">8</span>),fontsize=<span class="number">15</span>)</span><br><span class="line"></span><br><span class="line">ax.set_ylabel(<span class="string">'Frequency'</span>,fontsize = <span class="number">15</span>)</span><br><span class="line">ax.set_xlabel(<span class="string">'Age'</span>,fontsize = <span class="number">15</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img alt data-src="https://github.com/SimpCosm/eat_tensorflow2_in_30_days_ipynbs/raw/master/data/1-1-年龄分布.jpg"></p><p>年龄和label的相关性</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line">%config InlineBackend.figure_format = <span class="string">'png'</span></span><br><span class="line">ax = dftrain_raw.query(<span class="string">'Survived == 0'</span>)[<span class="string">'Age'</span>].plot(kind = <span class="string">'density'</span>,</span><br><span class="line">                      figsize = (<span class="number">12</span>,<span class="number">8</span>),fontsize=<span class="number">15</span>)</span><br><span class="line">dftrain_raw.query(<span class="string">'Survived == 1'</span>)[<span class="string">'Age'</span>].plot(kind = <span class="string">'density'</span>,</span><br><span class="line">                      figsize = (<span class="number">12</span>,<span class="number">8</span>),fontsize=<span class="number">15</span>)</span><br><span class="line">ax.legend([<span class="string">'Survived==0'</span>,<span class="string">'Survived==1'</span>],fontsize = <span class="number">12</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">'Density'</span>,fontsize = <span class="number">15</span>)</span><br><span class="line">ax.set_xlabel(<span class="string">'Age'</span>,fontsize = <span class="number">15</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img alt data-src="https://github.com/SimpCosm/eat_tensorflow2_in_30_days_ipynbs/raw/master/data/1-1-年龄相关性.jpg"></p><p>下面为正式的数据预处理</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">preprocessing</span><span class="params">(dfdata)</span>:</span></span><br><span class="line"></span><br><span class="line">    dfresult= pd.DataFrame()</span><br><span class="line"></span><br><span class="line">    <span class="comment">#Pclass</span></span><br><span class="line">    dfPclass = pd.get_dummies(dfdata[<span class="string">'Pclass'</span>])</span><br><span class="line">    dfPclass.columns = [<span class="string">'Pclass_'</span> +str(x) <span class="keyword">for</span> x <span class="keyword">in</span> dfPclass.columns ]</span><br><span class="line">    dfresult = pd.concat([dfresult,dfPclass],axis = <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#Sex</span></span><br><span class="line">    dfSex = pd.get_dummies(dfdata[<span class="string">'Sex'</span>])</span><br><span class="line">    dfresult = pd.concat([dfresult,dfSex],axis = <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#Age</span></span><br><span class="line">    dfresult[<span class="string">'Age'</span>] = dfdata[<span class="string">'Age'</span>].fillna(<span class="number">0</span>)</span><br><span class="line">    dfresult[<span class="string">'Age_null'</span>] = pd.isna(dfdata[<span class="string">'Age'</span>]).astype(<span class="string">'int32'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#SibSp,Parch,Fare</span></span><br><span class="line">    dfresult[<span class="string">'SibSp'</span>] = dfdata[<span class="string">'SibSp'</span>]</span><br><span class="line">    dfresult[<span class="string">'Parch'</span>] = dfdata[<span class="string">'Parch'</span>]</span><br><span class="line">    dfresult[<span class="string">'Fare'</span>] = dfdata[<span class="string">'Fare'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment">#Carbin</span></span><br><span class="line">    dfresult[<span class="string">'Cabin_null'</span>] =  pd.isna(dfdata[<span class="string">'Cabin'</span>]).astype(<span class="string">'int32'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#Embarked</span></span><br><span class="line">    dfEmbarked = pd.get_dummies(dfdata[<span class="string">'Embarked'</span>],dummy_na=<span class="literal">True</span>)</span><br><span class="line">    dfEmbarked.columns = [<span class="string">'Embarked_'</span> + str(x) <span class="keyword">for</span> x <span class="keyword">in</span> dfEmbarked.columns]</span><br><span class="line">    dfresult = pd.concat([dfresult,dfEmbarked],axis = <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span>(dfresult)</span><br></pre></td></tr></table></figure><p>运行数据预处理</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">x_train = preprocessing(dftrain_raw)</span><br><span class="line">y_train = dftrain_raw[<span class="string">'Survived'</span>].values</span><br><span class="line"></span><br><span class="line">x_test = preprocessing(dftest_raw)</span><br><span class="line">y_test = dftest_raw[<span class="string">'Survived'</span>].values</span><br><span class="line"></span><br><span class="line">print(<span class="string">"x_train.shape ="</span>, x_train.shape )</span><br><span class="line">print(<span class="string">"x_test.shape ="</span>, x_test.shape )</span><br></pre></td></tr></table></figure><p>可以看到</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x_train.shape = (<span class="number">712</span>, <span class="number">15</span>)</span><br><span class="line">x_test.shape = (<span class="number">179</span>, <span class="number">15</span>)</span><br></pre></td></tr></table></figure><h4 id="定义模型"><a href="#定义模型" class="headerlink" title="定义模型"></a>定义模型</h4><p>使用Keras接口有以下3种方式构建模型：</p><ul><li>使用Sequential按层顺序构建模型</li><li>使用函数式API构建任意结构模型</li><li>继承Model基类构建自定义模型。</li></ul><p>此处选择使用最简单的Sequential，按层顺序模型。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">tf.keras.backend.clear_session()</span><br><span class="line"></span><br><span class="line">model = models.Sequential()</span><br><span class="line">model.add(layers.Dense(<span class="number">20</span>,activation = <span class="string">'relu'</span>,input_shape=(<span class="number">15</span>,)))</span><br><span class="line">model.add(layers.Dense(<span class="number">10</span>,activation = <span class="string">'relu'</span> ))</span><br><span class="line">model.add(layers.Dense(<span class="number">1</span>,activation = <span class="string">'sigmoid'</span> ))</span><br><span class="line"></span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure><p>模型输出</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">Model: "sequential"</span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">Layer (type)                 Output Shape              Param #   </span><br><span class="line">=================================================================</span><br><span class="line">dense (Dense)                (None, 20)                320       </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">dense_1 (Dense)              (None, 10)                210       </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">dense_2 (Dense)              (None, 1)                 11        </span><br><span class="line">=================================================================</span><br><span class="line">Total params: 541</span><br><span class="line">Trainable params: 541</span><br><span class="line">Non-trainable params: 0</span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br></pre></td></tr></table></figure><h4 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h4><p>训练模型通常有3种方法：</p><ul><li>内置fit方法</li><li>内置train_on_batch方法</li><li>自定义训练循环。</li></ul><p>此处我们选择最常用也最简单的内置fit方法。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 二分类问题选择二元交叉熵损失函数</span></span><br><span class="line">model.compile(optimizer=<span class="string">'adam'</span>,</span><br><span class="line">            loss=<span class="string">'binary_crossentropy'</span>,</span><br><span class="line">            metrics=[<span class="string">'AUC'</span>])</span><br><span class="line"></span><br><span class="line">history = model.fit(x_train,y_train,</span><br><span class="line">                    batch_size= <span class="number">64</span>,</span><br><span class="line">                    epochs= <span class="number">30</span>,</span><br><span class="line">                    validation_split=<span class="number">0.2</span> <span class="comment">#分割一部分训练数据用于验证</span></span><br><span class="line">                   )</span><br></pre></td></tr></table></figure><p>训练过程如下：</p><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line">Train on <span class="number">569</span> samples, validate on <span class="number">143</span> samples</span><br><span class="line">Epoch <span class="number">1</span>/<span class="number">30</span></span><br><span class="line"><span class="number">569</span>/<span class="number">569</span> [==============================] - <span class="number">1</span>s <span class="number">2</span>ms/sample - loss: <span class="number">3.5841</span> - AUC: <span class="number">0.4079</span> - val_loss: <span class="number">3.4429</span> - val_AUC: <span class="number">0.4129</span></span><br><span class="line">Epoch <span class="number">2</span>/<span class="number">30</span></span><br><span class="line"><span class="number">569</span>/<span class="number">569</span> [==============================] - <span class="number">0</span>s <span class="number">102</span>us/sample - loss: <span class="number">2.6093</span> - AUC: <span class="number">0.3967</span> - val_loss: <span class="number">2.4886</span> - val_AUC: <span class="number">0.4139</span></span><br><span class="line">Epoch <span class="number">3</span>/<span class="number">30</span></span><br><span class="line"><span class="number">569</span>/<span class="number">569</span> [==============================] - <span class="number">0</span>s <span class="number">68</span>us/sample - loss: <span class="number">1.8375</span> - AUC: <span class="number">0.4003</span> - val_loss: <span class="number">1.7383</span> - val_AUC: <span class="number">0.4223</span></span><br><span class="line">Epoch <span class="number">4</span>/<span class="number">30</span></span><br><span class="line"><span class="number">569</span>/<span class="number">569</span> [==============================] - <span class="number">0</span>s <span class="number">83</span>us/sample - loss: <span class="number">1.2545</span> - AUC: <span class="number">0.4390</span> - val_loss: <span class="number">1.1936</span> - val_AUC: <span class="number">0.4765</span></span><br><span class="line">Epoch <span class="number">5</span>/<span class="number">30</span></span><br><span class="line"><span class="number">569</span>/<span class="number">569</span> [==============================] - ETA: <span class="number">0</span>s - loss: <span class="number">1.4435</span> - AUC: <span class="number">0.375</span> - <span class="number">0</span>s <span class="number">90</span>us/sample - loss: <span class="number">0.9141</span> - AUC: <span class="number">0.5192</span> - val_loss: <span class="number">0.8274</span> - val_AUC: <span class="number">0.5584</span></span><br><span class="line">Epoch <span class="number">6</span>/<span class="number">30</span></span><br><span class="line"><span class="number">569</span>/<span class="number">569</span> [==============================] - <span class="number">0</span>s <span class="number">110</span>us/sample - loss: <span class="number">0.7052</span> - AUC: <span class="number">0.6290</span> - val_loss: <span class="number">0.6596</span> - val_AUC: <span class="number">0.6880</span></span><br><span class="line">Epoch <span class="number">7</span>/<span class="number">30</span></span><br><span class="line"><span class="number">569</span>/<span class="number">569</span> [==============================] - <span class="number">0</span>s <span class="number">90</span>us/sample - loss: <span class="number">0.6410</span> - AUC: <span class="number">0.7086</span> - val_loss: <span class="number">0.6519</span> - val_AUC: <span class="number">0.6845</span></span><br><span class="line">Epoch <span class="number">8</span>/<span class="number">30</span></span><br><span class="line"><span class="number">569</span>/<span class="number">569</span> [==============================] - <span class="number">0</span>s <span class="number">93</span>us/sample - loss: <span class="number">0.6246</span> - AUC: <span class="number">0.7080</span> - val_loss: <span class="number">0.6480</span> - val_AUC: <span class="number">0.6846</span></span><br><span class="line">Epoch <span class="number">9</span>/<span class="number">30</span></span><br><span class="line"><span class="number">569</span>/<span class="number">569</span> [==============================] - <span class="number">0</span>s <span class="number">73</span>us/sample - loss: <span class="number">0.6088</span> - AUC: <span class="number">0.7113</span> - val_loss: <span class="number">0.6497</span> - val_AUC: <span class="number">0.6838</span></span><br><span class="line">Epoch <span class="number">10</span>/<span class="number">30</span></span><br><span class="line"><span class="number">569</span>/<span class="number">569</span> [==============================] - <span class="number">0</span>s <span class="number">79</span>us/sample - loss: <span class="number">0.6051</span> - AUC: <span class="number">0.7117</span> - val_loss: <span class="number">0.6454</span> - val_AUC: <span class="number">0.6873</span></span><br><span class="line">Epoch <span class="number">11</span>/<span class="number">30</span></span><br><span class="line"><span class="number">569</span>/<span class="number">569</span> [==============================] - <span class="number">0</span>s <span class="number">96</span>us/sample - loss: <span class="number">0.5972</span> - AUC: <span class="number">0.7218</span> - val_loss: <span class="number">0.6369</span> - val_AUC: <span class="number">0.6888</span></span><br><span class="line">Epoch <span class="number">12</span>/<span class="number">30</span></span><br><span class="line"><span class="number">569</span>/<span class="number">569</span> [==============================] - <span class="number">0</span>s <span class="number">92</span>us/sample - loss: <span class="number">0.5918</span> - AUC: <span class="number">0.7294</span> - val_loss: <span class="number">0.6330</span> - val_AUC: <span class="number">0.6908</span></span><br><span class="line">Epoch <span class="number">13</span>/<span class="number">30</span></span><br><span class="line"><span class="number">569</span>/<span class="number">569</span> [==============================] - <span class="number">0</span>s <span class="number">75</span>us/sample - loss: <span class="number">0.5864</span> - AUC: <span class="number">0.7363</span> - val_loss: <span class="number">0.6281</span> - val_AUC: <span class="number">0.6948</span></span><br><span class="line">Epoch <span class="number">14</span>/<span class="number">30</span></span><br><span class="line"><span class="number">569</span>/<span class="number">569</span> [==============================] - <span class="number">0</span>s <span class="number">104</span>us/sample - loss: <span class="number">0.5832</span> - AUC: <span class="number">0.7426</span> - val_loss: <span class="number">0.6240</span> - val_AUC: <span class="number">0.7030</span></span><br><span class="line">Epoch <span class="number">15</span>/<span class="number">30</span></span><br><span class="line"><span class="number">569</span>/<span class="number">569</span> [==============================] - <span class="number">0</span>s <span class="number">74</span>us/sample - loss: <span class="number">0.5777</span> - AUC: <span class="number">0.7507</span> - val_loss: <span class="number">0.6200</span> - val_AUC: <span class="number">0.7066</span></span><br><span class="line">Epoch <span class="number">16</span>/<span class="number">30</span></span><br><span class="line"><span class="number">569</span>/<span class="number">569</span> [==============================] - <span class="number">0</span>s <span class="number">79</span>us/sample - loss: <span class="number">0.5726</span> - AUC: <span class="number">0.7569</span> - val_loss: <span class="number">0.6155</span> - val_AUC: <span class="number">0.7132</span></span><br><span class="line">Epoch <span class="number">17</span>/<span class="number">30</span></span><br><span class="line"><span class="number">569</span>/<span class="number">569</span> [==============================] - <span class="number">0</span>s <span class="number">99</span>us/sample - loss: <span class="number">0.5674</span> - AUC: <span class="number">0.7643</span> - val_loss: <span class="number">0.6070</span> - val_AUC: <span class="number">0.7255</span></span><br><span class="line">Epoch <span class="number">18</span>/<span class="number">30</span></span><br><span class="line"><span class="number">569</span>/<span class="number">569</span> [==============================] - <span class="number">0</span>s <span class="number">97</span>us/sample - loss: <span class="number">0.5631</span> - AUC: <span class="number">0.7721</span> - val_loss: <span class="number">0.6061</span> - val_AUC: <span class="number">0.7305</span></span><br><span class="line">Epoch <span class="number">19</span>/<span class="number">30</span></span><br><span class="line"><span class="number">569</span>/<span class="number">569</span> [==============================] - <span class="number">0</span>s <span class="number">73</span>us/sample - loss: <span class="number">0.5580</span> - AUC: <span class="number">0.7792</span> - val_loss: <span class="number">0.6027</span> - val_AUC: <span class="number">0.7332</span></span><br><span class="line">Epoch <span class="number">20</span>/<span class="number">30</span></span><br><span class="line"><span class="number">569</span>/<span class="number">569</span> [==============================] - <span class="number">0</span>s <span class="number">85</span>us/sample - loss: <span class="number">0.5533</span> - AUC: <span class="number">0.7861</span> - val_loss: <span class="number">0.5997</span> - val_AUC: <span class="number">0.7366</span></span><br><span class="line">Epoch <span class="number">21</span>/<span class="number">30</span></span><br><span class="line"><span class="number">569</span>/<span class="number">569</span> [==============================] - <span class="number">0</span>s <span class="number">87</span>us/sample - loss: <span class="number">0.5497</span> - AUC: <span class="number">0.7926</span> - val_loss: <span class="number">0.5961</span> - val_AUC: <span class="number">0.7433</span></span><br><span class="line">Epoch <span class="number">22</span>/<span class="number">30</span></span><br><span class="line"><span class="number">569</span>/<span class="number">569</span> [==============================] - <span class="number">0</span>s <span class="number">101</span>us/sample - loss: <span class="number">0.5454</span> - AUC: <span class="number">0.7987</span> - val_loss: <span class="number">0.5943</span> - val_AUC: <span class="number">0.7438</span></span><br><span class="line">Epoch <span class="number">23</span>/<span class="number">30</span></span><br><span class="line"><span class="number">569</span>/<span class="number">569</span> [==============================] - <span class="number">0</span>s <span class="number">100</span>us/sample - loss: <span class="number">0.5398</span> - AUC: <span class="number">0.8057</span> - val_loss: <span class="number">0.5926</span> - val_AUC: <span class="number">0.7492</span></span><br><span class="line">Epoch <span class="number">24</span>/<span class="number">30</span></span><br><span class="line"><span class="number">569</span>/<span class="number">569</span> [==============================] - <span class="number">0</span>s <span class="number">79</span>us/sample - loss: <span class="number">0.5328</span> - AUC: <span class="number">0.8122</span> - val_loss: <span class="number">0.5912</span> - val_AUC: <span class="number">0.7493</span></span><br><span class="line">Epoch <span class="number">25</span>/<span class="number">30</span></span><br><span class="line"><span class="number">569</span>/<span class="number">569</span> [==============================] - <span class="number">0</span>s <span class="number">86</span>us/sample - loss: <span class="number">0.5283</span> - AUC: <span class="number">0.8147</span> - val_loss: <span class="number">0.5902</span> - val_AUC: <span class="number">0.7509</span></span><br><span class="line">Epoch <span class="number">26</span>/<span class="number">30</span></span><br><span class="line"><span class="number">569</span>/<span class="number">569</span> [==============================] - <span class="number">0</span>s <span class="number">67</span>us/sample - loss: <span class="number">0.5246</span> - AUC: <span class="number">0.8196</span> - val_loss: <span class="number">0.5845</span> - val_AUC: <span class="number">0.7552</span></span><br><span class="line">Epoch <span class="number">27</span>/<span class="number">30</span></span><br><span class="line"><span class="number">569</span>/<span class="number">569</span> [==============================] - <span class="number">0</span>s <span class="number">72</span>us/sample - loss: <span class="number">0.5205</span> - AUC: <span class="number">0.8271</span> - val_loss: <span class="number">0.5837</span> - val_AUC: <span class="number">0.7584</span></span><br><span class="line">Epoch <span class="number">28</span>/<span class="number">30</span></span><br><span class="line"><span class="number">569</span>/<span class="number">569</span> [==============================] - <span class="number">0</span>s <span class="number">74</span>us/sample - loss: <span class="number">0.5144</span> - AUC: <span class="number">0.8302</span> - val_loss: <span class="number">0.5848</span> - val_AUC: <span class="number">0.7561</span></span><br><span class="line">Epoch <span class="number">29</span>/<span class="number">30</span></span><br><span class="line"><span class="number">569</span>/<span class="number">569</span> [==============================] - <span class="number">0</span>s <span class="number">77</span>us/sample - loss: <span class="number">0.5099</span> - AUC: <span class="number">0.8326</span> - val_loss: <span class="number">0.5809</span> - val_AUC: <span class="number">0.7583</span></span><br><span class="line">Epoch <span class="number">30</span>/<span class="number">30</span></span><br><span class="line"><span class="number">569</span>/<span class="number">569</span> [==============================] - <span class="number">0</span>s <span class="number">80</span>us/sample - loss: <span class="number">0.5071</span> - AUC: <span class="number">0.8349</span> - val_loss: <span class="number">0.5816</span> - val_AUC: <span class="number">0.7605</span></span><br></pre></td></tr></table></figure><h4 id="评估模型"><a href="#评估模型" class="headerlink" title="评估模型"></a>评估模型</h4><p>我们首先评估一下模型在训练集和验证集上的效果。</p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line">%config InlineBackend.figure_format = <span class="string">'svg'</span></span><br><span class="line"></span><br><span class="line">import matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">def plot_metric(<span class="keyword">history</span>, metric):</span><br><span class="line">    train_metrics = <span class="keyword">history</span>.<span class="keyword">history</span>[metric]</span><br><span class="line">    val_metrics = <span class="keyword">history</span>.<span class="keyword">history</span>[<span class="string">'val_'</span>+metric]</span><br><span class="line">    epochs = <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(train_metrics) + <span class="number">1</span>)</span><br><span class="line">    plt.plot(epochs, train_metrics, <span class="string">'bo--'</span>)</span><br><span class="line">    plt.plot(epochs, val_metrics, <span class="string">'ro-'</span>)</span><br><span class="line">    plt.title(<span class="string">'Training and validation '</span>+ metric)</span><br><span class="line">    plt.xlabel(<span class="string">"Epochs"</span>)</span><br><span class="line">    plt.ylabel(metric)</span><br><span class="line">    plt.legend([<span class="string">"train_"</span>+metric, <span class="string">'val_'</span>+metric])</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><p>查看训练过程中随着迭代次数增加，误差的减少：</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="title">plot_metric</span><span class="params">(history,<span class="string">"loss"</span>)</span></span></span><br></pre></td></tr></table></figure><p><img alt data-src="https://github.com/SimpCosm/eat_tensorflow2_in_30_days_ipynbs/raw/master/data/1-1-Loss%E6%9B%B2%E7%BA%BF.jpg"></p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="title">plot_metric</span><span class="params">(history,<span class="string">"AUC"</span>)</span></span></span><br></pre></td></tr></table></figure><p><img alt data-src="https://github.com/SimpCosm/eat_tensorflow2_in_30_days_ipynbs/raw/master/data/1-1-AUC%E6%9B%B2%E7%BA%BF.jpg"></p><p>我们再看一下模型在测试集上的效果</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.evaluate(x = x_test,y = y_test)</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">6</span>/<span class="number">6</span> [==============================] - <span class="number">0</span>s <span class="number">2</span>ms/step - loss: <span class="number">0.5665</span> - auc: <span class="number">0.7485</span></span><br><span class="line">[<span class="number">0.5664713382720947</span>, <span class="number">0.7484948039054871</span>]</span><br></pre></td></tr></table></figure><h4 id="使用模型"><a href="#使用模型" class="headerlink" title="使用模型"></a>使用模型</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 预测概率</span></span><br><span class="line">model.predict(x_test[<span class="number">0</span>:<span class="number">10</span>])</span><br></pre></td></tr></table></figure><p>输出如下：</p><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">array</span>([[<span class="number">0.26501188</span>],</span><br><span class="line">       [<span class="number">0.40970832</span>],</span><br><span class="line">       [<span class="number">0.44285864</span>],</span><br><span class="line">       [<span class="number">0.78408605</span>],</span><br><span class="line">       [<span class="number">0.47650957</span>],</span><br><span class="line">       [<span class="number">0.43849158</span>],</span><br><span class="line">       [<span class="number">0.27426785</span>],</span><br><span class="line">       [<span class="number">0.5962582</span> ],</span><br><span class="line">       [<span class="number">0.59476686</span>],</span><br><span class="line">       [<span class="number">0.17882936</span>]], dtype=<span class="built_in">float</span>32)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 预测类别</span></span><br><span class="line">model.predict_classes(x_test[<span class="number">0</span>:<span class="number">10</span>])</span><br></pre></td></tr></table></figure><p>输出如下：</p><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">array</span>([[<span class="number">0</span>],</span><br><span class="line">       [<span class="number">0</span>],</span><br><span class="line">       [<span class="number">0</span>],</span><br><span class="line">       [<span class="number">1</span>],</span><br><span class="line">       [<span class="number">0</span>],</span><br><span class="line">       [<span class="number">0</span>],</span><br><span class="line">       [<span class="number">0</span>],</span><br><span class="line">       [<span class="number">1</span>],</span><br><span class="line">       [<span class="number">1</span>],</span><br><span class="line">       [<span class="number">0</span>]], dtype=<span class="built_in">int</span>32)</span><br></pre></td></tr></table></figure><h4 id="保存模型"><a href="#保存模型" class="headerlink" title="保存模型"></a>保存模型</h4><p>保存模型有两种方式，推荐TensorFlow原生方式进行保存。</p><ul><li>使用Keras方式保存模型，仅仅适合使用Python环境恢复模型</li><li>使用TensorFlow原生方式保存，可以跨平台进行模型部署</li></ul><h5 id="Keras方式保存"><a href="#Keras方式保存" class="headerlink" title="Keras方式保存"></a>Keras方式保存</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 保存模型结构及权重</span></span><br><span class="line">model.save(<span class="string">'./data/keras_model.h5'</span>)  </span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除现有模型</span></span><br><span class="line"><span class="keyword">del</span> model</span><br><span class="line"></span><br><span class="line"><span class="comment"># identical to the previous one</span></span><br><span class="line">model = models.load_model(<span class="string">'./data/keras_model.h5'</span>)</span><br><span class="line">model.evaluate(x_test,y_test)</span><br><span class="line"><span class="comment"># 输出如下</span></span><br><span class="line"><span class="comment"># [0.5191367897907448, 0.8122605]</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 保存模型结构</span></span><br><span class="line">json_str = model.to_json()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 恢复模型结构</span></span><br><span class="line">model_json = models.model_from_json(json_str)</span><br><span class="line"><span class="comment">#保存模型权重</span></span><br><span class="line">model.save_weights(<span class="string">'./data/keras_model_weight.h5'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 恢复模型结构</span></span><br><span class="line">model_json = models.model_from_json(json_str)</span><br><span class="line">model_json.compile(</span><br><span class="line">        optimizer=<span class="string">'adam'</span>,</span><br><span class="line">        loss=<span class="string">'binary_crossentropy'</span>,</span><br><span class="line">        metrics=[<span class="string">'AUC'</span>]</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载权重</span></span><br><span class="line">model_json.load_weights(<span class="string">'./data/keras_model_weight.h5'</span>)</span><br><span class="line">model_json.evaluate(x_test,y_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出如下</span></span><br><span class="line"><span class="comment"># [0.5191367897907448, 0.8122605]</span></span><br></pre></td></tr></table></figure><h5 id="TensorFlow原生方式保存"><a href="#TensorFlow原生方式保存" class="headerlink" title="TensorFlow原生方式保存"></a>TensorFlow原生方式保存</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 保存权重，该方式仅仅保存权重张量</span></span><br><span class="line">model.save_weights(<span class="string">'./data/tf_model_weights.ckpt'</span>,save_format = <span class="string">"tf"</span>)</span><br><span class="line"><span class="comment"># 保存模型结构与模型参数到文件,该方式保存的模型具有跨平台性便于部署</span></span><br><span class="line"></span><br><span class="line">model.save(<span class="string">'./data/tf_model_savedmodel'</span>, save_format=<span class="string">"tf"</span>)</span><br><span class="line">print(<span class="string">'export saved model.'</span>)</span><br><span class="line"></span><br><span class="line">model_loaded = tf.keras.models.load_model(<span class="string">'./data/tf_model_savedmodel'</span>)</span><br><span class="line">model_loaded.evaluate(x_test,y_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出如下</span></span><br><span class="line"><span class="comment"># [0.5191365896656527, 0.8122605]</span></span><br></pre></td></tr></table></figure><h3 id="图片数据建模流程"><a href="#图片数据建模流程" class="headerlink" title="图片数据建模流程"></a>图片数据建模流程</h3><h4 id="准备数据-1"><a href="#准备数据-1" class="headerlink" title="准备数据"></a>准备数据</h4><p>cifar2数据集为cifar10数据集的子集，只包括前两种类别airplane和automobile。训练集有airplane和automobile图片各5000张，测试集有airplane和automobile图片各1000张。cifar2任务的目标是训练一个模型来对飞机airplane和机动车automobile两种图片进行分类。</p><p>我们准备的Cifar2数据集的文件结构如下所示。</p><p><img alt data-src="https://github.com/SimpCosm/eat_tensorflow2_in_30_days_ipynbs/raw/master/data/cifar2.jpg"></p><p>在tensorflow中准备图片数据的常用方案有两种：</p><ul><li>使用 <code>tf.keras</code> 中的 <code>ImageDataGenerator</code> 工具构建图片数据生成器，这种更为简单，其使用范例可以参考以下文章：<a href="https://mp.weixin.qq.com/s?__biz=MzU3OTQzNTU2OA==&amp;mid=2247484795&amp;idx=1&amp;sn=16947726702b87ee535aef0d6ae2db30&amp;chksm=fd676824ca10e1321e77c5fa44339c0a79442cd8d7fbcc58697be166a4b0f990306848724692&amp;mpshare=1&amp;scene=1&amp;srcid=1227ARPw2Ir8nVC4B84CjcIx&amp;sharer_sharetime=1609043128020&amp;sharer_shareid=808295d573831eb57288f1fc0ad3ac69&amp;key=a58ea5adca8c8f06e4a7b7a15ed218f88cbee52ab3ee0fca3f2dd3f0797a36a6de26f8e75bd4787ddf97195c3959d94fe5060be0d3f9f6cd1eba11c0ad1ee37709088084d70034bd03efd43dacc32acd45a231c8359dd84ad73c28b11a9dc50556486b6e1e1ab89ad11da9621e5cdd858fcb53d91037d5116d638d12fced85b3&amp;ascene=0&amp;uin=MTYzMDEzMjAxMg%3D%3D&amp;devicetype=iMac+MacBookAir7%2C2+OSX+OSX+10.14.6+build(18G6032" target="_blank" rel="external nofollow noopener noreferrer">Keras图像数据预处理范例——Cifar2图片分类</a>&amp;version=11020113&amp;lang=zh_CN&amp;exportkey=A8nc9Ve3hcMzsggW3DOY8mU%3D&amp;pass_ticket=JOjUjT6HXslkPfqXrPY1oG3qVEXbIIc1IAKdh8xjlrGyB8OtZ8JjRan45%2Ff%2Bknjb&amp;wx_header=0)</li><li>使用 <code>tf.data.Dataset</code> 搭配 <code>tf.image</code> 中的一些图片处理方法构建数据管道，这种方法是TensorFlow的原生方法，更加灵活，使用得当的话也可以获得更好的性能。</li></ul><p>我们此处介绍第二种方法。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf </span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> datasets,layers,models</span><br><span class="line"></span><br><span class="line">BATCH_SIZE = <span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_image</span><span class="params">(img_path,size = <span class="params">(<span class="number">32</span>,<span class="number">32</span>)</span>)</span>:</span></span><br><span class="line">    label = tf.constant(<span class="number">1</span>,tf.int8) <span class="keyword">if</span> tf.strings.regex_full_match(img_path,<span class="string">".*automobile.*"</span>) \</span><br><span class="line">            <span class="keyword">else</span> tf.constant(<span class="number">0</span>,tf.int8)</span><br><span class="line">    img = tf.io.read_file(img_path)</span><br><span class="line">    img = tf.image.decode_jpeg(img) <span class="comment"># 注意此处为jpeg格式</span></span><br><span class="line">    img = tf.image.resize(img,size)/<span class="number">255.0</span></span><br><span class="line">    <span class="keyword">return</span>(img, label)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用并行化预处理 num_parallel_calls 和预存数据prefetch来提升性能</span></span><br><span class="line">ds_train = tf.data.Dataset.list_files(<span class="string">"./data/cifar2/train/*/*.jpg"</span>) \</span><br><span class="line">           .map(load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE) \</span><br><span class="line">           .shuffle(buffer_size = <span class="number">1000</span>).batch(BATCH_SIZE) \</span><br><span class="line">           .prefetch(tf.data.experimental.AUTOTUNE)  </span><br><span class="line"></span><br><span class="line">ds_test = tf.data.Dataset.list_files(<span class="string">"./data/cifar2/test/*/*.jpg"</span>) \</span><br><span class="line">           .map(load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE) \</span><br><span class="line">           .batch(BATCH_SIZE) \</span><br><span class="line">           .prefetch(tf.data.experimental.AUTOTUNE)</span><br></pre></td></tr></table></figure><p>查看部分样本：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line">%config InlineBackend.figure_format = <span class="string">'svg'</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#查看部分样本</span></span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt </span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">8</span>,<span class="number">8</span>)) </span><br><span class="line"><span class="keyword">for</span> i,(img,label) <span class="keyword">in</span> enumerate(ds_train.unbatch().take(<span class="number">9</span>)):</span><br><span class="line">    ax=plt.subplot(<span class="number">3</span>,<span class="number">3</span>,i+<span class="number">1</span>)</span><br><span class="line">    ax.imshow(img.numpy())</span><br><span class="line">    ax.set_title(<span class="string">"label = %d"</span>%label)</span><br><span class="line">    ax.set_xticks([])</span><br><span class="line">    ax.set_yticks([]) </span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img alt data-src="https://github.com/SimpCosm/eat_tensorflow2_in_30_days_ipynbs/raw/master/data/1-2-图片预览.jpg"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> x,y <span class="keyword">in</span> ds_train.take(<span class="number">1</span>):</span><br><span class="line">    print(x.shape,y.shape)</span><br><span class="line"><span class="comment"># 输出 (100, 32, 32, 3) (100,)</span></span><br></pre></td></tr></table></figure><h4 id="定义模型-1"><a href="#定义模型-1" class="headerlink" title="定义模型"></a>定义模型</h4><p>使用Keras接口有以下3种方式构建模型：</p><ul><li>使用Sequential按层顺序构建模型</li><li>使用函数式API构建任意结构模型</li><li>继承Model基类构建自定义模型</li></ul><p>此处选择使用函数式API构建模型。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">tf.keras.backend.clear_session() <span class="comment">#清空会话</span></span><br><span class="line"></span><br><span class="line">inputs = layers.Input(shape=(<span class="number">32</span>,<span class="number">32</span>,<span class="number">3</span>))</span><br><span class="line">x = layers.Conv2D(<span class="number">32</span>,kernel_size=(<span class="number">3</span>,<span class="number">3</span>))(inputs)</span><br><span class="line">x = layers.MaxPool2D()(x)</span><br><span class="line">x = layers.Conv2D(<span class="number">64</span>,kernel_size=(<span class="number">5</span>,<span class="number">5</span>))(x)</span><br><span class="line">x = layers.MaxPool2D()(x)</span><br><span class="line">x = layers.Dropout(rate=<span class="number">0.1</span>)(x)</span><br><span class="line">x = layers.Flatten()(x)</span><br><span class="line">x = layers.Dense(<span class="number">32</span>,activation=<span class="string">'relu'</span>)(x)</span><br><span class="line">outputs = layers.Dense(<span class="number">1</span>,activation = <span class="string">'sigmoid'</span>)(x)</span><br><span class="line"></span><br><span class="line">model = models.Model(inputs = inputs,outputs = outputs)</span><br><span class="line"></span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure><p>输出如下：</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">Model: "model"</span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">Layer (type)                 Output Shape              Param #   </span><br><span class="line">=================================================================</span><br><span class="line">input_1 (InputLayer)         [(None, 32, 32, 3)]       0         </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">conv2d (Conv2D)              (None, 30, 30, 32)        896       </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">max_pooling2d (MaxPooling2D) (None, 15, 15, 32)        0         </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">conv2d_1 (Conv2D)            (None, 11, 11, 64)        51264     </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">max<span class="emphasis">_pooling2d_</span>1 (MaxPooling2 (None, 5, 5, 64)          0         </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">dropout (Dropout)            (None, 5, 5, 64)          0         </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">flatten (Flatten)            (None, 1600)              0         </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">dense (Dense)                (None, 32)                51232     </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">dense_1 (Dense)              (None, 1)                 33        </span><br><span class="line">=================================================================</span><br><span class="line">Total params: 103,425</span><br><span class="line">Trainable params: 103,425</span><br><span class="line">Non-trainable params: 0</span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br></pre></td></tr></table></figure><h4 id="训练模型-1"><a href="#训练模型-1" class="headerlink" title="训练模型"></a>训练模型</h4><p>训练模型通常有3种方法：</p><ul><li>内置fit方法</li><li>内置train_on_batch方法</li><li>自定义训练循环</li></ul><p>此处我们选择最常用也最简单的内置fit方法。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">stamp = datetime.datetime.now().strftime(<span class="string">"%Y%m%d-%H%M%S"</span>)</span><br><span class="line">logdir = os.path.join(<span class="string">'data'</span>, <span class="string">'autograph'</span>, stamp)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 在 Python3 下建议使用 pathlib 修正各操作系统的路径</span></span><br><span class="line"><span class="comment"># from pathlib import Path</span></span><br><span class="line"><span class="comment"># stamp = datetime.datetime.now().strftime("%Y%m%d-%H%M%S")</span></span><br><span class="line"><span class="comment"># logdir = str(Path('./data/autograph/' + stamp))</span></span><br><span class="line"></span><br><span class="line">tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">model.compile(</span><br><span class="line">        optimizer=tf.keras.optimizers.Adam(learning_rate=<span class="number">0.001</span>),</span><br><span class="line">        loss=tf.keras.losses.binary_crossentropy,</span><br><span class="line">        metrics=[<span class="string">"accuracy"</span>]</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">history = model.fit(ds_train,epochs= <span class="number">10</span>,validation_data=ds_test,</span><br><span class="line">                    callbacks = [tensorboard_callback],workers = <span class="number">4</span>)</span><br></pre></td></tr></table></figure><p>输出如下：</p><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">Train <span class="keyword">for</span> <span class="number">100</span> steps, validate <span class="keyword">for</span> <span class="number">20</span> steps</span><br><span class="line">Epoch <span class="number">1</span>/<span class="number">10</span></span><br><span class="line"><span class="number">100</span>/<span class="number">100</span> [==============================] - <span class="number">16</span>s <span class="number">156</span>ms/step - loss: <span class="number">0.4830</span> - accuracy: <span class="number">0.7697</span> - val_loss: <span class="number">0.3396</span> - val_accuracy: <span class="number">0.8475</span></span><br><span class="line">Epoch <span class="number">2</span>/<span class="number">10</span></span><br><span class="line"><span class="number">100</span>/<span class="number">100</span> [==============================] - <span class="number">14</span>s <span class="number">142</span>ms/step - loss: <span class="number">0.3437</span> - accuracy: <span class="number">0.8469</span> - val_loss: <span class="number">0.2997</span> - val_accuracy: <span class="number">0.8680</span></span><br><span class="line">Epoch <span class="number">3</span>/<span class="number">10</span></span><br><span class="line"><span class="number">100</span>/<span class="number">100</span> [==============================] - <span class="number">13</span>s <span class="number">131</span>ms/step - loss: <span class="number">0.2871</span> - accuracy: <span class="number">0.8777</span> - val_loss: <span class="number">0.2390</span> - val_accuracy: <span class="number">0.9015</span></span><br><span class="line">Epoch <span class="number">4</span>/<span class="number">10</span></span><br><span class="line"><span class="number">100</span>/<span class="number">100</span> [==============================] - <span class="number">12</span>s <span class="number">117</span>ms/step - loss: <span class="number">0.2410</span> - accuracy: <span class="number">0.9040</span> - val_loss: <span class="number">0.2005</span> - val_accuracy: <span class="number">0.9195</span></span><br><span class="line">Epoch <span class="number">5</span>/<span class="number">10</span></span><br><span class="line"><span class="number">100</span>/<span class="number">100</span> [==============================] - <span class="number">13</span>s <span class="number">130</span>ms/step - loss: <span class="number">0.1992</span> - accuracy: <span class="number">0.9213</span> - val_loss: <span class="number">0.1949</span> - val_accuracy: <span class="number">0.9180</span></span><br><span class="line">Epoch <span class="number">6</span>/<span class="number">10</span></span><br><span class="line"><span class="number">100</span>/<span class="number">100</span> [==============================] - <span class="number">14</span>s <span class="number">136</span>ms/step - loss: <span class="number">0.1737</span> - accuracy: <span class="number">0.9323</span> - val_loss: <span class="number">0.1723</span> - val_accuracy: <span class="number">0.9275</span></span><br><span class="line">Epoch <span class="number">7</span>/<span class="number">10</span></span><br><span class="line"><span class="number">100</span>/<span class="number">100</span> [==============================] - <span class="number">14</span>s <span class="number">139</span>ms/step - loss: <span class="number">0.1531</span> - accuracy: <span class="number">0.9412</span> - val_loss: <span class="number">0.1670</span> - val_accuracy: <span class="number">0.9310</span></span><br><span class="line">Epoch <span class="number">8</span>/<span class="number">10</span></span><br><span class="line"><span class="number">100</span>/<span class="number">100</span> [==============================] - <span class="number">13</span>s <span class="number">134</span>ms/step - loss: <span class="number">0.1299</span> - accuracy: <span class="number">0.9525</span> - val_loss: <span class="number">0.1553</span> - val_accuracy: <span class="number">0.9340</span></span><br><span class="line">Epoch <span class="number">9</span>/<span class="number">10</span></span><br><span class="line"><span class="number">100</span>/<span class="number">100</span> [==============================] - <span class="number">14</span>s <span class="number">137</span>ms/step - loss: <span class="number">0.1158</span> - accuracy: <span class="number">0.9556</span> - val_loss: <span class="number">0.1581</span> - val_accuracy: <span class="number">0.9340</span></span><br><span class="line">Epoch <span class="number">10</span>/<span class="number">10</span></span><br><span class="line"><span class="number">100</span>/<span class="number">100</span> [==============================] - <span class="number">14</span>s <span class="number">142</span>ms/step - loss: <span class="number">0.1006</span> - accuracy: <span class="number">0.9617</span> - val_loss: <span class="number">0.1614</span> - val_accuracy: <span class="number">0.9345</span></span><br></pre></td></tr></table></figure><h4 id="评估模型-1"><a href="#评估模型-1" class="headerlink" title="评估模型"></a>评估模型</h4><figure class="highlight livescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">%load_ext tensorboard</span><br><span class="line"><span class="comment">#%tensorboard --logdir ./data/keras_model</span></span><br><span class="line"><span class="keyword">from</span> tensorboard <span class="keyword">import</span> notebook</span><br><span class="line">notebook.<span class="keyword">list</span>() </span><br><span class="line"><span class="comment">#在tensorboard中查看模型</span></span><br><span class="line">notebook.start(<span class="string">"--logdir ./data/keras_model"</span>)</span><br></pre></td></tr></table></figure><p><img alt data-src="https://github.com/SimpCosm/eat_tensorflow2_in_30_days_ipynbs/raw/master/data/1-2-tensorboard.jpg"></p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">import pandas <span class="keyword">as</span> pd </span><br><span class="line">dfhistory = pd.DataFrame(<span class="keyword">history</span>.<span class="keyword">history</span>)</span><br><span class="line">dfhistory.<span class="built_in">index</span> = <span class="built_in">range</span>(<span class="number">1</span>,<span class="built_in">len</span>(dfhistory) + <span class="number">1</span>)</span><br><span class="line">dfhistory.<span class="built_in">index</span>.name = <span class="string">'epoch'</span></span><br><span class="line"></span><br><span class="line">dfhistory</span><br></pre></td></tr></table></figure><p><img alt data-src="https://github.com/SimpCosm/eat_tensorflow2_in_30_days_ipynbs/raw/master/data/1-2-dfhistory.jpg"></p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line">%config InlineBackend.figure_format = <span class="string">'svg'</span></span><br><span class="line"></span><br><span class="line">import matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">def plot_metric(<span class="keyword">history</span>, metric):</span><br><span class="line">    train_metrics = <span class="keyword">history</span>.<span class="keyword">history</span>[metric]</span><br><span class="line">    val_metrics = <span class="keyword">history</span>.<span class="keyword">history</span>[<span class="string">'val_'</span>+metric]</span><br><span class="line">    epochs = <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(train_metrics) + <span class="number">1</span>)</span><br><span class="line">    plt.plot(epochs, train_metrics, <span class="string">'bo--'</span>)</span><br><span class="line">    plt.plot(epochs, val_metrics, <span class="string">'ro-'</span>)</span><br><span class="line">    plt.title(<span class="string">'Training and validation '</span>+ metric)</span><br><span class="line">    plt.xlabel(<span class="string">"Epochs"</span>)</span><br><span class="line">    plt.ylabel(metric)</span><br><span class="line">    plt.legend([<span class="string">"train_"</span>+metric, <span class="string">'val_'</span>+metric])</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="title">plot_metric</span><span class="params">(history,<span class="string">"loss"</span>)</span></span></span><br></pre></td></tr></table></figure><p><img alt data-src="https://github.com/SimpCosm/eat_tensorflow2_in_30_days_ipynbs/raw/master/data/1-2-Loss曲线.jpg"></p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="title">plot_metric</span><span class="params">(history,<span class="string">"accuracy"</span>)</span></span></span><br></pre></td></tr></table></figure><p><img alt data-src="https://github.com/SimpCosm/eat_tensorflow2_in_30_days_ipynbs/raw/master/data/1-2-Accuracy曲线.jpg"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 可以使用evaluate对数据进行评估</span></span><br><span class="line">val_loss,val_accuracy = model.evaluate(ds_test,workers=<span class="number">4</span>)</span><br><span class="line">print(val_loss,val_accuracy)</span><br><span class="line"><span class="comment"># 0.16139143370091916 0.9345</span></span><br></pre></td></tr></table></figure><h4 id="使用模型-1"><a href="#使用模型-1" class="headerlink" title="使用模型"></a>使用模型</h4><ul><li>可以使用model.predict(ds_test)进行预测。</li><li>可以使用model.predict_on_batch(x_test)对一个批量进行预测。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.predict(ds_test)</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">array</span>([[<span class="number">9.9996173e-01</span>],</span><br><span class="line">       [<span class="number">9.5104784e-01</span>],</span><br><span class="line">       [<span class="number">2.8648047e-04</span>],</span><br><span class="line">       ...,</span><br><span class="line">       [<span class="number">1.1484033e-03</span>],</span><br><span class="line">       [<span class="number">3.5589080e-02</span>],</span><br><span class="line">       [<span class="number">9.8537153e-01</span>]], dtype=<span class="built_in">float</span>32)</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> x,y <span class="keyword">in</span> ds_test.take(<span class="number">1</span>):</span><br><span class="line">    print(model.predict_on_batch(x[<span class="number">0</span>:<span class="number">20</span>]))</span><br></pre></td></tr></table></figure><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">8.8849956e-01</span>]</span><br><span class="line"> [<span class="number">5.9769617e-04</span>]</span><br><span class="line"> [<span class="number">9.7809315e-01</span>]</span><br><span class="line"> [<span class="number">9.9903524e-01</span>]</span><br><span class="line"> [<span class="number">9.1890675e-01</span>]</span><br><span class="line"> [<span class="number">1.0246566e-02</span>]</span><br><span class="line"> [<span class="number">3.8106637e-03</span>]</span><br><span class="line"> [<span class="number">8.3489519e-01</span>]</span><br><span class="line"> [<span class="number">4.3317820e-03</span>]</span><br><span class="line"> [<span class="number">9.9998546e-01</span>]</span><br><span class="line"> [<span class="number">2.1413717e-02</span>]</span><br><span class="line"> [<span class="number">2.5603941e-04</span>]</span><br><span class="line"> [<span class="number">1.8045523e-04</span>]</span><br><span class="line"> [<span class="number">9.9734712e-01</span>]</span><br><span class="line"> [<span class="number">2.3647046e-01</span>]</span><br><span class="line"> [<span class="number">8.7527412e-01</span>]</span><br><span class="line"> [<span class="number">6.2612216e-03</span>]</span><br><span class="line"> [<span class="number">1.6598338e-01</span>]</span><br><span class="line"> [<span class="number">5.2631170e-01</span>]</span><br><span class="line"> [<span class="number">9.9995863e-01</span>]]</span><br></pre></td></tr></table></figure><h4 id="保存模型-1"><a href="#保存模型-1" class="headerlink" title="保存模型"></a>保存模型</h4><p>推荐使用TensorFlow原生方式保存模型。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 保存权重，该方式仅仅保存权重张量</span></span><br><span class="line">model.save_weights(<span class="string">'./data/tf_model_weights.ckpt'</span>,save_format = <span class="string">"tf"</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 保存模型结构与模型参数到文件,该方式保存的模型具有跨平台性便于部署</span></span><br><span class="line">model.save(<span class="string">'./data/tf_model_savedmodel'</span>, save_format=<span class="string">"tf"</span>)</span><br><span class="line">print(<span class="string">'export saved model.'</span>)</span><br><span class="line"></span><br><span class="line">model_loaded = tf.keras.models.load_model(<span class="string">'./data/tf_model_savedmodel'</span>)</span><br><span class="line">model_loaded.evaluate(ds_test)</span><br><span class="line"><span class="comment"># [0.16139124035835267, 0.9345]</span></span><br></pre></td></tr></table></figure><h3 id="文本数据建模流程"><a href="#文本数据建模流程" class="headerlink" title="文本数据建模流程"></a>文本数据建模流程</h3><h4 id="准备数据-2"><a href="#准备数据-2" class="headerlink" title="准备数据"></a>准备数据</h4><p>imdb数据集的目标是<strong>根据电影评论的文本内容预测评论的情感标签</strong>。训练集有20000条电影评论文本，测试集有5000条电影评论文本，其中正面评论和负面评论都各占一半。文本数据预处理较为繁琐，包括中文切词（本示例不涉及），构建词典，编码转换，序列填充，构建数据管道等等。</p><p>在tensorflow中完成文本数据预处理的常用方案有两种：</p><ul><li>第一种是利用 <code>tf.keras.preprocessing</code> 中的Tokenizer词典构建工具和 <code>tf.keras.utils.Sequence</code> 构建文本数据生成器管道，这种方法较为复杂，其使用范例可以参考<a href="https://zhuanlan.zhihu.com/p/67697840" target="_blank" rel="external nofollow noopener noreferrer">以下文章</a></li><li>第二种是使用 <code>tf.data.Dataset</code> 搭配 <code>.keras.layers.experimental.preprocessing.TextVectorization</code>预处理层，这种方法为TensorFlow原生方式，相对也更加简单一些。</li></ul><p>我们此处介绍第二种方法。</p><p><img alt data-src="https://github.com/SimpCosm/eat_tensorflow2_in_30_days_ipynbs/raw/master/data/电影评论.jpg"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> models,layers,preprocessing,optimizers,losses,metrics</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.layers.experimental.preprocessing <span class="keyword">import</span> TextVectorization</span><br><span class="line"><span class="keyword">import</span> re,string</span><br><span class="line"></span><br><span class="line">train_data_path = <span class="string">"./data/imdb/train.csv"</span></span><br><span class="line">test_data_path =  <span class="string">"./data/imdb/test.csv"</span></span><br><span class="line"></span><br><span class="line">MAX_WORDS = <span class="number">10000</span>  <span class="comment"># 仅考虑最高频的10000个词</span></span><br><span class="line">MAX_LEN = <span class="number">200</span>  <span class="comment"># 每个样本保留200个词的长度</span></span><br><span class="line">BATCH_SIZE = <span class="number">20</span> </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#构建管道</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">split_line</span><span class="params">(line)</span>:</span></span><br><span class="line">    arr = tf.strings.split(line,<span class="string">"\t"</span>)</span><br><span class="line">    label = tf.expand_dims(tf.cast(tf.strings.to_number(arr[<span class="number">0</span>]),tf.int32),axis = <span class="number">0</span>)</span><br><span class="line">    text = tf.expand_dims(arr[<span class="number">1</span>],axis = <span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> (text,label)</span><br><span class="line"></span><br><span class="line">ds_train_raw =  tf.data.TextLineDataset(filenames = [train_data_path]) \</span><br><span class="line">   .map(split_line,num_parallel_calls = tf.data.experimental.AUTOTUNE) \</span><br><span class="line">   .shuffle(buffer_size = <span class="number">1000</span>).batch(BATCH_SIZE) \</span><br><span class="line">   .prefetch(tf.data.experimental.AUTOTUNE)</span><br><span class="line"></span><br><span class="line">ds_test_raw = tf.data.TextLineDataset(filenames = [test_data_path]) \</span><br><span class="line">   .map(split_line,num_parallel_calls = tf.data.experimental.AUTOTUNE) \</span><br><span class="line">   .batch(BATCH_SIZE) \</span><br><span class="line">   .prefetch(tf.data.experimental.AUTOTUNE)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建词典</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">clean_text</span><span class="params">(text)</span>:</span></span><br><span class="line">    lowercase = tf.strings.lower(text)</span><br><span class="line">    stripped_html = tf.strings.regex_replace(lowercase, <span class="string">'&lt;br /&gt;'</span>, <span class="string">' '</span>)</span><br><span class="line">    cleaned_punctuation = tf.strings.regex_replace(stripped_html,</span><br><span class="line">         <span class="string">'[%s]'</span> % re.escape(string.punctuation),<span class="string">''</span>)</span><br><span class="line">    <span class="keyword">return</span> cleaned_punctuation</span><br><span class="line"></span><br><span class="line">vectorize_layer = TextVectorization(</span><br><span class="line">    standardize=clean_text,</span><br><span class="line">    split = <span class="string">'whitespace'</span>,</span><br><span class="line">    max_tokens=MAX_WORDS<span class="number">-1</span>, <span class="comment">#有一个留给占位符</span></span><br><span class="line">    output_mode=<span class="string">'int'</span>,</span><br><span class="line">    output_sequence_length=MAX_LEN)</span><br><span class="line"></span><br><span class="line">ds_text = ds_train_raw.map(<span class="keyword">lambda</span> text,label: text)</span><br><span class="line">vectorize_layer.adapt(ds_text)</span><br><span class="line">print(vectorize_layer.get_vocabulary()[<span class="number">0</span>:<span class="number">100</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 单词编码</span></span><br><span class="line">ds_train = ds_train_raw.map(<span class="keyword">lambda</span> text,label:(vectorize_layer(text),label)) \</span><br><span class="line">    .prefetch(tf.data.experimental.AUTOTUNE)</span><br><span class="line">ds_test = ds_test_raw.map(<span class="keyword">lambda</span> text,label:(vectorize_layer(text),label)) \</span><br><span class="line">    .prefetch(tf.data.experimental.AUTOTUNE)</span><br></pre></td></tr></table></figure><figure class="highlight scheme"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="name">b</span><span class="symbol">'the</span>', b<span class="symbol">'and</span>', b<span class="symbol">'a</span>', b<span class="symbol">'of</span>', b<span class="symbol">'to</span>', b<span class="symbol">'is</span>', b<span class="symbol">'in</span>', b<span class="symbol">'it</span>', b<span class="symbol">'i</span>', b<span class="symbol">'this</span>', b<span class="symbol">'that</span>', b<span class="symbol">'was</span>', b<span class="symbol">'as</span>', b<span class="symbol">'for</span>', b<span class="symbol">'with</span>', b<span class="symbol">'movie</span>', b<span class="symbol">'but</span>', b<span class="symbol">'film</span>', b<span class="symbol">'on</span>', b<span class="symbol">'not</span>', b<span class="symbol">'you</span>', b<span class="symbol">'his</span>', b<span class="symbol">'are</span>', b<span class="symbol">'have</span>', b<span class="symbol">'be</span>', b<span class="symbol">'he</span>', b<span class="symbol">'one</span>', b<span class="symbol">'its</span>', b<span class="symbol">'at</span>', b<span class="symbol">'all</span>', b<span class="symbol">'by</span>', b<span class="symbol">'an</span>', b<span class="symbol">'they</span>', b<span class="symbol">'from</span>', b<span class="symbol">'who</span>', b<span class="symbol">'so</span>', b<span class="symbol">'like</span>', b<span class="symbol">'her</span>', b<span class="symbol">'just</span>', b<span class="symbol">'or</span>', b<span class="symbol">'about</span>', b<span class="symbol">'has</span>', b<span class="symbol">'if</span>', b<span class="symbol">'out</span>', b<span class="symbol">'some</span>', b<span class="symbol">'there</span>', b<span class="symbol">'what</span>', b<span class="symbol">'good</span>', b<span class="symbol">'more</span>', b<span class="symbol">'when</span>', b<span class="symbol">'very</span>', b<span class="symbol">'she</span>', b<span class="symbol">'even</span>', b<span class="symbol">'my</span>', b<span class="symbol">'no</span>', b<span class="symbol">'would</span>', b<span class="symbol">'up</span>', b<span class="symbol">'time</span>', b<span class="symbol">'only</span>', b<span class="symbol">'which</span>', b<span class="symbol">'story</span>', b<span class="symbol">'really</span>', b<span class="symbol">'their</span>', b<span class="symbol">'were</span>', b<span class="symbol">'had</span>', b<span class="symbol">'see</span>', b<span class="symbol">'can</span>', b<span class="symbol">'me</span>', b<span class="symbol">'than</span>', b<span class="symbol">'we</span>', b<span class="symbol">'much</span>', b<span class="symbol">'well</span>', b<span class="symbol">'get</span>', b<span class="symbol">'been</span>', b<span class="symbol">'will</span>', b<span class="symbol">'into</span>', b<span class="symbol">'people</span>', b<span class="symbol">'also</span>', b<span class="symbol">'other</span>', b<span class="symbol">'do</span>', b<span class="symbol">'bad</span>', b<span class="symbol">'because</span>', b<span class="symbol">'great</span>', b<span class="symbol">'first</span>', b<span class="symbol">'how</span>', b<span class="symbol">'him</span>', b<span class="symbol">'most</span>', b<span class="symbol">'dont</span>', b<span class="symbol">'made</span>', b<span class="symbol">'then</span>', b<span class="symbol">'them</span>', b<span class="symbol">'films</span>', b<span class="symbol">'movies</span>', b<span class="symbol">'way</span>', b<span class="symbol">'make</span>', b<span class="symbol">'could</span>', b<span class="symbol">'too</span>', b<span class="symbol">'any</span>', b<span class="symbol">'after</span>', b<span class="symbol">'characters</span>']</span><br></pre></td></tr></table></figure><h4 id="定义模型-2"><a href="#定义模型-2" class="headerlink" title="定义模型"></a>定义模型</h4><p>使用Keras接口有以下3种方式构建模型：</p><ul><li>使用Sequential按层顺序构建模型</li><li>使用函数式API构建任意结构模型</li><li>继承Model基类构建自定义模型</li></ul><p>此处选择使用继承Model基类构建自定义模型。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 演示自定义模型范例，实际上应该优先使用Sequential或者函数式API</span></span><br><span class="line">tf.keras.backend.clear_session()</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CnnModel</span><span class="params">(models.Model)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(CnnModel, self).__init__()</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">build</span><span class="params">(self,input_shape)</span>:</span></span><br><span class="line">        self.embedding = layers.Embedding(MAX_WORDS,<span class="number">7</span>,input_length=MAX_LEN)</span><br><span class="line">        self.conv_1 = layers.Conv1D(<span class="number">16</span>, kernel_size= <span class="number">5</span>,name = <span class="string">"conv_1"</span>,activation = <span class="string">"relu"</span>)</span><br><span class="line">        self.pool_1 = layers.MaxPool1D(name = <span class="string">"pool_1"</span>)</span><br><span class="line">        self.conv_2 = layers.Conv1D(<span class="number">128</span>, kernel_size=<span class="number">2</span>,name = <span class="string">"conv_2"</span>,activation = <span class="string">"relu"</span>)</span><br><span class="line">        self.pool_2 = layers.MaxPool1D(name = <span class="string">"pool_2"</span>)</span><br><span class="line">        self.flatten = layers.Flatten()</span><br><span class="line">        self.dense = layers.Dense(<span class="number">1</span>,activation = <span class="string">"sigmoid"</span>)</span><br><span class="line">        super(CnnModel,self).build(input_shape)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = self.embedding(x)</span><br><span class="line">        x = self.conv_1(x)</span><br><span class="line">        x = self.pool_1(x)</span><br><span class="line">        x = self.conv_2(x)</span><br><span class="line">        x = self.pool_2(x)</span><br><span class="line">        x = self.flatten(x)</span><br><span class="line">        x = self.dense(x)</span><br><span class="line">        <span class="keyword">return</span>(x)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 用于显示Output Shape</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">summary</span><span class="params">(self)</span>:</span></span><br><span class="line">        x_input = layers.Input(shape = MAX_LEN)</span><br><span class="line">        output = self.call(x_input)</span><br><span class="line">        model = tf.keras.Model(inputs = x_input,outputs = output)</span><br><span class="line">        model.summary()</span><br><span class="line">    </span><br><span class="line">model = CnnModel()</span><br><span class="line">model.build(input_shape =(<span class="literal">None</span>,MAX_LEN))</span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">Model: "model"</span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">Layer (type)                 Output Shape              Param #   </span><br><span class="line">=================================================================</span><br><span class="line">input_1 (InputLayer)         [(None, 200)]             0         </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">embedding (Embedding)        (None, 200, 7)            70000     </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">conv_1 (Conv1D)              (None, 196, 16)           576       </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">pool_1 (MaxPooling1D)        (None, 98, 16)            0         </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">conv_2 (Conv1D)              (None, 97, 128)           4224      </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">pool_2 (MaxPooling1D)        (None, 48, 128)           0         </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">flatten (Flatten)            (None, 6144)              0         </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">dense (Dense)                (None, 1)                 6145      </span><br><span class="line">=================================================================</span><br><span class="line">Total params: 80,945</span><br><span class="line">Trainable params: 80,945</span><br><span class="line">Non-trainable params: 0</span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br></pre></td></tr></table></figure><h4 id="训练模型-2"><a href="#训练模型-2" class="headerlink" title="训练模型"></a>训练模型</h4><p>训练模型通常有3种方法：</p><ul><li>内置fit方法</li><li>内置train_on_batch方法</li><li>自定义训练循环。</li></ul><p>此处我们通过自定义训练循环训练模型。</p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"># 打印时间分割线</span><br><span class="line">@tf<span class="function">.<span class="keyword">function</span></span></span><br><span class="line">def printbar():</span><br><span class="line">    today_ts = <span class="keyword">tf</span>.timestamp()%(<span class="number">24</span>*<span class="number">60</span>*<span class="number">60</span>)</span><br><span class="line">    </span><br><span class="line">    hour = <span class="keyword">tf</span>.cast(today_ts//<span class="number">3600</span>+<span class="number">8</span>,<span class="keyword">tf</span>.int32)%<span class="keyword">tf</span>.constant(<span class="number">24</span>)</span><br><span class="line">    minite = <span class="keyword">tf</span>.cast((today_ts%<span class="number">3600</span>)//<span class="number">60</span>,<span class="keyword">tf</span>.int32)</span><br><span class="line">    second = <span class="keyword">tf</span>.cast(<span class="keyword">tf</span>.<span class="built_in">floor</span>(today_ts%<span class="number">60</span>),<span class="keyword">tf</span>.int32)</span><br><span class="line">    </span><br><span class="line">    def timeformat(<span class="keyword">m</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">tf</span>.strings.length(<span class="keyword">tf</span>.strings.format(<span class="string">"&#123;&#125;"</span>,<span class="keyword">m</span>))==<span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span>(<span class="keyword">tf</span>.strings.format(<span class="string">"0&#123;&#125;"</span>,<span class="keyword">m</span>))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span>(<span class="keyword">tf</span>.strings.format(<span class="string">"&#123;&#125;"</span>,<span class="keyword">m</span>))</span><br><span class="line">    </span><br><span class="line">    timestring = <span class="keyword">tf</span>.strings.<span class="keyword">join</span>([timeformat(hour),timeformat(minite),</span><br><span class="line">                timeformat(second)],separator = <span class="string">":"</span>)</span><br><span class="line">    <span class="keyword">tf</span>.<span class="keyword">print</span>(<span class="string">"=========="</span>*<span class="number">8</span>+timestring)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">optimizer = optimizers.Nadam()</span><br><span class="line">loss_func = losses.BinaryCrossentropy()</span><br><span class="line"></span><br><span class="line">train_loss = metrics.Mean(name=<span class="string">'train_loss'</span>)</span><br><span class="line">train_metric = metrics.BinaryAccuracy(name=<span class="string">'train_accuracy'</span>)</span><br><span class="line"></span><br><span class="line">valid_loss = metrics.Mean(name=<span class="string">'valid_loss'</span>)</span><br><span class="line">valid_metric = metrics.BinaryAccuracy(name=<span class="string">'valid_accuracy'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@tf.function</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_step</span><span class="params">(model, features, labels)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">        predictions = model(features,training = <span class="literal">True</span>)</span><br><span class="line">        loss = loss_func(labels, predictions)</span><br><span class="line">    gradients = tape.gradient(loss, model.trainable_variables)</span><br><span class="line">    optimizer.apply_gradients(zip(gradients, model.trainable_variables))</span><br><span class="line"></span><br><span class="line">    train_loss.update_state(loss)</span><br><span class="line">    train_metric.update_state(labels, predictions)</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="meta">@tf.function</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">valid_step</span><span class="params">(model, features, labels)</span>:</span></span><br><span class="line">    predictions = model(features,training = <span class="literal">False</span>)</span><br><span class="line">    batch_loss = loss_func(labels, predictions)</span><br><span class="line">    valid_loss.update_state(batch_loss)</span><br><span class="line">    valid_metric.update_state(labels, predictions)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_model</span><span class="params">(model,ds_train,ds_valid,epochs)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> tf.range(<span class="number">1</span>,epochs+<span class="number">1</span>):</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> features, labels <span class="keyword">in</span> ds_train:</span><br><span class="line">            train_step(model,features,labels)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> features, labels <span class="keyword">in</span> ds_valid:</span><br><span class="line">            valid_step(model,features,labels)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#此处logs模板需要根据metric具体情况修改</span></span><br><span class="line">        logs = <span class="string">'Epoch=&#123;&#125;,Loss:&#123;&#125;,Accuracy:&#123;&#125;,Valid Loss:&#123;&#125;,Valid Accuracy:&#123;&#125;'</span> </span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> epoch%<span class="number">1</span>==<span class="number">0</span>:</span><br><span class="line">            printbar()</span><br><span class="line">            tf.print(tf.strings.format(logs,</span><br><span class="line">            (epoch,train_loss.result(),train_metric.result(),valid_loss.result(),valid_metric.result())))</span><br><span class="line">            tf.print(<span class="string">""</span>)</span><br><span class="line">        </span><br><span class="line">        train_loss.reset_states()</span><br><span class="line">        valid_loss.reset_states()</span><br><span class="line">        train_metric.reset_states()</span><br><span class="line">        valid_metric.reset_states()</span><br><span class="line"></span><br><span class="line">train_model(model,ds_train,ds_test,epochs = <span class="number">6</span>)</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">================================================================================<span class="number">13</span>:<span class="number">54</span>:<span class="number">08</span></span><br><span class="line">Epoch=<span class="number">1</span>,Loss:<span class="number">0.442317516</span>,Accuracy:<span class="number">0.7695</span>,Valid Loss:<span class="number">0.323672801</span>,Valid Accuracy:<span class="number">0.8614</span></span><br><span class="line"></span><br><span class="line">================================================================================<span class="number">13</span>:<span class="number">54</span>:<span class="number">20</span></span><br><span class="line">Epoch=<span class="number">2</span>,Loss:<span class="number">0.245737702</span>,Accuracy:<span class="number">0.90215</span>,Valid Loss:<span class="number">0.356488883</span>,Valid Accuracy:<span class="number">0.8554</span></span><br><span class="line"></span><br><span class="line">================================================================================<span class="number">13</span>:<span class="number">54</span>:<span class="number">32</span></span><br><span class="line">Epoch=<span class="number">3</span>,Loss:<span class="number">0.17360799</span>,Accuracy:<span class="number">0.93455</span>,Valid Loss:<span class="number">0.361132562</span>,Valid Accuracy:<span class="number">0.8674</span></span><br><span class="line"></span><br><span class="line">================================================================================<span class="number">13</span>:<span class="number">54</span>:<span class="number">44</span></span><br><span class="line">Epoch=<span class="number">4</span>,Loss:<span class="number">0.113476314</span>,Accuracy:<span class="number">0.95975</span>,Valid Loss:<span class="number">0.483677238</span>,Valid Accuracy:<span class="number">0.856</span></span><br><span class="line"></span><br><span class="line">================================================================================<span class="number">13</span>:<span class="number">54</span>:<span class="number">57</span></span><br><span class="line">Epoch=<span class="number">5</span>,Loss:<span class="number">0.0698405355</span>,Accuracy:<span class="number">0.9768</span>,Valid Loss:<span class="number">0.607856631</span>,Valid Accuracy:<span class="number">0.857</span></span><br><span class="line"></span><br><span class="line">================================================================================<span class="number">13</span>:<span class="number">55</span>:<span class="number">15</span></span><br><span class="line">Epoch=<span class="number">6</span>,Loss:<span class="number">0.0366807655</span>,Accuracy:<span class="number">0.98825</span>,Valid Loss:<span class="number">0.745884955</span>,Valid Accuracy:<span class="number">0.854</span></span><br></pre></td></tr></table></figure><h4 id="评估模型-2"><a href="#评估模型-2" class="headerlink" title="评估模型"></a>评估模型</h4><p>通过自定义训练循环训练的模型没有经过编译，无法直接使用model.evaluate(ds_valid)方法</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate_model</span><span class="params">(model,ds_valid)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> features, labels <span class="keyword">in</span> ds_valid:</span><br><span class="line">         valid_step(model,features,labels)</span><br><span class="line">    logs = <span class="string">'Valid Loss:&#123;&#125;,Valid Accuracy:&#123;&#125;'</span> </span><br><span class="line">    tf.print(tf.strings.format(logs,(valid_loss.result(),valid_metric.result())))</span><br><span class="line">    </span><br><span class="line">    valid_loss.reset_states()</span><br><span class="line">    train_metric.reset_states()</span><br><span class="line">    valid_metric.reset_states()</span><br><span class="line"></span><br><span class="line">evaluate_model(model,ds_test)</span><br><span class="line"><span class="comment"># Valid Loss:0.745884418,Valid Accuracy:0.854</span></span><br></pre></td></tr></table></figure><h4 id="使用模型-2"><a href="#使用模型-2" class="headerlink" title="使用模型"></a>使用模型</h4><p>可以使用以下方法:</p><ul><li>model.predict(ds_test)</li><li>model(x_test)</li><li>model.call(x_test)</li><li>model.predict_on_batch(x_test)</li></ul><p>推荐优先使用 <code>model.predict(ds_test)</code> 方法，既可以对Dataset，也可以对Tensor使用。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.predict(ds_test)</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">array</span>([[<span class="number">0.7864823</span> ],</span><br><span class="line">       [<span class="number">0.9999901</span> ],</span><br><span class="line">       [<span class="number">0.99944776</span>],</span><br><span class="line">       ...,</span><br><span class="line">       [<span class="number">0.8498302</span> ],</span><br><span class="line">       [<span class="number">0.13382755</span>],</span><br><span class="line">       [<span class="number">1.</span>        ]], dtype=<span class="built_in">float</span>32)</span><br></pre></td></tr></table></figure><figure class="highlight leaf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">for x_test,_ in ds_test.take(1):</span><br><span class="line">    print(model(x_test))</span><br><span class="line">    #以下方法等价：</span><br><span class="line">    <span class="function"><span class="keyword">#</span><span class="title">print</span><span class="params">(<span class="variable">model</span>.<span class="variable">call</span>(<span class="variable">x_test</span>)</span></span>)</span><br><span class="line">    <span class="function"><span class="keyword">#</span><span class="title">print</span><span class="params">(<span class="variable">model</span>.<span class="variable">predict_on_batch</span>(<span class="variable">x_test</span>)</span></span>)</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">tf.Tensor(</span><br><span class="line">[[<span class="number">7.8648227e-01</span>]</span><br><span class="line"> [<span class="number">9.9999011e-01</span>]</span><br><span class="line"> [<span class="number">9.9944776e-01</span>]</span><br><span class="line"> [<span class="number">3.7153201e-09</span>]</span><br><span class="line"> [<span class="number">9.4462049e-01</span>]</span><br><span class="line"> [<span class="number">2.3522753e-04</span>]</span><br><span class="line"> [<span class="number">1.2044354e-04</span>]</span><br><span class="line"> [<span class="number">9.3752089e-07</span>]</span><br><span class="line"> [<span class="number">9.9996352e-01</span>]</span><br><span class="line"> [<span class="number">9.3435925e-01</span>]</span><br><span class="line"> [<span class="number">9.8746723e-01</span>]</span><br><span class="line"> [<span class="number">9.9908626e-01</span>]</span><br><span class="line"> [<span class="number">4.1563155e-08</span>]</span><br><span class="line"> [<span class="number">4.1808244e-03</span>]</span><br><span class="line"> [<span class="number">8.0184749e-05</span>]</span><br><span class="line"> [<span class="number">8.3910513e-01</span>]</span><br><span class="line"> [<span class="number">3.5167937e-05</span>]</span><br><span class="line"> [<span class="number">7.2113985e-01</span>]</span><br><span class="line"> [<span class="number">4.5228912e-03</span>]</span><br><span class="line"> [<span class="number">9.9942589e-01</span>]], shape=(<span class="number">20</span>, <span class="number">1</span>), dtype=<span class="built_in">float</span>32)</span><br></pre></td></tr></table></figure><h4 id="保存模型-2"><a href="#保存模型-2" class="headerlink" title="保存模型"></a>保存模型</h4><p>推荐使用TensorFlow原生方式保存模型。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">model.save(<span class="string">'./data/tf_model_savedmodel'</span>, save_format=<span class="string">"tf"</span>)</span><br><span class="line">print(<span class="string">'export saved model.'</span>)</span><br><span class="line"></span><br><span class="line">model_loaded = tf.keras.models.load_model(<span class="string">'./data/tf_model_savedmodel'</span>)</span><br><span class="line">model_loaded.predict(ds_test)</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">array</span>([[<span class="number">0.7864823</span> ],</span><br><span class="line">       [<span class="number">0.9999901</span> ],</span><br><span class="line">       [<span class="number">0.99944776</span>],</span><br><span class="line">       ...,</span><br><span class="line">       [<span class="number">0.8498302</span> ],</span><br><span class="line">       [<span class="number">0.13382755</span>],</span><br><span class="line">       [<span class="number">1.</span>        ]], dtype=<span class="built_in">float</span>32)</span><br></pre></td></tr></table></figure><h3 id="时间序列数据建模流程"><a href="#时间序列数据建模流程" class="headerlink" title="时间序列数据建模流程"></a>时间序列数据建模流程</h3><p>本小节将利用TensorFlow2.0建立时间序列RNN模型，对国内的新冠肺炎疫情结束时间进行预测。</p><h4 id="准备数据-3"><a href="#准备数据-3" class="headerlink" title="准备数据"></a>准备数据</h4><p>本文的数据集取自tushare，数据集在本项目的 data 目录下。</p><p><img alt data-src="https://github.com/SimpCosm/eat_tensorflow2_in_30_days_ipynbs/raw/master/data/1-4-新增人数.png"></p><figure class="highlight xl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf </span><br><span class="line">from tensorflow.keras <span class="keyword">import</span> models,layers,losses,metrics,callbacks </span><br><span class="line">%matplotlib inline</span><br><span class="line">%config InlineBackend.figure_format = <span class="string">'svg'</span></span><br><span class="line"></span><br><span class="line">df = pd.read_csv(<span class="string">"./data/covid-19.csv"</span>,sep = <span class="string">"\t"</span>)</span><br><span class="line">df.plot(x = <span class="string">"date"</span>,y = [<span class="string">"confirmed_num"</span>,<span class="string">"cured_num"</span>,<span class="string">"dead_num"</span>],figsize=(<span class="number">10</span>,<span class="number">6</span>))</span><br><span class="line">plt.xticks(rotation=<span class="number">60</span>)</span><br></pre></td></tr></table></figure><p><img alt data-src="https://github.com/SimpCosm/eat_tensorflow2_in_30_days_ipynbs/raw/master/data/1-4-累积曲线.png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">dfdata = df.set_index(<span class="string">"date"</span>)</span><br><span class="line">dfdiff = dfdata.diff(periods=<span class="number">1</span>).dropna()</span><br><span class="line">dfdiff = dfdiff.reset_index(<span class="string">"date"</span>)</span><br><span class="line"></span><br><span class="line">dfdiff.plot(x = <span class="string">"date"</span>,y = [<span class="string">"confirmed_num"</span>,<span class="string">"cured_num"</span>,<span class="string">"dead_num"</span>],figsize=(<span class="number">10</span>,<span class="number">6</span>))</span><br><span class="line">plt.xticks(rotation=<span class="number">60</span>)</span><br><span class="line">dfdiff = dfdiff.drop(<span class="string">"date"</span>,axis = <span class="number">1</span>).astype(<span class="string">"float32"</span>)</span><br></pre></td></tr></table></figure><p><img alt data-src="https://github.com/SimpCosm/eat_tensorflow2_in_30_days_ipynbs/raw/master/data/1-4-新增曲线.png"></p><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># 用某日前8天窗口数据作为输入预测该日数据</span></span><br><span class="line"><span class="type">WINDOW_SIZE</span> = <span class="number">8</span></span><br><span class="line"></span><br><span class="line"><span class="title">def</span> batch_dataset(dataset):</span><br><span class="line">    dataset_batched = dataset.batch(<span class="type">WINDOW_SIZE</span>,drop_remainder=<span class="type">True</span>)</span><br><span class="line">    return dataset_batched</span><br><span class="line"></span><br><span class="line"><span class="title">ds_data</span> = tf.<span class="class"><span class="keyword">data</span>.<span class="type">Dataset</span>.from_tensor_slices(<span class="title">tf</span>.<span class="title">constant</span>(<span class="title">dfdiff</span>.<span class="title">values</span>,<span class="title">dtype</span> = <span class="title">tf</span>.<span class="title">float32</span>)) \</span></span><br><span class="line">   .window(<span class="type">WINDOW_SIZE</span>,shift=<span class="number">1</span>).flat_map(batch_dataset)</span><br><span class="line"></span><br><span class="line"><span class="title">ds_label</span> = tf.<span class="class"><span class="keyword">data</span>.<span class="type">Dataset</span>.from_tensor_slices(</span></span><br><span class="line"><span class="class">    <span class="title">tf</span>.<span class="title">constant</span>(<span class="title">dfdiff</span>.<span class="title">values</span>[<span class="type">WINDOW_SIZE</span>:],<span class="title">dtype</span> = <span class="title">tf</span>.<span class="title">float32</span>))</span></span><br><span class="line"></span><br><span class="line"><span class="meta"># 数据较小，可以将全部训练数据放入到一个batch中，提升性能</span></span><br><span class="line"><span class="title">ds_train</span> = tf.<span class="class"><span class="keyword">data</span>.<span class="type">Dataset</span>.zip((<span class="title">ds_data</span>,<span class="title">ds_label</span>)).batch(38).cache()</span></span><br></pre></td></tr></table></figure><h4 id="定义模型-3"><a href="#定义模型-3" class="headerlink" title="定义模型"></a>定义模型</h4><p>使用Keras接口有以下3种方式构建模型：</p><ul><li>使用Sequential按层顺序构建模型</li><li>使用函数式API构建任意结构模型</li><li>继承Model基类构建自定义模型</li></ul><p>此处选择使用函数式API构建任意结构模型。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 考虑到新增确诊，新增治愈，新增死亡人数数据不可能小于0，设计如下结构</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Block</span><span class="params">(layers.Layer)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, **kwargs)</span>:</span></span><br><span class="line">        super(Block, self).__init__(**kwargs)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span><span class="params">(self, x_input,x)</span>:</span></span><br><span class="line">        x_out = tf.maximum((<span class="number">1</span>+x)*x_input[:,<span class="number">-1</span>,:],<span class="number">0.0</span>)</span><br><span class="line">        <span class="keyword">return</span> x_out</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_config</span><span class="params">(self)</span>:</span>  </span><br><span class="line">        config = super(Block, self).get_config()</span><br><span class="line">        <span class="keyword">return</span> config</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">tf.keras.backend.clear_session()</span><br><span class="line">x_input = layers.Input(shape = (<span class="literal">None</span>,<span class="number">3</span>),dtype = tf.float32)</span><br><span class="line">x = layers.LSTM(<span class="number">3</span>,return_sequences = <span class="literal">True</span>,input_shape=(<span class="literal">None</span>,<span class="number">3</span>))(x_input)</span><br><span class="line">x = layers.LSTM(<span class="number">3</span>,return_sequences = <span class="literal">True</span>,input_shape=(<span class="literal">None</span>,<span class="number">3</span>))(x)</span><br><span class="line">x = layers.LSTM(<span class="number">3</span>,return_sequences = <span class="literal">True</span>,input_shape=(<span class="literal">None</span>,<span class="number">3</span>))(x)</span><br><span class="line">x = layers.LSTM(<span class="number">3</span>,input_shape=(<span class="literal">None</span>,<span class="number">3</span>))(x)</span><br><span class="line">x = layers.Dense(<span class="number">3</span>)(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 考虑到新增确诊，新增治愈，新增死亡人数数据不可能小于0，设计如下结构</span></span><br><span class="line"><span class="comment"># x = tf.maximum((1+x)*x_input[:,-1,:],0.0)</span></span><br><span class="line">x = Block()(x_input,x)</span><br><span class="line">model = models.Model(inputs = [x_input],outputs = [x])</span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">Model: "model"</span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">Layer (type)                 Output Shape              Param #   </span><br><span class="line">=================================================================</span><br><span class="line">input_1 (InputLayer)         [(None, None, 3)]         0         </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">lstm (LSTM)                  (None, None, 3)           84        </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">lstm_1 (LSTM)                (None, None, 3)           84        </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">lstm_2 (LSTM)                (None, None, 3)           84        </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">lstm_3 (LSTM)                (None, 3)                 84        </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">dense (Dense)                (None, 3)                 12        </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">block (Block)                (None, 3)                 0         </span><br><span class="line">=================================================================</span><br><span class="line">Total params: 348</span><br><span class="line">Trainable params: 348</span><br><span class="line">Non-trainable params: 0</span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br></pre></td></tr></table></figure><h4 id="训练模型-3"><a href="#训练模型-3" class="headerlink" title="训练模型"></a>训练模型</h4><p>训练模型通常有3种方法：</p><ul><li>内置fit方法</li><li>内置train_on_batch方法</li><li>自定义训练循环</li></ul><p>此处我们选择最常用也最简单的内置fit方法。</p><p>注：循环神经网络调试较为困难，需要设置多个不同的学习率多次尝试，以取得较好的效果。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 自定义损失函数，考虑平方差和预测目标的比值</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MSPE</span><span class="params">(losses.Loss)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span><span class="params">(self,y_true,y_pred)</span>:</span></span><br><span class="line">        err_percent = (y_true - y_pred)**<span class="number">2</span>/(tf.maximum(y_true**<span class="number">2</span>,<span class="number">1e-7</span>))</span><br><span class="line">        mean_err_percent = tf.reduce_mean(err_percent)</span><br><span class="line">        <span class="keyword">return</span> mean_err_percent</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_config</span><span class="params">(self)</span>:</span></span><br><span class="line">        config = super(MSPE, self).get_config()</span><br><span class="line">        <span class="keyword">return</span> config</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"></span><br><span class="line">optimizer = tf.keras.optimizers.Adam(learning_rate=<span class="number">0.01</span>)</span><br><span class="line">model.compile(optimizer=optimizer,loss=MSPE(name = <span class="string">"MSPE"</span>))</span><br><span class="line"></span><br><span class="line">stamp = datetime.datetime.now().strftime(<span class="string">"%Y%m%d-%H%M%S"</span>)</span><br><span class="line">logdir = os.path.join(<span class="string">'data'</span>, <span class="string">'autograph'</span>, stamp)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 在 Python3 下建议使用 pathlib 修正各操作系统的路径</span></span><br><span class="line"><span class="comment"># from pathlib import Path</span></span><br><span class="line"><span class="comment"># stamp = datetime.datetime.now().strftime("%Y%m%d-%H%M%S")</span></span><br><span class="line"><span class="comment"># logdir = str(Path('./data/autograph/' + stamp))</span></span><br><span class="line"></span><br><span class="line">tb_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># 如果loss在100个epoch后没有提升，学习率减半。</span></span><br><span class="line">lr_callback = tf.keras.callbacks.ReduceLROnPlateau(monitor=<span class="string">"loss"</span>,factor = <span class="number">0.5</span>, patience = <span class="number">100</span>)</span><br><span class="line"><span class="comment"># 当loss在200个epoch后没有提升，则提前终止训练。</span></span><br><span class="line">stop_callback = tf.keras.callbacks.EarlyStopping(monitor = <span class="string">"loss"</span>, patience= <span class="number">200</span>)</span><br><span class="line">callbacks_list = [tb_callback,lr_callback,stop_callback]</span><br><span class="line"></span><br><span class="line">history = model.fit(ds_train,epochs=<span class="number">500</span>,callbacks = callbacks_list)</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Epoch <span class="number">1</span>/<span class="number">500</span></span><br><span class="line"><span class="number">1</span>/<span class="number">1</span> [==============================] - <span class="number">0</span>s <span class="number">19</span>ms/step - loss: <span class="number">3.4135</span> - lr: <span class="number">0.0100</span></span><br><span class="line">Epoch <span class="number">2</span>/<span class="number">500</span></span><br><span class="line"><span class="number">1</span>/<span class="number">1</span> [==============================] - ETA: <span class="number">0</span>s - loss: <span class="number">3.0553</span>WARNING:tensorflow:Method (on_train_batch_end) <span class="keyword">is</span> slow compared to the batch update (<span class="number">0.271260</span>). Check your callbacks.</span><br><span class="line"><span class="number">1</span>/<span class="number">1</span> [==============================] - <span class="number">0</span>s <span class="number">14</span>ms/step - loss: <span class="number">3.0553</span> - lr: <span class="number">0.0100</span></span><br><span class="line">Epoch <span class="number">3</span>/<span class="number">500</span></span><br><span class="line"><span class="number">1</span>/<span class="number">1</span> [==============================] - <span class="number">0</span>s <span class="number">10</span>ms/step - loss: <span class="number">2.7220</span> - lr: <span class="number">0.0100</span></span><br><span class="line">Epoch <span class="number">4</span>/<span class="number">500</span></span><br><span class="line"><span class="number">1</span>/<span class="number">1</span> [==============================] - <span class="number">0</span>s <span class="number">10</span>ms/step - loss: <span class="number">2.3993</span> - lr: <span class="number">0.0100</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure><h4 id="评估模型-3"><a href="#评估模型-3" class="headerlink" title="评估模型"></a>评估模型</h4><p>评估模型一般要设置验证集或者测试集，由于此例数据较少，我们仅仅可视化损失函数在训练集上的迭代情况。</p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line">%config InlineBackend.figure_format = <span class="string">'svg'</span></span><br><span class="line"></span><br><span class="line">import matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">def plot_metric(<span class="keyword">history</span>, metric):</span><br><span class="line">    train_metrics = <span class="keyword">history</span>.<span class="keyword">history</span>[metric]</span><br><span class="line">    epochs = <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(train_metrics) + <span class="number">1</span>)</span><br><span class="line">    plt.plot(epochs, train_metrics, <span class="string">'bo--'</span>)</span><br><span class="line">    plt.title(<span class="string">'Training '</span>+ metric)</span><br><span class="line">    plt.xlabel(<span class="string">"Epochs"</span>)</span><br><span class="line">    plt.ylabel(metric)</span><br><span class="line">    plt.legend([<span class="string">"train_"</span>+metric])</span><br><span class="line">    plt.show()</span><br><span class="line">plot_metric(<span class="keyword">history</span>,<span class="string">"loss"</span>)</span><br></pre></td></tr></table></figure><p><img alt data-src="https://github.com/SimpCosm/eat_tensorflow2_in_30_days_ipynbs/raw/master/data/1-4-损失函数曲线.png"></p><h4 id="使用模型-3"><a href="#使用模型-3" class="headerlink" title="使用模型"></a>使用模型</h4><p>此处我们使用模型预测疫情结束时间，即 新增确诊病例为0 的时间。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用dfresult记录现有数据以及此后预测的疫情数据</span></span><br><span class="line">dfresult = dfdiff[[<span class="string">"confirmed_num"</span>,<span class="string">"cured_num"</span>,<span class="string">"dead_num"</span>]].copy()</span><br><span class="line">dfresult.tail()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 预测此后100天的新增走势,将其结果添加到dfresult中</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">    arr_predict = model.predict(tf.constant(tf.expand_dims(dfresult.values[<span class="number">-38</span>:,:],axis = <span class="number">0</span>)))</span><br><span class="line"></span><br><span class="line">    dfpredict = pd.DataFrame(tf.cast(tf.floor(arr_predict),tf.float32).numpy(),</span><br><span class="line">                columns = dfresult.columns)</span><br><span class="line">    dfresult = dfresult.append(dfpredict,ignore_index=<span class="literal">True</span>)</span><br><span class="line">dfresult.query(<span class="string">"confirmed_num==0"</span>).head()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第55天开始新增确诊降为0，第45天对应3月10日，也就是10天后，即预计3月20日新增确诊降为0</span></span><br><span class="line"><span class="comment"># 注：该预测偏乐观</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dfresult.query(<span class="string">"cured_num==0"</span>).head()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第164天开始新增治愈降为0，第45天对应3月10日，也就是大概4个月后，即7月10日左右全部治愈。</span></span><br><span class="line"><span class="comment"># 注: 该预测偏悲观，并且存在问题，如果将每天新增治愈人数加起来，将超过累计确诊人数。</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dfresult.query(<span class="string">"dead_num==0"</span>).head()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第60天开始，新增死亡降为0，第45天对应3月10日，也就是大概15天后，即20200325</span></span><br><span class="line"><span class="comment"># 该预测较为合理</span></span><br></pre></td></tr></table></figure><h4 id="保存模型-3"><a href="#保存模型-3" class="headerlink" title="保存模型"></a>保存模型</h4><p>推荐使用TensorFlow原生方式保存模型。</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model.save(<span class="string">'./data/tf_model_savedmodel'</span>, <span class="attribute">save_format</span>=<span class="string">"tf"</span>)</span><br><span class="line"><span class="builtin-name">print</span>(<span class="string">'export saved model.'</span>)</span><br></pre></td></tr></table></figure><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">model_loaded = tf.keras.models.load<span class="constructor">_model('.<span class="operator">/</span><span class="params">data</span><span class="operator">/</span><span class="params">tf_model_savedmodel</span>',<span class="params">compile</span>=False)</span></span><br><span class="line">optimizer = tf.keras.optimizers.<span class="constructor">Adam(<span class="params">learning_rate</span>=0.001)</span></span><br><span class="line">model_loaded.compile(optimizer=optimizer,loss=<span class="constructor">MSPE(<span class="params">name</span> = <span class="string">"MSPE"</span>)</span>)</span><br><span class="line">model_loaded.predict(ds_train)</span><br></pre></td></tr></table></figure><h2 id="核心概念"><a href="#核心概念" class="headerlink" title="核心概念"></a>核心概念</h2><p>程序 = 数据结构+算法。<br>TensorFlow程序 = 张量数据结构 + 计算图算法语言</p><p><strong>张量</strong> 和 <strong>计算图</strong> 是 TensorFlow 的核心概念。</p><h3 id="张量数据结构"><a href="#张量数据结构" class="headerlink" title="张量数据结构"></a>张量数据结构</h3><p>Tensorflow的基本数据结构是张量Tensor。张量即多维数组，Tensorflow的张量和numpy中的array很类似。</p><p>从行为特性来看，有两种类型的张量：</p><ul><li>常量constant，常量的值在计算图中不可以被重新赋值</li><li>变量Variable，变量可以在计算图中用assign等算子重新赋值</li></ul><h4 id="常量张量"><a href="#常量张量" class="headerlink" title="常量张量"></a>常量张量</h4><p>张量的数据类型和 <code>numpy.array</code> 基本一一对应。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">i = tf.constant(<span class="number">1</span>) <span class="comment"># tf.int32 类型常量</span></span><br><span class="line">l = tf.constant(<span class="number">1</span>,dtype = tf.int64) <span class="comment"># tf.int64 类型常量</span></span><br><span class="line">f = tf.constant(<span class="number">1.23</span>) <span class="comment">#tf.float32 类型常量</span></span><br><span class="line">d = tf.constant(<span class="number">3.14</span>,dtype = tf.double) <span class="comment"># tf.double 类型常量</span></span><br><span class="line">s = tf.constant(<span class="string">"hello world"</span>) <span class="comment"># tf.string类型常量</span></span><br><span class="line">b = tf.constant(<span class="literal">True</span>) <span class="comment">#tf.bool类型常量</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(tf.int64 == np.int64) </span><br><span class="line">print(tf.bool == np.bool)</span><br><span class="line">print(tf.double == np.float64)</span><br><span class="line">print(tf.string == np.unicode) <span class="comment"># tf.string类型和np.unicode类型不等价</span></span><br></pre></td></tr></table></figure><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="literal">True</span></span><br><span class="line"><span class="literal">True</span></span><br><span class="line"><span class="literal">True</span></span><br><span class="line"><span class="literal">False</span></span><br></pre></td></tr></table></figure><p>不同类型的数据可以用不同维度(rank)的张量来表示：</p><ul><li>标量为0维张量，向量为1维张量，矩阵为2维张量</li><li>彩色图像有rgb三个通道，可以表示为3维张量</li><li>视频还有时间维，可以表示为4维张量<br>可以简单地总结为：有几层中括号，就是多少维的张量。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">scalar = tf.constant(<span class="literal">True</span>)  <span class="comment">#标量，0维张量</span></span><br><span class="line"></span><br><span class="line">print(tf.rank(scalar))</span><br><span class="line">print(scalar.numpy().ndim)  <span class="comment"># tf.rank的作用和numpy的ndim方法相同</span></span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tf.Tensor(<span class="number">0</span>, shape=(), dtype=<span class="built_in">int</span>32)</span><br><span class="line"><span class="number">0</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">vector = tf.constant([<span class="number">1.0</span>,<span class="number">2.0</span>,<span class="number">3.0</span>,<span class="number">4.0</span>]) <span class="comment">#向量，1维张量</span></span><br><span class="line"></span><br><span class="line">print(tf.rank(vector))</span><br><span class="line">print(np.ndim(vector.numpy()))</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tf.Tensor(<span class="number">1</span>, shape=(), dtype=<span class="built_in">int</span>32)</span><br><span class="line"><span class="number">1</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">matrix = tf.constant([[<span class="number">1.0</span>,<span class="number">2.0</span>],[<span class="number">3.0</span>,<span class="number">4.0</span>]]) <span class="comment">#矩阵, 2维张量</span></span><br><span class="line"></span><br><span class="line">print(tf.rank(matrix).numpy())</span><br><span class="line">print(np.ndim(matrix))</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2</span></span><br><span class="line"><span class="number">2</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tensor3 = tf.constant([[[<span class="number">1.0</span>,<span class="number">2.0</span>],[<span class="number">3.0</span>,<span class="number">4.0</span>]],[[<span class="number">5.0</span>,<span class="number">6.0</span>],[<span class="number">7.0</span>,<span class="number">8.0</span>]]])  <span class="comment"># 3维张量</span></span><br><span class="line">print(tensor3)</span><br><span class="line">print(tf.rank(tensor3))</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">tf.Tensor(</span><br><span class="line">[[[<span class="number">1.</span> <span class="number">2.</span>]</span><br><span class="line">  [<span class="number">3.</span> <span class="number">4.</span>]]</span><br><span class="line"></span><br><span class="line"> [[<span class="number">5.</span> <span class="number">6.</span>]</span><br><span class="line">  [<span class="number">7.</span> <span class="number">8.</span>]]], shape=(<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>), dtype=<span class="built_in">float</span>32)</span><br><span class="line">tf.Tensor(<span class="number">3</span>, shape=(), dtype=<span class="built_in">int</span>32)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tensor4 = tf.constant([[[[<span class="number">1.0</span>,<span class="number">1.0</span>],[<span class="number">2.0</span>,<span class="number">2.0</span>]],[[<span class="number">3.0</span>,<span class="number">3.0</span>],[<span class="number">4.0</span>,<span class="number">4.0</span>]]],</span><br><span class="line">                        [[[<span class="number">5.0</span>,<span class="number">5.0</span>],[<span class="number">6.0</span>,<span class="number">6.0</span>]],[[<span class="number">7.0</span>,<span class="number">7.0</span>],[<span class="number">8.0</span>,<span class="number">8.0</span>]]]])  <span class="comment"># 4维张量</span></span><br><span class="line">print(tensor4)</span><br><span class="line">print(tf.rank(tensor4))</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">tf.Tensor(</span><br><span class="line">[[[[<span class="number">1.</span> <span class="number">1.</span>]</span><br><span class="line">   [<span class="number">2.</span> <span class="number">2.</span>]]</span><br><span class="line"></span><br><span class="line">  [[<span class="number">3.</span> <span class="number">3.</span>]</span><br><span class="line">   [<span class="number">4.</span> <span class="number">4.</span>]]]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> [[[<span class="number">5.</span> <span class="number">5.</span>]</span><br><span class="line">   [<span class="number">6.</span> <span class="number">6.</span>]]</span><br><span class="line"></span><br><span class="line">  [[<span class="number">7.</span> <span class="number">7.</span>]</span><br><span class="line">   [<span class="number">8.</span> <span class="number">8.</span>]]]], shape=(<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>), dtype=<span class="built_in">float</span>32)</span><br><span class="line">tf.Tensor(<span class="number">4</span>, shape=(), dtype=<span class="built_in">int</span>32)</span><br></pre></td></tr></table></figure><ul><li>可以用<code>tf.cast</code>改变张量的数据类型</li><li>可以用<code>numpy</code>方法将tensorflow中的张量转化成numpy中的张量</li><li>可以用<code>shape</code>方法查看张量的尺寸</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">h = tf.constant([<span class="number">123</span>,<span class="number">456</span>],dtype = tf.int32)</span><br><span class="line">f = tf.cast(h,tf.float32)</span><br><span class="line">print(h.dtype, f.dtype)</span><br></pre></td></tr></table></figure><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;<span class="string">dtype:</span> <span class="string">'int32'</span>&gt; &lt;<span class="string">dtype:</span> <span class="string">'float32'</span>&gt;</span><br></pre></td></tr></table></figure><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">y = tf.constant(<span class="string">[[1.0,2.0],[3.0,4.0]]</span>)</span><br><span class="line"><span class="built_in">print</span>(y.numpy()) #转换成np.array</span><br><span class="line"><span class="built_in">print</span>(y.shape)</span><br></pre></td></tr></table></figure><figure class="highlight scheme"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="name">1.</span> <span class="number">2</span>.]</span><br><span class="line"> [<span class="name">3.</span> <span class="number">4</span>.]]</span><br><span class="line">(<span class="name">2</span>, <span class="number">2</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">u = tf.constant(<span class="string">u"你好 世界"</span>)</span><br><span class="line">print(u.numpy())  </span><br><span class="line">print(u.numpy().decode(<span class="string">"utf-8"</span>))</span><br></pre></td></tr></table></figure><figure class="highlight taggerscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">b'<span class="symbol">\x</span>e4<span class="symbol">\x</span>bd<span class="symbol">\x</span>a0<span class="symbol">\x</span>e5<span class="symbol">\x</span>a5<span class="symbol">\x</span>bd <span class="symbol">\x</span>e4<span class="symbol">\x</span>b8<span class="symbol">\x</span>96<span class="symbol">\x</span>e7<span class="symbol">\x</span>95<span class="symbol">\x</span>8c'</span><br><span class="line">你好 世界</span><br></pre></td></tr></table></figure><h4 id="变量张量"><a href="#变量张量" class="headerlink" title="变量张量"></a>变量张量</h4><p>模型中需要被训练的参数一般被设置成变量Variable</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 常量值不可以改变，常量的重新赋值相当于创造新的内存空间</span></span><br><span class="line">c = tf.constant([<span class="number">1.0</span>,<span class="number">2.0</span>])</span><br><span class="line">print(c)</span><br><span class="line">print(id(c))</span><br><span class="line">c = c + tf.constant([<span class="number">1.0</span>,<span class="number">1.0</span>])</span><br><span class="line">print(c)</span><br><span class="line">print(id(c))</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tf.Tensor([<span class="number">1.</span> <span class="number">2.</span>], shape=(<span class="number">2</span>,), dtype=<span class="built_in">float</span>32)</span><br><span class="line"><span class="number">5276289568</span></span><br><span class="line">tf.Tensor([<span class="number">2.</span> <span class="number">3.</span>], shape=(<span class="number">2</span>,), dtype=<span class="built_in">float</span>32)</span><br><span class="line"><span class="number">5276290240</span></span><br></pre></td></tr></table></figure><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 变量的值可以改变，可以通过assign, assign_add等方法给变量重新赋值</span></span><br><span class="line">v = tf.Variable([1.0,2.0],name = <span class="string">"v"</span>)</span><br><span class="line"><span class="builtin-name">print</span>(v)</span><br><span class="line"><span class="builtin-name">print</span>(id(v))</span><br><span class="line">v.assign_add([1.0,1.0])</span><br><span class="line"><span class="builtin-name">print</span>(v)</span><br><span class="line"><span class="builtin-name">print</span>(id(v))</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;tf.Variable <span class="string">'v:0'</span> shape=(<span class="number">2</span>,) dtype=<span class="built_in">float</span>32, numpy=<span class="built_in">array</span>([<span class="number">1.</span>, <span class="number">2.</span>], dtype=<span class="built_in">float</span>32)&gt;</span><br><span class="line"><span class="number">5276259888</span></span><br><span class="line">&lt;tf.Variable <span class="string">'v:0'</span> shape=(<span class="number">2</span>,) dtype=<span class="built_in">float</span>32, numpy=<span class="built_in">array</span>([<span class="number">2.</span>, <span class="number">3.</span>], dtype=<span class="built_in">float</span>32)&gt;</span><br><span class="line"><span class="number">5276259888</span></span><br></pre></td></tr></table></figure><h3 id="计算图"><a href="#计算图" class="headerlink" title="计算图"></a>计算图</h3><p>Tensorflow 有三种计算图的构建方式：静态计算图，动态计算图，以及Autograph。</p><ul><li>在TensorFlow1.0时代，采用的是静态计算图，需要先使用TensorFlow的各种算子创建计算图，然后再开启一个会话Session，显式执行计算图。</li><li>在TensorFlow2.0时代，采用的是动态计算图，即每使用一个算子后，该算子会被动态加入到隐含的默认计算图中立即执行得到结果，而无需开启Session。<ul><li>使用动态计算图即Eager Excution的好处是方便调试程序，它会让TensorFlow代码的表现和Python原生代码的表现一样，写起来就像写numpy一样，各种日志打印，控制流全部都是可以使用的。</li><li>使用动态计算图的缺点是运行效率相对会低一些。因为使用动态图会有许多次Python进程和TensorFlow的C++进程之间的通信。而静态计算图构建完成之后几乎全部在TensorFlow内核上使用C++代码执行，效率更高。此外静态图会对计算步骤进行一定的优化，剪去和结果无关的计算步骤。</li></ul></li><li>如果需要在TensorFlow2.0中使用静态图，可以使用<code>@tf.function</code> 装饰器将普通Python函数转换成对应的TensorFlow计算图构建代码。运行该函数就相当于在TensorFlow1.0中用Session执行代码。使用<code>tf.function</code>构建静态图的方式叫做 <code>Autograph</code></li></ul><h4 id="计算图简介"><a href="#计算图简介" class="headerlink" title="计算图简介"></a>计算图简介</h4><p>计算图由节点(nodes)和线(edges)组成。</p><ul><li>节点表示操作符Operator，或者称之为算子，线表示计算间的依赖。</li><li>实线表示有数据传递依赖，传递的数据即张量。</li><li>虚线通常可以表示控制依赖，即执行先后顺序。</li></ul><p><img alt data-src="https://github.com/SimpCosm/eat_tensorflow2_in_30_days_ipynbs/raw/master/data/strjoin_graph.png"></p><h4 id="静态计算图"><a href="#静态计算图" class="headerlink" title="静态计算图"></a>静态计算图</h4><p>在TensorFlow1.0中，使用静态计算图分两步：</p><ul><li>定义计算图</li><li>在会话中执行计算图</li></ul><h5 id="TensorFlow-1-0静态计算图范例"><a href="#TensorFlow-1-0静态计算图范例" class="headerlink" title="TensorFlow 1.0静态计算图范例"></a>TensorFlow 1.0静态计算图范例</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义计算图</span></span><br><span class="line">g = tf.Graph()</span><br><span class="line"><span class="keyword">with</span> g.as_default():</span><br><span class="line">    <span class="comment">#placeholder为占位符，执行会话时候指定填充对象</span></span><br><span class="line">    x = tf.placeholder(name=<span class="string">'x'</span>, shape=[], dtype=tf.string)  </span><br><span class="line">    y = tf.placeholder(name=<span class="string">'y'</span>, shape=[], dtype=tf.string)</span><br><span class="line">    z = tf.string_join([x,y],name = <span class="string">'join'</span>,separator=<span class="string">' '</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 执行计算图</span></span><br><span class="line"><span class="keyword">with</span> tf.Session(graph = g) <span class="keyword">as</span> sess:</span><br><span class="line">    print(sess.run(fetches = z,feed_dict = &#123;x:<span class="string">"hello"</span>,y:<span class="string">"world"</span>&#125;))</span><br></pre></td></tr></table></figure><h5 id="TensorFlow2-0-怀旧版静态计算图"><a href="#TensorFlow2-0-怀旧版静态计算图" class="headerlink" title="TensorFlow2.0 怀旧版静态计算图"></a>TensorFlow2.0 怀旧版静态计算图</h5><p>TensorFlow2.0为了确保对老版本tensorflow项目的兼容性，在tf.compat.v1子模块中保留了对TensorFlow1.0那种静态计算图构建风格的支持。</p><p>可称之为怀旧版静态计算图，已经不推荐使用了。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">g = tf.compat.v1.Graph()</span><br><span class="line"><span class="keyword">with</span> g.as_default():</span><br><span class="line">    x = tf.compat.v1.placeholder(name=<span class="string">'x'</span>, shape=[], dtype=tf.string)</span><br><span class="line">    y = tf.compat.v1.placeholder(name=<span class="string">'y'</span>, shape=[], dtype=tf.string)</span><br><span class="line">    z = tf.strings.join([x,y],name = <span class="string">"join"</span>,separator = <span class="string">" "</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.compat.v1.Session(graph = g) <span class="keyword">as</span> sess:</span><br><span class="line">    <span class="comment"># fetches的结果非常像一个函数的返回值，而feed_dict中的占位符相当于函数的参数序列。</span></span><br><span class="line">    result = sess.run(fetches = z,feed_dict = &#123;x:<span class="string">"hello"</span>,y:<span class="string">"world"</span>&#125;)</span><br><span class="line">    print(result)</span><br></pre></td></tr></table></figure><figure class="highlight sml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">b'hello world'</span><br></pre></td></tr></table></figure><h4 id="动态计算图"><a href="#动态计算图" class="headerlink" title="动态计算图"></a>动态计算图</h4><p>在TensorFlow2.0中，使用的是动态计算图和Autograph。与TensorFlow1.0中使用静态计算图分两步不同，动态计算图已经不区分计算图的定义和执行了，而是定义后立即执行。因此称之为 <code>Eager Excution</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 动态计算图在每个算子处都进行构建，构建后立即执行</span></span><br><span class="line"></span><br><span class="line">x = tf.constant(<span class="string">"hello"</span>)</span><br><span class="line">y = tf.constant(<span class="string">"world"</span>)</span><br><span class="line">z = tf.strings.join([x,y],separator=<span class="string">" "</span>)</span><br><span class="line"></span><br><span class="line">tf.print(z)</span><br></pre></td></tr></table></figure><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">hello world</span></span><br></pre></td></tr></table></figure><figure class="highlight sas"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 可以将动态计算图代码的输入和输出关系封装成函数</span><br><span class="line"></span><br><span class="line">def strjo<span class="meta">in(</span><span class="meta">x</span>,y):</span><br><span class="line">    z =  tf.strings.jo<span class="meta">in(</span>[<span class="meta">x</span>,y],separator = <span class="string">" "</span>)</span><br><span class="line">    tf.p<span class="meta">rint(</span>z)</span><br><span class="line">    <span class="meta">return</span> z</span><br><span class="line"></span><br><span class="line">result = strjo<span class="meta">in(</span>tf.constant(<span class="string">"hello"</span>),tf.constant(<span class="string">"world"</span>))</span><br><span class="line">p<span class="meta">rint(</span>result)</span><br></pre></td></tr></table></figure><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hello world</span><br><span class="line">tf.<span class="constructor">Tensor(<span class="params">b</span>'<span class="params">hello</span> <span class="params">world</span>', <span class="params">shape</span>=()</span>, dtype=<span class="built_in">string</span>)</span><br></pre></td></tr></table></figure><h4 id="Autograph"><a href="#Autograph" class="headerlink" title="Autograph"></a>Autograph</h4><p>动态计算图运行效率相对较低。</p><p>可以用 <code>@tf.function</code> 装饰器将普通Python函数转换成和TensorFlow1.0对应的静态计算图构建代码。</p><p>在TensorFlow1.0中，使用计算图分两步，第一步定义计算图，第二步在会话中执行计算图。</p><p>在TensorFlow2.0中，如果采用Autograph的方式使用计算图，第一步定义计算图变成了 <strong>定义函数</strong>，第二步执行计算图变成了<strong>调用函数</strong>。</p><p>不需要使用会话了，一些都像原始的Python语法一样自然。</p><p>实践中，我们一般会先用动态计算图调试代码，然后在需要提高性能的的地方利用@tf.function切换成Autograph获得更高的效率。</p><p>当然，<code>@tf.function</code>的使用需要遵循一定的规范，我们后面章节将重点介绍。</p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow <span class="keyword">as</span> <span class="keyword">tf</span></span><br><span class="line"></span><br><span class="line"># 使用autograph构建静态图</span><br><span class="line"></span><br><span class="line">@tf<span class="function">.<span class="keyword">function</span></span></span><br><span class="line">def strjoin(<span class="keyword">x</span>,<span class="keyword">y</span>):</span><br><span class="line">    <span class="keyword">z</span> =  <span class="keyword">tf</span>.strings.<span class="keyword">join</span>([<span class="keyword">x</span>,<span class="keyword">y</span>],separator = <span class="string">" "</span>)</span><br><span class="line">    <span class="keyword">tf</span>.<span class="keyword">print</span>(<span class="keyword">z</span>)</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">z</span></span><br><span class="line"></span><br><span class="line">result = strjoin(<span class="keyword">tf</span>.constant(<span class="string">"hello"</span>),<span class="keyword">tf</span>.constant(<span class="string">"world"</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span>(result)</span><br></pre></td></tr></table></figure><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hello world</span><br><span class="line">tf.<span class="constructor">Tensor(<span class="params">b</span>'<span class="params">hello</span> <span class="params">world</span>', <span class="params">shape</span>=()</span>, dtype=<span class="built_in">string</span>)</span><br></pre></td></tr></table></figure><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">import datetime</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建日志</span></span><br><span class="line">import os</span><br><span class="line">stamp = datetime.datetime.now().strftime(<span class="string">"%Y%m%d-%H%M%S"</span>)</span><br><span class="line">logdir = os.path.join(<span class="string">'data'</span>, <span class="string">'autograph'</span>, stamp)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 在 Python3 下建议使用 pathlib 修正各操作系统的路径</span></span><br><span class="line"><span class="comment"># from pathlib import Path</span></span><br><span class="line"><span class="comment"># stamp = datetime.datetime.now().strftime("%Y%m%d-%H%M%S")</span></span><br><span class="line"><span class="comment"># logdir = str(Path('./data/autograph/' + stamp))</span></span><br><span class="line"></span><br><span class="line">writer = tf.summary.create_file_writer(logdir)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开启autograph跟踪</span></span><br><span class="line">tf.summary.trace_on(<span class="attribute">graph</span>=<span class="literal">True</span>, <span class="attribute">profiler</span>=<span class="literal">True</span>) </span><br><span class="line"></span><br><span class="line"><span class="comment"># 执行autograph</span></span><br><span class="line">result = strjoin(<span class="string">"hello"</span>,<span class="string">"world"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#将计算图信息写入日志</span></span><br><span class="line">with writer.as_default():</span><br><span class="line">    tf.summary.trace_export(</span><br><span class="line">        <span class="attribute">name</span>=<span class="string">"autograph"</span>,</span><br><span class="line">        <span class="attribute">step</span>=0,</span><br><span class="line">        <span class="attribute">profiler_outdir</span>=logdir)</span><br></pre></td></tr></table></figure><figure class="highlight haml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#启动 tensorboard在jupyter中的魔法命令</span><br><span class="line"><span class="tag">%<span class="selector-tag">load_ext</span></span> tensorboard</span><br><span class="line">#启动tensorboard</span><br><span class="line"><span class="tag">%<span class="selector-tag">tensorboard</span></span> --logdir ./data/autograph/</span><br></pre></td></tr></table></figure><p><img alt data-src="https://github.com/SimpCosm/eat_tensorflow2_in_30_days_ipynbs/raw/master/data/2-2-tensorboard计算图.jpg"></p><h3 id="自动微分机制"><a href="#自动微分机制" class="headerlink" title="自动微分机制"></a>自动微分机制</h3><p>神经网络通常依赖反向传播求梯度来更新网络参数，求梯度过程通常是一件非常复杂而容易出错的事情，而深度学习框架可以帮助我们自动地完成这种求梯度运算。</p><p>Tensorflow一般使用梯度磁带 <code>tf.GradientTape</code> 来记录正向运算过程，然后反播磁带自动得到梯度值。</p><p>这种利用<code>tf.GradientTape</code> 求微分的方法叫做Tensorflow的 <strong>自动微分机制</strong></p><h4 id="利用梯度磁带求导数"><a href="#利用梯度磁带求导数" class="headerlink" title="利用梯度磁带求导数"></a>利用梯度磁带求导数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"></span><br><span class="line"><span class="comment"># f(x) = a*x**2 + b*x + c的导数</span></span><br><span class="line"></span><br><span class="line">x = tf.Variable(<span class="number">0.0</span>,name = <span class="string">"x"</span>,dtype = tf.float32)</span><br><span class="line">a = tf.constant(<span class="number">1.0</span>)</span><br><span class="line">b = tf.constant(<span class="number">-2.0</span>)</span><br><span class="line">c = tf.constant(<span class="number">1.0</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">    y = a*tf.pow(x,<span class="number">2</span>) + b*x + c</span><br><span class="line">    </span><br><span class="line">dy_dx = tape.gradient(y,x)</span><br><span class="line">print(dy_dx)</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.Tensor(<span class="number">-2.0</span>, shape=(), dtype=<span class="built_in">float</span>32)</span><br></pre></td></tr></table></figure><figure class="highlight gml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 对常量张量也可以求导，需要增加watch</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.GradientTape() as tape:</span><br><span class="line">    tape.watch([a,b,c])</span><br><span class="line">    <span class="symbol">y</span> = a*tf.pow(<span class="symbol">x</span>,<span class="number">2</span>) + b*<span class="symbol">x</span> + c</span><br><span class="line">    </span><br><span class="line">dy_dx,dy_da,dy_db,dy_dc = tape.gradient(<span class="symbol">y</span>,[<span class="symbol">x</span>,a,b,c])</span><br><span class="line">print(dy_da)</span><br><span class="line">print(dy_dc)</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tf.Tensor(<span class="number">0.0</span>, shape=(), dtype=<span class="built_in">float</span>32)</span><br><span class="line">tf.Tensor(<span class="number">1.0</span>, shape=(), dtype=<span class="built_in">float</span>32)</span><br></pre></td></tr></table></figure><figure class="highlight gml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 可以求二阶导数</span><br><span class="line"><span class="keyword">with</span> tf.GradientTape() as tape2:</span><br><span class="line">    <span class="keyword">with</span> tf.GradientTape() as tape1:   </span><br><span class="line">        <span class="symbol">y</span> = a*tf.pow(<span class="symbol">x</span>,<span class="number">2</span>) + b*<span class="symbol">x</span> + c</span><br><span class="line">    dy_dx = tape1.gradient(<span class="symbol">y</span>,<span class="symbol">x</span>)   </span><br><span class="line">dy2_dx2 = tape2.gradient(dy_dx,<span class="symbol">x</span>)</span><br><span class="line"></span><br><span class="line">print(dy2_dx2)</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.Tensor(<span class="number">2.0</span>, shape=(), dtype=<span class="built_in">float</span>32)</span><br></pre></td></tr></table></figure><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 可以在autograph中使用</span></span><br><span class="line"></span><br><span class="line">@tf<span class="function">.<span class="keyword">function</span></span></span><br><span class="line"><span class="function"><span class="title">def</span> <span class="title">f</span><span class="params">(x)</span>:   </span></span><br><span class="line"><span class="function">    <span class="title">a</span> = <span class="title">tf</span>.<span class="title">constant</span><span class="params">(<span class="number">1.0</span>)</span></span></span><br><span class="line"><span class="function">    <span class="title">b</span> = <span class="title">tf</span>.<span class="title">constant</span><span class="params">(<span class="number">-2.0</span>)</span></span></span><br><span class="line"><span class="function">    <span class="title">c</span> = <span class="title">tf</span>.<span class="title">constant</span><span class="params">(<span class="number">1.0</span>)</span></span></span><br><span class="line"><span class="function">    </span></span><br><span class="line"><span class="function">    # 自变量转换成<span class="title">tf</span>.<span class="title">float32</span></span></span><br><span class="line"><span class="function">    <span class="title">x</span> = <span class="title">tf</span>.<span class="title">cast</span><span class="params">(x,tf.float32)</span></span></span><br><span class="line"><span class="function">    <span class="title">with</span> <span class="title">tf</span>.<span class="title">GradientTape</span><span class="params">()</span> <span class="title">as</span> <span class="title">tape</span>:</span></span><br><span class="line"><span class="function">        <span class="title">tape</span>.<span class="title">watch</span><span class="params">(x)</span></span></span><br><span class="line"><span class="function">        <span class="title">y</span> = <span class="title">a</span>*<span class="title">tf</span>.<span class="title">pow</span><span class="params">(x,<span class="number">2</span>)</span>+<span class="title">b</span>*<span class="title">x</span>+<span class="title">c</span></span></span><br><span class="line"><span class="function">    <span class="title">dy_dx</span> = <span class="title">tape</span>.<span class="title">gradient</span><span class="params">(y,x)</span> </span></span><br><span class="line"><span class="function">    </span></span><br><span class="line"><span class="function">    <span class="title">return</span><span class="params">(<span class="params">(dy_dx,y)</span>)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="title">tf</span>.<span class="title">print</span><span class="params">(f<span class="params">(tf.constant<span class="params">(<span class="number">0.0</span>)</span>)</span>)</span></span></span><br><span class="line"><span class="function"><span class="title">tf</span>.<span class="title">print</span><span class="params">(f<span class="params">(tf.constant<span class="params">(<span class="number">1.0</span>)</span>)</span>)</span></span></span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(<span class="number">-2</span>, <span class="number">1</span>)</span><br><span class="line">(<span class="number">0</span>, <span class="number">0</span>)</span><br></pre></td></tr></table></figure><h4 id="利用梯度磁带和优化器求最小值"><a href="#利用梯度磁带和优化器求最小值" class="headerlink" title="利用梯度磁带和优化器求最小值"></a>利用梯度磁带和优化器求最小值</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 求f(x) = a*x**2 + b*x + c的最小值</span></span><br><span class="line"><span class="comment"># 使用optimizer.apply_gradients</span></span><br><span class="line"></span><br><span class="line">x = tf.Variable(<span class="number">0.0</span>,name = <span class="string">"x"</span>,dtype = tf.float32)</span><br><span class="line">a = tf.constant(<span class="number">1.0</span>)</span><br><span class="line">b = tf.constant(<span class="number">-2.0</span>)</span><br><span class="line">c = tf.constant(<span class="number">1.0</span>)</span><br><span class="line"></span><br><span class="line">optimizer = tf.keras.optimizers.SGD(learning_rate=<span class="number">0.01</span>)</span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">    <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">        y = a*tf.pow(x,<span class="number">2</span>) + b*x + c</span><br><span class="line">    dy_dx = tape.gradient(y,x)</span><br><span class="line">    optimizer.apply_gradients(grads_and_vars=[(dy_dx,x)])</span><br><span class="line">    </span><br><span class="line">tf.print(<span class="string">"y ="</span>,y,<span class="string">"; x ="</span>,x)</span><br></pre></td></tr></table></figure><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">y</span> = <span class="number">0</span> <span class="comment">; x = 0.999998569</span></span><br></pre></td></tr></table></figure><figure class="highlight llvm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"># 求f(<span class="keyword">x</span>) = a*<span class="keyword">x</span>**<span class="number">2</span> + b*<span class="keyword">x</span> + <span class="keyword">c</span>的最小值</span><br><span class="line"># 使用optimizer.minimize</span><br><span class="line"># optimizer.minimize相当于先用tape求gradient,再apply_gradient</span><br><span class="line"></span><br><span class="line"><span class="keyword">x</span> = tf.Variable(<span class="number">0.0</span>,name = <span class="string">"x"</span>,dtype = tf.float<span class="number">32</span>)</span><br><span class="line"></span><br><span class="line">#注意f()无参数</span><br><span class="line">def f():   </span><br><span class="line">    a = tf.<span class="keyword">constant</span>(<span class="number">1.0</span>)</span><br><span class="line">    b = tf.<span class="keyword">constant</span>(<span class="number">-2.0</span>)</span><br><span class="line">    <span class="keyword">c</span> = tf.<span class="keyword">constant</span>(<span class="number">1.0</span>)</span><br><span class="line">    y = a*tf.pow(<span class="keyword">x</span>,<span class="number">2</span>)+b*<span class="keyword">x</span>+<span class="keyword">c</span></span><br><span class="line">    return(y)</span><br><span class="line"></span><br><span class="line">optimizer = tf.keras.optimizers.SGD(learning_rate=<span class="number">0.01</span>)   </span><br><span class="line">for _ in range(<span class="number">1000</span>):</span><br><span class="line">    optimizer.minimize(f,[<span class="keyword">x</span>])   </span><br><span class="line">    </span><br><span class="line">tf.print(<span class="string">"y ="</span>,f(),<span class="string">"; x ="</span>,<span class="keyword">x</span>)</span><br></pre></td></tr></table></figure><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">y</span> = <span class="number">0</span> <span class="comment">; x = 0.999998569</span></span><br></pre></td></tr></table></figure><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"># 在autograph中完成最小值求解</span><br><span class="line"># 使用optimizer.apply_gradients</span><br><span class="line"></span><br><span class="line"><span class="keyword">x</span> = <span class="keyword">tf</span>.Variable(<span class="number">0.0</span>,name = <span class="string">"x"</span>,dtype = <span class="keyword">tf</span>.float32)</span><br><span class="line">optimizer = <span class="keyword">tf</span>.keras.optimizers.SGD(learning_rate=<span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line">@tf<span class="function">.<span class="keyword">function</span></span></span><br><span class="line">def minimizef():</span><br><span class="line">    <span class="keyword">a</span> = <span class="keyword">tf</span>.constant(<span class="number">1.0</span>)</span><br><span class="line">    <span class="keyword">b</span> = <span class="keyword">tf</span>.constant(-<span class="number">2.0</span>)</span><br><span class="line">    <span class="keyword">c</span> = <span class="keyword">tf</span>.constant(<span class="number">1.0</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> _ in <span class="keyword">tf</span>.<span class="built_in">range</span>(<span class="number">1000</span>): #注意autograph时使用<span class="keyword">tf</span>.<span class="built_in">range</span>(<span class="number">1000</span>)而不是<span class="built_in">range</span>(<span class="number">1000</span>)</span><br><span class="line">        with <span class="keyword">tf</span>.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">            <span class="keyword">y</span> = <span class="keyword">a</span>*<span class="keyword">tf</span>.<span class="built_in">pow</span>(<span class="keyword">x</span>,<span class="number">2</span>) + <span class="keyword">b</span>*<span class="keyword">x</span> + <span class="keyword">c</span></span><br><span class="line">        dy_dx = tape.gradient(<span class="keyword">y</span>,<span class="keyword">x</span>)</span><br><span class="line">        optimizer.apply_gradients(grads_and_vars=[(dy_dx,<span class="keyword">x</span>)])</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">y</span> = <span class="keyword">a</span>*<span class="keyword">tf</span>.<span class="built_in">pow</span>(<span class="keyword">x</span>,<span class="number">2</span>) + <span class="keyword">b</span>*<span class="keyword">x</span> + <span class="keyword">c</span></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">y</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">tf</span>.<span class="keyword">print</span>(minimizef())</span><br><span class="line"><span class="keyword">tf</span>.<span class="keyword">print</span>(<span class="keyword">x</span>)</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span></span><br><span class="line"><span class="number">0.999998569</span></span><br></pre></td></tr></table></figure><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在autograph中完成最小值求解</span></span><br><span class="line"><span class="comment"># 使用optimizer.minimize</span></span><br><span class="line"></span><br><span class="line">x = tf.Variable(<span class="number">0.0</span>,name = <span class="string">"x"</span>,dtype = tf.float32)</span><br><span class="line">optimizer = tf.keras.optimizers.SGD(learning_rate=<span class="number">0.01</span>)   </span><br><span class="line"></span><br><span class="line">@tf<span class="function">.<span class="keyword">function</span></span></span><br><span class="line"><span class="function"><span class="title">def</span> <span class="title">f</span><span class="params">()</span>:   </span></span><br><span class="line"><span class="function">    <span class="title">a</span> = <span class="title">tf</span>.<span class="title">constant</span><span class="params">(<span class="number">1.0</span>)</span></span></span><br><span class="line"><span class="function">    <span class="title">b</span> = <span class="title">tf</span>.<span class="title">constant</span><span class="params">(<span class="number">-2.0</span>)</span></span></span><br><span class="line"><span class="function">    <span class="title">c</span> = <span class="title">tf</span>.<span class="title">constant</span><span class="params">(<span class="number">1.0</span>)</span></span></span><br><span class="line"><span class="function">    <span class="title">y</span> = <span class="title">a</span>*<span class="title">tf</span>.<span class="title">pow</span><span class="params">(x,<span class="number">2</span>)</span>+<span class="title">b</span>*<span class="title">x</span>+<span class="title">c</span></span></span><br><span class="line"><span class="function">    <span class="title">return</span><span class="params">(y)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">@<span class="title">tf</span>.<span class="title">function</span></span></span><br><span class="line"><span class="function"><span class="title">def</span> <span class="title">train</span><span class="params">(epoch)</span>:  </span></span><br><span class="line"><span class="function">    <span class="title">for</span> <span class="title">_</span> <span class="title">in</span> <span class="title">tf</span>.<span class="title">range</span><span class="params">(epoch)</span>:  </span></span><br><span class="line"><span class="function">        <span class="title">optimizer</span>.<span class="title">minimize</span><span class="params">(f,[x])</span></span></span><br><span class="line"><span class="function">    <span class="title">r</span>结构<span class="title">eturn</span><span class="params">(f<span class="params">()</span>)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="title">tf</span>.<span class="title">print</span><span class="params">(train<span class="params">(<span class="number">1000</span>)</span>)</span></span></span><br><span class="line"><span class="function"><span class="title">tf</span>.<span class="title">print</span><span class="params">(x)</span></span></span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span></span><br><span class="line"><span class="number">0.999998569</span></span><br></pre></td></tr></table></figure><h2 id="结构层次"><a href="#结构层次" class="headerlink" title="结构层次"></a>结构层次</h2><p>本章我们介绍TensorFlow中5个不同的层次结构：即硬件层，内核层，低阶API，中阶API，高阶API。并以线性回归和DNN二分类模型为例，直观对比展示在不同层级实现模型的特点。</p><p>TensorFlow的层次结构从低到高可以分成如下五层。</p><ul><li>最底层为硬件层，TensorFlow支持CPU、GPU或TPU加入计算资源池。</li><li>第二层为C++实现的内核，kernel可以跨平台分布运行。</li><li>第三层为Python实现的操作符，提供了封装C++内核的低级API指令，主要包括各种张量操作算子、计算图、自动微分. 如<code>tf.Variable</code>, <code>tf.constant</code>, <code>tf.function</code>, <code>tf.GradientTape</code>, <code>tf.nn.softmax</code> … 如果把模型比作一个房子，那么第三层API就是【模型之砖】。</li><li>第四层为Python实现的模型组件，对低级API进行了函数封装，主要包括各种模型层，损失函数，优化器，数据管道，特征列等等。 如<code>tf.keras.layers</code>, <code>tf.keras.losses</code>, <code>tf.keras.metrics</code>, <code>tf.keras.optimizers</code>, <code>tf.data.DataSet</code>, <code>tf.feature_column</code>… 如果把模型比作一个房子，那么第四层API就是【模型之墙】。</li><li>第五层为Python实现的模型成品，一般为按照OOP方式封装的高级API，主要为tf.keras.models提供的模型的类接口。 如果把模型比作一个房子，那么第五层API就是模型本身，即【模型之屋】。</li></ul><p><img alt data-src="https://github.com/SimpCosm/eat_tensorflow2_in_30_days_ipynbs/raw/master/data/tensorflow_structure.jpg"></p><h3 id="低阶API示范"><a href="#低阶API示范" class="headerlink" title="低阶API示范"></a>低阶API示范</h3><p>下面的范例使用TensorFlow的低阶API实现线性回归模型和DNN二分类模型。</p><p>低阶API主要包括张量操作，计算图和自动微分。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment">#打印时间分割线</span></span><br><span class="line"><span class="meta">@tf.function</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">printbar</span><span class="params">()</span>:</span></span><br><span class="line">    today_ts = tf.timestamp()%(<span class="number">24</span>*<span class="number">60</span>*<span class="number">60</span>)</span><br><span class="line"></span><br><span class="line">    hour = tf.cast(today_ts//<span class="number">3600</span>+<span class="number">8</span>,tf.int32)%tf.constant(<span class="number">24</span>)</span><br><span class="line">    minite = tf.cast((today_ts%<span class="number">3600</span>)//<span class="number">60</span>,tf.int32)</span><br><span class="line">    second = tf.cast(tf.floor(today_ts%<span class="number">60</span>),tf.int32)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">timeformat</span><span class="params">(m)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> tf.strings.length(tf.strings.format(<span class="string">"&#123;&#125;"</span>,m))==<span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span>(tf.strings.format(<span class="string">"0&#123;&#125;"</span>,m))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span>(tf.strings.format(<span class="string">"&#123;&#125;"</span>,m))</span><br><span class="line">    </span><br><span class="line">    timestring = tf.strings.join([timeformat(hour),timeformat(minite),</span><br><span class="line">                timeformat(second)],separator = <span class="string">":"</span>)</span><br><span class="line">    tf.print(<span class="string">"=========="</span>*<span class="number">8</span>+timestring)</span><br></pre></td></tr></table></figure><h4 id="线性回归模型"><a href="#线性回归模型" class="headerlink" title="线性回归模型"></a>线性回归模型</h4><h5 id="准备数据-4"><a href="#准备数据-4" class="headerlink" title="准备数据"></a>准备数据</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt </span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#样本数量</span></span><br><span class="line">n = <span class="number">400</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成测试用数据集</span></span><br><span class="line">X = tf.random.uniform([n,<span class="number">2</span>],minval=<span class="number">-10</span>,maxval=<span class="number">10</span>) </span><br><span class="line">w0 = tf.constant([[<span class="number">2.0</span>],[<span class="number">-3.0</span>]])</span><br><span class="line">b0 = tf.constant([[<span class="number">3.0</span>]])</span><br><span class="line">Y = X@w0 + b0 + tf.random.normal([n,<span class="number">1</span>],mean = <span class="number">0.0</span>,stddev= <span class="number">2.0</span>)  <span class="comment"># @表示矩阵乘法,增加正态扰动</span></span><br></pre></td></tr></table></figure><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 数据可视化</span></span><br><span class="line"></span><br><span class="line">%matplotlib inline</span><br><span class="line">%config InlineBackend.<span class="attr">figure_format</span> = 'svg'</span><br><span class="line"></span><br><span class="line">plt.figure(<span class="attr">figsize</span> = (<span class="number">12</span>,<span class="number">5</span>))</span><br><span class="line"><span class="attr">ax1</span> = plt.subplot(<span class="number">121</span>)</span><br><span class="line">ax1.scatter(X[:,<span class="number">0</span>],Y[:,<span class="number">0</span>], <span class="attr">c</span> = <span class="string">"b"</span>)</span><br><span class="line">plt.xlabel(<span class="string">"x1"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"y"</span>,<span class="attr">rotation</span> = <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="attr">ax2</span> = plt.subplot(<span class="number">122</span>)</span><br><span class="line">ax2.scatter(X[:,<span class="number">1</span>],Y[:,<span class="number">0</span>], <span class="attr">c</span> = <span class="string">"g"</span>)</span><br><span class="line">plt.xlabel(<span class="string">"x2"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"y"</span>,<span class="attr">rotation</span> = <span class="number">0</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img alt data-src="https://github.com/SimpCosm/eat_tensorflow2_in_30_days_ipynbs/raw/master/data/3-1-01-回归数据可视化.png"></p><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># 构建数据管道迭代器</span><br><span class="line">def data_iter(<span class="built_in">features</span>, <span class="built_in">labels</span>, batch_size=<span class="number">8</span>):</span><br><span class="line">    num_examples = len(<span class="built_in">features</span>)</span><br><span class="line">    <span class="built_in">indices</span> = list(<span class="built_in">range</span>(num_examples))</span><br><span class="line">    <span class="built_in">np</span>.<span class="built_in">random</span>.shuffle(<span class="built_in">indices</span>)  #样本的读取顺序是随机的</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, num_examples, batch_size):</span><br><span class="line">        indexs = <span class="built_in">indices</span>[i: <span class="built_in">min</span>(i + batch_size, num_examples)]</span><br><span class="line">        yield tf.gather(<span class="built_in">features</span>,indexs), tf.gather(<span class="built_in">labels</span>,indexs)</span><br><span class="line">        </span><br><span class="line"># 测试数据管道效果   </span><br><span class="line">batch_size = <span class="number">8</span></span><br><span class="line">(<span class="built_in">features</span>,<span class="built_in">labels</span>) = next(data_iter(X,Y,batch_size))</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">features</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">labels</span>)</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">tf.Tensor(</span><br><span class="line">[[ <span class="number">2.6161194</span>   <span class="number">0.11071014</span>]</span><br><span class="line"> [ <span class="number">9.79207</span>    <span class="number">-0.70180416</span>]</span><br><span class="line"> [ <span class="number">9.792343</span>    <span class="number">6.9149055</span> ]</span><br><span class="line"> [<span class="number">-2.4186516</span>  <span class="number">-9.375019</span>  ]</span><br><span class="line"> [ <span class="number">9.83749</span>    <span class="number">-3.4637213</span> ]</span><br><span class="line"> [ <span class="number">7.3953056</span>   <span class="number">4.374569</span>  ]</span><br><span class="line"> [<span class="number">-0.14686584</span> <span class="number">-0.28063297</span>]</span><br><span class="line"> [ <span class="number">0.49001217</span> <span class="number">-9.739792</span>  ]], shape=(<span class="number">8</span>, <span class="number">2</span>), dtype=<span class="built_in">float</span>32)</span><br><span class="line">tf.Tensor(</span><br><span class="line">[[ <span class="number">9.334667</span> ]</span><br><span class="line"> [<span class="number">22.058844</span> ]</span><br><span class="line"> [ <span class="number">3.0695205</span>]</span><br><span class="line"> [<span class="number">26.736238</span> ]</span><br><span class="line"> [<span class="number">35.292133</span> ]</span><br><span class="line"> [ <span class="number">4.2943544</span>]</span><br><span class="line"> [ <span class="number">1.6713585</span>]</span><br><span class="line"> [<span class="number">34.826904</span> ]], shape=(<span class="number">8</span>, <span class="number">1</span>), dtype=<span class="built_in">float</span>32)</span><br></pre></td></tr></table></figure><h5 id="定义模型-4"><a href="#定义模型-4" class="headerlink" title="定义模型"></a>定义模型</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">w = tf.Variable(tf.random.normal(w0.shape))</span><br><span class="line">b = tf.Variable(tf.zeros_like(b0,dtype = tf.float32))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义模型</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LinearRegression</span>:</span>     </span><br><span class="line">    <span class="comment">#正向传播</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span><span class="params">(self,x)</span>:</span> </span><br><span class="line">        <span class="keyword">return</span> x@w + b</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 损失函数</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">loss_func</span><span class="params">(self,y_true,y_pred)</span>:</span>  </span><br><span class="line">        <span class="keyword">return</span> tf.reduce_mean((y_true - y_pred)**<span class="number">2</span>/<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">model = LinearRegression()</span><br></pre></td></tr></table></figure><h5 id="训练模型-4"><a href="#训练模型-4" class="headerlink" title="训练模型"></a>训练模型</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用动态图调试</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_step</span><span class="params">(model, features, labels)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">        predictions = model(features)</span><br><span class="line">        loss = model.loss_func(labels, predictions)</span><br><span class="line">    <span class="comment"># 反向传播求梯度</span></span><br><span class="line">    dloss_dw,dloss_db = tape.gradient(loss,[w,b])</span><br><span class="line">    <span class="comment"># 梯度下降法更新参数</span></span><br><span class="line">    w.assign(w - <span class="number">0.001</span>*dloss_dw)</span><br><span class="line">    b.assign(b - <span class="number">0.001</span>*dloss_db)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> loss</span><br></pre></td></tr></table></figure><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 测试train_step效果</span><br><span class="line">batch_size = <span class="number">10</span></span><br><span class="line">(features,labels) = next(data<span class="constructor">_iter(X,Y,<span class="params">batch_size</span>)</span>)</span><br><span class="line">train<span class="constructor">_step(<span class="params">model</span>,<span class="params">features</span>,<span class="params">labels</span>)</span></span><br></pre></td></tr></table></figure><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">tf.Tensor:</span> <span class="attr">shape</span>=<span class="string">(),</span> <span class="attr">dtype</span>=<span class="string">float32,</span> <span class="attr">numpy</span>=<span class="string">211.09982</span>&gt;</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_model</span><span class="params">(model,epochs)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> tf.range(<span class="number">1</span>,epochs+<span class="number">1</span>):</span><br><span class="line">        <span class="keyword">for</span> features, labels <span class="keyword">in</span> data_iter(X,Y,<span class="number">10</span>):</span><br><span class="line">            loss = train_step(model,features,labels)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> epoch%<span class="number">50</span>==<span class="number">0</span>:</span><br><span class="line">            printbar()</span><br><span class="line">            tf.print(<span class="string">"epoch ="</span>,epoch,<span class="string">"loss = "</span>,loss)</span><br><span class="line">            tf.print(<span class="string">"w ="</span>,w)</span><br><span class="line">            tf.print(<span class="string">"b ="</span>,b)</span><br><span class="line"></span><br><span class="line">train_model(model,epochs = <span class="number">200</span>)</span><br></pre></td></tr></table></figure><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">================================================================================<span class="number">16</span>:<span class="number">35</span>:<span class="number">56</span></span><br><span class="line">epoch = <span class="number">50</span> loss =  <span class="number">1.78806472</span></span><br><span class="line">w = <span class="string">[[1.97554708]</span></span><br><span class="line"><span class="string"> [-2.97719598]]</span></span><br><span class="line">b = <span class="string">[[2.60692883]]</span></span><br><span class="line">================================================================================<span class="number">16</span>:<span class="number">36</span>:<span class="number">00</span></span><br><span class="line">epoch = <span class="number">100</span> loss =  <span class="number">2.64588404</span></span><br><span class="line">w = <span class="string">[[1.97319281]</span></span><br><span class="line"><span class="string"> [-2.97810626]]</span></span><br><span class="line">b = <span class="string">[[2.95525956]]</span></span><br><span class="line">================================================================================<span class="number">16</span>:<span class="number">36</span>:<span class="number">04</span></span><br><span class="line">epoch = <span class="number">150</span> loss =  <span class="number">1.42576694</span></span><br><span class="line">w = <span class="string">[[1.96466208]</span></span><br><span class="line"><span class="string"> [-2.98337793]]</span></span><br><span class="line">b = <span class="string">[[3.00264144]]</span></span><br><span class="line">================================================================================<span class="number">16</span>:<span class="number">36</span>:<span class="number">08</span></span><br><span class="line">epoch = <span class="number">200</span> loss =  <span class="number">1.68992615</span></span><br><span class="line">w = <span class="string">[[1.97718477]</span></span><br><span class="line"><span class="string"> [-2.983814]]</span></span><br><span class="line">b = <span class="string">[[3.01013041]]</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">##使用autograph机制转换成静态图加速</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@tf.function</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_step</span><span class="params">(model, features, labels)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">        predictions = model(features)</span><br><span class="line">        loss = model.loss_func(labels, predictions)</span><br><span class="line">    <span class="comment"># 反向传播求梯度</span></span><br><span class="line">    dloss_dw,dloss_db = tape.gradient(loss,[w,b])</span><br><span class="line">    <span class="comment"># 梯度下降法更新参数</span></span><br><span class="line">    w.assign(w - <span class="number">0.001</span>*dloss_dw)</span><br><span class="line">    b.assign(b - <span class="number">0.001</span>*dloss_db)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_model</span><span class="params">(model,epochs)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> tf.range(<span class="number">1</span>,epochs+<span class="number">1</span>):</span><br><span class="line">        <span class="keyword">for</span> features, labels <span class="keyword">in</span> data_iter(X,Y,<span class="number">10</span>):</span><br><span class="line">            loss = train_step(model,features,labels)</span><br><span class="line">        <span class="keyword">if</span> epoch%<span class="number">50</span>==<span class="number">0</span>:</span><br><span class="line">            printbar()</span><br><span class="line">            tf.print(<span class="string">"epoch ="</span>,epoch,<span class="string">"loss = "</span>,loss)</span><br><span class="line">            tf.print(<span class="string">"w ="</span>,w)</span><br><span class="line">            tf.print(<span class="string">"b ="</span>,b)</span><br><span class="line"></span><br><span class="line">train_model(model,epochs = <span class="number">200</span>)</span><br></pre></td></tr></table></figure><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">================================================================================<span class="number">16</span>:<span class="number">36</span>:<span class="number">35</span></span><br><span class="line">epoch = <span class="number">50</span> loss =  <span class="number">0.894210339</span></span><br><span class="line">w = <span class="string">[[1.96927285]</span></span><br><span class="line"><span class="string"> [-2.98914337]]</span></span><br><span class="line">b = <span class="string">[[3.00987792]]</span></span><br><span class="line">================================================================================<span class="number">16</span>:<span class="number">36</span>:<span class="number">36</span></span><br><span class="line">epoch = <span class="number">100</span> loss =  <span class="number">1.58621466</span></span><br><span class="line">w = <span class="string">[[1.97566223]</span></span><br><span class="line"><span class="string"> [-2.98550248]]</span></span><br><span class="line">b = <span class="string">[[3.00998402]]</span></span><br><span class="line">================================================================================<span class="number">16</span>:<span class="number">36</span>:<span class="number">37</span></span><br><span class="line">epoch = <span class="number">150</span> loss =  <span class="number">2.2695992</span></span><br><span class="line">w = <span class="string">[[1.96664226]</span></span><br><span class="line"><span class="string"> [-2.99248481]]</span></span><br><span class="line">b = <span class="string">[[3.01028705]]</span></span><br><span class="line">================================================================================<span class="number">16</span>:<span class="number">36</span>:<span class="number">38</span></span><br><span class="line">epoch = <span class="number">200</span> loss =  <span class="number">1.90848124</span></span><br><span class="line">w = <span class="string">[[1.98000824]</span></span><br><span class="line"><span class="string"> [-2.98888135]]</span></span><br><span class="line">b = <span class="string">[[3.01085401]]</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 结果可视化</span></span><br><span class="line"></span><br><span class="line">%matplotlib inline</span><br><span class="line">%config InlineBackend.figure_format = <span class="string">'svg'</span></span><br><span class="line"></span><br><span class="line">plt.figure(figsize = (<span class="number">12</span>,<span class="number">5</span>))</span><br><span class="line">ax1 = plt.subplot(<span class="number">121</span>)</span><br><span class="line">ax1.scatter(X[:,<span class="number">0</span>],Y[:,<span class="number">0</span>], c = <span class="string">"b"</span>,label = <span class="string">"samples"</span>)</span><br><span class="line">ax1.plot(X[:,<span class="number">0</span>],w[<span class="number">0</span>]*X[:,<span class="number">0</span>]+b[<span class="number">0</span>],<span class="string">"-r"</span>,linewidth = <span class="number">5.0</span>,label = <span class="string">"model"</span>)</span><br><span class="line">ax1.legend()</span><br><span class="line">plt.xlabel(<span class="string">"x1"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"y"</span>,rotation = <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ax2 = plt.subplot(<span class="number">122</span>)</span><br><span class="line">ax2.scatter(X[:,<span class="number">1</span>],Y[:,<span class="number">0</span>], c = <span class="string">"g"</span>,label = <span class="string">"samples"</span>)</span><br><span class="line">ax2.plot(X[:,<span class="number">1</span>],w[<span class="number">1</span>]*X[:,<span class="number">1</span>]+b[<span class="number">0</span>],<span class="string">"-r"</span>,linewidth = <span class="number">5.0</span>,label = <span class="string">"model"</span>)</span><br><span class="line">ax2.legend()</span><br><span class="line">plt.xlabel(<span class="string">"x2"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"y"</span>,rotation = <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img alt data-src="https://github.com/SimpCosm/eat_tensorflow2_in_30_days_ipynbs/raw/master/data/3-1-2-回归结果可视化.png"></p><h4 id="DNN二分类模型"><a href="#DNN二分类模型" class="headerlink" title="DNN二分类模型"></a>DNN二分类模型</h4><h5 id="准备数据-5"><a href="#准备数据-5" class="headerlink" title="准备数据"></a>准备数据</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">%matplotlib inline</span><br><span class="line">%config InlineBackend.figure_format = <span class="string">'svg'</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#正负样本数量</span></span><br><span class="line">n_positive,n_negative = <span class="number">2000</span>,<span class="number">2000</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#生成正样本, 小圆环分布</span></span><br><span class="line">r_p = <span class="number">5.0</span> + tf.random.truncated_normal([n_positive,<span class="number">1</span>],<span class="number">0.0</span>,<span class="number">1.0</span>)</span><br><span class="line">theta_p = tf.random.uniform([n_positive,<span class="number">1</span>],<span class="number">0.0</span>,<span class="number">2</span>*np.pi) </span><br><span class="line">Xp = tf.concat([r_p*tf.cos(theta_p),r_p*tf.sin(theta_p)],axis = <span class="number">1</span>)</span><br><span class="line">Yp = tf.ones_like(r_p)</span><br><span class="line"></span><br><span class="line"><span class="comment">#生成负样本, 大圆环分布</span></span><br><span class="line">r_n = <span class="number">8.0</span> + tf.random.truncated_normal([n_negative,<span class="number">1</span>],<span class="number">0.0</span>,<span class="number">1.0</span>)</span><br><span class="line">theta_n = tf.random.uniform([n_negative,<span class="number">1</span>],<span class="number">0.0</span>,<span class="number">2</span>*np.pi) </span><br><span class="line">Xn = tf.concat([r_n*tf.cos(theta_n),r_n*tf.sin(theta_n)],axis = <span class="number">1</span>)</span><br><span class="line">Yn = tf.zeros_like(r_n)</span><br><span class="line"></span><br><span class="line"><span class="comment">#汇总样本</span></span><br><span class="line">X = tf.concat([Xp,Xn],axis = <span class="number">0</span>)</span><br><span class="line">Y = tf.concat([Yp,Yn],axis = <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#可视化</span></span><br><span class="line">plt.figure(figsize = (<span class="number">6</span>,<span class="number">6</span>))</span><br><span class="line">plt.scatter(Xp[:,<span class="number">0</span>].numpy(),Xp[:,<span class="number">1</span>].numpy(),c = <span class="string">"r"</span>)</span><br><span class="line">plt.scatter(Xn[:,<span class="number">0</span>].numpy(),Xn[:,<span class="number">1</span>].numpy(),c = <span class="string">"g"</span>)</span><br><span class="line">plt.legend([<span class="string">"positive"</span>,<span class="string">"negative"</span>]);</span><br></pre></td></tr></table></figure><p><img alt data-src="https://github.com/SimpCosm/eat_tensorflow2_in_30_days_ipynbs/raw/master/data/3-1-03-分类数据可视化.png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 构建数据管道迭代器</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">data_iter</span><span class="params">(features, labels, batch_size=<span class="number">8</span>)</span>:</span></span><br><span class="line">    num_examples = len(features)</span><br><span class="line">    indices = list(range(num_examples))</span><br><span class="line">    np.random.shuffle(indices)  <span class="comment">#样本的读取顺序是随机的</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, num_examples, batch_size):</span><br><span class="line">        indexs = indices[i: min(i + batch_size, num_examples)]</span><br><span class="line">        <span class="keyword">yield</span> tf.gather(features,indexs), tf.gather(labels,indexs)</span><br><span class="line">        </span><br><span class="line"><span class="comment"># 测试数据管道效果   </span></span><br><span class="line">batch_size = <span class="number">10</span></span><br><span class="line">(features,labels) = next(data_iter(X,Y,batch_size))</span><br><span class="line">print(features)</span><br><span class="line">print(labels)</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">tf.Tensor(</span><br><span class="line">[[ <span class="number">0.03732629</span>  <span class="number">3.5783494</span> ]</span><br><span class="line"> [ <span class="number">0.542919</span>    <span class="number">5.035079</span>  ]</span><br><span class="line"> [ <span class="number">5.860281</span>   <span class="number">-2.4476354</span> ]</span><br><span class="line"> [ <span class="number">0.63657564</span>  <span class="number">3.194231</span>  ]</span><br><span class="line"> [<span class="number">-3.5072308</span>   <span class="number">2.5578873</span> ]</span><br><span class="line"> [<span class="number">-2.4109735</span>  <span class="number">-3.6621518</span> ]</span><br><span class="line"> [ <span class="number">4.0975413</span>  <span class="number">-2.4172943</span> ]</span><br><span class="line"> [ <span class="number">1.9393908</span>  <span class="number">-6.782317</span>  ]</span><br><span class="line"> [<span class="number">-4.7453732</span>  <span class="number">-0.5176727</span> ]</span><br><span class="line"> [<span class="number">-1.4057113</span>  <span class="number">-7.9775257</span> ]], shape=(<span class="number">10</span>, <span class="number">2</span>), dtype=<span class="built_in">float</span>32)</span><br><span class="line">tf.Tensor(</span><br><span class="line">[[<span class="number">1.</span>]</span><br><span class="line"> [<span class="number">1.</span>]</span><br><span class="line"> [<span class="number">0.</span>]</span><br><span class="line"> [<span class="number">1.</span>]</span><br><span class="line"> [<span class="number">1.</span>]</span><br><span class="line"> [<span class="number">1.</span>]</span><br><span class="line"> [<span class="number">1.</span>]</span><br><span class="line"> [<span class="number">0.</span>]</span><br><span class="line"> [<span class="number">1.</span>]</span><br><span class="line"> [<span class="number">0.</span>]], shape=(<span class="number">10</span>, <span class="number">1</span>), dtype=<span class="built_in">float</span>32)</span><br></pre></td></tr></table></figure><h5 id="定义模型-5"><a href="#定义模型-5" class="headerlink" title="定义模型"></a>定义模型</h5><p>此处范例我们利用tf.Module来组织模型变量，关于tf.Module的较详细介绍参考本书第四章最后一节: Autograph和tf.Module。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DNNModel</span><span class="params">(tf.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,name = None)</span>:</span></span><br><span class="line">        super(DNNModel, self).__init__(name=name)</span><br><span class="line">        self.w1 = tf.Variable(tf.random.truncated_normal([<span class="number">2</span>,<span class="number">4</span>]),dtype = tf.float32)</span><br><span class="line">        self.b1 = tf.Variable(tf.zeros([<span class="number">1</span>,<span class="number">4</span>]),dtype = tf.float32)</span><br><span class="line">        self.w2 = tf.Variable(tf.random.truncated_normal([<span class="number">4</span>,<span class="number">8</span>]),dtype = tf.float32)</span><br><span class="line">        self.b2 = tf.Variable(tf.zeros([<span class="number">1</span>,<span class="number">8</span>]),dtype = tf.float32)</span><br><span class="line">        self.w3 = tf.Variable(tf.random.truncated_normal([<span class="number">8</span>,<span class="number">1</span>]),dtype = tf.float32)</span><br><span class="line">        self.b3 = tf.Variable(tf.zeros([<span class="number">1</span>,<span class="number">1</span>]),dtype = tf.float32)</span><br><span class="line"></span><br><span class="line">     </span><br><span class="line">    <span class="comment"># 正向传播</span></span><br><span class="line"><span class="meta">    @tf.function(input_signature=[tf.TensorSpec(shape = [None,2], dtype = tf.float32)])  </span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span><span class="params">(self,x)</span>:</span></span><br><span class="line">        x = tf.nn.relu(x@self.w1 + self.b1)</span><br><span class="line">        x = tf.nn.relu(x@self.w2 + self.b2)</span><br><span class="line">        y = tf.nn.sigmoid(x@self.w3 + self.b3)</span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 损失函数(二元交叉熵)</span></span><br><span class="line"><span class="meta">    @tf.function(input_signature=[tf.TensorSpec(shape = [None,1], dtype = tf.float32),</span></span><br><span class="line">                              tf.TensorSpec(shape = [<span class="literal">None</span>,<span class="number">1</span>], dtype = tf.float32)])  </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">loss_func</span><span class="params">(self,y_true,y_pred)</span>:</span>  </span><br><span class="line">        <span class="comment">#将预测值限制在 1e-7 以上, 1 - 1e-7 以下，避免log(0)错误</span></span><br><span class="line">        eps = <span class="number">1e-7</span></span><br><span class="line">        y_pred = tf.clip_by_value(y_pred,eps,<span class="number">1.0</span>-eps)</span><br><span class="line">        bce = - y_true*tf.math.log(y_pred) - (<span class="number">1</span>-y_true)*tf.math.log(<span class="number">1</span>-y_pred)</span><br><span class="line">        <span class="keyword">return</span>  tf.reduce_mean(bce)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 评估指标(准确率)</span></span><br><span class="line"><span class="meta">    @tf.function(input_signature=[tf.TensorSpec(shape = [None,1], dtype = tf.float32),</span></span><br><span class="line">                              tf.TensorSpec(shape = [<span class="literal">None</span>,<span class="number">1</span>], dtype = tf.float32)]) </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">metric_func</span><span class="params">(self,y_true,y_pred)</span>:</span></span><br><span class="line">        y_pred = tf.where(y_pred&gt;<span class="number">0.5</span>,tf.ones_like(y_pred,dtype = tf.float32),</span><br><span class="line">                          tf.zeros_like(y_pred,dtype = tf.float32))</span><br><span class="line">        acc = tf.reduce_mean(<span class="number">1</span>-tf.abs(y_true-y_pred))</span><br><span class="line">        <span class="keyword">return</span> acc</span><br><span class="line">    </span><br><span class="line">model = DNNModel()</span><br></pre></td></tr></table></figure><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># 测试模型结构</span><br><span class="line">batch_size = <span class="number">10</span></span><br><span class="line">(<span class="built_in">features</span>,<span class="built_in">labels</span>) = next(data_iter(X,Y,batch_size))</span><br><span class="line"></span><br><span class="line">predictions = model(<span class="built_in">features</span>)</span><br><span class="line"></span><br><span class="line">loss = model.loss_func(<span class="built_in">labels</span>,predictions)</span><br><span class="line">metric = model.metric_func(<span class="built_in">labels</span>,predictions)</span><br><span class="line"></span><br><span class="line">tf.<span class="built_in">print</span>(<span class="string">"init loss:"</span>,loss)</span><br><span class="line">tf.<span class="built_in">print</span>(<span class="string">"init metric"</span>,metric)</span><br><span class="line">init loss: <span class="number">1.76568353</span></span><br><span class="line">init metric <span class="number">0.6</span></span><br><span class="line"><span class="built_in">print</span>(len(model.trainable_variables))</span><br><span class="line"><span class="number">6</span></span><br></pre></td></tr></table></figure><h5 id="训练模型-5"><a href="#训练模型-5" class="headerlink" title="训练模型"></a>训练模型</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">##使用autograph机制转换成静态图加速</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@tf.function</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_step</span><span class="params">(model, features, labels)</span>:</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 正向传播求损失</span></span><br><span class="line">    <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">        predictions = model(features)</span><br><span class="line">        loss = model.loss_func(labels, predictions) </span><br><span class="line">        </span><br><span class="line">    <span class="comment"># 反向传播求梯度</span></span><br><span class="line">    grads = tape.gradient(loss, model.trainable_variables)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 执行梯度下降</span></span><br><span class="line">    <span class="keyword">for</span> p, dloss_dp <span class="keyword">in</span> zip(model.trainable_variables,grads):</span><br><span class="line">        p.assign(p - <span class="number">0.001</span>*dloss_dp)</span><br><span class="line">        </span><br><span class="line">    <span class="comment"># 计算评估指标</span></span><br><span class="line">    metric = model.metric_func(labels,predictions)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> loss, metric</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_model</span><span class="params">(model,epochs)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> tf.range(<span class="number">1</span>,epochs+<span class="number">1</span>):</span><br><span class="line">        <span class="keyword">for</span> features, labels <span class="keyword">in</span> data_iter(X,Y,<span class="number">100</span>):</span><br><span class="line">            loss,metric = train_step(model,features,labels)</span><br><span class="line">        <span class="keyword">if</span> epoch%<span class="number">100</span>==<span class="number">0</span>:</span><br><span class="line">            printbar()</span><br><span class="line">            tf.print(<span class="string">"epoch ="</span>,epoch,<span class="string">"loss = "</span>,loss, <span class="string">"accuracy = "</span>, metric)</span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">train_model(model,epochs = <span class="number">600</span>)</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">================================================================================<span class="number">16</span>:<span class="number">47</span>:<span class="number">35</span></span><br><span class="line">epoch = <span class="number">100</span> loss =  <span class="number">0.567795336</span> accuracy =  <span class="number">0.71</span></span><br><span class="line">================================================================================<span class="number">16</span>:<span class="number">47</span>:<span class="number">39</span></span><br><span class="line">epoch = <span class="number">200</span> loss =  <span class="number">0.50955683</span> accuracy =  <span class="number">0.77</span></span><br><span class="line">================================================================================<span class="number">16</span>:<span class="number">47</span>:<span class="number">43</span></span><br><span class="line">epoch = <span class="number">300</span> loss =  <span class="number">0.421476126</span> accuracy =  <span class="number">0.84</span></span><br><span class="line">================================================================================<span class="number">16</span>:<span class="number">47</span>:<span class="number">47</span></span><br><span class="line">epoch = <span class="number">400</span> loss =  <span class="number">0.330618203</span> accuracy =  <span class="number">0.9</span></span><br><span class="line">================================================================================<span class="number">16</span>:<span class="number">47</span>:<span class="number">51</span></span><br><span class="line">epoch = <span class="number">500</span> loss =  <span class="number">0.308296859</span> accuracy =  <span class="number">0.89</span></span><br><span class="line">================================================================================<span class="number">16</span>:<span class="number">47</span>:<span class="number">55</span></span><br><span class="line">epoch = <span class="number">600</span> loss =  <span class="number">0.279367268</span> accuracy =  <span class="number">0.96</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 结果可视化</span></span><br><span class="line">fig, (ax1,ax2) = plt.subplots(nrows=<span class="number">1</span>,ncols=<span class="number">2</span>,figsize = (<span class="number">12</span>,<span class="number">5</span>))</span><br><span class="line">ax1.scatter(Xp[:,<span class="number">0</span>],Xp[:,<span class="number">1</span>],c = <span class="string">"r"</span>)</span><br><span class="line">ax1.scatter(Xn[:,<span class="number">0</span>],Xn[:,<span class="number">1</span>],c = <span class="string">"g"</span>)</span><br><span class="line">ax1.legend([<span class="string">"positive"</span>,<span class="string">"negative"</span>]);</span><br><span class="line">ax1.set_title(<span class="string">"y_true"</span>);</span><br><span class="line"></span><br><span class="line">Xp_pred = tf.boolean_mask(X,tf.squeeze(model(X)&gt;=<span class="number">0.5</span>),axis = <span class="number">0</span>)</span><br><span class="line">Xn_pred = tf.boolean_mask(X,tf.squeeze(model(X)&lt;<span class="number">0.5</span>),axis = <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">ax2.scatter(Xp_pred[:,<span class="number">0</span>],Xp_pred[:,<span class="number">1</span>],c = <span class="string">"r"</span>)</span><br><span class="line">ax2.scatter(Xn_pred[:,<span class="number">0</span>],Xn_pred[:,<span class="number">1</span>],c = <span class="string">"g"</span>)</span><br><span class="line">ax2.legend([<span class="string">"positive"</span>,<span class="string">"negative"</span>]);</span><br><span class="line">ax2.set_title(<span class="string">"y_pred"</span>);</span><br></pre></td></tr></table></figure><p><img alt data-src="https://github.com/SimpCosm/eat_tensorflow2_in_30_days_ipynbs/raw/master/data/3-1-04-分类结果可视化.png"></p><h3 id="中阶API示范"><a href="#中阶API示范" class="headerlink" title="中阶API示范"></a>中阶API示范</h3><p>下面的范例使用TensorFlow的中阶API实现线性回归模型和和DNN二分类模型。</p><p>TensorFlow的中阶API主要包括各种模型层，损失函数，优化器，数据管道，特征列等等。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment">#打印时间分割线</span></span><br><span class="line"><span class="meta">@tf.function</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">printbar</span><span class="params">()</span>:</span></span><br><span class="line">    today_ts = tf.timestamp()%(<span class="number">24</span>*<span class="number">60</span>*<span class="number">60</span>)</span><br><span class="line"></span><br><span class="line">    hour = tf.cast(today_ts//<span class="number">3600</span>+<span class="number">8</span>,tf.int32)%tf.constant(<span class="number">24</span>)</span><br><span class="line">    minite = tf.cast((today_ts%<span class="number">3600</span>)//<span class="number">60</span>,tf.int32)</span><br><span class="line">    second = tf.cast(tf.floor(today_ts%<span class="number">60</span>),tf.int32)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">timeformat</span><span class="params">(m)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> tf.strings.length(tf.strings.format(<span class="string">"&#123;&#125;"</span>,m))==<span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span>(tf.strings.format(<span class="string">"0&#123;&#125;"</span>,m))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span>(tf.strings.format(<span class="string">"&#123;&#125;"</span>,m))</span><br><span class="line">    </span><br><span class="line">    timestring = tf.strings.join([timeformat(hour),timeformat(minite),</span><br><span class="line">                timeformat(second)],separator = <span class="string">":"</span>)</span><br><span class="line">    tf.print(<span class="string">"=========="</span>*<span class="number">8</span>+timestring)</span><br></pre></td></tr></table></figure><h4 id="线性回归模型-1"><a href="#线性回归模型-1" class="headerlink" title="线性回归模型"></a>线性回归模型</h4><h5 id="准备数据-6"><a href="#准备数据-6" class="headerlink" title="准备数据"></a>准备数据</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt </span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers,losses,metrics,optimizers</span><br><span class="line"></span><br><span class="line"><span class="comment">#样本数量</span></span><br><span class="line">n = <span class="number">400</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成测试用数据集</span></span><br><span class="line">X = tf.random.uniform([n,<span class="number">2</span>],minval=<span class="number">-10</span>,maxval=<span class="number">10</span>) </span><br><span class="line">w0 = tf.constant([[<span class="number">2.0</span>],[<span class="number">-3.0</span>]])</span><br><span class="line">b0 = tf.constant([[<span class="number">3.0</span>]])</span><br><span class="line">Y = X@w0 + b0 + tf.random.normal([n,<span class="number">1</span>],mean = <span class="number">0.0</span>,stddev= <span class="number">2.0</span>)  <span class="comment"># @表示矩阵乘法,增加正态扰动</span></span><br><span class="line"><span class="comment"># 数据可视化</span></span><br><span class="line">%matplotlib inline</span><br><span class="line">%config InlineBackend.figure_format = <span class="string">'svg'</span></span><br><span class="line">plt.figure(figsize = (<span class="number">12</span>,<span class="number">5</span>))</span><br><span class="line">ax1 = plt.subplot(<span class="number">121</span>)</span><br><span class="line">ax1.scatter(X[:,<span class="number">0</span>],Y[:,<span class="number">0</span>], c = <span class="string">"b"</span>)</span><br><span class="line">plt.xlabel(<span class="string">"x1"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"y"</span>,rotation = <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">ax2 = plt.subplot(<span class="number">122</span>)</span><br><span class="line">ax2.scatter(X[:,<span class="number">1</span>],Y[:,<span class="number">0</span>], c = <span class="string">"g"</span>)</span><br><span class="line">plt.xlabel(<span class="string">"x2"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"y"</span>,rotation = <span class="number">0</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img alt data-src="https://github.com/SimpCosm/eat_tensorflow2_in_30_days_ipynbs/raw/master/data/3-2-01-回归数据可视化.png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#构建输入数据管道</span></span><br><span class="line">ds = tf.data.Dataset.from_tensor_slices((X,Y)) \</span><br><span class="line">     .shuffle(buffer_size = <span class="number">100</span>).batch(<span class="number">10</span>) \</span><br><span class="line">     .prefetch(tf.data.experimental.AUTOTUNE)</span><br></pre></td></tr></table></figure><h5 id="定义模型-6"><a href="#定义模型-6" class="headerlink" title="定义模型"></a>定义模型</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">model = layers.Dense(units = <span class="number">1</span>) </span><br><span class="line">model.build(input_shape = (<span class="number">2</span>,)) <span class="comment">#用build方法创建variables</span></span><br><span class="line">model.loss_func = losses.mean_squared_error</span><br><span class="line">model.optimizer = optimizers.SGD(learning_rate=<span class="number">0.001</span>)</span><br></pre></td></tr></table></figure><h5 id="训练模型-6"><a href="#训练模型-6" class="headerlink" title="训练模型"></a>训练模型</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#使用autograph机制转换成静态图加速</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@tf.function</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_step</span><span class="params">(model, features, labels)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">        predictions = model(features)</span><br><span class="line">        loss = model.loss_func(tf.reshape(labels,[<span class="number">-1</span>]), tf.reshape(predictions,[<span class="number">-1</span>]))</span><br><span class="line">    grads = tape.gradient(loss,model.variables)</span><br><span class="line">    model.optimizer.apply_gradients(zip(grads,model.variables))</span><br><span class="line">    <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试train_step效果</span></span><br><span class="line">features,labels = next(ds.as_numpy_iterator())</span><br><span class="line">train_step(model,features,labels)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_model</span><span class="params">(model,epochs)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> tf.range(<span class="number">1</span>,epochs+<span class="number">1</span>):</span><br><span class="line">        loss = tf.constant(<span class="number">0.0</span>)</span><br><span class="line">        <span class="keyword">for</span> features, labels <span class="keyword">in</span> ds:</span><br><span class="line">            loss = train_step(model,features,labels)</span><br><span class="line">        <span class="keyword">if</span> epoch%<span class="number">50</span>==<span class="number">0</span>:</span><br><span class="line">            printbar()</span><br><span class="line">            tf.print(<span class="string">"epoch ="</span>,epoch,<span class="string">"loss = "</span>,loss)</span><br><span class="line">            tf.print(<span class="string">"w ="</span>,model.variables[<span class="number">0</span>])</span><br><span class="line">            tf.print(<span class="string">"b ="</span>,model.variables[<span class="number">1</span>])</span><br><span class="line">train_model(model,epochs = <span class="number">200</span>)</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">================================================================================<span class="number">17</span>:<span class="number">01</span>:<span class="number">48</span></span><br><span class="line">epoch = <span class="number">50</span> loss =  <span class="number">2.56481647</span></span><br><span class="line">w = [[<span class="number">1.99355531</span>]</span><br><span class="line"> [<span class="number">-2.99061537</span>]]</span><br><span class="line">b = [<span class="number">3.09484935</span>]</span><br><span class="line">================================================================================<span class="number">17</span>:<span class="number">01</span>:<span class="number">51</span></span><br><span class="line">epoch = <span class="number">100</span> loss =  <span class="number">5.96198225</span></span><br><span class="line">w = [[<span class="number">1.98028314</span>]</span><br><span class="line"> [<span class="number">-2.96975136</span>]]</span><br><span class="line">b = [<span class="number">3.09501529</span>]</span><br><span class="line">================================================================================<span class="number">17</span>:<span class="number">01</span>:<span class="number">54</span></span><br><span class="line">epoch = <span class="number">150</span> loss =  <span class="number">4.79625702</span></span><br><span class="line">w = [[<span class="number">2.00056171</span>]</span><br><span class="line"> [<span class="number">-2.98774862</span>]]</span><br><span class="line">b = [<span class="number">3.09567738</span>]</span><br><span class="line">================================================================================<span class="number">17</span>:<span class="number">01</span>:<span class="number">58</span></span><br><span class="line">epoch = <span class="number">200</span> loss =  <span class="number">8.26704407</span></span><br><span class="line">w = [[<span class="number">2.00282311</span>]</span><br><span class="line"> [<span class="number">-2.99300027</span>]]</span><br><span class="line">b = [<span class="number">3.09406662</span>]</span><br></pre></td></tr></table></figure><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 结果可视化</span></span><br><span class="line"></span><br><span class="line">%matplotlib inline</span><br><span class="line">%config InlineBackend.<span class="attr">figure_format</span> = 'svg'</span><br><span class="line"></span><br><span class="line">w,<span class="attr">b</span> = model.variables</span><br><span class="line"></span><br><span class="line">plt.figure(<span class="attr">figsize</span> = (<span class="number">12</span>,<span class="number">5</span>))</span><br><span class="line"><span class="attr">ax1</span> = plt.subplot(<span class="number">121</span>)</span><br><span class="line">ax1.scatter(X[:,<span class="number">0</span>],Y[:,<span class="number">0</span>], <span class="attr">c</span> = <span class="string">"b"</span>,<span class="attr">label</span> = <span class="string">"samples"</span>)</span><br><span class="line">ax1.plot(X[:,<span class="number">0</span>],w[<span class="number">0</span>]*X[:,<span class="number">0</span>]+b[<span class="number">0</span>],<span class="string">"-r"</span>,<span class="attr">linewidth</span> = <span class="number">5.0</span>,<span class="attr">label</span> = <span class="string">"model"</span>)</span><br><span class="line">ax1.legend()</span><br><span class="line">plt.xlabel(<span class="string">"x1"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"y"</span>,<span class="attr">rotation</span> = <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="attr">ax2</span> = plt.subplot(<span class="number">122</span>)</span><br><span class="line">ax2.scatter(X[:,<span class="number">1</span>],Y[:,<span class="number">0</span>], <span class="attr">c</span> = <span class="string">"g"</span>,<span class="attr">label</span> = <span class="string">"samples"</span>)</span><br><span class="line">ax2.plot(X[:,<span class="number">1</span>],w[<span class="number">1</span>]*X[:,<span class="number">1</span>]+b[<span class="number">0</span>],<span class="string">"-r"</span>,<span class="attr">linewidth</span> = <span class="number">5.0</span>,<span class="attr">label</span> = <span class="string">"model"</span>)</span><br><span class="line">ax2.legend()</span><br><span class="line">plt.xlabel(<span class="string">"x2"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"y"</span>,<span class="attr">rotation</span> = <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img alt data-src="https://github.com/SimpCosm/eat_tensorflow2_in_30_days_ipynbs/raw/master/data/3-2-02-回归结果可视化.png"></p><h4 id="DNN二分类模型-1"><a href="#DNN二分类模型-1" class="headerlink" title="DNN二分类模型"></a>DNN二分类模型</h4><h5 id="准备数据-7"><a href="#准备数据-7" class="headerlink" title="准备数据"></a>准备数据</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers,losses,metrics,optimizers</span><br><span class="line">%matplotlib inline</span><br><span class="line">%config InlineBackend.figure_format = <span class="string">'svg'</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#正负样本数量</span></span><br><span class="line">n_positive,n_negative = <span class="number">2000</span>,<span class="number">2000</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#生成正样本, 小圆环分布</span></span><br><span class="line">r_p = <span class="number">5.0</span> + tf.random.truncated_normal([n_positive,<span class="number">1</span>],<span class="number">0.0</span>,<span class="number">1.0</span>)</span><br><span class="line">theta_p = tf.random.uniform([n_positive,<span class="number">1</span>],<span class="number">0.0</span>,<span class="number">2</span>*np.pi) </span><br><span class="line">Xp = tf.concat([r_p*tf.cos(theta_p),r_p*tf.sin(theta_p)],axis = <span class="number">1</span>)</span><br><span class="line">Yp = tf.ones_like(r_p)</span><br><span class="line"></span><br><span class="line"><span class="comment">#生成负样本, 大圆环分布</span></span><br><span class="line">r_n = <span class="number">8.0</span> + tf.random.truncated_normal([n_negative,<span class="number">1</span>],<span class="number">0.0</span>,<span class="number">1.0</span>)</span><br><span class="line">theta_n = tf.random.uniform([n_negative,<span class="number">1</span>],<span class="number">0.0</span>,<span class="number">2</span>*np.pi) </span><br><span class="line">Xn = tf.concat([r_n*tf.cos(theta_n),r_n*tf.sin(theta_n)],axis = <span class="number">1</span>)</span><br><span class="line">Yn = tf.zeros_like(r_n)</span><br><span class="line"></span><br><span class="line"><span class="comment">#汇总样本</span></span><br><span class="line">X = tf.concat([Xp,Xn],axis = <span class="number">0</span>)</span><br><span class="line">Y = tf.concat([Yp,Yn],axis = <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#可视化</span></span><br><span class="line">plt.figure(figsize = (<span class="number">6</span>,<span class="number">6</span>))</span><br><span class="line">plt.scatter(Xp[:,<span class="number">0</span>].numpy(),Xp[:,<span class="number">1</span>].numpy(),c = <span class="string">"r"</span>)</span><br><span class="line">plt.scatter(Xn[:,<span class="number">0</span>].numpy(),Xn[:,<span class="number">1</span>].numpy(),c = <span class="string">"g"</span>)</span><br><span class="line">plt.legend([<span class="string">"positive"</span>,<span class="string">"negative"</span>]);</span><br></pre></td></tr></table></figure><p><img alt data-src="https://github.com/SimpCosm/eat_tensorflow2_in_30_days_ipynbs/raw/master/data/3-2-03-分类数据可视化.png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#构建输入数据管道</span></span><br><span class="line">ds = tf.data.Dataset.from_tensor_slices((X,Y)) \</span><br><span class="line">     .shuffle(buffer_size = <span class="number">4000</span>).batch(<span class="number">100</span>) \</span><br><span class="line">     .prefetch(tf.data.experimental.AUTOTUNE)</span><br></pre></td></tr></table></figure><h5 id="定义模型-7"><a href="#定义模型-7" class="headerlink" title="定义模型"></a>定义模型</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DNNModel</span><span class="params">(tf.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,name = None)</span>:</span></span><br><span class="line">        super(DNNModel, self).__init__(name=name)</span><br><span class="line">        self.dense1 = layers.Dense(<span class="number">4</span>,activation = <span class="string">"relu"</span>) </span><br><span class="line">        self.dense2 = layers.Dense(<span class="number">8</span>,activation = <span class="string">"relu"</span>)</span><br><span class="line">        self.dense3 = layers.Dense(<span class="number">1</span>,activation = <span class="string">"sigmoid"</span>)</span><br><span class="line"></span><br><span class="line">     </span><br><span class="line">    <span class="comment"># 正向传播</span></span><br><span class="line"><span class="meta">    @tf.function(input_signature=[tf.TensorSpec(shape = [None,2], dtype = tf.float32)])  </span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span><span class="params">(self,x)</span>:</span></span><br><span class="line">        x = self.dense1(x)</span><br><span class="line">        x = self.dense2(x)</span><br><span class="line">        y = self.dense3(x)</span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line">    </span><br><span class="line">model = DNNModel()</span><br><span class="line">model.loss_func = losses.binary_crossentropy</span><br><span class="line">model.metric_func = metrics.binary_accuracy</span><br><span class="line">model.optimizer = optimizers.Adam(learning_rate=<span class="number">0.001</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 测试模型结构</span></span><br><span class="line">(features,labels) = next(ds.as_numpy_iterator())</span><br><span class="line"></span><br><span class="line">predictions = model(features)</span><br><span class="line"></span><br><span class="line">loss = model.loss_func(tf.reshape(labels,[<span class="number">-1</span>]),tf.reshape(predictions,[<span class="number">-1</span>]))</span><br><span class="line">metric = model.metric_func(tf.reshape(labels,[<span class="number">-1</span>]),tf.reshape(predictions,[<span class="number">-1</span>]))</span><br><span class="line"></span><br><span class="line">tf.print(<span class="string">"init loss:"</span>,loss)</span><br><span class="line">tf.print(<span class="string">"init metric"</span>,metric)</span><br><span class="line">init loss: <span class="number">1.13653195</span></span><br><span class="line">init metric <span class="number">0.5</span></span><br></pre></td></tr></table></figure><h5 id="训练模型-7"><a href="#训练模型-7" class="headerlink" title="训练模型"></a>训练模型</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#使用autograph机制转换成静态图加速</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@tf.function</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_step</span><span class="params">(model, features, labels)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">        predictions = model(features)</span><br><span class="line">        loss = model.loss_func(tf.reshape(labels,[<span class="number">-1</span>]), tf.reshape(predictions,[<span class="number">-1</span>]))</span><br><span class="line">    grads = tape.gradient(loss,model.trainable_variables)</span><br><span class="line">    model.optimizer.apply_gradients(zip(grads,model.trainable_variables))</span><br><span class="line">    </span><br><span class="line">    metric = model.metric_func(tf.reshape(labels,[<span class="number">-1</span>]), tf.reshape(predictions,[<span class="number">-1</span>]))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> loss,metric</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试train_step效果</span></span><br><span class="line">features,labels = next(ds.as_numpy_iterator())</span><br><span class="line">train_step(model,features,labels)</span><br></pre></td></tr></table></figure><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(<span class="tag">&lt;<span class="name">tf.Tensor:</span> <span class="attr">shape</span>=<span class="string">(),</span> <span class="attr">dtype</span>=<span class="string">float32,</span> <span class="attr">numpy</span>=<span class="string">1.2033114</span>&gt;</span>,</span><br><span class="line"> <span class="tag">&lt;<span class="name">tf.Tensor:</span> <span class="attr">shape</span>=<span class="string">(),</span> <span class="attr">dtype</span>=<span class="string">float32,</span> <span class="attr">numpy</span>=<span class="string">0.47</span>&gt;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_model</span><span class="params">(model,epochs)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> tf.range(<span class="number">1</span>,epochs+<span class="number">1</span>):</span><br><span class="line">        loss, metric = tf.constant(<span class="number">0.0</span>),tf.constant(<span class="number">0.0</span>)</span><br><span class="line">        <span class="keyword">for</span> features, labels <span class="keyword">in</span> ds:</span><br><span class="line">            loss,metric = train_step(model,features,labels)</span><br><span class="line">        <span class="keyword">if</span> epoch%<span class="number">10</span>==<span class="number">0</span>:</span><br><span class="line">            printbar()</span><br><span class="line">            tf.print(<span class="string">"epoch ="</span>,epoch,<span class="string">"loss = "</span>,loss, <span class="string">"accuracy = "</span>,metric)</span><br><span class="line">train_model(model,epochs = <span class="number">60</span>)</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">================================================================================<span class="number">17</span>:<span class="number">07</span>:<span class="number">36</span></span><br><span class="line">epoch = <span class="number">10</span> loss =  <span class="number">0.556449413</span> accuracy =  <span class="number">0.79</span></span><br><span class="line">================================================================================<span class="number">17</span>:<span class="number">07</span>:<span class="number">38</span></span><br><span class="line">epoch = <span class="number">20</span> loss =  <span class="number">0.439187407</span> accuracy =  <span class="number">0.86</span></span><br><span class="line">================================================================================<span class="number">17</span>:<span class="number">07</span>:<span class="number">40</span></span><br><span class="line">epoch = <span class="number">30</span> loss =  <span class="number">0.259921253</span> accuracy =  <span class="number">0.95</span></span><br><span class="line">================================================================================<span class="number">17</span>:<span class="number">07</span>:<span class="number">42</span></span><br><span class="line">epoch = <span class="number">40</span> loss =  <span class="number">0.244920313</span> accuracy =  <span class="number">0.9</span></span><br><span class="line">================================================================================<span class="number">17</span>:<span class="number">07</span>:<span class="number">43</span></span><br><span class="line">epoch = <span class="number">50</span> loss =  <span class="number">0.19839409</span> accuracy =  <span class="number">0.92</span></span><br><span class="line">================================================================================<span class="number">17</span>:<span class="number">07</span>:<span class="number">45</span></span><br><span class="line">epoch = <span class="number">60</span> loss =  <span class="number">0.126151696</span> accuracy =  <span class="number">0.95</span></span><br></pre></td></tr></table></figure><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 结果可视化</span></span><br><span class="line">fig, (ax1,ax2) = plt.subplots(<span class="attr">nrows=1,ncols=2,figsize</span> = (<span class="number">12</span>,<span class="number">5</span>))</span><br><span class="line">ax1.scatter(Xp[:,<span class="number">0</span>].numpy(),Xp[:,<span class="number">1</span>].numpy(),<span class="attr">c</span> = <span class="string">"r"</span>)</span><br><span class="line">ax1.scatter(Xn[:,<span class="number">0</span>].numpy(),Xn[:,<span class="number">1</span>].numpy(),<span class="attr">c</span> = <span class="string">"g"</span>)</span><br><span class="line">ax1.legend([<span class="string">"positive"</span>,<span class="string">"negative"</span>]);</span><br><span class="line">ax1.set_title(<span class="string">"y_true"</span>);</span><br><span class="line"></span><br><span class="line"><span class="attr">Xp_pred</span> = tf.boolean_mask(X,tf.squeeze(model(X)&gt;=<span class="number">0.5</span>),<span class="attr">axis</span> = <span class="number">0</span>)</span><br><span class="line"><span class="attr">Xn_pred</span> = tf.boolean_mask(X,tf.squeeze(model(X)&lt;<span class="number">0.5</span>),<span class="attr">axis</span> = <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">ax2.scatter(Xp_pred[:,<span class="number">0</span>].numpy(),Xp_pred[:,<span class="number">1</span>].numpy(),<span class="attr">c</span> = <span class="string">"r"</span>)</span><br><span class="line">ax2.scatter(Xn_pred[:,<span class="number">0</span>].numpy(),Xn_pred[:,<span class="number">1</span>].numpy(),<span class="attr">c</span> = <span class="string">"g"</span>)</span><br><span class="line">ax2.legend([<span class="string">"positive"</span>,<span class="string">"negative"</span>]);</span><br><span class="line">ax2.set_title(<span class="string">"y_pred"</span>);</span><br></pre></td></tr></table></figure><p><img alt data-src="https://github.com/SimpCosm/eat_tensorflow2_in_30_days_ipynbs/raw/master/data/3-2-04-分类结果可视化.png"></p><h3 id="高阶API示范"><a href="#高阶API示范" class="headerlink" title="高阶API示范"></a>高阶API示范</h3><p>下面的范例使用TensorFlow的高阶API实现线性回归模型和DNN二分类模型。</p><p>TensorFlow的高阶API主要为tf.keras.models提供的模型的类接口。</p><p>使用Keras接口有以下3种方式构建模型：使用Sequential按层顺序构建模型，使用函数式API构建任意结构模型，继承Model基类构建自定义模型。</p><p>此处分别演示使用Sequential按层顺序构建模型以及继承Model基类构建自定义模型。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment">#打印时间分割线</span></span><br><span class="line"><span class="meta">@tf.function</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">printbar</span><span class="params">()</span>:</span></span><br><span class="line">    today_ts = tf.timestamp()%(<span class="number">24</span>*<span class="number">60</span>*<span class="number">60</span>)</span><br><span class="line"></span><br><span class="line">    hour = tf.cast(today_ts//<span class="number">3600</span>+<span class="number">8</span>,tf.int32)%tf.constant(<span class="number">24</span>)</span><br><span class="line">    minite = tf.cast((today_ts%<span class="number">3600</span>)//<span class="number">60</span>,tf.int32)</span><br><span class="line">    second = tf.cast(tf.floor(today_ts%<span class="number">60</span>),tf.int32)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">timeformat</span><span class="params">(m)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> tf.strings.length(tf.strings.format(<span class="string">"&#123;&#125;"</span>,m))==<span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span>(tf.strings.format(<span class="string">"0&#123;&#125;"</span>,m))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span>(tf.strings.format(<span class="string">"&#123;&#125;"</span>,m))</span><br><span class="line">    </span><br><span class="line">    timestring = tf.strings.join([timeformat(hour),timeformat(minite),</span><br><span class="line">                timeformat(second)],separator = <span class="string">":"</span>)</span><br><span class="line">    tf.print(<span class="string">"=========="</span>*<span class="number">8</span>+timestring)</span><br></pre></td></tr></table></figure><h4 id="线性回归模型-2"><a href="#线性回归模型-2" class="headerlink" title="线性回归模型"></a>线性回归模型</h4><p>此范例我们使用Sequential按层顺序构建模型，并使用内置model.fit方法训练模型【面向新手】。</p><h5 id="准备数据-8"><a href="#准备数据-8" class="headerlink" title="准备数据"></a>准备数据</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt </span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> models,layers,losses,metrics,optimizers</span><br><span class="line"></span><br><span class="line"><span class="comment">#样本数量</span></span><br><span class="line">n = <span class="number">400</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成测试用数据集</span></span><br><span class="line">X = tf.random.uniform([n,<span class="number">2</span>],minval=<span class="number">-10</span>,maxval=<span class="number">10</span>) </span><br><span class="line">w0 = tf.constant([[<span class="number">2.0</span>],[<span class="number">-3.0</span>]])</span><br><span class="line">b0 = tf.constant([[<span class="number">3.0</span>]])</span><br><span class="line">Y = X@w0 + b0 + tf.random.normal([n,<span class="number">1</span>],mean = <span class="number">0.0</span>,stddev= <span class="number">2.0</span>)  <span class="comment"># @表示矩阵乘法,增加正态扰动</span></span><br><span class="line"><span class="comment"># 数据可视化</span></span><br><span class="line"></span><br><span class="line">%matplotlib inline</span><br><span class="line">%config InlineBackend.figure_format = <span class="string">'svg'</span></span><br><span class="line">plt.figure(figsize = (<span class="number">12</span>,<span class="number">5</span>))</span><br><span class="line">ax1 = plt.subplot(<span class="number">121</span>)</span><br><span class="line">ax1.scatter(X[:,<span class="number">0</span>],Y[:,<span class="number">0</span>], c = <span class="string">"b"</span>)</span><br><span class="line">plt.xlabel(<span class="string">"x1"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"y"</span>,rotation = <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">ax2 = plt.subplot(<span class="number">122</span>)</span><br><span class="line">ax2.scatter(X[:,<span class="number">1</span>],Y[:,<span class="number">0</span>], c = <span class="string">"g"</span>)</span><br><span class="line">plt.xlabel(<span class="string">"x2"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"y"</span>,rotation = <span class="number">0</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img alt data-src="https://github.com/SimpCosm/eat_tensorflow2_in_30_days_ipynbs/raw/master/data/3-3-01-回归数据可视化.png"></p><h5 id="定义模型-8"><a href="#定义模型-8" class="headerlink" title="定义模型"></a>定义模型</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tf.keras.backend.clear_session()</span><br><span class="line"></span><br><span class="line">model = models.Sequential()</span><br><span class="line">model.add(layers.Dense(<span class="number">1</span>,input_shape =(<span class="number">2</span>,)))</span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Model: "sequential"</span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">Layer (type)                 Output Shape              Param #   </span><br><span class="line">=================================================================</span><br><span class="line">dense (Dense)                (None, 1)                 3         </span><br><span class="line">=================================================================</span><br><span class="line">Total params: 3</span><br><span class="line">Trainable params: 3</span><br><span class="line">Non-trainable params: 0</span><br></pre></td></tr></table></figure><h5 id="训练模型-8"><a href="#训练模型-8" class="headerlink" title="训练模型"></a>训练模型</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">### 使用fit方法进行训练</span></span><br><span class="line"></span><br><span class="line">model.compile(optimizer=<span class="string">"adam"</span>,loss=<span class="string">"mse"</span>,metrics=[<span class="string">"mae"</span>])</span><br><span class="line">model.fit(X,Y,batch_size = <span class="number">10</span>,epochs = <span class="number">200</span>)  </span><br><span class="line"></span><br><span class="line">tf.print(<span class="string">"w = "</span>,model.layers[<span class="number">0</span>].kernel)</span><br><span class="line">tf.print(<span class="string">"b = "</span>,model.layers[<span class="number">0</span>].bias)</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Epoch <span class="number">197</span>/<span class="number">200</span></span><br><span class="line"><span class="number">400</span>/<span class="number">400</span> [==============================] - <span class="number">0</span>s <span class="number">190</span>us/sample - loss: <span class="number">4.3977</span> - mae: <span class="number">1.7129</span></span><br><span class="line">Epoch <span class="number">198</span>/<span class="number">200</span></span><br><span class="line"><span class="number">400</span>/<span class="number">400</span> [==============================] - <span class="number">0</span>s <span class="number">172</span>us/sample - loss: <span class="number">4.3918</span> - mae: <span class="number">1.7117</span></span><br><span class="line">Epoch <span class="number">199</span>/<span class="number">200</span></span><br><span class="line"><span class="number">400</span>/<span class="number">400</span> [==============================] - <span class="number">0</span>s <span class="number">134</span>us/sample - loss: <span class="number">4.3861</span> - mae: <span class="number">1.7106</span></span><br><span class="line">Epoch <span class="number">200</span>/<span class="number">200</span></span><br><span class="line"><span class="number">400</span>/<span class="number">400</span> [==============================] - <span class="number">0</span>s <span class="number">166</span>us/sample - loss: <span class="number">4.3786</span> - mae: <span class="number">1.7092</span></span><br><span class="line">w =  [[<span class="number">1.99339032</span>]</span><br><span class="line"> [<span class="number">-3.00866461</span>]]</span><br><span class="line">b =  [<span class="number">2.67018795</span>]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 结果可视化</span></span><br><span class="line"></span><br><span class="line">%matplotlib inline</span><br><span class="line">%config InlineBackend.figure_format = <span class="string">'svg'</span></span><br><span class="line"></span><br><span class="line">w,b = model.variables</span><br><span class="line"></span><br><span class="line">plt.figure(figsize = (<span class="number">12</span>,<span class="number">5</span>))</span><br><span class="line">ax1 = plt.subplot(<span class="number">121</span>)</span><br><span class="line">ax1.scatter(X[:,<span class="number">0</span>],Y[:,<span class="number">0</span>], c = <span class="string">"b"</span>,label = <span class="string">"samples"</span>)</span><br><span class="line">ax1.plot(X[:,<span class="number">0</span>],w[<span class="number">0</span>]*X[:,<span class="number">0</span>]+b[<span class="number">0</span>],<span class="string">"-r"</span>,linewidth = <span class="number">5.0</span>,label = <span class="string">"model"</span>)</span><br><span class="line">ax1.legend()</span><br><span class="line">plt.xlabel(<span class="string">"x1"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"y"</span>,rotation = <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">ax2 = plt.subplot(<span class="number">122</span>)</span><br><span class="line">ax2.scatter(X[:,<span class="number">1</span>],Y[:,<span class="number">0</span>], c = <span class="string">"g"</span>,label = <span class="string">"samples"</span>)</span><br><span class="line">ax2.plot(X[:,<span class="number">1</span>],w[<span class="number">1</span>]*X[:,<span class="number">1</span>]+b[<span class="number">0</span>],<span class="string">"-r"</span>,linewidth = <span class="number">5.0</span>,label = <span class="string">"model"</span>)</span><br><span class="line">ax2.legend()</span><br><span class="line">plt.xlabel(<span class="string">"x2"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"y"</span>,rotation = <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img alt data-src="https://github.com/SimpCosm/eat_tensorflow2_in_30_days_ipynbs/raw/master/data/3-3-02-回归结果可视化.png"></p><h4 id="DNN二分类模型-2"><a href="#DNN二分类模型-2" class="headerlink" title="DNN二分类模型"></a>DNN二分类模型</h4><p>此范例我们使用继承Model基类构建自定义模型，并构建自定义训练循环【面向专家】</p><h5 id="准备数据-9"><a href="#准备数据-9" class="headerlink" title="准备数据"></a>准备数据</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers,losses,metrics,optimizers</span><br><span class="line">%matplotlib inline</span><br><span class="line">%config InlineBackend.figure_format = <span class="string">'svg'</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#正负样本数量</span></span><br><span class="line">n_positive,n_negative = <span class="number">2000</span>,<span class="number">2000</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#生成正样本, 小圆环分布</span></span><br><span class="line">r_p = <span class="number">5.0</span> + tf.random.truncated_normal([n_positive,<span class="number">1</span>],<span class="number">0.0</span>,<span class="number">1.0</span>)</span><br><span class="line">theta_p = tf.random.uniform([n_positive,<span class="number">1</span>],<span class="number">0.0</span>,<span class="number">2</span>*np.pi) </span><br><span class="line">Xp = tf.concat([r_p*tf.cos(theta_p),r_p*tf.sin(theta_p)],axis = <span class="number">1</span>)</span><br><span class="line">Yp = tf.ones_like(r_p)</span><br><span class="line"></span><br><span class="line"><span class="comment">#生成负样本, 大圆环分布</span></span><br><span class="line">r_n = <span class="number">8.0</span> + tf.random.truncated_normal([n_negative,<span class="number">1</span>],<span class="number">0.0</span>,<span class="number">1.0</span>)</span><br><span class="line">theta_n = tf.random.uniform([n_negative,<span class="number">1</span>],<span class="number">0.0</span>,<span class="number">2</span>*np.pi) </span><br><span class="line">Xn = tf.concat([r_n*tf.cos(theta_n),r_n*tf.sin(theta_n)],axis = <span class="number">1</span>)</span><br><span class="line">Yn = tf.zeros_like(r_n)</span><br><span class="line"></span><br><span class="line"><span class="comment">#汇总样本</span></span><br><span class="line">X = tf.concat([Xp,Xn],axis = <span class="number">0</span>)</span><br><span class="line">Y = tf.concat([Yp,Yn],axis = <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#样本洗牌</span></span><br><span class="line">data = tf.concat([X,Y],axis = <span class="number">1</span>)</span><br><span class="line">data = tf.random.shuffle(data)</span><br><span class="line">X = data[:,:<span class="number">2</span>]</span><br><span class="line">Y = data[:,<span class="number">2</span>:]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#可视化</span></span><br><span class="line">plt.figure(figsize = (<span class="number">6</span>,<span class="number">6</span>))</span><br><span class="line">plt.scatter(Xp[:,<span class="number">0</span>].numpy(),Xp[:,<span class="number">1</span>].numpy(),c = <span class="string">"r"</span>)</span><br><span class="line">plt.scatter(Xn[:,<span class="number">0</span>].numpy(),Xn[:,<span class="number">1</span>].numpy(),c = <span class="string">"g"</span>)</span><br><span class="line">plt.legend([<span class="string">"positive"</span>,<span class="string">"negative"</span>]);</span><br></pre></td></tr></table></figure><p><img alt data-src="https://github.com/SimpCosm/eat_tensorflow2_in_30_days_ipynbs/raw/master/data/3-3-03-分类数据可视化.png"></p><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="title">ds_train</span> = tf.<span class="class"><span class="keyword">data</span>.<span class="type">Dataset</span>.from_tensor_slices((<span class="type">X</span>[0:<span class="title">n</span>*3//4,:],<span class="type">Y</span>[0:<span class="title">n</span>*3//4,:])) \</span></span><br><span class="line">     .shuffle(buffer_size = <span class="number">1000</span>).batch(<span class="number">20</span>) \</span><br><span class="line">     .prefetch(tf.<span class="class"><span class="keyword">data</span>.experimental.<span class="type">AUTOTUNE</span>) \</span></span><br><span class="line">     .cache()</span><br><span class="line"></span><br><span class="line"><span class="title">ds_valid</span> = tf.<span class="class"><span class="keyword">data</span>.<span class="type">Dataset</span>.from_tensor_slices((<span class="type">X</span>[<span class="title">n</span>*3//4:,:],<span class="type">Y</span>[<span class="title">n</span>*3//4:,:])) \</span></span><br><span class="line">     .batch(<span class="number">20</span>) \</span><br><span class="line">     .prefetch(tf.<span class="class"><span class="keyword">data</span>.experimental.<span class="type">AUTOTUNE</span>) \</span></span><br><span class="line">     .cache()</span><br></pre></td></tr></table></figure><h5 id="定义模型-9"><a href="#定义模型-9" class="headerlink" title="定义模型"></a>定义模型</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">tf.keras.backend.clear_session()</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DNNModel</span><span class="params">(models.Model)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(DNNModel, self).__init__()</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">build</span><span class="params">(self,input_shape)</span>:</span></span><br><span class="line">        self.dense1 = layers.Dense(<span class="number">4</span>,activation = <span class="string">"relu"</span>,name = <span class="string">"dense1"</span>) </span><br><span class="line">        self.dense2 = layers.Dense(<span class="number">8</span>,activation = <span class="string">"relu"</span>,name = <span class="string">"dense2"</span>)</span><br><span class="line">        self.dense3 = layers.Dense(<span class="number">1</span>,activation = <span class="string">"sigmoid"</span>,name = <span class="string">"dense3"</span>)</span><br><span class="line">        super(DNNModel,self).build(input_shape)</span><br><span class="line"> </span><br><span class="line">    <span class="comment"># 正向传播</span></span><br><span class="line"><span class="meta">    @tf.function(input_signature=[tf.TensorSpec(shape = [None,2], dtype = tf.float32)])  </span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span><span class="params">(self,x)</span>:</span></span><br><span class="line">        x = self.dense1(x)</span><br><span class="line">        x = self.dense2(x)</span><br><span class="line">        y = self.dense3(x)</span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line">model = DNNModel()</span><br><span class="line">model.build(input_shape =(<span class="literal">None</span>,<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">Model: "dnn_model"</span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">Layer (type)                 Output Shape              Param #   </span><br><span class="line">=================================================================</span><br><span class="line">dense1 (Dense)               multiple                  12        </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">dense2 (Dense)               multiple                  40        </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">dense3 (Dense)               multiple                  9         </span><br><span class="line">=================================================================</span><br><span class="line">Total params: 61</span><br><span class="line">Trainable params: 61</span><br><span class="line">Non-trainable params: 0</span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br></pre></td></tr></table></figure><h5 id="训练模型-9"><a href="#训练模型-9" class="headerlink" title="训练模型"></a>训练模型</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">### 自定义训练循环</span></span><br><span class="line"></span><br><span class="line">optimizer = optimizers.Adam(learning_rate=<span class="number">0.01</span>)</span><br><span class="line">loss_func = tf.keras.losses.BinaryCrossentropy()</span><br><span class="line"></span><br><span class="line">train_loss = tf.keras.metrics.Mean(name=<span class="string">'train_loss'</span>)</span><br><span class="line">train_metric = tf.keras.metrics.BinaryAccuracy(name=<span class="string">'train_accuracy'</span>)</span><br><span class="line"></span><br><span class="line">valid_loss = tf.keras.metrics.Mean(name=<span class="string">'valid_loss'</span>)</span><br><span class="line">valid_metric = tf.keras.metrics.BinaryAccuracy(name=<span class="string">'valid_accuracy'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@tf.function</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_step</span><span class="params">(model, features, labels)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">        predictions = model(features)</span><br><span class="line">        loss = loss_func(labels, predictions)</span><br><span class="line">    grads = tape.gradient(loss, model.trainable_variables)</span><br><span class="line">    optimizer.apply_gradients(zip(grads, model.trainable_variables))</span><br><span class="line"></span><br><span class="line">    train_loss.update_state(loss)</span><br><span class="line">    train_metric.update_state(labels, predictions)</span><br><span class="line"></span><br><span class="line"><span class="meta">@tf.function</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">valid_step</span><span class="params">(model, features, labels)</span>:</span></span><br><span class="line">    predictions = model(features)</span><br><span class="line">    batch_loss = loss_func(labels, predictions)</span><br><span class="line">    valid_loss.update_state(batch_loss)</span><br><span class="line">    valid_metric.update_state(labels, predictions)</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_model</span><span class="params">(model,ds_train,ds_valid,epochs)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> tf.range(<span class="number">1</span>,epochs+<span class="number">1</span>):</span><br><span class="line">        <span class="keyword">for</span> features, labels <span class="keyword">in</span> ds_train:</span><br><span class="line">            train_step(model,features,labels)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> features, labels <span class="keyword">in</span> ds_valid:</span><br><span class="line">            valid_step(model,features,labels)</span><br><span class="line"></span><br><span class="line">        logs = <span class="string">'Epoch=&#123;&#125;,Loss:&#123;&#125;,Accuracy:&#123;&#125;,Valid Loss:&#123;&#125;,Valid Accuracy:&#123;&#125;'</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span>  epoch%<span class="number">100</span> ==<span class="number">0</span>:</span><br><span class="line">            printbar()</span><br><span class="line">            tf.print(tf.strings.format(logs,</span><br><span class="line">            (epoch,train_loss.result(),train_metric.result(),valid_loss.result(),valid_metric.result())))</span><br><span class="line">        </span><br><span class="line">        train_loss.reset_states()</span><br><span class="line">        valid_loss.reset_states()</span><br><span class="line">        train_metric.reset_states()</span><br><span class="line">        valid_metric.reset_states()</span><br><span class="line"></span><br><span class="line">train_model(model,ds_train,ds_valid,<span class="number">1000</span>)</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">================================================================================<span class="number">17</span>:<span class="number">35</span>:<span class="number">02</span></span><br><span class="line">Epoch=<span class="number">100</span>,Loss:<span class="number">0.194088802</span>,Accuracy:<span class="number">0.923064</span>,Valid Loss:<span class="number">0.215538561</span>,Valid Accuracy:<span class="number">0.904368</span></span><br><span class="line">================================================================================<span class="number">17</span>:<span class="number">35</span>:<span class="number">22</span></span><br><span class="line">Epoch=<span class="number">200</span>,Loss:<span class="number">0.151239693</span>,Accuracy:<span class="number">0.93768847</span>,Valid Loss:<span class="number">0.181166962</span>,Valid Accuracy:<span class="number">0.920664132</span></span><br><span class="line">================================================================================<span class="number">17</span>:<span class="number">35</span>:<span class="number">43</span></span><br><span class="line">Epoch=<span class="number">300</span>,Loss:<span class="number">0.134556711</span>,Accuracy:<span class="number">0.944247484</span>,Valid Loss:<span class="number">0.171530813</span>,Valid Accuracy:<span class="number">0.926396072</span></span><br><span class="line">================================================================================<span class="number">17</span>:<span class="number">36</span>:<span class="number">04</span></span><br><span class="line">Epoch=<span class="number">400</span>,Loss:<span class="number">0.125722557</span>,Accuracy:<span class="number">0.949172914</span>,Valid Loss:<span class="number">0.16731061</span>,Valid Accuracy:<span class="number">0.929318547</span></span><br><span class="line">================================================================================<span class="number">17</span>:<span class="number">36</span>:<span class="number">24</span></span><br><span class="line">Epoch=<span class="number">500</span>,Loss:<span class="number">0.120216407</span>,Accuracy:<span class="number">0.952525079</span>,Valid Loss:<span class="number">0.164817035</span>,Valid Accuracy:<span class="number">0.931044817</span></span><br><span class="line">================================================================================<span class="number">17</span>:<span class="number">36</span>:<span class="number">44</span></span><br><span class="line">Epoch=<span class="number">600</span>,Loss:<span class="number">0.116434008</span>,Accuracy:<span class="number">0.954830289</span>,Valid Loss:<span class="number">0.163089141</span>,Valid Accuracy:<span class="number">0.932202339</span></span><br><span class="line">================================================================================<span class="number">17</span>:<span class="number">37</span>:<span class="number">05</span></span><br><span class="line">Epoch=<span class="number">700</span>,Loss:<span class="number">0.113658346</span>,Accuracy:<span class="number">0.956433</span>,Valid Loss:<span class="number">0.161804497</span>,Valid Accuracy:<span class="number">0.933092058</span></span><br><span class="line">================================================================================<span class="number">17</span>:<span class="number">37</span>:<span class="number">25</span></span><br><span class="line">Epoch=<span class="number">800</span>,Loss:<span class="number">0.111522928</span>,Accuracy:<span class="number">0.957467675</span>,Valid Loss:<span class="number">0.160796657</span>,Valid Accuracy:<span class="number">0.93379426</span></span><br><span class="line">================================================================================<span class="number">17</span>:<span class="number">37</span>:<span class="number">46</span></span><br><span class="line">Epoch=<span class="number">900</span>,Loss:<span class="number">0.109816991</span>,Accuracy:<span class="number">0.958205402</span>,Valid Loss:<span class="number">0.159987748</span>,Valid Accuracy:<span class="number">0.934343576</span></span><br><span class="line">================================================================================<span class="number">17</span>:<span class="number">38</span>:<span class="number">06</span></span><br><span class="line">Epoch=<span class="number">1000</span>,Loss:<span class="number">0.10841465</span>,Accuracy:<span class="number">0.958805501</span>,Valid Loss:<span class="number">0.159325734</span>,Valid Accuracy:<span class="number">0.934785843</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 结果可视化</span></span><br><span class="line">fig, (ax1,ax2) = plt.subplots(nrows=<span class="number">1</span>,ncols=<span class="number">2</span>,figsize = (<span class="number">12</span>,<span class="number">5</span>))</span><br><span class="line">ax1.scatter(Xp[:,<span class="number">0</span>].numpy(),Xp[:,<span class="number">1</span>].numpy(),c = <span class="string">"r"</span>)</span><br><span class="line">ax1.scatter(Xn[:,<span class="number">0</span>].numpy(),Xn[:,<span class="number">1</span>].numpy(),c = <span class="string">"g"</span>)</span><br><span class="line">ax1.legend([<span class="string">"positive"</span>,<span class="string">"negative"</span>]);</span><br><span class="line">ax1.set_title(<span class="string">"y_true"</span>);</span><br><span class="line"></span><br><span class="line">Xp_pred = tf.boolean_mask(X,tf.squeeze(model(X)&gt;=<span class="number">0.5</span>),axis = <span class="number">0</span>)</span><br><span class="line">Xn_pred = tf.boolean_mask(X,tf.squeeze(model(X)&lt;<span class="number">0.5</span>),axis = <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">ax2.scatter(Xp_pred[:,<span class="number">0</span>].numpy(),Xp_pred[:,<span class="number">1</span>].numpy(),c = <span class="string">"r"</span>)</span><br><span class="line">ax2.scatter(Xn_pred[:,<span class="number">0</span>].numpy(),Xn_pred[:,<span class="number">1</span>].numpy(),c = <span class="string">"g"</span>)</span><br><span class="line">ax2.legend([<span class="string">"positive"</span>,<span class="string">"negative"</span>]);</span><br><span class="line">ax2.set_title(<span class="string">"y_pred"</span>);</span><br></pre></td></tr></table></figure><p><img alt data-src="https://github.com/SimpCosm/eat_tensorflow2_in_30_days_ipynbs/raw/master/data/3-3-04-分类结果可视化.png"></p><h2 id="低阶API"><a href="#低阶API" class="headerlink" title="低阶API"></a>低阶API</h2><p>TensorFlow的低阶API主要包括张量操作，计算图和自动微分。如果把模型比作一个房子，那么低阶API就是【模型之砖】。在低阶API层次上，可以把TensorFlow当做一个增强版的numpy来使用。TensorFlow提供的方法比numpy更全面，运算速度更快，如果需要的话，还可以使用GPU进行加速。前面几章我们对低阶API已经有了一个整体的认识，本章我们将重点详细介绍张量操作和Autograph计算图。</p><h3 id="张量的结构操作"><a href="#张量的结构操作" class="headerlink" title="张量的结构操作"></a>张量的结构操作</h3><p>张量的操作主要包括：</p><ul><li>张量结构操作：张量创建，索引切片，维度变换，合并分割。</li><li>张量数学运算：标量运算，向量运算，矩阵运算。</li></ul><p>另外我们会介绍张量运算的广播机制。</p><h4 id="创建张量"><a href="#创建张量" class="headerlink" title="创建张量"></a>创建张量</h4><p>张量创建的许多方法和numpy中创建array的方法很像。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a = tf.constant([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],dtype = tf.float32)</span><br><span class="line">tf.print(a)</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="number">1</span> <span class="number">2</span> <span class="number">3</span>]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">b = tf.range(<span class="number">1</span>,<span class="number">10</span>,delta = <span class="number">2</span>)</span><br><span class="line">tf.print(b)</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="number">1</span> <span class="number">3</span> <span class="number">5</span> <span class="number">7</span> <span class="number">9</span>]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">c = tf.linspace(<span class="number">0.0</span>,<span class="number">2</span>*<span class="number">3.14</span>,<span class="number">100</span>)</span><br><span class="line">tf.print(c)</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="number">0</span> <span class="number">0.0634343475</span> <span class="number">0.126868695</span> ... <span class="number">6.15313148</span> <span class="number">6.21656609</span> <span class="number">6.28</span>]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">d = tf.zeros([<span class="number">3</span>,<span class="number">3</span>])</span><br><span class="line">tf.print(d)</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = tf.ones([<span class="number">3</span>,<span class="number">3</span>])</span><br><span class="line">b = tf.zeros_like(a,dtype= tf.float32)</span><br><span class="line">tf.print(a)</span><br><span class="line">tf.print(b)</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">1</span> <span class="number">1</span> <span class="number">1</span>]</span><br><span class="line"> [<span class="number">1</span> <span class="number">1</span> <span class="number">1</span>]</span><br><span class="line"> [<span class="number">1</span> <span class="number">1</span> <span class="number">1</span>]]</span><br><span class="line">[[<span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">b = tf.fill([<span class="number">3</span>,<span class="number">2</span>],<span class="number">5</span>)</span><br><span class="line">tf.print(b)</span><br></pre></td></tr></table></figure><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">5</span> <span class="number">5</span>]</span><br><span class="line"> [<span class="number">5</span> <span class="number">5</span>]</span><br><span class="line"> [<span class="number">5</span> <span class="number">5</span>]]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#均匀分布随机</span></span><br><span class="line">tf.random.set_seed(<span class="number">1.0</span>)</span><br><span class="line">a = tf.random.uniform([<span class="number">5</span>],minval=<span class="number">0</span>,maxval=<span class="number">10</span>)</span><br><span class="line">tf.print(a)</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="number">1.65130854</span> <span class="number">9.01481247</span> <span class="number">6.30974197</span> <span class="number">4.34546089</span> <span class="number">2.9193902</span>]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#正态分布随机</span></span><br><span class="line">b = tf.random.normal([<span class="number">3</span>,<span class="number">3</span>],mean=<span class="number">0.0</span>,stddev=<span class="number">1.0</span>)</span><br><span class="line">tf.print(b)</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">0.403087884</span> <span class="number">-1.0880208</span> <span class="number">-0.0630953535</span>]</span><br><span class="line"> [<span class="number">1.33655667</span> <span class="number">0.711760104</span> <span class="number">-0.489286453</span>]</span><br><span class="line"> [<span class="number">-0.764221311</span> <span class="number">-1.03724861</span> <span class="number">-1.25193381</span>]]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#正态分布随机，剔除2倍方差以外数据重新生成</span></span><br><span class="line">c = tf.random.truncated_normal((<span class="number">5</span>,<span class="number">5</span>), mean=<span class="number">0.0</span>, stddev=<span class="number">1.0</span>, dtype=tf.float32)</span><br><span class="line">tf.print(c)</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">-0.457012236</span> <span class="number">-0.406867266</span> <span class="number">0.728577733</span> <span class="number">-0.892977774</span> <span class="number">-0.369404584</span>]</span><br><span class="line"> [<span class="number">0.323488563</span> <span class="number">1.19383323</span> <span class="number">0.888299048</span> <span class="number">1.25985599</span> <span class="number">-1.95951891</span>]</span><br><span class="line"> [<span class="number">-0.202244401</span> <span class="number">0.294496894</span> <span class="number">-0.468728036</span> <span class="number">1.29494202</span> <span class="number">1.48142183</span>]</span><br><span class="line"> [<span class="number">0.0810953453</span> <span class="number">1.63843894</span> <span class="number">0.556645</span> <span class="number">0.977199793</span> <span class="number">-1.17777884</span>]</span><br><span class="line"> [<span class="number">1.67368948</span> <span class="number">0.0647980496</span> <span class="number">-0.705142677</span> <span class="number">-0.281972528</span> <span class="number">0.126546144</span>]]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 特殊矩阵</span></span><br><span class="line">I = tf.eye(<span class="number">3</span>,<span class="number">3</span>) <span class="comment">#单位矩阵</span></span><br><span class="line">tf.print(I)</span><br><span class="line">tf.print(<span class="string">" "</span>)</span><br><span class="line">t = tf.linalg.diag([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]) <span class="comment">#对角阵</span></span><br><span class="line">tf.print(t)</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">1</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">1</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">1</span>]]</span><br><span class="line"> </span><br><span class="line">[[<span class="number">1</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">2</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">3</span>]]</span><br></pre></td></tr></table></figure><h4 id="索引切片"><a href="#索引切片" class="headerlink" title="索引切片"></a>索引切片</h4><p>张量的索引切片方式和numpy几乎是一样的。切片时支持缺省参数和省略号。</p><p>对于tf.Variable,可以通过索引和切片对部分元素进行修改。</p><p>对于提取张量的连续子区域，也可以使用tf.slice.</p><p>此外，对于不规则的切片提取,可以使用tf.gather,tf.gather_nd,tf.boolean_mask。</p><p>tf.boolean_mask功能最为强大，它可以实现tf.gather,tf.gather_nd的功能，并且tf.boolean_mask还可以实现布尔索引。</p><p>如果要通过修改张量的某些元素得到新的张量，可以使用tf.where，tf.scatter_nd。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tf.random.set_seed(<span class="number">3</span>)</span><br><span class="line">t = tf.random.uniform([<span class="number">5</span>,<span class="number">5</span>],minval=<span class="number">0</span>,maxval=<span class="number">10</span>,dtype=tf.int32)</span><br><span class="line">tf.print(t)</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">4</span> <span class="number">7</span> <span class="number">4</span> <span class="number">2</span> <span class="number">9</span>]</span><br><span class="line"> [<span class="number">9</span> <span class="number">1</span> <span class="number">2</span> <span class="number">4</span> <span class="number">7</span>]</span><br><span class="line"> [<span class="number">7</span> <span class="number">2</span> <span class="number">7</span> <span class="number">4</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">9</span> <span class="number">6</span> <span class="number">9</span> <span class="number">7</span> <span class="number">2</span>]</span><br><span class="line"> [<span class="number">3</span> <span class="number">7</span> <span class="number">0</span> <span class="number">0</span> <span class="number">3</span>]]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#第0行</span></span><br><span class="line">tf.print(t[<span class="number">0</span>])</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="number">4</span> <span class="number">7</span> <span class="number">4</span> <span class="number">2</span> <span class="number">9</span>]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#倒数第一行</span></span><br><span class="line">tf.print(t[<span class="number">-1</span>])</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="number">3</span> <span class="number">7</span> <span class="number">0</span> <span class="number">0</span> <span class="number">3</span>]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#第1行第3列</span></span><br><span class="line">tf.print(t[<span class="number">1</span>,<span class="number">3</span>])</span><br><span class="line">tf.print(t[<span class="number">1</span>][<span class="number">3</span>])</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">4</span></span><br><span class="line"><span class="number">4</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#第1行至第3行</span></span><br><span class="line">tf.print(t[<span class="number">1</span>:<span class="number">4</span>,:])</span><br><span class="line">tf.print(tf.slice(t,[<span class="number">1</span>,<span class="number">0</span>],[<span class="number">3</span>,<span class="number">5</span>])) <span class="comment">#tf.slice(input,begin_vector,size_vector)</span></span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">9</span> <span class="number">1</span> <span class="number">2</span> <span class="number">4</span> <span class="number">7</span>]</span><br><span class="line"> [<span class="number">7</span> <span class="number">2</span> <span class="number">7</span> <span class="number">4</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">9</span> <span class="number">6</span> <span class="number">9</span> <span class="number">7</span> <span class="number">2</span>]]</span><br><span class="line">[[<span class="number">9</span> <span class="number">1</span> <span class="number">2</span> <span class="number">4</span> <span class="number">7</span>]</span><br><span class="line"> [<span class="number">7</span> <span class="number">2</span> <span class="number">7</span> <span class="number">4</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">9</span> <span class="number">6</span> <span class="number">9</span> <span class="number">7</span> <span class="number">2</span>]]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#第1行至最后一行，第0列到最后一列每隔两列取一列</span></span><br><span class="line">tf.print(t[<span class="number">1</span>:<span class="number">4</span>,:<span class="number">4</span>:<span class="number">2</span>])</span><br></pre></td></tr></table></figure><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">9</span> <span class="number">2</span>]</span><br><span class="line"> [<span class="number">7</span> <span class="number">7</span>]</span><br><span class="line"> [<span class="number">9</span> <span class="number">9</span>]]</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#对变量来说，还可以使用索引和切片修改部分元素</span><br><span class="line">x = tf.Variable([[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4</span>]],dtype = tf.<span class="built_in">float</span>32)</span><br><span class="line">x[<span class="number">1</span>,:].assign(tf.constant([<span class="number">0.0</span>,<span class="number">0.0</span>]))</span><br><span class="line">tf.print(x)</span><br></pre></td></tr></table></figure><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">1</span> <span class="number">2</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span>]]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a = tf.random.uniform([<span class="number">3</span>,<span class="number">3</span>,<span class="number">3</span>],minval=<span class="number">0</span>,maxval=<span class="number">10</span>,dtype=tf.int32)</span><br><span class="line">tf.print(a)</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[[[<span class="number">7</span> <span class="number">3</span> <span class="number">9</span>]</span><br><span class="line">  [<span class="number">9</span> <span class="number">0</span> <span class="number">7</span>]</span><br><span class="line">  [<span class="number">9</span> <span class="number">6</span> <span class="number">7</span>]]</span><br><span class="line"></span><br><span class="line"> [[<span class="number">1</span> <span class="number">3</span> <span class="number">3</span>]</span><br><span class="line">  [<span class="number">0</span> <span class="number">8</span> <span class="number">1</span>]</span><br><span class="line">  [<span class="number">3</span> <span class="number">1</span> <span class="number">0</span>]]</span><br><span class="line"></span><br><span class="line"> [[<span class="number">4</span> <span class="number">0</span> <span class="number">6</span>]</span><br><span class="line">  [<span class="number">6</span> <span class="number">2</span> <span class="number">2</span>]</span><br><span class="line">  [<span class="number">7</span> <span class="number">9</span> <span class="number">5</span>]]]</span><br></pre></td></tr></table></figure><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#省略号可以表示多个冒号</span></span><br><span class="line">tf.<span class="builtin-name">print</span>(a[<span class="built_in">..</span>.,1])</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">3</span> <span class="number">0</span> <span class="number">6</span>]</span><br><span class="line"> [<span class="number">3</span> <span class="number">8</span> <span class="number">1</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">2</span> <span class="number">9</span>]]</span><br></pre></td></tr></table></figure><p>以上切片方式相对规则，对于不规则的切片提取,可以使用tf.gather,tf.gather_nd,tf.boolean_mask。</p><p>考虑班级成绩册的例子，有4个班级，每个班级10个学生，每个学生7门科目成绩。可以用一个4×10×7的张量来表示。</p><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scores = tf.random.uniform((<span class="number">4</span>,<span class="number">10</span>,<span class="number">7</span>),minval=<span class="number">0</span>,maxval=<span class="number">100</span>,dtype=tf.<span class="built_in">int</span>32)</span><br><span class="line">tf.print(scores)</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">[[[<span class="number">52</span> <span class="number">82</span> <span class="number">66</span> ... <span class="number">17</span> <span class="number">86</span> <span class="number">14</span>]</span><br><span class="line">  [<span class="number">8</span> <span class="number">36</span> <span class="number">94</span> ... <span class="number">13</span> <span class="number">78</span> <span class="number">41</span>]</span><br><span class="line">  [<span class="number">77</span> <span class="number">53</span> <span class="number">51</span> ... <span class="number">22</span> <span class="number">91</span> <span class="number">56</span>]</span><br><span class="line">  ...</span><br><span class="line">  [<span class="number">11</span> <span class="number">19</span> <span class="number">26</span> ... <span class="number">89</span> <span class="number">86</span> <span class="number">68</span>]</span><br><span class="line">  [<span class="number">60</span> <span class="number">72</span> <span class="number">0</span> ... <span class="number">11</span> <span class="number">26</span> <span class="number">15</span>]</span><br><span class="line">  [<span class="number">24</span> <span class="number">99</span> <span class="number">38</span> ... <span class="number">97</span> <span class="number">44</span> <span class="number">74</span>]]</span><br><span class="line"></span><br><span class="line"> [[<span class="number">79</span> <span class="number">73</span> <span class="number">73</span> ... <span class="number">35</span> <span class="number">3</span> <span class="number">81</span>]</span><br><span class="line">  [<span class="number">83</span> <span class="number">36</span> <span class="number">31</span> ... <span class="number">75</span> <span class="number">38</span> <span class="number">85</span>]</span><br><span class="line">  [<span class="number">54</span> <span class="number">26</span> <span class="number">67</span> ... <span class="number">60</span> <span class="number">68</span> <span class="number">98</span>]</span><br><span class="line">  ...</span><br><span class="line">  [<span class="number">20</span> <span class="number">5</span> <span class="number">18</span> ... <span class="number">32</span> <span class="number">45</span> <span class="number">3</span>]</span><br><span class="line">  [<span class="number">72</span> <span class="number">52</span> <span class="number">81</span> ... <span class="number">88</span> <span class="number">41</span> <span class="number">20</span>]</span><br><span class="line">  [<span class="number">0</span> <span class="number">21</span> <span class="number">89</span> ... <span class="number">53</span> <span class="number">10</span> <span class="number">90</span>]]</span><br><span class="line"></span><br><span class="line"> [[<span class="number">52</span> <span class="number">80</span> <span class="number">22</span> ... <span class="number">29</span> <span class="number">25</span> <span class="number">60</span>]</span><br><span class="line">  [<span class="number">78</span> <span class="number">71</span> <span class="number">54</span> ... <span class="number">43</span> <span class="number">98</span> <span class="number">81</span>]</span><br><span class="line">  [<span class="number">21</span> <span class="number">66</span> <span class="number">53</span> ... <span class="number">97</span> <span class="number">75</span> <span class="number">77</span>]</span><br><span class="line">  ...</span><br><span class="line">  [<span class="number">6</span> <span class="number">74</span> <span class="number">3</span> ... <span class="number">53</span> <span class="number">65</span> <span class="number">43</span>]</span><br><span class="line">  [<span class="number">98</span> <span class="number">36</span> <span class="number">72</span> ... <span class="number">33</span> <span class="number">36</span> <span class="number">81</span>]</span><br><span class="line">  [<span class="number">61</span> <span class="number">78</span> <span class="number">70</span> ... <span class="number">7</span> <span class="number">59</span> <span class="number">21</span>]]</span><br><span class="line"></span><br><span class="line"> [[<span class="number">56</span> <span class="number">57</span> <span class="number">45</span> ... <span class="number">23</span> <span class="number">15</span> <span class="number">3</span>]</span><br><span class="line">  [<span class="number">35</span> <span class="number">8</span> <span class="number">82</span> ... <span class="number">11</span> <span class="number">59</span> <span class="number">97</span>]</span><br><span class="line">  [<span class="number">44</span> <span class="number">6</span> <span class="number">99</span> ... <span class="number">81</span> <span class="number">60</span> <span class="number">27</span>]</span><br><span class="line">  ...</span><br><span class="line">  [<span class="number">76</span> <span class="number">26</span> <span class="number">35</span> ... <span class="number">51</span> <span class="number">8</span> <span class="number">17</span>]</span><br><span class="line">  [<span class="number">33</span> <span class="number">52</span> <span class="number">53</span> ... <span class="number">78</span> <span class="number">37</span> <span class="number">31</span>]</span><br><span class="line">  [<span class="number">71</span> <span class="number">27</span> <span class="number">44</span> ... <span class="number">0</span> <span class="number">52</span> <span class="number">16</span>]]]</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#抽取每个班级第<span class="number">0</span>个学生，第<span class="number">5</span>个学生，第<span class="number">9</span>个学生的全部成绩</span><br><span class="line">p = tf.gather(scores,[<span class="number">0</span>,<span class="number">5</span>,<span class="number">9</span>],axis=<span class="number">1</span>)</span><br><span class="line">tf.print(p)</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[[[<span class="number">52</span> <span class="number">82</span> <span class="number">66</span> ... <span class="number">17</span> <span class="number">86</span> <span class="number">14</span>]</span><br><span class="line">  [<span class="number">24</span> <span class="number">80</span> <span class="number">70</span> ... <span class="number">72</span> <span class="number">63</span> <span class="number">96</span>]</span><br><span class="line">  [<span class="number">24</span> <span class="number">99</span> <span class="number">38</span> ... <span class="number">97</span> <span class="number">44</span> <span class="number">74</span>]]</span><br><span class="line"></span><br><span class="line"> [[<span class="number">79</span> <span class="number">73</span> <span class="number">73</span> ... <span class="number">35</span> <span class="number">3</span> <span class="number">81</span>]</span><br><span class="line">  [<span class="number">46</span> <span class="number">10</span> <span class="number">94</span> ... <span class="number">23</span> <span class="number">18</span> <span class="number">92</span>]</span><br><span class="line">  [<span class="number">0</span> <span class="number">21</span> <span class="number">89</span> ... <span class="number">53</span> <span class="number">10</span> <span class="number">90</span>]]</span><br><span class="line"></span><br><span class="line"> [[<span class="number">52</span> <span class="number">80</span> <span class="number">22</span> ... <span class="number">29</span> <span class="number">25</span> <span class="number">60</span>]</span><br><span class="line">  [<span class="number">19</span> <span class="number">12</span> <span class="number">23</span> ... <span class="number">87</span> <span class="number">86</span> <span class="number">25</span>]</span><br><span class="line">  [<span class="number">61</span> <span class="number">78</span> <span class="number">70</span> ... <span class="number">7</span> <span class="number">59</span> <span class="number">21</span>]]</span><br><span class="line"></span><br><span class="line"> [[<span class="number">56</span> <span class="number">57</span> <span class="number">45</span> ... <span class="number">23</span> <span class="number">15</span> <span class="number">3</span>]</span><br><span class="line">  [<span class="number">6</span> <span class="number">41</span> <span class="number">79</span> ... <span class="number">97</span> <span class="number">43</span> <span class="number">13</span>]</span><br><span class="line">  [<span class="number">71</span> <span class="number">27</span> <span class="number">44</span> ... <span class="number">0</span> <span class="number">52</span> <span class="number">16</span>]]]</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#抽取每个班级第<span class="number">0</span>个学生，第<span class="number">5</span>个学生，第<span class="number">9</span>个学生的第<span class="number">1</span>门课程，第<span class="number">3</span>门课程，第<span class="number">6</span>门课程成绩</span><br><span class="line">q = tf.gather(tf.gather(scores,[<span class="number">0</span>,<span class="number">5</span>,<span class="number">9</span>],axis=<span class="number">1</span>),[<span class="number">1</span>,<span class="number">3</span>,<span class="number">6</span>],axis=<span class="number">2</span>)</span><br><span class="line">tf.print(q)</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[[[<span class="number">82</span> <span class="number">55</span> <span class="number">14</span>]</span><br><span class="line">  [<span class="number">80</span> <span class="number">46</span> <span class="number">96</span>]</span><br><span class="line">  [<span class="number">99</span> <span class="number">58</span> <span class="number">74</span>]]</span><br><span class="line"></span><br><span class="line"> [[<span class="number">73</span> <span class="number">48</span> <span class="number">81</span>]</span><br><span class="line">  [<span class="number">10</span> <span class="number">38</span> <span class="number">92</span>]</span><br><span class="line">  [<span class="number">21</span> <span class="number">86</span> <span class="number">90</span>]]</span><br><span class="line"></span><br><span class="line"> [[<span class="number">80</span> <span class="number">57</span> <span class="number">60</span>]</span><br><span class="line">  [<span class="number">12</span> <span class="number">34</span> <span class="number">25</span>]</span><br><span class="line">  [<span class="number">78</span> <span class="number">71</span> <span class="number">21</span>]]</span><br><span class="line"></span><br><span class="line"> [[<span class="number">57</span> <span class="number">75</span> <span class="number">3</span>]</span><br><span class="line">  [<span class="number">41</span> <span class="number">47</span> <span class="number">13</span>]</span><br><span class="line">  [<span class="number">27</span> <span class="number">96</span> <span class="number">16</span>]]]</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 抽取第<span class="number">0</span>个班级第<span class="number">0</span>个学生，第<span class="number">2</span>个班级的第<span class="number">4</span>个学生，第<span class="number">3</span>个班级的第<span class="number">6</span>个学生的全部成绩</span><br><span class="line">#indices的长度为采样样本的个数，每个元素为采样位置的坐标</span><br><span class="line">s = tf.gather_nd(scores,indices = [(<span class="number">0</span>,<span class="number">0</span>),(<span class="number">2</span>,<span class="number">4</span>),(<span class="number">3</span>,<span class="number">6</span>)])</span><br><span class="line">s</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;tf.Tensor: shape=(<span class="number">3</span>, <span class="number">7</span>), dtype=<span class="built_in">int</span>32, numpy=</span><br><span class="line"><span class="built_in">array</span>([[<span class="number">52</span>, <span class="number">82</span>, <span class="number">66</span>, <span class="number">55</span>, <span class="number">17</span>, <span class="number">86</span>, <span class="number">14</span>],</span><br><span class="line">       [<span class="number">99</span>, <span class="number">94</span>, <span class="number">46</span>, <span class="number">70</span>,  <span class="number">1</span>, <span class="number">63</span>, <span class="number">41</span>],</span><br><span class="line">       [<span class="number">46</span>, <span class="number">83</span>, <span class="number">70</span>, <span class="number">80</span>, <span class="number">90</span>, <span class="number">85</span>, <span class="number">17</span>]], dtype=<span class="built_in">int</span>32)&gt;</span><br></pre></td></tr></table></figure><p>以上tf.gather和tf.gather_nd的功能也可以用tf.boolean_mask来实现。</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#抽取每个班级第0个学生，第5个学生，第9个学生的全部成绩</span></span><br><span class="line">p = tf.boolean_mask(scores,[<span class="literal">True</span>,<span class="literal">False</span>,<span class="literal">False</span>,<span class="literal">False</span>,<span class="literal">False</span>,</span><br><span class="line">                            <span class="literal">True</span>,<span class="literal">False</span>,<span class="literal">False</span>,<span class="literal">False</span>,<span class="literal">True</span>],<span class="attribute">axis</span>=1)</span><br><span class="line">tf.<span class="builtin-name">print</span>(p)</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[[[<span class="number">52</span> <span class="number">82</span> <span class="number">66</span> ... <span class="number">17</span> <span class="number">86</span> <span class="number">14</span>]</span><br><span class="line">  [<span class="number">24</span> <span class="number">80</span> <span class="number">70</span> ... <span class="number">72</span> <span class="number">63</span> <span class="number">96</span>]</span><br><span class="line">  [<span class="number">24</span> <span class="number">99</span> <span class="number">38</span> ... <span class="number">97</span> <span class="number">44</span> <span class="number">74</span>]]</span><br><span class="line"></span><br><span class="line"> [[<span class="number">79</span> <span class="number">73</span> <span class="number">73</span> ... <span class="number">35</span> <span class="number">3</span> <span class="number">81</span>]</span><br><span class="line">  [<span class="number">46</span> <span class="number">10</span> <span class="number">94</span> ... <span class="number">23</span> <span class="number">18</span> <span class="number">92</span>]</span><br><span class="line">  [<span class="number">0</span> <span class="number">21</span> <span class="number">89</span> ... <span class="number">53</span> <span class="number">10</span> <span class="number">90</span>]]</span><br><span class="line"></span><br><span class="line"> [[<span class="number">52</span> <span class="number">80</span> <span class="number">22</span> ... <span class="number">29</span> <span class="number">25</span> <span class="number">60</span>]</span><br><span class="line">  [<span class="number">19</span> <span class="number">12</span> <span class="number">23</span> ... <span class="number">87</span> <span class="number">86</span> <span class="number">25</span>]</span><br><span class="line">  [<span class="number">61</span> <span class="number">78</span> <span class="number">70</span> ... <span class="number">7</span> <span class="number">59</span> <span class="number">21</span>]]</span><br><span class="line"></span><br><span class="line"> [[<span class="number">56</span> <span class="number">57</span> <span class="number">45</span> ... <span class="number">23</span> <span class="number">15</span> <span class="number">3</span>]</span><br><span class="line">  [<span class="number">6</span> <span class="number">41</span> <span class="number">79</span> ... <span class="number">97</span> <span class="number">43</span> <span class="number">13</span>]</span><br><span class="line">  [<span class="number">71</span> <span class="number">27</span> <span class="number">44</span> ... <span class="number">0</span> <span class="number">52</span> <span class="number">16</span>]]]</span><br></pre></td></tr></table></figure><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#抽取第0个班级第0个学生，第2个班级的第4个学生，第3个班级的第6个学生的全部成绩</span></span><br><span class="line">s = tf.boolean_mask(scores,</span><br><span class="line">    [[<span class="literal">True</span>,<span class="literal">False</span>,<span class="literal">False</span>,<span class="literal">False</span>,<span class="literal">False</span>,<span class="literal">False</span>,<span class="literal">False</span>,<span class="literal">False</span>,<span class="literal">False</span>,<span class="literal">False</span>],</span><br><span class="line">     [<span class="literal">False</span>,<span class="literal">False</span>,<span class="literal">False</span>,<span class="literal">False</span>,<span class="literal">False</span>,<span class="literal">False</span>,<span class="literal">False</span>,<span class="literal">False</span>,<span class="literal">False</span>,<span class="literal">False</span>],</span><br><span class="line">     [<span class="literal">False</span>,<span class="literal">False</span>,<span class="literal">False</span>,<span class="literal">False</span>,<span class="literal">True</span>,<span class="literal">False</span>,<span class="literal">False</span>,<span class="literal">False</span>,<span class="literal">False</span>,<span class="literal">False</span>],</span><br><span class="line">     [<span class="literal">False</span>,<span class="literal">False</span>,<span class="literal">False</span>,<span class="literal">False</span>,<span class="literal">False</span>,<span class="literal">False</span>,<span class="literal">True</span>,<span class="literal">False</span>,<span class="literal">False</span>,<span class="literal">False</span>]])</span><br><span class="line">tf.<span class="builtin-name">print</span>(s)</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">52</span> <span class="number">82</span> <span class="number">66</span> ... <span class="number">17</span> <span class="number">86</span> <span class="number">14</span>]</span><br><span class="line"> [<span class="number">99</span> <span class="number">94</span> <span class="number">46</span> ... <span class="number">1</span> <span class="number">63</span> <span class="number">41</span>]</span><br><span class="line"> [<span class="number">46</span> <span class="number">83</span> <span class="number">70</span> ... <span class="number">90</span> <span class="number">85</span> <span class="number">17</span>]]</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#利用tf.<span class="built_in">bool</span>ean_mask可以实现布尔索引</span><br><span class="line"></span><br><span class="line">#找到矩阵中小于<span class="number">0</span>的元素</span><br><span class="line">c = tf.constant([[<span class="number">-1</span>,<span class="number">1</span>,<span class="number">-1</span>],[<span class="number">2</span>,<span class="number">2</span>,<span class="number">-2</span>],[<span class="number">3</span>,<span class="number">-3</span>,<span class="number">3</span>]],dtype=tf.<span class="built_in">float</span>32)</span><br><span class="line">tf.print(c,<span class="string">"\n"</span>)</span><br><span class="line"></span><br><span class="line">tf.print(tf.<span class="built_in">bool</span>ean_mask(c,c&lt;<span class="number">0</span>),<span class="string">"\n"</span>) </span><br><span class="line">tf.print(c[c&lt;<span class="number">0</span>]) #布尔索引，为<span class="built_in">bool</span>ean_mask的语法糖形式</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">-1</span> <span class="number">1</span> <span class="number">-1</span>]</span><br><span class="line"> [<span class="number">2</span> <span class="number">2</span> <span class="number">-2</span>]</span><br><span class="line"> [<span class="number">3</span> <span class="number">-3</span> <span class="number">3</span>]] </span><br><span class="line"></span><br><span class="line">[<span class="number">-1</span> <span class="number">-1</span> <span class="number">-2</span> <span class="number">-3</span>] </span><br><span class="line"></span><br><span class="line">[<span class="number">-1</span> <span class="number">-1</span> <span class="number">-2</span> <span class="number">-3</span>]</span><br></pre></td></tr></table></figure><p>以上这些方法仅能提取张量的部分元素值，但不能更改张量的部分元素值得到新的张量。</p><p>如果要通过修改张量的部分元素值得到新的张量，可以使用tf.where和tf.scatter_nd。</p><p>tf.where可以理解为if的张量版本，此外它还可以用于找到满足条件的所有元素的位置坐标。</p><p>tf.scatter_nd的作用和tf.gather_nd有些相反，tf.gather_nd用于收集张量的给定位置的元素，</p><p>而tf.scatter_nd可以将某些值插入到一个给定shape的全0的张量的指定位置处。</p><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#找到张量中小于<span class="number">0</span>的元素,将其换成np.nan得到新的张量</span><br><span class="line">#tf.where和np.where作用类似，可以理解为<span class="keyword">if</span>的张量版本</span><br><span class="line"></span><br><span class="line">c = tf.constant([[<span class="number">-1</span>,<span class="number">1</span>,<span class="number">-1</span>],[<span class="number">2</span>,<span class="number">2</span>,<span class="number">-2</span>],[<span class="number">3</span>,<span class="number">-3</span>,<span class="number">3</span>]],dtype=tf.<span class="built_in">float</span>32)</span><br><span class="line">d = tf.where(c&lt;<span class="number">0</span>,tf.fill(c.shape,np.nan),c) </span><br><span class="line">d</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;tf.Tensor: shape=(<span class="number">3</span>, <span class="number">3</span>), dtype=<span class="built_in">float</span>32, numpy=</span><br><span class="line"><span class="built_in">array</span>([[nan,  <span class="number">1.</span>, nan],</span><br><span class="line">       [ <span class="number">2.</span>,  <span class="number">2.</span>, nan],</span><br><span class="line">       [ <span class="number">3.</span>, nan,  <span class="number">3.</span>]], dtype=<span class="built_in">float</span>32)&gt;</span><br></pre></td></tr></table></figure><figure class="highlight swift"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#如果<span class="keyword">where</span>只有一个参数，将返回所有满足条件的位置坐标</span><br><span class="line"><span class="built_in">indices</span> = tf.<span class="keyword">where</span>(<span class="built_in">c</span>&lt;<span class="number">0</span>)</span><br><span class="line"><span class="built_in">indices</span></span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;tf.Tensor: shape=(<span class="number">4</span>, <span class="number">2</span>), dtype=<span class="built_in">int</span>64, numpy=</span><br><span class="line"><span class="built_in">array</span>([[<span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">       [<span class="number">0</span>, <span class="number">2</span>],</span><br><span class="line">       [<span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">       [<span class="number">2</span>, <span class="number">1</span>]])&gt;</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#将张量的第[<span class="number">0</span>,<span class="number">0</span>]和[<span class="number">2</span>,<span class="number">1</span>]两个位置元素替换为<span class="number">0</span>得到新的张量</span><br><span class="line">d = c - tf.scatter_nd([[<span class="number">0</span>,<span class="number">0</span>],[<span class="number">2</span>,<span class="number">1</span>]],[c[<span class="number">0</span>,<span class="number">0</span>],c[<span class="number">2</span>,<span class="number">1</span>]],c.shape)</span><br><span class="line">d</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;tf.Tensor: shape=(<span class="number">3</span>, <span class="number">3</span>), dtype=<span class="built_in">float</span>32, numpy=</span><br><span class="line"><span class="built_in">array</span>([[ <span class="number">0.</span>,  <span class="number">1.</span>, <span class="number">-1.</span>],</span><br><span class="line">       [ <span class="number">2.</span>,  <span class="number">2.</span>, <span class="number">-2.</span>],</span><br><span class="line">       [ <span class="number">3.</span>,  <span class="number">0.</span>,  <span class="number">3.</span>]], dtype=<span class="built_in">float</span>32)&gt;</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#scatter_nd的作用和gather_nd有些相反</span><br><span class="line">#可以将某些值插入到一个给定shape的全<span class="number">0</span>的张量的指定位置处。</span><br><span class="line">indices = tf.where(c&lt;<span class="number">0</span>)</span><br><span class="line">tf.scatter_nd(indices,tf.gather_nd(c,indices),c.shape)</span><br><span class="line">&lt;tf.Tensor: shape=(<span class="number">3</span>, <span class="number">3</span>), dtype=<span class="built_in">float</span>32, numpy=</span><br><span class="line"><span class="built_in">array</span>([[<span class="number">-1.</span>,  <span class="number">0.</span>, <span class="number">-1.</span>],</span><br><span class="line">       [ <span class="number">0.</span>,  <span class="number">0.</span>, <span class="number">-2.</span>],</span><br><span class="line">       [ <span class="number">0.</span>, <span class="number">-3.</span>,  <span class="number">0.</span>]], dtype=<span class="built_in">float</span>32)&gt;</span><br></pre></td></tr></table></figure><h4 id="维度变换"><a href="#维度变换" class="headerlink" title="维度变换"></a>维度变换</h4><p>维度变换相关函数主要有 tf.reshape, tf.squeeze, tf.expand_dims, tf.transpose.</p><p>tf.reshape 可以改变张量的形状。</p><p>tf.squeeze 可以减少维度。</p><p>tf.expand_dims 可以增加维度。</p><p>tf.transpose 可以交换维度。</p><p>tf.reshape可以改变张量的形状，但是其本质上不会改变张量元素的存储顺序，所以，该操作实际上非常迅速，并且是可逆的。</p><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = tf.random.uniform(shape=[<span class="number">1</span>,<span class="number">3</span>,<span class="number">3</span>,<span class="number">2</span>],</span><br><span class="line">                      minval=<span class="number">0</span>,maxval=<span class="number">255</span>,dtype=tf.<span class="built_in">int</span>32)</span><br><span class="line">tf.print(a.shape)</span><br><span class="line">tf.print(a)</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">TensorShape([<span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">2</span>])</span><br><span class="line">[[[[<span class="number">135</span> <span class="number">178</span>]</span><br><span class="line">   [<span class="number">26</span> <span class="number">116</span>]</span><br><span class="line">   [<span class="number">29</span> <span class="number">224</span>]]</span><br><span class="line"></span><br><span class="line">  [[<span class="number">179</span> <span class="number">219</span>]</span><br><span class="line">   [<span class="number">153</span> <span class="number">209</span>]</span><br><span class="line">   [<span class="number">111</span> <span class="number">215</span>]]</span><br><span class="line"></span><br><span class="line">  [[<span class="number">39</span> <span class="number">7</span>]</span><br><span class="line">   [<span class="number">138</span> <span class="number">129</span>]</span><br><span class="line">   [<span class="number">59</span> <span class="number">205</span>]]]]</span><br></pre></td></tr></table></figure><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 改成 （3,6）形状的张量</span></span><br><span class="line">b = tf.reshape(a,[3,6])</span><br><span class="line">tf.<span class="builtin-name">print</span>(b.shape)</span><br><span class="line">tf.<span class="builtin-name">print</span>(b)</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">TensorShape([<span class="number">3</span>, <span class="number">6</span>])</span><br><span class="line">[[<span class="number">135</span> <span class="number">178</span> <span class="number">26</span> <span class="number">116</span> <span class="number">29</span> <span class="number">224</span>]</span><br><span class="line"> [<span class="number">179</span> <span class="number">219</span> <span class="number">153</span> <span class="number">209</span> <span class="number">111</span> <span class="number">215</span>]</span><br><span class="line"> [<span class="number">39</span> <span class="number">7</span> <span class="number">138</span> <span class="number">129</span> <span class="number">59</span> <span class="number">205</span>]]</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 改回成 [<span class="number">1</span>,<span class="number">3</span>,<span class="number">3</span>,<span class="number">2</span>] 形状的张量</span><br><span class="line">c = tf.reshape(b,[<span class="number">1</span>,<span class="number">3</span>,<span class="number">3</span>,<span class="number">2</span>])</span><br><span class="line">tf.print(c)</span><br></pre></td></tr></table></figure><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[[[[<span class="number">135</span> <span class="number">178</span>]</span><br><span class="line">   [<span class="number">26</span> <span class="number">116</span>]</span><br><span class="line">   [<span class="number">29</span> <span class="number">224</span>]]</span><br><span class="line"></span><br><span class="line">  [[<span class="number">179</span> <span class="number">219</span>]</span><br><span class="line">   [<span class="number">153</span> <span class="number">209</span>]</span><br><span class="line">   [<span class="number">111</span> <span class="number">215</span>]]</span><br><span class="line"></span><br><span class="line">  [[<span class="number">39</span> <span class="number">7</span>]</span><br><span class="line">   [<span class="number">138</span> <span class="number">129</span>]</span><br><span class="line">   [<span class="number">59</span> <span class="number">205</span>]]]]</span><br></pre></td></tr></table></figure><p>如果张量在某个维度上只有一个元素，利用tf.squeeze可以消除这个维度。</p><p>和tf.reshape相似，它本质上不会改变张量元素的存储顺序。</p><p>张量的各个元素在内存中是线性存储的，其一般规律是，同一层级中的相邻元素的物理地址也相邻。</p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">s = <span class="keyword">tf</span>.squeeze(<span class="keyword">a</span>)</span><br><span class="line"><span class="keyword">tf</span>.<span class="keyword">print</span>(s.shape)</span><br><span class="line"><span class="keyword">tf</span>.<span class="keyword">print</span>(s)</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">TensorShape([<span class="number">3</span>, <span class="number">3</span>, <span class="number">2</span>])</span><br><span class="line">[[[<span class="number">135</span> <span class="number">178</span>]</span><br><span class="line">  [<span class="number">26</span> <span class="number">116</span>]</span><br><span class="line">  [<span class="number">29</span> <span class="number">224</span>]]</span><br><span class="line"></span><br><span class="line"> [[<span class="number">179</span> <span class="number">219</span>]</span><br><span class="line">  [<span class="number">153</span> <span class="number">209</span>]</span><br><span class="line">  [<span class="number">111</span> <span class="number">215</span>]]</span><br><span class="line"></span><br><span class="line"> [[<span class="number">39</span> <span class="number">7</span>]</span><br><span class="line">  [<span class="number">138</span> <span class="number">129</span>]</span><br><span class="line">  [<span class="number">59</span> <span class="number">205</span>]]]</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">d = tf.expand_dims(s,axis=<span class="number">0</span>) #在第<span class="number">0</span>维插入长度为<span class="number">1</span>的一个维度</span><br><span class="line">d</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&lt;tf.Tensor: shape=(<span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">2</span>), dtype=<span class="built_in">int</span>32, numpy=</span><br><span class="line"><span class="built_in">array</span>([[[[<span class="number">135</span>, <span class="number">178</span>],</span><br><span class="line">         [ <span class="number">26</span>, <span class="number">116</span>],</span><br><span class="line">         [ <span class="number">29</span>, <span class="number">224</span>]],</span><br><span class="line"></span><br><span class="line">        [[<span class="number">179</span>, <span class="number">219</span>],</span><br><span class="line">         [<span class="number">153</span>, <span class="number">209</span>],</span><br><span class="line">         [<span class="number">111</span>, <span class="number">215</span>]],</span><br><span class="line"></span><br><span class="line">        [[ <span class="number">39</span>,   <span class="number">7</span>],</span><br><span class="line">         [<span class="number">138</span>, <span class="number">129</span>],</span><br><span class="line">         [ <span class="number">59</span>, <span class="number">205</span>]]]], dtype=<span class="built_in">int</span>32)&gt;</span><br></pre></td></tr></table></figure><p>tf.transpose可以交换张量的维度，与tf.reshape不同，它会改变张量元素的存储顺序。</p><p>tf.transpose常用于图片存储格式的变换上。</p><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># Batch,Height,Width,Channel</span><br><span class="line">a = tf.random.uniform(shape=[<span class="number">100</span>,<span class="number">600</span>,<span class="number">600</span>,<span class="number">4</span>],minval=<span class="number">0</span>,maxval=<span class="number">255</span>,dtype=tf.<span class="built_in">int</span>32)</span><br><span class="line">tf.print(a.shape)</span><br><span class="line"></span><br><span class="line"># 转换成 Channel,Height,Width,Batch</span><br><span class="line">s= tf.transpose(a,perm=[<span class="number">3</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">0</span>])</span><br><span class="line">tf.print(s.shape)</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">TensorShape([<span class="number">100</span>, <span class="number">600</span>, <span class="number">600</span>, <span class="number">4</span>])</span><br><span class="line">TensorShape([<span class="number">4</span>, <span class="number">600</span>, <span class="number">600</span>, <span class="number">100</span>])</span><br></pre></td></tr></table></figure><h4 id="合并分割"><a href="#合并分割" class="headerlink" title="合并分割"></a>合并分割</h4><p>和numpy类似，可以用tf.concat和tf.stack方法对多个张量进行合并，可以用tf.split方法把一个张量分割成多个张量。</p><p>tf.concat和tf.stack有略微的区别，tf.concat是连接，不会增加维度，而tf.stack是堆叠，会增加维度。</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">a = tf.constant(<span class="string">[[1.0,2.0],[3.0,4.0]]</span>)</span><br><span class="line">b = tf.constant(<span class="string">[[5.0,6.0],[7.0,8.0]]</span>)</span><br><span class="line">c = tf.constant(<span class="string">[[9.0,10.0],[11.0,12.0]]</span>)</span><br><span class="line"></span><br><span class="line">tf.<span class="built_in">concat</span>([a,b,c],axis = <span class="number">0</span>)</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&lt;tf.Tensor: shape=(<span class="number">6</span>, <span class="number">2</span>), dtype=<span class="built_in">float</span>32, numpy=</span><br><span class="line"><span class="built_in">array</span>([[ <span class="number">1.</span>,  <span class="number">2.</span>],</span><br><span class="line">       [ <span class="number">3.</span>,  <span class="number">4.</span>],</span><br><span class="line">       [ <span class="number">5.</span>,  <span class="number">6.</span>],</span><br><span class="line">       [ <span class="number">7.</span>,  <span class="number">8.</span>],</span><br><span class="line">       [ <span class="number">9.</span>, <span class="number">10.</span>],</span><br><span class="line">       [<span class="number">11.</span>, <span class="number">12.</span>]], dtype=<span class="built_in">float</span>32)&gt;</span><br></pre></td></tr></table></figure><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.concat([<span class="selector-tag">a</span>,<span class="selector-tag">b</span>,c],axis = <span class="number">1</span>)</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;tf.Tensor: shape=(<span class="number">2</span>, <span class="number">6</span>), dtype=<span class="built_in">float</span>32, numpy=</span><br><span class="line"><span class="built_in">array</span>([[ <span class="number">1.</span>,  <span class="number">2.</span>,  <span class="number">5.</span>,  <span class="number">6.</span>,  <span class="number">9.</span>, <span class="number">10.</span>],</span><br><span class="line">       [ <span class="number">3.</span>,  <span class="number">4.</span>,  <span class="number">7.</span>,  <span class="number">8.</span>, <span class="number">11.</span>, <span class="number">12.</span>]], dtype=<span class="built_in">float</span>32)&gt;</span><br></pre></td></tr></table></figure><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">tf</span><span class="selector-class">.stack</span>(<span class="selector-attr">[a,b,c]</span>)</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&lt;tf.Tensor: shape=(<span class="number">3</span>, <span class="number">2</span>, <span class="number">2</span>), dtype=<span class="built_in">float</span>32, numpy=</span><br><span class="line"><span class="built_in">array</span>([[[ <span class="number">1.</span>,  <span class="number">2.</span>],</span><br><span class="line">        [ <span class="number">3.</span>,  <span class="number">4.</span>]],</span><br><span class="line"></span><br><span class="line">       [[ <span class="number">5.</span>,  <span class="number">6.</span>],</span><br><span class="line">        [ <span class="number">7.</span>,  <span class="number">8.</span>]],</span><br><span class="line"></span><br><span class="line">       [[ <span class="number">9.</span>, <span class="number">10.</span>],</span><br><span class="line">        [<span class="number">11.</span>, <span class="number">12.</span>]]], dtype=<span class="built_in">float</span>32)&gt;</span><br></pre></td></tr></table></figure><figure class="highlight gcode"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.stack<span class="comment">([a,b,c],axis=1)</span></span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;tf.Tensor: shape=(<span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>), dtype=<span class="built_in">float</span>32, numpy=</span><br><span class="line"><span class="built_in">array</span>([[[ <span class="number">1.</span>,  <span class="number">2.</span>],</span><br><span class="line">        [ <span class="number">5.</span>,  <span class="number">6.</span>],</span><br><span class="line">        [ <span class="number">9.</span>, <span class="number">10.</span>]],</span><br><span class="line"></span><br><span class="line">       [[ <span class="number">3.</span>,  <span class="number">4.</span>],</span><br><span class="line">        [ <span class="number">7.</span>,  <span class="number">8.</span>],</span><br><span class="line">        [<span class="number">11.</span>, <span class="number">12.</span>]]], dtype=<span class="built_in">float</span>32)&gt;</span><br></pre></td></tr></table></figure><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">a = tf.constant(<span class="string">[[1.0,2.0],[3.0,4.0]]</span>)</span><br><span class="line">b = tf.constant(<span class="string">[[5.0,6.0],[7.0,8.0]]</span>)</span><br><span class="line">c = tf.constant(<span class="string">[[9.0,10.0],[11.0,12.0]]</span>)</span><br><span class="line"></span><br><span class="line">c = tf.<span class="built_in">concat</span>([a,b,c],axis = <span class="number">0</span>)</span><br></pre></td></tr></table></figure><p>tf.split是tf.concat的逆运算，可以指定分割份数平均分割，也可以通过指定每份的记录数量进行分割。</p><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#tf.split(value,num_or_size_splits,axis)</span></span><br><span class="line">tf.split<span class="params">(c,3,<span class="attr">axis</span> = 0)</span>  <span class="comment">#指定分割份数，平均分割</span></span><br></pre></td></tr></table></figure><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[&lt;tf.Tensor: shape=(<span class="number">2</span>, <span class="number">2</span>), dtype=float32, numpy=</span><br><span class="line"> array([[<span class="number">1.</span>, <span class="number">2.</span>],</span><br><span class="line">        [<span class="number">3.</span>, <span class="number">4.</span>]], dtype=float32)&gt;,</span><br><span class="line"> &lt;tf.Tensor: shape=(<span class="number">2</span>, <span class="number">2</span>), dtype=float32, numpy=</span><br><span class="line"> array([[<span class="number">5.</span>, <span class="number">6.</span>],</span><br><span class="line">        [<span class="number">7.</span>, <span class="number">8.</span>]], dtype=float32)&gt;,</span><br><span class="line"> &lt;tf.Tensor: shape=(<span class="number">2</span>, <span class="number">2</span>), dtype=float32, numpy=</span><br><span class="line"> array([[ <span class="number">9.</span>, <span class="number">10.</span>],</span><br><span class="line">        [<span class="number">11.</span>, <span class="number">12.</span>]], dtype=float32)&gt;]</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.split(c,[<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>],axis = <span class="number">0</span>) #指定每份的记录数量</span><br></pre></td></tr></table></figure><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[&lt;tf.Tensor: shape=(<span class="number">2</span>, <span class="number">2</span>), dtype=float32, numpy=</span><br><span class="line"> array([[<span class="number">1.</span>, <span class="number">2.</span>],</span><br><span class="line">        [<span class="number">3.</span>, <span class="number">4.</span>]], dtype=float32)&gt;,</span><br><span class="line"> &lt;tf.Tensor: shape=(<span class="number">2</span>, <span class="number">2</span>), dtype=float32, numpy=</span><br><span class="line"> array([[<span class="number">5.</span>, <span class="number">6.</span>],</span><br><span class="line">        [<span class="number">7.</span>, <span class="number">8.</span>]], dtype=float32)&gt;,</span><br><span class="line"> &lt;tf.Tensor: shape=(<span class="number">2</span>, <span class="number">2</span>), dtype=float32, numpy=</span><br><span class="line"> array([[ <span class="number">9.</span>, <span class="number">10.</span>],</span><br><span class="line">        [<span class="number">11.</span>, <span class="number">12.</span>]], dtype=float32)&gt;]</span><br></pre></td></tr></table></figure><h3 id="张量的数学运算"><a href="#张量的数学运算" class="headerlink" title="张量的数学运算"></a>张量的数学运算</h3><p>张量的操作主要包括张量的结构操作和张量的数学运算。</p><p>张量结构操作诸如：张量创建，索引切片，维度变换，合并分割。</p><p>张量数学运算主要有：标量运算，向量运算，矩阵运算。另外我们会介绍张量运算的广播机制。</p><p>本篇我们介绍张量的数学运算。</p><h4 id="标量运算"><a href="#标量运算" class="headerlink" title="标量运算"></a>标量运算</h4><p>张量的数学运算符可以分为标量运算符、向量运算符、以及矩阵运算符。</p><p>加减乘除乘方，以及三角函数，指数，对数等常见函数，逻辑比较运算符等都是标量运算符。</p><p>标量运算符的特点是对张量实施逐元素运算。</p><p>有些标量运算符对常用的数学运算符进行了重载。并且支持类似numpy的广播特性。</p><p>许多标量运算符都在 tf.math模块下。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf </span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a = tf.constant([[<span class="number">1.0</span>,<span class="number">2</span>],[<span class="number">-3</span>,<span class="number">4.0</span>]])</span><br><span class="line">b = tf.constant([[<span class="number">5.0</span>,<span class="number">6</span>],[<span class="number">7.0</span>,<span class="number">8.0</span>]])</span><br><span class="line">a+b  <span class="comment">#运算符重载</span></span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;tf.Tensor: shape=(<span class="number">2</span>, <span class="number">2</span>), dtype=<span class="built_in">float</span>32, numpy=</span><br><span class="line"><span class="built_in">array</span>([[ <span class="number">6.</span>,  <span class="number">8.</span>],</span><br><span class="line">       [ <span class="number">4.</span>, <span class="number">12.</span>]], dtype=<span class="built_in">float</span>32)&gt;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a-b</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;tf.Tensor: shape=(<span class="number">2</span>, <span class="number">2</span>), dtype=<span class="built_in">float</span>32, numpy=</span><br><span class="line"><span class="built_in">array</span>([[ <span class="number">-4.</span>,  <span class="number">-4.</span>],</span><br><span class="line">       [<span class="number">-10.</span>,  <span class="number">-4.</span>]], dtype=<span class="built_in">float</span>32)&gt;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a*b</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;tf.Tensor: shape=(<span class="number">2</span>, <span class="number">2</span>), dtype=<span class="built_in">float</span>32, numpy=</span><br><span class="line"><span class="built_in">array</span>([[  <span class="number">5.</span>,  <span class="number">12.</span>],</span><br><span class="line">       [<span class="number">-21.</span>,  <span class="number">32.</span>]], dtype=<span class="built_in">float</span>32)&gt;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a/b</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;tf.Tensor: shape=(<span class="number">2</span>, <span class="number">2</span>), dtype=<span class="built_in">float</span>32, numpy=</span><br><span class="line"><span class="built_in">array</span>([[ <span class="number">0.2</span>       ,  <span class="number">0.33333334</span>],</span><br><span class="line">       [<span class="number">-0.42857143</span>,  <span class="number">0.5</span>       ]], dtype=<span class="built_in">float</span>32)&gt;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a**<span class="number">2</span></span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;tf.Tensor: shape=(<span class="number">2</span>, <span class="number">2</span>), dtype=<span class="built_in">float</span>32, numpy=</span><br><span class="line"><span class="built_in">array</span>([[ <span class="number">1.</span>,  <span class="number">4.</span>],</span><br><span class="line">       [ <span class="number">9.</span>, <span class="number">16.</span>]], dtype=<span class="built_in">float</span>32)&gt;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a**(<span class="number">0.5</span>)</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;tf.Tensor: shape=(<span class="number">2</span>, <span class="number">2</span>), dtype=<span class="built_in">float</span>32, numpy=</span><br><span class="line"><span class="built_in">array</span>([[<span class="number">1.</span>       , <span class="number">1.4142135</span>],</span><br><span class="line">       [      nan, <span class="number">2.</span>       ]], dtype=<span class="built_in">float</span>32)&gt;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a%<span class="number">3</span> <span class="comment">#mod的运算符重载，等价于m = tf.math.mod(a,3)</span></span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;tf.Tensor: shape=(<span class="number">3</span>,), dtype=<span class="built_in">int</span>32, numpy=<span class="built_in">array</span>([<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>], dtype=<span class="built_in">int</span>32)&gt;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a//<span class="number">3</span>  <span class="comment">#地板除法</span></span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;tf.Tensor: shape=(<span class="number">2</span>, <span class="number">2</span>), dtype=<span class="built_in">float</span>32, numpy=</span><br><span class="line"><span class="built_in">array</span>([[ <span class="number">0.</span>,  <span class="number">0.</span>],</span><br><span class="line">       [<span class="number">-1.</span>,  <span class="number">1.</span>]], dtype=<span class="built_in">float</span>32)&gt;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(a&gt;=<span class="number">2</span>)</span><br></pre></td></tr></table></figure><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;tf.Tensor: shape=(<span class="number">2</span>, <span class="number">2</span>), dtype=<span class="type">bool</span>, numpy=</span><br><span class="line"><span class="keyword">array</span>([[<span class="keyword">False</span>,  <span class="keyword">True</span>],</span><br><span class="line">       [<span class="keyword">False</span>,  <span class="keyword">True</span>]])&gt;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(a&gt;=<span class="number">2</span>)&amp;(a&lt;=<span class="number">3</span>)</span><br></pre></td></tr></table></figure><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;tf.Tensor: shape=(<span class="number">2</span>, <span class="number">2</span>), dtype=<span class="type">bool</span>, numpy=</span><br><span class="line"><span class="keyword">array</span>([[<span class="keyword">False</span>,  <span class="keyword">True</span>],</span><br><span class="line">       [<span class="keyword">False</span>, <span class="keyword">False</span>]])&gt;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(a&gt;=<span class="number">2</span>)|(a&lt;=<span class="number">3</span>)</span><br></pre></td></tr></table></figure><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&lt;tf.Tensor:</span> <span class="string">shape=(2,</span> <span class="number">2</span><span class="string">),</span> <span class="string">dtype=bool,</span> <span class="string">numpy=</span></span><br><span class="line"><span class="string">array([[</span> <span class="literal">True</span><span class="string">,</span>  <span class="literal">True</span><span class="string">],</span></span><br><span class="line">       <span class="string">[</span> <span class="literal">True</span><span class="string">,</span>  <span class="literal">True</span><span class="string">]])&gt;</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a==<span class="number">5</span> <span class="comment">#tf.equal(a,5)</span></span><br></pre></td></tr></table></figure><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;tf.Tensor: shape=(3,), <span class="attribute">dtype</span>=bool, <span class="attribute">numpy</span>=array([<span class="literal">False</span>, <span class="literal">False</span>, <span class="literal">False</span>])&gt;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.sqrt(a)</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;tf.Tensor: shape=(<span class="number">2</span>, <span class="number">2</span>), dtype=<span class="built_in">float</span>32, numpy=</span><br><span class="line"><span class="built_in">array</span>([[<span class="number">1.</span>       , <span class="number">1.4142135</span>],</span><br><span class="line">       [      nan, <span class="number">2.</span>       ]], dtype=<span class="built_in">float</span>32)&gt;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = tf.constant([<span class="number">1.0</span>,<span class="number">8.0</span>])</span><br><span class="line">b = tf.constant([<span class="number">5.0</span>,<span class="number">6.0</span>])</span><br><span class="line">c = tf.constant([<span class="number">6.0</span>,<span class="number">7.0</span>])</span><br><span class="line">tf.add_n([a,b,c])</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;tf.Tensor: shape=(<span class="number">2</span>,), dtype=<span class="built_in">float</span>32, numpy=<span class="built_in">array</span>([<span class="number">12.</span>, <span class="number">21.</span>], dtype=<span class="built_in">float</span>32)&gt;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.print(tf.maximum(a,b))</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="number">5</span> <span class="number">8</span>]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.print(tf.minimum(a,b))</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="number">1</span> <span class="number">6</span>]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">x = tf.constant([<span class="number">2.6</span>,<span class="number">-2.7</span>])</span><br><span class="line"></span><br><span class="line">tf.print(tf.math.round(x)) <span class="comment">#保留整数部分，四舍五入</span></span><br><span class="line">tf.print(tf.math.floor(x)) <span class="comment">#保留整数部分，向下归整</span></span><br><span class="line">tf.print(tf.math.ceil(x))  <span class="comment">#保留整数部分，向上归整</span></span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[<span class="number">3</span> <span class="number">-3</span>]</span><br><span class="line">[<span class="number">2</span> <span class="number">-3</span>]</span><br><span class="line">[<span class="number">3</span> <span class="number">-2</span>]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 幅值裁剪</span></span><br><span class="line">x = tf.constant([<span class="number">0.9</span>,<span class="number">-0.8</span>,<span class="number">100.0</span>,<span class="number">-20.0</span>,<span class="number">0.7</span>])</span><br><span class="line">y = tf.clip_by_value(x,clip_value_min=<span class="number">-1</span>,clip_value_max=<span class="number">1</span>)</span><br><span class="line">z = tf.clip_by_norm(x,clip_norm = <span class="number">3</span>)</span><br><span class="line">tf.print(y)</span><br><span class="line">tf.print(z)</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[<span class="number">0.9</span> <span class="number">-0.8</span> <span class="number">1</span> <span class="number">-1</span> <span class="number">0.7</span>]</span><br><span class="line">[<span class="number">0.0264732055</span> <span class="number">-0.0235317405</span> <span class="number">2.94146752</span> <span class="number">-0.588293493</span> <span class="number">0.0205902718</span>]</span><br></pre></td></tr></table></figure><h4 id="向量运算"><a href="#向量运算" class="headerlink" title="向量运算"></a>向量运算</h4><p>向量运算符只在一个特定轴上运算，将一个向量映射到一个标量或者另外一个向量。<br>许多向量运算符都以reduce开头。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#向量reduce</span></span><br><span class="line">a = tf.range(<span class="number">1</span>,<span class="number">10</span>)</span><br><span class="line">tf.print(tf.reduce_sum(a))</span><br><span class="line">tf.print(tf.reduce_mean(a))</span><br><span class="line">tf.print(tf.reduce_max(a))</span><br><span class="line">tf.print(tf.reduce_min(a))</span><br><span class="line">tf.print(tf.reduce_prod(a))</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">45</span></span><br><span class="line"><span class="number">5</span></span><br><span class="line"><span class="number">9</span></span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="number">362880</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#张量指定维度进行reduce</span></span><br><span class="line">b = tf.reshape(a,(<span class="number">3</span>,<span class="number">3</span>))</span><br><span class="line">tf.print(tf.reduce_sum(b, axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>))</span><br><span class="line">tf.print(tf.reduce_sum(b, axis=<span class="number">0</span>, keepdims=<span class="literal">True</span>))</span><br></pre></td></tr></table></figure><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">6</span>]</span><br><span class="line"> [<span class="number">15</span>]</span><br><span class="line"> [<span class="number">24</span>]]</span><br><span class="line">[[<span class="number">12</span> <span class="number">15</span> <span class="number">18</span>]]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#bool类型的reduce</span></span><br><span class="line">p = tf.constant([<span class="literal">True</span>,<span class="literal">False</span>,<span class="literal">False</span>])</span><br><span class="line">q = tf.constant([<span class="literal">False</span>,<span class="literal">False</span>,<span class="literal">True</span>])</span><br><span class="line">tf.print(tf.reduce_all(p))</span><br><span class="line">tf.print(tf.reduce_any(q))</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span></span><br><span class="line"><span class="number">1</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#利用tf.foldr实现tf.reduce_sum</span></span><br><span class="line">s = tf.foldr(<span class="keyword">lambda</span> a,b:a+b,tf.range(<span class="number">10</span>)) </span><br><span class="line">tf.print(s)</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">45</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#cum扫描累积</span></span><br><span class="line">a = tf.range(<span class="number">1</span>,<span class="number">10</span>)</span><br><span class="line">tf.print(tf.math.cumsum(a))</span><br><span class="line">tf.print(tf.math.cumprod(a))</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[<span class="number">1</span> <span class="number">3</span> <span class="number">6</span> ... <span class="number">28</span> <span class="number">36</span> <span class="number">45</span>]</span><br><span class="line">[<span class="number">1</span> <span class="number">2</span> <span class="number">6</span> ... <span class="number">5040</span> <span class="number">40320</span> <span class="number">362880</span>]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#arg最大最小值索引</span></span><br><span class="line">a = tf.range(<span class="number">1</span>,<span class="number">10</span>)</span><br><span class="line">tf.print(tf.argmax(a))</span><br><span class="line">tf.print(tf.argmin(a))</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">8</span></span><br><span class="line"><span class="number">0</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#tf.math.top_k可以用于对张量排序</span></span><br><span class="line">a = tf.constant([<span class="number">1</span>,<span class="number">3</span>,<span class="number">7</span>,<span class="number">5</span>,<span class="number">4</span>,<span class="number">8</span>])</span><br><span class="line"></span><br><span class="line">values,indices = tf.math.top_k(a,<span class="number">3</span>,sorted=<span class="literal">True</span>)</span><br><span class="line">tf.print(values)</span><br><span class="line">tf.print(indices)</span><br><span class="line"></span><br><span class="line"><span class="comment">#利用tf.math.top_k可以在TensorFlow中实现KNN算法</span></span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[<span class="number">8</span> <span class="number">7</span> <span class="number">5</span>]</span><br><span class="line">[<span class="number">5</span> <span class="number">2</span> <span class="number">3</span>]</span><br></pre></td></tr></table></figure><h4 id="矩阵运算"><a href="#矩阵运算" class="headerlink" title="矩阵运算"></a>矩阵运算</h4><p>矩阵必须是二维的。类似tf.constant([1,2,3])这样的不是矩阵。</p><p>矩阵运算包括：矩阵乘法，矩阵转置，矩阵逆，矩阵求迹，矩阵范数，矩阵行列式，矩阵求特征值，矩阵分解等运算。</p><p>除了一些常用的运算外，大部分和矩阵有关的运算都在tf.linalg子包中。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#矩阵乘法</span></span><br><span class="line">a = tf.constant([[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4</span>]])</span><br><span class="line">b = tf.constant([[<span class="number">2</span>,<span class="number">0</span>],[<span class="number">0</span>,<span class="number">2</span>]])</span><br><span class="line">a@b  <span class="comment">#等价于tf.matmul(a,b)</span></span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;tf.Tensor: shape=(<span class="number">2</span>, <span class="number">2</span>), dtype=<span class="built_in">int</span>32, numpy=</span><br><span class="line"><span class="built_in">array</span>([[<span class="number">2</span>, <span class="number">4</span>],</span><br><span class="line">       [<span class="number">6</span>, <span class="number">8</span>]], dtype=<span class="built_in">int</span>32)&gt;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#矩阵转置</span></span><br><span class="line">a = tf.constant([[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4</span>]])</span><br><span class="line">tf.transpose(a)</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;tf.Tensor: shape=(<span class="number">2</span>, <span class="number">2</span>), dtype=<span class="built_in">int</span>32, numpy=</span><br><span class="line"><span class="built_in">array</span>([[<span class="number">1</span>, <span class="number">3</span>],</span><br><span class="line">       [<span class="number">2</span>, <span class="number">4</span>]], dtype=<span class="built_in">int</span>32)&gt;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#矩阵逆，必须为tf.float32或tf.double类型</span></span><br><span class="line">a = tf.constant([[<span class="number">1.0</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4</span>]],dtype = tf.float32)</span><br><span class="line">tf.linalg.inv(a)</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;tf.Tensor: shape=(<span class="number">2</span>, <span class="number">2</span>), dtype=<span class="built_in">float</span>32, numpy=</span><br><span class="line"><span class="built_in">array</span>([[<span class="number">-2.0000002</span> ,  <span class="number">1.0000001</span> ],</span><br><span class="line">       [ <span class="number">1.5000001</span> , <span class="number">-0.50000006</span>]], dtype=<span class="built_in">float</span>32)&gt;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#矩阵求trace</span></span><br><span class="line">a = tf.constant([[<span class="number">1.0</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4</span>]],dtype = tf.float32)</span><br><span class="line">tf.linalg.trace(a)</span><br></pre></td></tr></table></figure><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">tf.Tensor:</span> <span class="attr">shape</span>=<span class="string">(),</span> <span class="attr">dtype</span>=<span class="string">float32,</span> <span class="attr">numpy</span>=<span class="string">5.0</span>&gt;</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#矩阵求范数</span></span><br><span class="line">a = tf.constant([[<span class="number">1.0</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4</span>]])</span><br><span class="line">tf.linalg.norm(a)</span><br></pre></td></tr></table></figure><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">tf.Tensor:</span> <span class="attr">shape</span>=<span class="string">(),</span> <span class="attr">dtype</span>=<span class="string">float32,</span> <span class="attr">numpy</span>=<span class="string">5.477226</span>&gt;</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#矩阵行列式</span></span><br><span class="line">a = tf.constant([[<span class="number">1.0</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4</span>]])</span><br><span class="line">tf.linalg.det(a)</span><br></pre></td></tr></table></figure><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">tf.Tensor:</span> <span class="attr">shape</span>=<span class="string">(),</span> <span class="attr">dtype</span>=<span class="string">float32,</span> <span class="attr">numpy</span>=<span class="string">-2.0</span>&gt;</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#矩阵特征值</span></span><br><span class="line">a = tf.constant([[<span class="number">1.0</span>,<span class="number">2</span>],[<span class="number">-5</span>,<span class="number">4</span>]])</span><br><span class="line">tf.linalg.eigvals(a)</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;tf.Tensor: shape=(<span class="number">2</span>,), dtype=complex64, numpy=<span class="built_in">array</span>([<span class="number">2.4999995</span>+<span class="number">2.7838817</span>j, <span class="number">2.5</span>      <span class="number">-2.783882</span>j ], dtype=complex64)&gt;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#矩阵QR分解, 将一个方阵分解为一个正交矩阵q和上三角矩阵r</span></span><br><span class="line"><span class="comment">#QR分解实际上是对矩阵a实施Schmidt正交化得到q</span></span><br><span class="line"></span><br><span class="line">a = tf.constant([[<span class="number">1.0</span>,<span class="number">2.0</span>],[<span class="number">3.0</span>,<span class="number">4.0</span>]],dtype = tf.float32)</span><br><span class="line">q,r = tf.linalg.qr(a)</span><br><span class="line">tf.print(q)</span><br><span class="line">tf.print(r)</span><br><span class="line">tf.print(q@r)</span><br></pre></td></tr></table></figure><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">-0.316227794</span> <span class="number">-0.948683321</span>]</span><br><span class="line"> [<span class="number">-0.948683321</span> <span class="number">0.316227734</span>]]</span><br><span class="line">[[<span class="number">-3.1622777</span> <span class="number">-4.4271884</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">-0.632455349</span>]]</span><br><span class="line">[[<span class="number">1.00000012</span> <span class="number">1.99999976</span>]</span><br><span class="line"> [<span class="number">3</span> <span class="number">4</span>]]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#矩阵svd分解</span></span><br><span class="line"><span class="comment">#svd分解可以将任意一个矩阵分解为一个正交矩阵u,一个对角阵s和一个正交矩阵v.t()的乘积</span></span><br><span class="line"><span class="comment">#svd常用于矩阵压缩和降维</span></span><br><span class="line"></span><br><span class="line">a  = tf.constant([[<span class="number">1.0</span>,<span class="number">2.0</span>],[<span class="number">3.0</span>,<span class="number">4.0</span>],[<span class="number">5.0</span>,<span class="number">6.0</span>]], dtype = tf.float32)</span><br><span class="line">s,u,v = tf.linalg.svd(a)</span><br><span class="line">tf.print(u,<span class="string">"\n"</span>)</span><br><span class="line">tf.print(s,<span class="string">"\n"</span>)</span><br><span class="line">tf.print(v,<span class="string">"\n"</span>)</span><br><span class="line">tf.print(u@tf.linalg.diag(s)@tf.transpose(v))</span><br><span class="line"></span><br><span class="line"><span class="comment">#利用svd分解可以在TensorFlow中实现主成分分析降维</span></span><br></pre></td></tr></table></figure><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">0.229847744</span> <span class="number">-0.88346082</span>]</span><br><span class="line"> [<span class="number">0.524744868</span> <span class="number">-0.240782902</span>]</span><br><span class="line"> [<span class="number">0.819642067</span> <span class="number">0.401896209</span>]] </span><br><span class="line"></span><br><span class="line">[<span class="number">9.52551842</span> <span class="number">0.51429987</span>] </span><br><span class="line"></span><br><span class="line">[[<span class="number">0.619629562</span> <span class="number">0.784894466</span>]</span><br><span class="line"> [<span class="number">0.784894466</span> <span class="number">-0.619629562</span>]] </span><br><span class="line"></span><br><span class="line">[[<span class="number">1.00000119</span> <span class="number">2</span>]</span><br><span class="line"> [<span class="number">3.00000095</span> <span class="number">4.00000048</span>]</span><br><span class="line"> [<span class="number">5.00000143</span> <span class="number">6.00000095</span>]]</span><br></pre></td></tr></table></figure><h4 id="广播机制"><a href="#广播机制" class="headerlink" title="广播机制"></a>广播机制</h4><p>TensorFlow的广播规则和numpy是一样的:</p><ul><li>1、如果张量的维度不同，将维度较小的张量进行扩展，直到两个张量的维度都一样。</li><li>2、如果两个张量在某个维度上的长度是相同的，或者其中一个张量在该维度上的长度为1，那么我们就说这两个张量在该维度上是相容的。</li><li>3、如果两个张量在所有维度上都是相容的，它们就能使用广播。</li><li>4、广播之后，每个维度的长度将取两个张量在该维度长度的较大值。</li><li>5、在任何一个维度上，如果一个张量的长度为1，另一个张量长度大于1，那么在该维度上，就好像是对第一个张量进行了复制。</li></ul><p>tf.broadcast_to 以显式的方式按照广播机制扩展张量的维度。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a = tf.constant([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">b = tf.constant([[<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>],[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>],[<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>]])</span><br><span class="line">b + a  <span class="comment">#等价于 b + tf.broadcast_to(a,b.shape)</span></span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;tf.Tensor: shape=(<span class="number">3</span>, <span class="number">3</span>), dtype=<span class="built_in">int</span>32, numpy=</span><br><span class="line"><span class="built_in">array</span>([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">       [<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">       [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]], dtype=<span class="built_in">int</span>32)&gt;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.broadcast_to(a,b.shape)</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;tf.Tensor: shape=(<span class="number">3</span>, <span class="number">3</span>), dtype=<span class="built_in">int</span>32, numpy=</span><br><span class="line"><span class="built_in">array</span>([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">       [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">       [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]], dtype=<span class="built_in">int</span>32)&gt;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#计算广播后计算结果的形状，静态形状，TensorShape类型参数</span></span><br><span class="line">tf.broadcast_static_shape(a.shape,b.shape)</span><br></pre></td></tr></table></figure><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="title">TensorShape</span><span class="params">([<span class="number">3</span>, <span class="number">3</span>])</span></span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#计算广播后计算结果的形状，动态形状，Tensor类型参数</span></span><br><span class="line">c = tf.constant([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">d = tf.constant([[<span class="number">1</span>],[<span class="number">2</span>],[<span class="number">3</span>]])</span><br><span class="line">tf.broadcast_dynamic_shape(tf.shape(c),tf.shape(d))</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;tf.Tensor: shape=(<span class="number">2</span>,), dtype=<span class="built_in">int</span>32, numpy=<span class="built_in">array</span>([<span class="number">3</span>, <span class="number">3</span>], dtype=<span class="built_in">int</span>32)&gt;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#广播效果</span></span><br><span class="line">c+d <span class="comment">#等价于 tf.broadcast_to(c,[3,3]) + tf.broadcast_to(d,[3,3])</span></span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;tf.Tensor: shape=(<span class="number">3</span>, <span class="number">3</span>), dtype=<span class="built_in">int</span>32, numpy=</span><br><span class="line"><span class="built_in">array</span>([[<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">       [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>],</span><br><span class="line">       [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]], dtype=<span class="built_in">int</span>32)&gt;</span><br></pre></td></tr></table></figure><h3 id="AutoGraph的使用规范"><a href="#AutoGraph的使用规范" class="headerlink" title="AutoGraph的使用规范"></a>AutoGraph的使用规范</h3><p>有三种计算图的构建方式：静态计算图，动态计算图，以及Autograph。</p><p>TensorFlow 2.0主要使用的是动态计算图和Autograph。</p><p>动态计算图易于调试，编码效率较高，但执行效率偏低。</p><p>静态计算图执行效率很高，但较难调试。</p><p>而Autograph机制可以将动态图转换成静态计算图，兼收执行效率和编码效率之利。</p><p>当然Autograph机制能够转换的代码并不是没有任何约束的，有一些编码规范需要遵循，否则可能会转换失败或者不符合预期。</p><p>我们将着重介绍Autograph的编码规范和Autograph转换成静态图的原理。</p><p>并介绍使用tf.Module来更好地构建Autograph。</p><p>本篇我们介绍使用Autograph的编码规范。</p><h4 id="Autograph编码规范总结"><a href="#Autograph编码规范总结" class="headerlink" title="Autograph编码规范总结"></a>Autograph编码规范总结</h4><ul><li><p>被 <code>@tf.function</code> 修饰的函数应尽可能使用TensorFlow中的函数而不是Python中的其他函数。例如使用 <code>tf.print</code>而不是print，使用 <code>tf.range</code> 而不是range，使用 <code>tf.constant(True)</code> 而不是True.</p></li><li><p>避免在 <code>@tf.function</code> 修饰的函数内部定义 <code>tf.Variable</code>.</p></li><li><p>被 <code>@tf.function</code>修饰的函数不可修改该函数外部的Python列表或字典等数据结构变量。</p></li></ul><h4 id="Autograph编码规范解析"><a href="#Autograph编码规范解析" class="headerlink" title="Autograph编码规范解析"></a>Autograph编码规范解析</h4><p> <strong>被@tf.function修饰的函数应尽量使用TensorFlow中的函数而不是Python中的其他函数。</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="meta">@tf.function</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">np_random</span><span class="params">()</span>:</span></span><br><span class="line">    a = np.random.randn(<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line">    tf.print(a)</span><br><span class="line"></span><br><span class="line"><span class="meta">@tf.function</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tf_random</span><span class="params">()</span>:</span></span><br><span class="line">    a = tf.random.normal((<span class="number">3</span>,<span class="number">3</span>))</span><br><span class="line">    tf.print(a)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#np_random每次执行都是一样的结果。</span></span><br><span class="line">np_random()</span><br><span class="line">np_random()</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">array</span>([[ <span class="number">0.22619201</span>, <span class="number">-0.4550123</span> , <span class="number">-0.42587565</span>],</span><br><span class="line">       [ <span class="number">0.05429906</span>,  <span class="number">0.2312667</span> , <span class="number">-1.44819738</span>],</span><br><span class="line">       [ <span class="number">0.36571796</span>,  <span class="number">1.45578986</span>, <span class="number">-1.05348983</span>]])</span><br><span class="line"><span class="built_in">array</span>([[ <span class="number">0.22619201</span>, <span class="number">-0.4550123</span> , <span class="number">-0.42587565</span>],</span><br><span class="line">       [ <span class="number">0.05429906</span>,  <span class="number">0.2312667</span> , <span class="number">-1.44819738</span>],</span><br><span class="line">       [ <span class="number">0.36571796</span>,  <span class="number">1.45578986</span>, <span class="number">-1.05348983</span>]])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#tf_random每次执行都会有重新生成随机数。</span></span><br><span class="line">tf_random()</span><br><span class="line">tf_random()</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">-1.38956189</span> <span class="number">-0.394843668</span> <span class="number">0.420657277</span>]</span><br><span class="line"> [<span class="number">2.87235498</span> <span class="number">-1.33740318</span> <span class="number">-0.533843279</span>]</span><br><span class="line"> [<span class="number">0.918233037</span> <span class="number">0.118598573</span> <span class="number">-0.399486482</span>]]</span><br><span class="line">[[<span class="number">-0.858178258</span> <span class="number">1.67509317</span> <span class="number">0.511889517</span>]</span><br><span class="line"> [<span class="number">-0.545829177</span> <span class="number">-2.20118237</span> <span class="number">-0.968222201</span>]</span><br><span class="line"> [<span class="number">0.733958483</span> <span class="number">-0.61904633</span> <span class="number">0.77440238</span>]]</span><br></pre></td></tr></table></figure><p><strong>避免在@tf.function修饰的函数内部定义tf.Variable.</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 避免在@tf.function修饰的函数内部定义tf.Variable.</span></span><br><span class="line"></span><br><span class="line">x = tf.Variable(<span class="number">1.0</span>,dtype=tf.float32)</span><br><span class="line"><span class="meta">@tf.function</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">outer_var</span><span class="params">()</span>:</span></span><br><span class="line">    x.assign_add(<span class="number">1.0</span>)</span><br><span class="line">    tf.print(x)</span><br><span class="line">    <span class="keyword">return</span>(x)</span><br><span class="line"></span><br><span class="line">outer_var()</span><br><span class="line">outer_var()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@tf.function</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">inner_var</span><span class="params">()</span>:</span></span><br><span class="line">    x = tf.Variable(<span class="number">1.0</span>,dtype = tf.float32)</span><br><span class="line">    x.assign_add(<span class="number">1.0</span>)</span><br><span class="line">    tf.print(x)</span><br><span class="line">    <span class="keyword">return</span>(x)</span><br><span class="line"></span><br><span class="line"><span class="comment">#执行将报错</span></span><br><span class="line"><span class="comment">#inner_var()</span></span><br><span class="line"><span class="comment">#inner_var()</span></span><br></pre></td></tr></table></figure><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">---------------------------------------------------------------------------</span><br><span class="line">ValueError                                Traceback (most recent call last)</span><br><span class="line">&lt;ipython-input-<span class="number">12</span>-c95a7c3c1ddd&gt; <span class="keyword">in</span> &lt;<span class="keyword">module</span>&gt;</span><br><span class="line">      <span class="number">7</span></span><br><span class="line">      <span class="number">8</span> #执行将报错</span><br><span class="line">----&gt; <span class="number">9</span> inner<span class="constructor">_var()</span></span><br><span class="line">     <span class="number">10</span> inner<span class="constructor">_var()</span></span><br><span class="line"></span><br><span class="line">~/anaconda3/lib/python3.<span class="number">7</span>/site-packages/tensorflow_core/python/eager/def_function.py <span class="keyword">in</span> <span class="constructor">__call__(<span class="params">self</span>, <span class="operator">*</span><span class="params">args</span>, <span class="operator">**</span><span class="params">kwds</span>)</span></span><br><span class="line">    <span class="number">566</span>         xla_context.<span class="constructor">Exit()</span></span><br><span class="line">    <span class="number">567</span>     <span class="keyword">else</span>:</span><br><span class="line">--&gt; <span class="number">568</span>       result = self.<span class="constructor">_call(<span class="operator">*</span><span class="params">args</span>, <span class="operator">**</span><span class="params">kwds</span>)</span></span><br><span class="line">    <span class="number">569</span></span><br><span class="line">    <span class="number">570</span>     <span class="keyword">if</span> tracing_count<span class="operator"> == </span>self.<span class="constructor">_get_tracing_count()</span>:</span><br><span class="line">......</span><br><span class="line">ValueError: tf.<span class="keyword">function</span>-decorated <span class="keyword">function</span> tried <span class="keyword">to</span> create variables on non-first call.</span><br></pre></td></tr></table></figure><p><strong>被@tf.function修饰的函数不可修改该函数外部的Python列表或字典等结构类型变量。</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">tensor_list = []</span><br><span class="line"></span><br><span class="line"><span class="comment">#@tf.function #加上这一行切换成Autograph结果将不符合预期！！！</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">append_tensor</span><span class="params">(x)</span>:</span></span><br><span class="line">    tensor_list.append(x)</span><br><span class="line">    <span class="keyword">return</span> tensor_list</span><br><span class="line"></span><br><span class="line">append_tensor(tf.constant(<span class="number">5.0</span>))</span><br><span class="line">append_tensor(tf.constant(<span class="number">6.0</span>))</span><br><span class="line">print(tensor_list)</span><br></pre></td></tr></table></figure><figure class="highlight fsharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">[&lt;tf.Tensor: shape=(), dtype=float32, numpy=5.0&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=6.0&gt;]</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">tensor_list = []</span><br><span class="line"></span><br><span class="line"><span class="meta">@tf.function #加上这一行切换成Autograph结果将不符合预期！！！</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">append_tensor</span><span class="params">(x)</span>:</span></span><br><span class="line">    tensor_list.append(x)</span><br><span class="line">    <span class="keyword">return</span> tensor_list</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">append_tensor(tf.constant(<span class="number">5.0</span>))</span><br><span class="line">append_tensor(tf.constant(<span class="number">6.0</span>))</span><br><span class="line">print(tensor_list)</span><br></pre></td></tr></table></figure><figure class="highlight fsharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">[&lt;tf.Tensor 'x:0' shape=() dtype=float32&gt;]</span></span><br></pre></td></tr></table></figure><h3 id="AutoGraph的机制原理"><a href="#AutoGraph的机制原理" class="headerlink" title="AutoGraph的机制原理"></a>AutoGraph的机制原理</h3><p>有三种计算图的构建方式：静态计算图，动态计算图，以及Autograph。</p><p>TensorFlow 2.0主要使用的是动态计算图和Autograph。</p><p>动态计算图易于调试，编码效率较高，但执行效率偏低。</p><p>静态计算图执行效率很高，但较难调试。</p><p>而Autograph机制可以将动态图转换成静态计算图，兼收执行效率和编码效率之利。</p><p>当然Autograph机制能够转换的代码并不是没有任何约束的，有一些编码规范需要遵循，否则可能会转换失败或者不符合预期。</p><p>我们会介绍Autograph的编码规范和Autograph转换成静态图的原理。</p><p>并介绍使用tf.Module来更好地构建Autograph。</p><p>上篇我们介绍了Autograph的编码规范，本篇我们介绍Autograph的机制原理。</p><h4 id="Autograph的机制原理"><a href="#Autograph的机制原理" class="headerlink" title="Autograph的机制原理"></a>Autograph的机制原理</h4><p><strong>当我们使用@tf.function装饰一个函数的时候，后面到底发生了什么呢？</strong></p><p>例如我们写下如下代码。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"></span><br><span class="line"><span class="meta">@tf.function(autograph=True)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">myadd</span><span class="params">(a,b)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> tf.range(<span class="number">3</span>):</span><br><span class="line">        tf.print(i)</span><br><span class="line">    c = a+b</span><br><span class="line">    print(<span class="string">"tracing"</span>)</span><br><span class="line">    <span class="keyword">return</span> c</span><br></pre></td></tr></table></figure><p>后面什么都没有发生。仅仅是在Python堆栈中记录了这样一个函数的签名。</p><p><strong>当我们第一次调用这个被@tf.function装饰的函数时，后面到底发生了什么？</strong></p><p>例如我们写下如下代码。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">myadd(tf.constant(<span class="string">"hello"</span>),tf.constant(<span class="string">"world"</span>))</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tracing</span><br><span class="line"><span class="number">0</span></span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="number">2</span></span><br></pre></td></tr></table></figure><p>发生了2件事情，</p><p>第一件事情是创建计算图。</p><p>即创建一个静态计算图，跟踪执行一遍函数体中的Python代码，确定各个变量的Tensor类型，并根据执行顺序将算子添加到计算图中。<br>在这个过程中，如果开启了autograph=True(默认开启),会将Python控制流转换成TensorFlow图内控制流。<br>主要是将if语句转换成 tf.cond算子表达，将while和for循环语句转换成tf.while_loop算子表达，并在必要的时候添加<br>tf.control_dependencies指定执行顺序依赖关系。</p><p>相当于在 tensorflow1.0执行了类似下面的语句：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">g = tf.Graph()</span><br><span class="line"><span class="keyword">with</span> g.as_default():</span><br><span class="line">    a = tf.placeholder(shape=[],dtype=tf.string)</span><br><span class="line">    b = tf.placeholder(shape=[],dtype=tf.string)</span><br><span class="line">    cond = <span class="keyword">lambda</span> i: i&lt;tf.constant(<span class="number">3</span>)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">body</span><span class="params">(i)</span>:</span></span><br><span class="line">        tf.print(i)</span><br><span class="line">        <span class="keyword">return</span>(i+<span class="number">1</span>)</span><br><span class="line">    loop = tf.while_loop(cond,body,loop_vars=[<span class="number">0</span>])</span><br><span class="line">    loop</span><br><span class="line">    <span class="keyword">with</span> tf.control_dependencies(loop):</span><br><span class="line">        c = tf.strings.join([a,b])</span><br><span class="line">    print(<span class="string">"tracing"</span>)</span><br></pre></td></tr></table></figure><p>第二件事情是执行计算图。</p><p>相当于在 tensorflow1.0中执行了下面的语句：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session(graph=g) <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(c,feed_dict=&#123;a:tf.constant(<span class="string">"hello"</span>),b:tf.constant(<span class="string">"world"</span>)&#125;)</span><br></pre></td></tr></table></figure><p>因此我们先看到的是第一个步骤的结果：即Python调用标准输出流打印”tracing”语句。</p><p>然后看到第二个步骤的结果：TensorFlow调用标准输出流打印1,2,3。</p><p><strong>当我们再次用相同的输入参数类型调用这个被@tf.function装饰的函数时，后面到底发生了什么？</strong></p><p>例如我们写下如下代码。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">myadd(tf.constant(<span class="string">"good"</span>),tf.constant(<span class="string">"morning"</span>))</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span></span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="number">2</span></span><br></pre></td></tr></table></figure><p>只会发生一件事情，那就是上面步骤的第二步，执行计算图。</p><p>所以这一次我们没有看到打印”tracing”的结果。</p><p><strong>当我们再次用不同的的输入参数类型调用这个被@tf.function装饰的函数时，后面到底发生了什么？</strong></p><p>例如我们写下如下代码。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">myadd(tf.constant(<span class="number">1</span>),tf.constant(<span class="number">2</span>))</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tracing</span><br><span class="line"><span class="number">0</span></span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="number">2</span></span><br></pre></td></tr></table></figure><p>由于输入参数的类型已经发生变化，已经创建的计算图不能够再次使用。</p><p>需要重新做2件事情：创建新的计算图、执行计算图。</p><p>所以我们又会先看到的是第一个步骤的结果：即Python调用标准输出流打印”tracing”语句。</p><p>然后再看到第二个步骤的结果：TensorFlow调用标准输出流打印1,2,3。</p><p><strong>需要注意的是，如果调用被@tf.function装饰的函数时输入的参数不是Tensor类型，则每次都会重新创建计算图。</strong></p><p>例如我们写下如下代码。两次都会重新创建计算图。因此，一般建议调用@tf.function时应传入Tensor类型。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">myadd(<span class="string">"hello"</span>,<span class="string">"world"</span>)</span><br><span class="line">myadd(<span class="string">"good"</span>,<span class="string">"morning"</span>)</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">tracing</span><br><span class="line"><span class="number">0</span></span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="number">2</span></span><br><span class="line">tracing</span><br><span class="line"><span class="number">0</span></span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="number">2</span></span><br></pre></td></tr></table></figure><h4 id="重新理解Autograph的编码规范"><a href="#重新理解Autograph的编码规范" class="headerlink" title="重新理解Autograph的编码规范"></a>重新理解Autograph的编码规范</h4><p>了解了以上Autograph的机制原理，我们也就能够理解Autograph编码规范的3条建议了。</p><ol><li>被@tf.function修饰的函数应尽量使用TensorFlow中的函数而不是Python中的其他函数。例如使用tf.print而不是print.</li></ol><p>解释：Python中的函数仅仅会在跟踪执行函数以创建静态图的阶段使用，普通Python函数是无法嵌入到静态计算图中的，所以<br>在计算图构建好之后再次调用的时候，这些Python函数并没有被计算，而TensorFlow中的函数则可以嵌入到计算图中。使用普通的Python函数会导致<br>被@tf.function修饰前【eager执行】和被@tf.function修饰后【静态图执行】的输出不一致。</p><ol><li>避免在@tf.function修饰的函数内部定义tf.Variable. </li></ol><p>解释：如果函数内部定义了tf.Variable,那么在【eager执行】时，这种创建tf.Variable的行为在每次函数调用时候都会发生。但是在【静态图执行】时，这种创建tf.Variable的行为只会发生在第一步跟踪Python代码逻辑创建计算图时，这会导致被@tf.function修饰前【eager执行】和被@tf.function修饰后【静态图执行】的输出不一致。实际上，TensorFlow在这种情况下一般会报错。</p><ol><li>被@tf.function修饰的函数不可修改该函数外部的Python列表或字典等数据结构变量。</li></ol><p>解释：静态计算图是被编译成C++代码在TensorFlow内核中执行的。Python中的列表和字典等数据结构变量是无法嵌入到计算图中，它们仅仅能够在创建计算图时被读取，在执行计算图时是无法修改Python中的列表或字典这样的数据结构变量的。</p><h3 id="AutoGraph和tf-Module"><a href="#AutoGraph和tf-Module" class="headerlink" title="AutoGraph和tf.Module"></a>AutoGraph和tf.Module</h3><p>有三种计算图的构建方式：静态计算图，动态计算图，以及Autograph。</p><p>TensorFlow 2.0主要使用的是动态计算图和Autograph。</p><p>动态计算图易于调试，编码效率较高，但执行效率偏低。</p><p>静态计算图执行效率很高，但较难调试。</p><p>而Autograph机制可以将动态图转换成静态计算图，兼收执行效率和编码效率之利。</p><p>当然Autograph机制能够转换的代码并不是没有任何约束的，有一些编码规范需要遵循，否则可能会转换失败或者不符合预期。</p><p>前面我们介绍了Autograph的编码规范和Autograph转换成静态图的原理。</p><p>本篇我们介绍使用tf.Module来更好地构建Autograph。</p><h4 id="Autograph和tf-Module概述"><a href="#Autograph和tf-Module概述" class="headerlink" title="Autograph和tf.Module概述"></a>Autograph和tf.Module概述</h4><p>前面在介绍Autograph的编码规范时提到构建Autograph时应该避免在@tf.function修饰的函数内部定义tf.Variable. </p><p>但是如果在函数外部定义tf.Variable的话，又会显得这个函数有外部变量依赖，封装不够完美。</p><p>一种简单的思路是定义一个类，并将相关的tf.Variable创建放在类的初始化方法中。而将函数的逻辑放在其他方法中。</p><p>这样一顿猛如虎的操作之后，我们会觉得一切都如同人法地地法天天法道道法自然般的自然。</p><p>惊喜的是，TensorFlow提供了一个基类tf.Module，通过继承它构建子类，我们不仅可以获得以上的自然而然，而且可以非常方便地管理变量，还可以非常方便地管理它引用的其它Module，最重要的是，我们能够利用tf.saved_model保存模型并实现跨平台部署使用。</p><p>实际上，tf.keras.models.Model,tf.keras.layers.Layer 都是继承自tf.Module的，提供了方便的变量管理和所引用的子模块管理的功能。</p><p><strong>因此，利用tf.Module提供的封装，再结合TensoFlow丰富的低阶API，实际上我们能够基于TensorFlow开发任意机器学习模型(而非仅仅是神经网络模型)，并实现跨平台部署使用。</strong></p><h4 id="应用tf-Module封装Autograph"><a href="#应用tf-Module封装Autograph" class="headerlink" title="应用tf.Module封装Autograph"></a>应用tf.Module封装Autograph</h4><p>定义一个简单的function。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf </span><br><span class="line">x = tf.Variable(<span class="number">1.0</span>,dtype=tf.float32)</span><br><span class="line"></span><br><span class="line"><span class="comment">#在tf.function中用input_signature限定输入张量的签名类型：shape和dtype</span></span><br><span class="line"><span class="meta">@tf.function(input_signature=[tf.TensorSpec(shape = [], dtype = tf.float32)])    </span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_print</span><span class="params">(a)</span>:</span></span><br><span class="line">    x.assign_add(a)</span><br><span class="line">    tf.print(x)</span><br><span class="line">    <span class="keyword">return</span>(x)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">add_print(tf.constant(<span class="number">3.0</span>))</span><br><span class="line"><span class="comment">#add_print(tf.constant(3)) #输入不符合张量签名的参数将报错</span></span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">4</span></span><br></pre></td></tr></table></figure><p>下面利用tf.Module的子类化将其封装一下。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DemoModule</span><span class="params">(tf.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,init_value = tf.constant<span class="params">(<span class="number">0.0</span>)</span>,name=None)</span>:</span></span><br><span class="line">        super(DemoModule, self).__init__(name=name)</span><br><span class="line">        <span class="keyword">with</span> self.name_scope:  <span class="comment">#相当于with tf.name_scope("demo_module")</span></span><br><span class="line">            self.x = tf.Variable(init_value,dtype = tf.float32,trainable=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">     </span><br><span class="line"><span class="meta">    @tf.function(input_signature=[tf.TensorSpec(shape = [], dtype = tf.float32)])  </span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">addprint</span><span class="params">(self,a)</span>:</span></span><br><span class="line">        <span class="keyword">with</span> self.name_scope:</span><br><span class="line">            self.x.assign_add(a)</span><br><span class="line">            tf.print(self.x)</span><br><span class="line">            <span class="keyword">return</span>(self.x)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#执行</span></span><br><span class="line">demo = DemoModule(init_value = tf.constant(<span class="number">1.0</span>))</span><br><span class="line">result = demo.addprint(tf.constant(<span class="number">5.0</span>))</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">6</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#查看模块中的全部变量和全部可训练变量</span></span><br><span class="line">print(demo.variables)</span><br><span class="line">print(demo.trainable_variables)</span><br></pre></td></tr></table></figure><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(&lt;tf.Variable <span class="string">'demo_module/Variable:0'</span> shape=() <span class="attribute">dtype</span>=float32, <span class="attribute">numpy</span>=6.0&gt;,)</span><br><span class="line">(&lt;tf.Variable <span class="string">'demo_module/Variable:0'</span> shape=() <span class="attribute">dtype</span>=float32, <span class="attribute">numpy</span>=6.0&gt;,)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#查看模块中的全部子模块</span></span><br><span class="line">demo.submodules</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#使用tf.saved_model 保存模型，并指定需要跨平台部署的方法</span></span><br><span class="line">tf.saved_model.save(demo,<span class="string">"./data/demo/1"</span>,signatures = &#123;<span class="string">"serving_default"</span>:demo.addprint&#125;)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#加载模型</span></span><br><span class="line">demo2 = tf.saved_model.load(<span class="string">"./data/demo/1"</span>)</span><br><span class="line">demo2.addprint(tf.constant(<span class="number">5.0</span>))</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">11</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看模型文件相关信息，红框标出来的输出信息在模型部署和跨平台使用时有可能会用到</span></span><br><span class="line">!saved_model_cli show --dir ./data/demo/<span class="number">1</span> --all</span><br></pre></td></tr></table></figure><p><img alt data-src="https://github.com/SimpCosm/eat_tensorflow2_in_30_days_ipynbs/raw/master/data/查看模型文件信息.jpg"></p><p>在tensorboard中查看计算图，模块会被添加模块名demo_module,方便层次化呈现计算图结构。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建日志</span></span><br><span class="line">stamp = datetime.datetime.now().strftime(<span class="string">"%Y%m%d-%H%M%S"</span>)</span><br><span class="line">logdir = <span class="string">'./data/demomodule/%s'</span> % stamp</span><br><span class="line">writer = tf.summary.create_file_writer(logdir)</span><br><span class="line"></span><br><span class="line"><span class="comment">#开启autograph跟踪</span></span><br><span class="line">tf.summary.trace_on(graph=<span class="literal">True</span>, profiler=<span class="literal">True</span>) </span><br><span class="line"></span><br><span class="line"><span class="comment">#执行autograph</span></span><br><span class="line">demo = DemoModule(init_value = tf.constant(<span class="number">0.0</span>))</span><br><span class="line">result = demo.addprint(tf.constant(<span class="number">5.0</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">#将计算图信息写入日志</span></span><br><span class="line"><span class="keyword">with</span> writer.as_default():</span><br><span class="line">    tf.summary.trace_export(</span><br><span class="line">        name=<span class="string">"demomodule"</span>,</span><br><span class="line">        step=<span class="number">0</span>,</span><br><span class="line">        profiler_outdir=logdir)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#启动 tensorboard在jupyter中的魔法命令</span></span><br><span class="line">%reload_ext tensorboard</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorboard <span class="keyword">import</span> notebook</span><br><span class="line">notebook.list()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">notebook.start(<span class="string">"--logdir ./data/demomodule/"</span>)</span><br></pre></td></tr></table></figure><p><img alt data-src="https://github.com/SimpCosm/eat_tensorflow2_in_30_days_ipynbs/raw/master/data/demomodule的计算图结构.jpg"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>除了利用tf.Module的子类化实现封装，我们也可以通过给tf.Module添加属性的方法进行封装。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">mymodule = tf.Module()</span><br><span class="line">mymodule.x = tf.Variable(<span class="number">0.0</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">@tf.function(input_signature=[tf.TensorSpec(shape = [], dtype = tf.float32)])  </span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">addprint</span><span class="params">(a)</span>:</span></span><br><span class="line">    mymodule.x.assign_add(a)</span><br><span class="line">    tf.print(mymodule.x)</span><br><span class="line">    <span class="keyword">return</span> (mymodule.x)</span><br><span class="line"></span><br><span class="line">mymodule.addprint = addprint</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mymodule.addprint(tf.constant(<span class="number">1.0</span>)).numpy()</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1.0</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(mymodule.variables)</span><br></pre></td></tr></table></figure><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(&lt;tf.Variable <span class="string">'Variable:0'</span> shape=() <span class="attribute">dtype</span>=float32, <span class="attribute">numpy</span>=0.0&gt;,)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#使用tf.saved_model 保存模型</span></span><br><span class="line">tf.saved_model.save(mymodule,<span class="string">"./data/mymodule"</span>,</span><br><span class="line">    signatures = &#123;<span class="string">"serving_default"</span>:mymodule.addprint&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">#加载模型</span></span><br><span class="line">mymodule2 = tf.saved_model.load(<span class="string">"./data/mymodule"</span>)</span><br><span class="line">mymodule2.addprint(tf.constant(<span class="number">5.0</span>))</span><br></pre></td></tr></table></figure><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">INFO:</span><span class="string">tensorflow:</span>Assets written <span class="string">to:</span> .<span class="regexp">/data/</span>mymodule/assets</span><br><span class="line"><span class="number">5</span></span><br></pre></td></tr></table></figure><h4 id="tf-Module和tf-keras-Model，tf-keras-layers-Layer"><a href="#tf-Module和tf-keras-Model，tf-keras-layers-Layer" class="headerlink" title="tf.Module和tf.keras.Model，tf.keras.layers.Layer"></a>tf.Module和tf.keras.Model，tf.keras.layers.Layer</h4><p>tf.keras中的模型和层都是继承tf.Module实现的，也具有变量管理和子模块管理功能。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> models,layers,losses,metrics</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">print(issubclass(tf.keras.Model,tf.Module))</span><br><span class="line">print(issubclass(tf.keras.layers.Layer,tf.Module))</span><br><span class="line">print(issubclass(tf.keras.Model,tf.keras.layers.Layer))</span><br></pre></td></tr></table></figure><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="literal">True</span></span><br><span class="line"><span class="literal">True</span></span><br><span class="line"><span class="literal">True</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">tf.keras.backend.clear_session() </span><br><span class="line"></span><br><span class="line">model = models.Sequential()</span><br><span class="line"></span><br><span class="line">model.add(layers.Dense(<span class="number">4</span>,input_shape = (<span class="number">10</span>,)))</span><br><span class="line">model.add(layers.Dense(<span class="number">2</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">1</span>))</span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">Model: "sequential"</span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">Layer (type)                 Output Shape              Param #   </span><br><span class="line">=================================================================</span><br><span class="line">dense (Dense)                (None, 4)                 44        </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">dense_1 (Dense)              (None, 2)                 10        </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">dense_2 (Dense)              (None, 1)                 3         </span><br><span class="line">=================================================================</span><br><span class="line">Total params: 57</span><br><span class="line">Trainable params: 57</span><br><span class="line">Non-trainable params: 0</span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.variables</span><br></pre></td></tr></table></figure><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">[&lt;tf.Variable 'dense/kernel:<span class="number">0</span>' shape=(<span class="number">10</span>, <span class="number">4</span>) dtype=float32, numpy=</span><br><span class="line"> array([[<span class="number">-0.06741005</span>,  <span class="number">0.45534766</span>,  <span class="number">0.5190817</span> , <span class="number">-0.01806331</span>],</span><br><span class="line">        [<span class="number">-0.14258742</span>, <span class="number">-0.49711505</span>,  <span class="number">0.26030976</span>,  <span class="number">0.18607801</span>],</span><br><span class="line">        [<span class="number">-0.62806034</span>,  <span class="number">0.5327399</span> ,  <span class="number">0.42206633</span>,  <span class="number">0.29201728</span>],</span><br><span class="line">        [<span class="number">-0.16602087</span>, <span class="number">-0.18901917</span>,  <span class="number">0.55159235</span>, <span class="number">-0.01091868</span>],</span><br><span class="line">        [ <span class="number">0.04533798</span>,  <span class="number">0.326845</span>  , <span class="number">-0.582667</span>  ,  <span class="number">0.19431782</span>],</span><br><span class="line">        [ <span class="number">0.6494713</span> , <span class="number">-0.16174704</span>,  <span class="number">0.4062966</span> ,  <span class="number">0.48760796</span>],</span><br><span class="line">        [ <span class="number">0.58400524</span>, <span class="number">-0.6280886</span> , <span class="number">-0.11265379</span>, <span class="number">-0.6438277</span> ],</span><br><span class="line">        [ <span class="number">0.26642334</span>,  <span class="number">0.49275804</span>,  <span class="number">0.20793378</span>, <span class="number">-0.43889117</span>],</span><br><span class="line">        [ <span class="number">0.4092741</span> ,  <span class="number">0.09871006</span>, <span class="number">-0.2073121</span> ,  <span class="number">0.26047975</span>],</span><br><span class="line">        [ <span class="number">0.43910992</span>,  <span class="number">0.00199282</span>, <span class="number">-0.07711256</span>, <span class="number">-0.27966842</span>]],</span><br><span class="line">       dtype=float32)&gt;,</span><br><span class="line"> &lt;tf.Variable 'dense/bias:<span class="number">0</span>' shape=(<span class="number">4</span>,) dtype=float32, numpy=array([<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>], dtype=float32)&gt;,</span><br><span class="line"> &lt;tf.Variable 'dense_1/kernel:<span class="number">0</span>' shape=(<span class="number">4</span>, <span class="number">2</span>) dtype=float32, numpy=</span><br><span class="line"> array([[ <span class="number">0.5022683</span> , <span class="number">-0.0507431</span> ],</span><br><span class="line">        [<span class="number">-0.61540484</span>,  <span class="number">0.9369011</span> ],</span><br><span class="line">        [<span class="number">-0.14412141</span>, <span class="number">-0.54607415</span>],</span><br><span class="line">        [ <span class="number">0.2027781</span> , <span class="number">-0.4651153</span> ]], dtype=float32)&gt;,</span><br><span class="line"> &lt;tf.Variable 'dense_1/bias:<span class="number">0</span>' shape=(<span class="number">2</span>,) dtype=float32, numpy=array([<span class="number">0.</span>, <span class="number">0.</span>], dtype=float32)&gt;,</span><br><span class="line"> &lt;tf.Variable 'dense_2/kernel:<span class="number">0</span>' shape=(<span class="number">2</span>, <span class="number">1</span>) dtype=float32, numpy=</span><br><span class="line"> array([[<span class="number">-0.244825</span> ],</span><br><span class="line">        [<span class="number">-1.2101456</span>]], dtype=float32)&gt;,</span><br><span class="line"> &lt;tf.Variable 'dense_2/bias:<span class="number">0</span>' shape=(<span class="number">1</span>,) dtype=float32, numpy=array([<span class="number">0.</span>], dtype=float32)&gt;]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model.layers[<span class="number">0</span>].trainable = <span class="literal">False</span> <span class="comment">#冻结第0层的变量,使其不可训练</span></span><br><span class="line">model.trainable_variables</span><br></pre></td></tr></table></figure><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[&lt;tf.Variable 'dense_1/kernel:<span class="number">0</span>' shape=(<span class="number">4</span>, <span class="number">2</span>) dtype=float32, numpy=</span><br><span class="line"> array([[ <span class="number">0.5022683</span> , <span class="number">-0.0507431</span> ],</span><br><span class="line">        [<span class="number">-0.61540484</span>,  <span class="number">0.9369011</span> ],</span><br><span class="line">        [<span class="number">-0.14412141</span>, <span class="number">-0.54607415</span>],</span><br><span class="line">        [ <span class="number">0.2027781</span> , <span class="number">-0.4651153</span> ]], dtype=float32)&gt;,</span><br><span class="line"> &lt;tf.Variable 'dense_1/bias:<span class="number">0</span>' shape=(<span class="number">2</span>,) dtype=float32, numpy=array([<span class="number">0.</span>, <span class="number">0.</span>], dtype=float32)&gt;,</span><br><span class="line"> &lt;tf.Variable 'dense_2/kernel:<span class="number">0</span>' shape=(<span class="number">2</span>, <span class="number">1</span>) dtype=float32, numpy=</span><br><span class="line"> array([[<span class="number">-0.244825</span> ],</span><br><span class="line">        [<span class="number">-1.2101456</span>]], dtype=float32)&gt;,</span><br><span class="line"> &lt;tf.Variable 'dense_2/bias:<span class="number">0</span>' shape=(<span class="number">1</span>,) dtype=float32, numpy=array([<span class="number">0.</span>], dtype=float32)&gt;]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.submodules</span><br></pre></td></tr></table></figure><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">(&lt;<span class="selector-tag">tensorflow</span><span class="selector-class">.python</span><span class="selector-class">.keras</span><span class="selector-class">.engine</span><span class="selector-class">.input_layer</span><span class="selector-class">.InputLayer</span> <span class="selector-tag">at</span> 0<span class="selector-tag">x144d8c080</span>&gt;,</span><br><span class="line"> &lt;<span class="selector-tag">tensorflow</span><span class="selector-class">.python</span><span class="selector-class">.keras</span><span class="selector-class">.layers</span><span class="selector-class">.core</span><span class="selector-class">.Dense</span> <span class="selector-tag">at</span> 0<span class="selector-tag">x144daada0</span>&gt;,</span><br><span class="line"> &lt;<span class="selector-tag">tensorflow</span><span class="selector-class">.python</span><span class="selector-class">.keras</span><span class="selector-class">.layers</span><span class="selector-class">.core</span><span class="selector-class">.Dense</span> <span class="selector-tag">at</span> 0<span class="selector-tag">x144d8c5c0</span>&gt;,</span><br><span class="line"> &lt;<span class="selector-tag">tensorflow</span><span class="selector-class">.python</span><span class="selector-class">.keras</span><span class="selector-class">.layers</span><span class="selector-class">.core</span><span class="selector-class">.Dense</span> <span class="selector-tag">at</span> 0<span class="selector-tag">x144d7aa20</span>&gt;)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.layers</span><br></pre></td></tr></table></figure><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[&lt;tensorflow<span class="selector-class">.python</span><span class="selector-class">.keras</span><span class="selector-class">.layers</span><span class="selector-class">.core</span><span class="selector-class">.Dense</span> at <span class="number">0</span>x144daada0&gt;,</span><br><span class="line"> &lt;tensorflow<span class="selector-class">.python</span><span class="selector-class">.keras</span><span class="selector-class">.layers</span><span class="selector-class">.core</span><span class="selector-class">.Dense</span> at <span class="number">0</span>x144d8c5c0&gt;,</span><br><span class="line"> &lt;tensorflow<span class="selector-class">.python</span><span class="selector-class">.keras</span><span class="selector-class">.layers</span><span class="selector-class">.core</span><span class="selector-class">.Dense</span> at <span class="number">0</span>x144d7aa20&gt;]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(model.name)</span><br><span class="line">print(model.name_scope())</span><br></pre></td></tr></table></figure><figure class="highlight fortran"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">sequential</span></span><br><span class="line"><span class="keyword">sequential</span></span><br></pre></td></tr></table></figure><h2 id="中阶API"><a href="#中阶API" class="headerlink" title="中阶API"></a>中阶API</h2><h3 id="数据管道Dataset"><a href="#数据管道Dataset" class="headerlink" title="数据管道Dataset"></a>数据管道Dataset</h3><p>如果需要训练的数据大小不大，例如不到1G，那么可以直接全部读入内存中进行训练，这样一般效率最高。</p><p>但如果需要训练的数据很大，例如超过10G，无法一次载入内存，那么通常需要在训练的过程中分批逐渐读入。</p><p>使用 <code>tf.data</code> API 可以构建数据输入管道，轻松处理大量的数据，不同的数据格式，以及不同的数据转换。</p><h4 id="构建数据管道"><a href="#构建数据管道" class="headerlink" title="构建数据管道"></a>构建数据管道</h4><p>可以从 Numpy array, Pandas DataFrame, Python generator, csv文件, 文本文件, 文件路径, tfrecords文件等方式构建数据管道。</p><p>其中通过Numpy array, Pandas DataFrame, 文件路径构建数据管道是最常用的方法。</p><p>通过 tfrecords文件方式构建数据管道较为复杂，需要对样本构建tf.Example后压缩成字符串写到tfrecords文件，读取后再解析成tf.Example。</p><p>但tfrecords文件的优点是压缩后文件较小，便于网络传播，加载速度较快。</p><h5 id="从Numpy-array构建数据管道"><a href="#从Numpy-array构建数据管道" class="headerlink" title="从Numpy array构建数据管道"></a>从Numpy array构建数据管道</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 从Numpy array构建数据管道</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets </span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ds1 = tf.data.Dataset.from_tensor_slices((iris[<span class="string">"data"</span>],iris[<span class="string">"target"</span>]))</span><br><span class="line"><span class="keyword">for</span> features,label <span class="keyword">in</span> ds1.take(<span class="number">5</span>):</span><br><span class="line">    print(features,label)</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tf.Tensor([<span class="number">5.1</span> <span class="number">3.5</span> <span class="number">1.4</span> <span class="number">0.2</span>], shape=(<span class="number">4</span>,), dtype=<span class="built_in">float</span>64) tf.Tensor(<span class="number">0</span>, shape=(), dtype=<span class="built_in">int</span>64)</span><br><span class="line">tf.Tensor([<span class="number">4.9</span> <span class="number">3.</span>  <span class="number">1.4</span> <span class="number">0.2</span>], shape=(<span class="number">4</span>,), dtype=<span class="built_in">float</span>64) tf.Tensor(<span class="number">0</span>, shape=(), dtype=<span class="built_in">int</span>64)</span><br><span class="line">tf.Tensor([<span class="number">4.7</span> <span class="number">3.2</span> <span class="number">1.3</span> <span class="number">0.2</span>], shape=(<span class="number">4</span>,), dtype=<span class="built_in">float</span>64) tf.Tensor(<span class="number">0</span>, shape=(), dtype=<span class="built_in">int</span>64)</span><br><span class="line">tf.Tensor([<span class="number">4.6</span> <span class="number">3.1</span> <span class="number">1.5</span> <span class="number">0.2</span>], shape=(<span class="number">4</span>,), dtype=<span class="built_in">float</span>64) tf.Tensor(<span class="number">0</span>, shape=(), dtype=<span class="built_in">int</span>64)</span><br><span class="line">tf.Tensor([<span class="number">5.</span>  <span class="number">3.6</span> <span class="number">1.4</span> <span class="number">0.2</span>], shape=(<span class="number">4</span>,), dtype=<span class="built_in">float</span>64) tf.Tensor(<span class="number">0</span>, shape=(), dtype=<span class="built_in">int</span>64)</span><br></pre></td></tr></table></figure><h5 id="从-Pandas-DataFrame构建数据管道"><a href="#从-Pandas-DataFrame构建数据管道" class="headerlink" title="从 Pandas DataFrame构建数据管道"></a>从 Pandas DataFrame构建数据管道</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 从 Pandas DataFrame构建数据管道</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets </span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line">dfiris = pd.DataFrame(iris[<span class="string">"data"</span>],columns = iris.feature_names)</span><br><span class="line">ds2 = tf.data.Dataset.from_tensor_slices((dfiris.to_dict(<span class="string">"list"</span>),iris[<span class="string">"target"</span>]))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> features,label <span class="keyword">in</span> ds2.take(<span class="number">3</span>):</span><br><span class="line">    print(features,label)</span><br></pre></td></tr></table></figure><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="string">'sepal length (cm)'</span>: &lt;tf.Tensor: shape=(), <span class="attribute">dtype</span>=float32, <span class="attribute">numpy</span>=5.1&gt;, <span class="string">'sepal width (cm)'</span>: &lt;tf.Tensor: shape=(), <span class="attribute">dtype</span>=float32, <span class="attribute">numpy</span>=3.5&gt;, <span class="string">'petal length (cm)'</span>: &lt;tf.Tensor: shape=(), <span class="attribute">dtype</span>=float32, <span class="attribute">numpy</span>=1.4&gt;, <span class="string">'petal width (cm)'</span>: &lt;tf.Tensor: shape=(), <span class="attribute">dtype</span>=float32, <span class="attribute">numpy</span>=0.2&gt;&#125; tf.Tensor(0, shape=(), <span class="attribute">dtype</span>=int64)</span><br><span class="line">&#123;<span class="string">'sepal length (cm)'</span>: &lt;tf.Tensor: shape=(), <span class="attribute">dtype</span>=float32, <span class="attribute">numpy</span>=4.9&gt;, <span class="string">'sepal width (cm)'</span>: &lt;tf.Tensor: shape=(), <span class="attribute">dtype</span>=float32, <span class="attribute">numpy</span>=3.0&gt;, <span class="string">'petal length (cm)'</span>: &lt;tf.Tensor: shape=(), <span class="attribute">dtype</span>=float32, <span class="attribute">numpy</span>=1.4&gt;, <span class="string">'petal width (cm)'</span>: &lt;tf.Tensor: shape=(), <span class="attribute">dtype</span>=float32, <span class="attribute">numpy</span>=0.2&gt;&#125; tf.Tensor(0, shape=(), <span class="attribute">dtype</span>=int64)</span><br><span class="line">&#123;<span class="string">'sepal length (cm)'</span>: &lt;tf.Tensor: shape=(), <span class="attribute">dtype</span>=float32, <span class="attribute">numpy</span>=4.7&gt;, <span class="string">'sepal width (cm)'</span>: &lt;tf.Tensor: shape=(), <span class="attribute">dtype</span>=float32, <span class="attribute">numpy</span>=3.2&gt;, <span class="string">'petal length (cm)'</span>: &lt;tf.Tensor: shape=(), <span class="attribute">dtype</span>=float32, <span class="attribute">numpy</span>=1.3&gt;, <span class="string">'petal width (cm)'</span>: &lt;tf.Tensor: shape=(), <span class="attribute">dtype</span>=float32, <span class="attribute">numpy</span>=0.2&gt;&#125; tf.Tensor(0, shape=(), <span class="attribute">dtype</span>=int64)</span><br></pre></td></tr></table></figure><h5 id="从Python-generator构建数据管道"><a href="#从Python-generator构建数据管道" class="headerlink" title="从Python generator构建数据管道"></a>从Python generator构建数据管道</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 从Python generator构建数据管道</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt </span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.preprocessing.image <span class="keyword">import</span> ImageDataGenerator</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义一个从文件中读取图片的generator</span></span><br><span class="line">image_generator = ImageDataGenerator(rescale=<span class="number">1.0</span>/<span class="number">255</span>).flow_from_directory(</span><br><span class="line">                    <span class="string">"./data/cifar2/test/"</span>,</span><br><span class="line">                    target_size=(<span class="number">32</span>, <span class="number">32</span>),</span><br><span class="line">                    batch_size=<span class="number">20</span>,</span><br><span class="line">                    class_mode=<span class="string">'binary'</span>)</span><br><span class="line"></span><br><span class="line">classdict = image_generator.class_indices</span><br><span class="line">print(classdict)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generator</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">for</span> features,label <span class="keyword">in</span> image_generator:</span><br><span class="line">        <span class="keyword">yield</span> (features,label)</span><br><span class="line"></span><br><span class="line">ds3 = tf.data.Dataset.from_generator(generator,output_types=(tf.float32,tf.int32))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line">%config InlineBackend.figure_format = <span class="string">'svg'</span></span><br><span class="line">plt.figure(figsize=(<span class="number">6</span>,<span class="number">6</span>)) </span><br><span class="line"><span class="keyword">for</span> i,(img,label) <span class="keyword">in</span> enumerate(ds3.unbatch().take(<span class="number">9</span>)):</span><br><span class="line">    ax=plt.subplot(<span class="number">3</span>,<span class="number">3</span>,i+<span class="number">1</span>)</span><br><span class="line">    ax.imshow(img.numpy())</span><br><span class="line">    ax.set_title(<span class="string">"label = %d"</span>%label)</span><br><span class="line">    ax.set_xticks([])</span><br><span class="line">    ax.set_yticks([]) </span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img alt data-src="https://github.com/SimpCosm/eat_tensorflow2_in_30_days_ipynbs/raw/master/data/5-1-cifar2预览.jpg"></p><h5 id="从csv文件构建数据管道"><a href="#从csv文件构建数据管道" class="headerlink" title="从csv文件构建数据管道"></a>从csv文件构建数据管道</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 从csv文件构建数据管道</span></span><br><span class="line">ds4 = tf.data.experimental.make_csv_dataset(</span><br><span class="line">      file_pattern = [<span class="string">"./data/titanic/train.csv"</span>,<span class="string">"./data/titanic/test.csv"</span>],</span><br><span class="line">      batch_size=<span class="number">3</span>, </span><br><span class="line">      label_name=<span class="string">"Survived"</span>,</span><br><span class="line">      na_value=<span class="string">""</span>,</span><br><span class="line">      num_epochs=<span class="number">1</span>,</span><br><span class="line">      ignore_errors=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> data,label <span class="keyword">in</span> ds4.take(<span class="number">2</span>):</span><br><span class="line">    print(data,label)</span><br></pre></td></tr></table></figure><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">OrderedDict([(<span class="string">'PassengerId'</span>, &lt;tf.Tensor: shape=(3,), <span class="attribute">dtype</span>=int32, <span class="attribute">numpy</span>=array([540,  58, 764], <span class="attribute">dtype</span>=int32)&gt;), (<span class="string">'Pclass'</span>, &lt;tf.Tensor: shape=(3,), <span class="attribute">dtype</span>=int32, <span class="attribute">numpy</span>=array([1, 3, 1], <span class="attribute">dtype</span>=int32)&gt;), (<span class="string">'Name'</span>, &lt;tf.Tensor: shape=(3,), <span class="attribute">dtype</span>=string, numpy=</span><br><span class="line">array([b<span class="string">'Frolicher, Miss. Hedwig Margaritha'</span>, b<span class="string">'Novel, Mr. Mansouer'</span>,</span><br><span class="line">       b<span class="string">'Carter, Mrs. William Ernest (Lucile Polk)'</span>], <span class="attribute">dtype</span>=object)&gt;), (<span class="string">'Sex'</span>, &lt;tf.Tensor: shape=(3,), <span class="attribute">dtype</span>=string, <span class="attribute">numpy</span>=array([b<span class="string">'female'</span>, b<span class="string">'male'</span>, b<span class="string">'female'</span>], <span class="attribute">dtype</span>=object)&gt;), (<span class="string">'Age'</span>, &lt;tf.Tensor: shape=(3,), <span class="attribute">dtype</span>=float32, <span class="attribute">numpy</span>=array([22. , 28.5, 36. ], <span class="attribute">dtype</span>=float32)&gt;), (<span class="string">'SibSp'</span>, &lt;tf.Tensor: shape=(3,), <span class="attribute">dtype</span>=int32, <span class="attribute">numpy</span>=array([0, 0, 1], <span class="attribute">dtype</span>=int32)&gt;), (<span class="string">'Parch'</span>, &lt;tf.Tensor: shape=(3,), <span class="attribute">dtype</span>=int32, <span class="attribute">numpy</span>=array([2, 0, 2], <span class="attribute">dtype</span>=int32)&gt;), (<span class="string">'Ticket'</span>, &lt;tf.Tensor: shape=(3,), <span class="attribute">dtype</span>=string, <span class="attribute">numpy</span>=array([b<span class="string">'13568'</span>, b<span class="string">'2697'</span>, b<span class="string">'113760'</span>], <span class="attribute">dtype</span>=object)&gt;), (<span class="string">'Fare'</span>, &lt;tf.Tensor: shape=(3,), <span class="attribute">dtype</span>=float32, <span class="attribute">numpy</span>=array([ 49.5   ,   7.2292, 120.    ], <span class="attribute">dtype</span>=float32)&gt;), (<span class="string">'Cabin'</span>, &lt;tf.Tensor: shape=(3,), <span class="attribute">dtype</span>=string, <span class="attribute">numpy</span>=array([b<span class="string">'B39'</span>, b<span class="string">''</span>, b<span class="string">'B96 B98'</span>], <span class="attribute">dtype</span>=object)&gt;), (<span class="string">'Embarked'</span>, &lt;tf.Tensor: shape=(3,), <span class="attribute">dtype</span>=string, <span class="attribute">numpy</span>=array([b<span class="string">'C'</span>, b<span class="string">'C'</span>, b<span class="string">'S'</span>], <span class="attribute">dtype</span>=object)&gt;)]) tf.Tensor([1 0 1], shape=(3,), <span class="attribute">dtype</span>=int32)</span><br><span class="line">OrderedDict([(<span class="string">'PassengerId'</span>, &lt;tf.Tensor: shape=(3,), <span class="attribute">dtype</span>=int32, <span class="attribute">numpy</span>=array([845,  66, 390], <span class="attribute">dtype</span>=int32)&gt;), (<span class="string">'Pclass'</span>, &lt;tf.Tensor: shape=(3,), <span class="attribute">dtype</span>=int32, <span class="attribute">numpy</span>=array([3, 3, 2], <span class="attribute">dtype</span>=int32)&gt;), (<span class="string">'Name'</span>, &lt;tf.Tensor: shape=(3,), <span class="attribute">dtype</span>=string, numpy=</span><br><span class="line">array([b<span class="string">'Culumovic, Mr. Jeso'</span>, b<span class="string">'Moubarek, Master. Gerios'</span>,</span><br><span class="line">       b<span class="string">'Lehmann, Miss. Bertha'</span>], <span class="attribute">dtype</span>=object)&gt;), (<span class="string">'Sex'</span>, &lt;tf.Tensor: shape=(3,), <span class="attribute">dtype</span>=string, <span class="attribute">numpy</span>=array([b<span class="string">'male'</span>, b<span class="string">'male'</span>, b<span class="string">'female'</span>], <span class="attribute">dtype</span>=object)&gt;), (<span class="string">'Age'</span>, &lt;tf.Tensor: shape=(3,), <span class="attribute">dtype</span>=float32, <span class="attribute">numpy</span>=array([17.,  0., 17.], <span class="attribute">dtype</span>=float32)&gt;), (<span class="string">'SibSp'</span>, &lt;tf.Tensor: shape=(3,), <span class="attribute">dtype</span>=int32, <span class="attribute">numpy</span>=array([0, 1, 0], <span class="attribute">dtype</span>=int32)&gt;), (<span class="string">'Parch'</span>, &lt;tf.Tensor: shape=(3,), <span class="attribute">dtype</span>=int32, <span class="attribute">numpy</span>=array([0, 1, 0], <span class="attribute">dtype</span>=int32)&gt;), (<span class="string">'Ticket'</span>, &lt;tf.Tensor: shape=(3,), <span class="attribute">dtype</span>=string, <span class="attribute">numpy</span>=array([b<span class="string">'315090'</span>, b<span class="string">'2661'</span>, b<span class="string">'SC 1748'</span>], <span class="attribute">dtype</span>=object)&gt;), (<span class="string">'Fare'</span>, &lt;tf.Tensor: shape=(3,), <span class="attribute">dtype</span>=float32, <span class="attribute">numpy</span>=array([ 8.6625, 15.2458, 12.    ], <span class="attribute">dtype</span>=float32)&gt;), (<span class="string">'Cabin'</span>, &lt;tf.Tensor: shape=(3,), <span class="attribute">dtype</span>=string, <span class="attribute">numpy</span>=array([b<span class="string">''</span>, b<span class="string">''</span>, b<span class="string">''</span>], <span class="attribute">dtype</span>=object)&gt;), (<span class="string">'Embarked'</span>, &lt;tf.Tensor: shape=(3,), <span class="attribute">dtype</span>=string, <span class="attribute">numpy</span>=array([b<span class="string">'S'</span>, b<span class="string">'C'</span>, b<span class="string">'C'</span>], <span class="attribute">dtype</span>=object)&gt;)]) tf.Tensor([0 1 1], shape=(3,), <span class="attribute">dtype</span>=int32)</span><br></pre></td></tr></table></figure><h5 id="从文本文件构建数据管道"><a href="#从文本文件构建数据管道" class="headerlink" title="从文本文件构建数据管道"></a>从文本文件构建数据管道</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 从文本文件构建数据管道</span></span><br><span class="line"></span><br><span class="line">ds5 = tf.data.TextLineDataset(</span><br><span class="line">    filenames = [<span class="string">"./data/titanic/train.csv"</span>,<span class="string">"./data/titanic/test.csv"</span>]</span><br><span class="line">    ).skip(<span class="number">1</span>) <span class="comment">#略去第一行header</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> ds5.take(<span class="number">5</span>):</span><br><span class="line">    print(line)</span><br></pre></td></tr></table></figure><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tf.Tensor(b'<span class="number">493</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="string">"Molson, Mr. Harry Markland"</span>,male,<span class="number">55.0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">113787</span>,<span class="number">30.5</span>,C30,S', shape=(), dtype=<span class="type">string</span>)</span><br><span class="line">tf.Tensor(b'<span class="number">53</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="string">"Harper, Mrs. Henry Sleeper (Myna Haxtun)"</span>,female,<span class="number">49.0</span>,<span class="number">1</span>,<span class="number">0</span>,PC <span class="number">17572</span>,<span class="number">76.7292</span>,D33,C', shape=(), dtype=<span class="type">string</span>)</span><br><span class="line">tf.Tensor(b'<span class="number">388</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="string">"Buss, Miss. Kate"</span>,female,<span class="number">36.0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">27849</span>,<span class="number">13.0</span>,,S', shape=(), dtype=<span class="type">string</span>)</span><br><span class="line">tf.Tensor(b'<span class="number">192</span>,<span class="number">0</span>,<span class="number">2</span>,<span class="string">"Carbines, Mr. William"</span>,male,<span class="number">19.0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">28424</span>,<span class="number">13.0</span>,,S', shape=(), dtype=<span class="type">string</span>)</span><br><span class="line">tf.Tensor(b'<span class="number">687</span>,<span class="number">0</span>,<span class="number">3</span>,<span class="string">"Panula, Mr. Jaako Arnold"</span>,male,<span class="number">14.0</span>,<span class="number">4</span>,<span class="number">1</span>,<span class="number">3101295</span>,<span class="number">39.6875</span>,,S', shape=(), dtype=<span class="type">string</span>)</span><br></pre></td></tr></table></figure><h5 id="从文件路径构建数据管道"><a href="#从文件路径构建数据管道" class="headerlink" title="从文件路径构建数据管道"></a>从文件路径构建数据管道</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ds6 = tf.data.Dataset.list_files(<span class="string">"./data/cifar2/train/*/*.jpg"</span>)</span><br><span class="line"><span class="keyword">for</span> file <span class="keyword">in</span> ds6.take(<span class="number">5</span>):</span><br><span class="line">    print(file)</span><br></pre></td></tr></table></figure><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tf.<span class="constructor">Tensor(<span class="params">b</span>'.<span class="operator">/</span><span class="params">data</span><span class="operator">/</span><span class="params">cifar2</span><span class="operator">/</span><span class="params">train</span><span class="operator">/</span><span class="params">automobile</span><span class="operator">/</span>1263.<span class="params">jpg</span>', <span class="params">shape</span>=()</span>, dtype=<span class="built_in">string</span>)</span><br><span class="line">tf.<span class="constructor">Tensor(<span class="params">b</span>'.<span class="operator">/</span><span class="params">data</span><span class="operator">/</span><span class="params">cifar2</span><span class="operator">/</span><span class="params">train</span><span class="operator">/</span><span class="params">airplane</span><span class="operator">/</span>2837.<span class="params">jpg</span>', <span class="params">shape</span>=()</span>, dtype=<span class="built_in">string</span>)</span><br><span class="line">tf.<span class="constructor">Tensor(<span class="params">b</span>'.<span class="operator">/</span><span class="params">data</span><span class="operator">/</span><span class="params">cifar2</span><span class="operator">/</span><span class="params">train</span><span class="operator">/</span><span class="params">airplane</span><span class="operator">/</span>4264.<span class="params">jpg</span>', <span class="params">shape</span>=()</span>, dtype=<span class="built_in">string</span>)</span><br><span class="line">tf.<span class="constructor">Tensor(<span class="params">b</span>'.<span class="operator">/</span><span class="params">data</span><span class="operator">/</span><span class="params">cifar2</span><span class="operator">/</span><span class="params">train</span><span class="operator">/</span><span class="params">automobile</span><span class="operator">/</span>4241.<span class="params">jpg</span>', <span class="params">shape</span>=()</span>, dtype=<span class="built_in">string</span>)</span><br><span class="line">tf.<span class="constructor">Tensor(<span class="params">b</span>'.<span class="operator">/</span><span class="params">data</span><span class="operator">/</span><span class="params">cifar2</span><span class="operator">/</span><span class="params">train</span><span class="operator">/</span><span class="params">automobile</span><span class="operator">/</span>192.<span class="params">jpg</span>', <span class="params">shape</span>=()</span>, dtype=<span class="built_in">string</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_image</span><span class="params">(img_path,size = <span class="params">(<span class="number">32</span>,<span class="number">32</span>)</span>)</span>:</span></span><br><span class="line">    label = <span class="number">1</span> <span class="keyword">if</span> tf.strings.regex_full_match(img_path,<span class="string">".*/automobile/.*"</span>) <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">    img = tf.io.read_file(img_path)</span><br><span class="line">    img = tf.image.decode_jpeg(img) <span class="comment">#注意此处为jpeg格式</span></span><br><span class="line">    img = tf.image.resize(img,size)</span><br><span class="line">    <span class="keyword">return</span>(img,label)</span><br><span class="line"></span><br><span class="line">%matplotlib inline</span><br><span class="line">%config InlineBackend.figure_format = <span class="string">'svg'</span></span><br><span class="line"><span class="keyword">for</span> i,(img,label) <span class="keyword">in</span> enumerate(ds6.map(load_image).take(<span class="number">2</span>)):</span><br><span class="line">    plt.figure(i)</span><br><span class="line">    plt.imshow((img/<span class="number">255.0</span>).numpy())</span><br><span class="line">    plt.title(<span class="string">"label = %d"</span>%label)</span><br><span class="line">    plt.xticks([])</span><br><span class="line">    plt.yticks([])</span><br></pre></td></tr></table></figure><p><img alt data-src="https://github.com/SimpCosm/eat_tensorflow2_in_30_days_ipynbs/raw/master/data/5-1-car2.jpg"></p><h5 id="从tfrecords文件构建数据管道"><a href="#从tfrecords文件构建数据管道" class="headerlink" title="从tfrecords文件构建数据管道"></a>从tfrecords文件构建数据管道</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># inpath：原始数据路径 outpath:TFRecord文件输出路径</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_tfrecords</span><span class="params">(inpath,outpath)</span>:</span> </span><br><span class="line">    writer = tf.io.TFRecordWriter(outpath)</span><br><span class="line">    dirs = os.listdir(inpath)</span><br><span class="line">    <span class="keyword">for</span> index, name <span class="keyword">in</span> enumerate(dirs):</span><br><span class="line">        class_path = inpath +<span class="string">"/"</span>+ name+<span class="string">"/"</span></span><br><span class="line">        <span class="keyword">for</span> img_name <span class="keyword">in</span> os.listdir(class_path):</span><br><span class="line">            img_path = class_path + img_name</span><br><span class="line">            img = tf.io.read_file(img_path)</span><br><span class="line">            <span class="comment">#img = tf.image.decode_image(img)</span></span><br><span class="line">            <span class="comment">#img = tf.image.encode_jpeg(img) #统一成jpeg格式压缩</span></span><br><span class="line">            example = tf.train.Example(</span><br><span class="line">               features=tf.train.Features(feature=&#123;</span><br><span class="line">                    <span class="string">'label'</span>: tf.train.Feature(int64_list=tf.train.Int64List(value=[index])),</span><br><span class="line">                    <span class="string">'img_raw'</span>: tf.train.Feature(bytes_list=tf.train.BytesList(value=[img.numpy()]))</span><br><span class="line">               &#125;))</span><br><span class="line">            writer.write(example.SerializeToString())</span><br><span class="line">    writer.close()</span><br><span class="line">    </span><br><span class="line">create_tfrecords(<span class="string">"./data/cifar2/test/"</span>,<span class="string">"./data/cifar2_test.tfrecords/"</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_example</span><span class="params">(proto)</span>:</span></span><br><span class="line">    description =&#123; <span class="string">'img_raw'</span> : tf.io.FixedLenFeature([], tf.string),</span><br><span class="line">                   <span class="string">'label'</span>: tf.io.FixedLenFeature([], tf.int64)&#125; </span><br><span class="line">    example = tf.io.parse_single_example(proto, description)</span><br><span class="line">    img = tf.image.decode_jpeg(example[<span class="string">"img_raw"</span>])   <span class="comment">#注意此处为jpeg格式</span></span><br><span class="line">    img = tf.image.resize(img, (<span class="number">32</span>,<span class="number">32</span>))</span><br><span class="line">    label = example[<span class="string">"label"</span>]</span><br><span class="line">    <span class="keyword">return</span>(img,label)</span><br><span class="line"></span><br><span class="line">ds7 = tf.data.TFRecordDataset(<span class="string">"./data/cifar2_test.tfrecords"</span>).map(parse_example).shuffle(<span class="number">3000</span>)</span><br><span class="line"></span><br><span class="line">%matplotlib inline</span><br><span class="line">%config InlineBackend.figure_format = <span class="string">'svg'</span></span><br><span class="line">plt.figure(figsize=(<span class="number">6</span>,<span class="number">6</span>)) </span><br><span class="line"><span class="keyword">for</span> i,(img,label) <span class="keyword">in</span> enumerate(ds7.take(<span class="number">9</span>)):</span><br><span class="line">    ax=plt.subplot(<span class="number">3</span>,<span class="number">3</span>,i+<span class="number">1</span>)</span><br><span class="line">    ax.imshow((img/<span class="number">255.0</span>).numpy())</span><br><span class="line">    ax.set_title(<span class="string">"label = %d"</span>%label)</span><br><span class="line">    ax.set_xticks([])</span><br><span class="line">    ax.set_yticks([]) </span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img alt data-src="https://github.com/SimpCosm/eat_tensorflow2_in_30_days_ipynbs/raw/master/data/5-1-car9.jpg"></p><h4 id="应用数据转换"><a href="#应用数据转换" class="headerlink" title="应用数据转换"></a>应用数据转换</h4><p>Dataset数据结构应用非常灵活，因为它本质上是一个Sequece序列，其每个元素可以是各种类型，例如可以是张量，列表，字典，也可以是Dataset。</p><p>Dataset包含了非常丰富的数据转换功能。</p><ul><li><p>map: 将转换函数映射到数据集每一个元素。</p></li><li><p>flat_map: 将转换函数映射到数据集的每一个元素，并将嵌套的Dataset压平。</p></li><li><p>interleave: 效果类似flat_map,但可以将不同来源的数据夹在一起。</p></li><li><p>filter: 过滤掉某些元素。</p></li><li><p>zip: 将两个长度相同的Dataset横向铰合。</p></li><li><p>concatenate: 将两个Dataset纵向连接。</p></li><li><p>reduce: 执行归并操作。</p></li><li><p>batch : 构建批次，每次放一个批次。比原始数据增加一个维度。 其逆操作为unbatch。</p></li><li><p>padded_batch: 构建批次，类似batch, 但可以填充到相同的形状。</p></li><li><p>window :构建滑动窗口，返回Dataset of Dataset.</p></li><li><p>shuffle: 数据顺序洗牌。</p></li><li><p>repeat: 重复数据若干次，不带参数时，重复无数次。</p></li><li><p>shard: 采样，从某个位置开始隔固定距离采样一个元素。</p></li><li><p>take: 采样，从开始位置取前几个元素。</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#map:将转换函数映射到数据集每一个元素</span></span><br><span class="line"></span><br><span class="line">ds = tf.data.Dataset.from_tensor_slices([<span class="string">"hello world"</span>,<span class="string">"hello China"</span>,<span class="string">"hello Beijing"</span>])</span><br><span class="line">ds_map = ds.map(<span class="keyword">lambda</span> x:tf.strings.split(x,<span class="string">" "</span>))</span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> ds_map:</span><br><span class="line">    print(x)</span><br></pre></td></tr></table></figure><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tf.<span class="constructor">Tensor([<span class="params">b</span>'<span class="params">hello</span>' <span class="params">b</span>'<span class="params">world</span>'], <span class="params">shape</span>=(2,)</span>, dtype=<span class="built_in">string</span>)</span><br><span class="line">tf.<span class="constructor">Tensor([<span class="params">b</span>'<span class="params">hello</span>' <span class="params">b</span>'China'], <span class="params">shape</span>=(2,)</span>, dtype=<span class="built_in">string</span>)</span><br><span class="line">tf.<span class="constructor">Tensor([<span class="params">b</span>'<span class="params">hello</span>' <span class="params">b</span>'Beijing'], <span class="params">shape</span>=(2,)</span>, dtype=<span class="built_in">string</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#flat_map:将转换函数映射到数据集的每一个元素，并将嵌套的Dataset压平。</span></span><br><span class="line"></span><br><span class="line">ds = tf.data.Dataset.from_tensor_slices([<span class="string">"hello world"</span>,<span class="string">"hello China"</span>,<span class="string">"hello Beijing"</span>])</span><br><span class="line">ds_flatmap = ds.flat_map(<span class="keyword">lambda</span> x:tf.data.Dataset.from_tensor_slices(tf.strings.split(x,<span class="string">" "</span>)))</span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> ds_flatmap:</span><br><span class="line">    print(x)</span><br></pre></td></tr></table></figure><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">tf.<span class="constructor">Tensor(<span class="params">b</span>'<span class="params">hello</span>', <span class="params">shape</span>=()</span>, dtype=<span class="built_in">string</span>)</span><br><span class="line">tf.<span class="constructor">Tensor(<span class="params">b</span>'<span class="params">world</span>', <span class="params">shape</span>=()</span>, dtype=<span class="built_in">string</span>)</span><br><span class="line">tf.<span class="constructor">Tensor(<span class="params">b</span>'<span class="params">hello</span>', <span class="params">shape</span>=()</span>, dtype=<span class="built_in">string</span>)</span><br><span class="line">tf.<span class="constructor">Tensor(<span class="params">b</span>'China', <span class="params">shape</span>=()</span>, dtype=<span class="built_in">string</span>)</span><br><span class="line">tf.<span class="constructor">Tensor(<span class="params">b</span>'<span class="params">hello</span>', <span class="params">shape</span>=()</span>, dtype=<span class="built_in">string</span>)</span><br><span class="line">tf.<span class="constructor">Tensor(<span class="params">b</span>'Beijing', <span class="params">shape</span>=()</span>, dtype=<span class="built_in">string</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># interleave: 效果类似flat_map,但可以将不同来源的数据夹在一起。</span></span><br><span class="line"></span><br><span class="line">ds = tf.data.Dataset.from_tensor_slices([<span class="string">"hello world"</span>,<span class="string">"hello China"</span>,<span class="string">"hello Beijing"</span>])</span><br><span class="line">ds_interleave = ds.interleave(<span class="keyword">lambda</span> x:tf.data.Dataset.from_tensor_slices(tf.strings.split(x,<span class="string">" "</span>)))</span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> ds_interleave:</span><br><span class="line">    print(x)</span><br></pre></td></tr></table></figure><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">tf.<span class="constructor">Tensor(<span class="params">b</span>'<span class="params">hello</span>', <span class="params">shape</span>=()</span>, dtype=<span class="built_in">string</span>)</span><br><span class="line">tf.<span class="constructor">Tensor(<span class="params">b</span>'<span class="params">hello</span>', <span class="params">shape</span>=()</span>, dtype=<span class="built_in">string</span>)</span><br><span class="line">tf.<span class="constructor">Tensor(<span class="params">b</span>'<span class="params">hello</span>', <span class="params">shape</span>=()</span>, dtype=<span class="built_in">string</span>)</span><br><span class="line">tf.<span class="constructor">Tensor(<span class="params">b</span>'<span class="params">world</span>', <span class="params">shape</span>=()</span>, dtype=<span class="built_in">string</span>)</span><br><span class="line">tf.<span class="constructor">Tensor(<span class="params">b</span>'China', <span class="params">shape</span>=()</span>, dtype=<span class="built_in">string</span>)</span><br><span class="line">tf.<span class="constructor">Tensor(<span class="params">b</span>'Beijing', <span class="params">shape</span>=()</span>, dtype=<span class="built_in">string</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#filter:过滤掉某些元素。</span></span><br><span class="line"></span><br><span class="line">ds = tf.data.Dataset.from_tensor_slices([<span class="string">"hello world"</span>,<span class="string">"hello China"</span>,<span class="string">"hello Beijing"</span>])</span><br><span class="line"><span class="comment">#找出含有字母a或B的元素</span></span><br><span class="line">ds_filter = ds.filter(<span class="keyword">lambda</span> x: tf.strings.regex_full_match(x, <span class="string">".*[a|B].*"</span>))</span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> ds_filter:</span><br><span class="line">    print(x)</span><br></pre></td></tr></table></figure><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tf.<span class="constructor">Tensor(<span class="params">b</span>'<span class="params">hello</span> China', <span class="params">shape</span>=()</span>, dtype=<span class="built_in">string</span>)</span><br><span class="line">tf.<span class="constructor">Tensor(<span class="params">b</span>'<span class="params">hello</span> Beijing', <span class="params">shape</span>=()</span>, dtype=<span class="built_in">string</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#zip:将两个长度相同的Dataset横向铰合。</span></span><br><span class="line"></span><br><span class="line">ds1 = tf.data.Dataset.range(<span class="number">0</span>,<span class="number">3</span>)</span><br><span class="line">ds2 = tf.data.Dataset.range(<span class="number">3</span>,<span class="number">6</span>)</span><br><span class="line">ds3 = tf.data.Dataset.range(<span class="number">6</span>,<span class="number">9</span>)</span><br><span class="line">ds_zip = tf.data.Dataset.zip((ds1,ds2,ds3))</span><br><span class="line"><span class="keyword">for</span> x,y,z <span class="keyword">in</span> ds_zip:</span><br><span class="line">    print(x.numpy(),y.numpy(),z.numpy())</span><br></pre></td></tr></table></figure><figure class="highlight basic"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">0 </span><span class="number">3</span> <span class="number">6</span></span><br><span class="line"><span class="symbol">1 </span><span class="number">4</span> <span class="number">7</span></span><br><span class="line"><span class="symbol">2 </span><span class="number">5</span> <span class="number">8</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#condatenate:将两个Dataset纵向连接。</span></span><br><span class="line"></span><br><span class="line">ds1 = tf.data.Dataset.range(<span class="number">0</span>,<span class="number">3</span>)</span><br><span class="line">ds2 = tf.data.Dataset.range(<span class="number">3</span>,<span class="number">6</span>)</span><br><span class="line">ds_concat = tf.data.Dataset.concatenate(ds1,ds2)</span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> ds_concat:</span><br><span class="line">    print(x)</span><br></pre></td></tr></table></figure><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">tf.<span class="constructor">Tensor(0, <span class="params">shape</span>=()</span>, dtype=<span class="built_in">int64</span>)</span><br><span class="line">tf.<span class="constructor">Tensor(1, <span class="params">shape</span>=()</span>, dtype=<span class="built_in">int64</span>)</span><br><span class="line">tf.<span class="constructor">Tensor(2, <span class="params">shape</span>=()</span>, dtype=<span class="built_in">int64</span>)</span><br><span class="line">tf.<span class="constructor">Tensor(3, <span class="params">shape</span>=()</span>, dtype=<span class="built_in">int64</span>)</span><br><span class="line">tf.<span class="constructor">Tensor(4, <span class="params">shape</span>=()</span>, dtype=<span class="built_in">int64</span>)</span><br><span class="line">tf.<span class="constructor">Tensor(5, <span class="params">shape</span>=()</span>, dtype=<span class="built_in">int64</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#reduce:执行归并操作。</span></span><br><span class="line"></span><br><span class="line">ds = tf.data.Dataset.from_tensor_slices([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5.0</span>])</span><br><span class="line">result = ds.reduce(<span class="number">0.0</span>,<span class="keyword">lambda</span> x,y:tf.add(x,y))</span><br><span class="line">result</span><br></pre></td></tr></table></figure><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">tf.Tensor:</span> <span class="attr">shape</span>=<span class="string">(),</span> <span class="attr">dtype</span>=<span class="string">float32,</span> <span class="attr">numpy</span>=<span class="string">15.0</span>&gt;</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#batch:构建批次，每次放一个批次。比原始数据增加一个维度。 其逆操作为unbatch。 </span></span><br><span class="line"></span><br><span class="line">ds = tf.data.Dataset.range(<span class="number">12</span>)</span><br><span class="line">ds_batch = ds.batch(<span class="number">4</span>)</span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> ds_batch:</span><br><span class="line">    print(x)</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tf.Tensor([<span class="number">0</span> <span class="number">1</span> <span class="number">2</span> <span class="number">3</span>], shape=(<span class="number">4</span>,), dtype=<span class="built_in">int</span>64)</span><br><span class="line">tf.Tensor([<span class="number">4</span> <span class="number">5</span> <span class="number">6</span> <span class="number">7</span>], shape=(<span class="number">4</span>,), dtype=<span class="built_in">int</span>64)</span><br><span class="line">tf.Tensor([ <span class="number">8</span>  <span class="number">9</span> <span class="number">10</span> <span class="number">11</span>], shape=(<span class="number">4</span>,), dtype=<span class="built_in">int</span>64)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#padded_batch:构建批次，类似batch, 但可以填充到相同的形状。</span></span><br><span class="line"></span><br><span class="line">elements = [[<span class="number">1</span>, <span class="number">2</span>],[<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>],[<span class="number">6</span>, <span class="number">7</span>],[<span class="number">8</span>]]</span><br><span class="line">ds = tf.data.Dataset.from_generator(<span class="keyword">lambda</span>: iter(elements), tf.int32)</span><br><span class="line"></span><br><span class="line">ds_padded_batch = ds.padded_batch(<span class="number">2</span>,padded_shapes = [<span class="number">4</span>,])</span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> ds_padded_batch:</span><br><span class="line">    print(x)</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">tf.Tensor(</span><br><span class="line">[[<span class="number">1</span> <span class="number">2</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">3</span> <span class="number">4</span> <span class="number">5</span> <span class="number">0</span>]], shape=(<span class="number">2</span>, <span class="number">4</span>), dtype=<span class="built_in">int</span>32)</span><br><span class="line">tf.Tensor(</span><br><span class="line">[[<span class="number">6</span> <span class="number">7</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">8</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]], shape=(<span class="number">2</span>, <span class="number">4</span>), dtype=<span class="built_in">int</span>32)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#window:构建滑动窗口，返回Dataset of Dataset.</span></span><br><span class="line"></span><br><span class="line">ds = tf.data.Dataset.range(<span class="number">12</span>)</span><br><span class="line"><span class="comment">#window返回的是Dataset of Dataset,可以用flat_map压平</span></span><br><span class="line">ds_window = ds.window(<span class="number">3</span>, shift=<span class="number">1</span>).flat_map(<span class="keyword">lambda</span> x: x.batch(<span class="number">3</span>,drop_remainder=<span class="literal">True</span>)) </span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> ds_window:</span><br><span class="line">    print(x)</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">tf.Tensor([<span class="number">0</span> <span class="number">1</span> <span class="number">2</span>], shape=(<span class="number">3</span>,), dtype=<span class="built_in">int</span>64)</span><br><span class="line">tf.Tensor([<span class="number">1</span> <span class="number">2</span> <span class="number">3</span>], shape=(<span class="number">3</span>,), dtype=<span class="built_in">int</span>64)</span><br><span class="line">tf.Tensor([<span class="number">2</span> <span class="number">3</span> <span class="number">4</span>], shape=(<span class="number">3</span>,), dtype=<span class="built_in">int</span>64)</span><br><span class="line">tf.Tensor([<span class="number">3</span> <span class="number">4</span> <span class="number">5</span>], shape=(<span class="number">3</span>,), dtype=<span class="built_in">int</span>64)</span><br><span class="line">tf.Tensor([<span class="number">4</span> <span class="number">5</span> <span class="number">6</span>], shape=(<span class="number">3</span>,), dtype=<span class="built_in">int</span>64)</span><br><span class="line">tf.Tensor([<span class="number">5</span> <span class="number">6</span> <span class="number">7</span>], shape=(<span class="number">3</span>,), dtype=<span class="built_in">int</span>64)</span><br><span class="line">tf.Tensor([<span class="number">6</span> <span class="number">7</span> <span class="number">8</span>], shape=(<span class="number">3</span>,), dtype=<span class="built_in">int</span>64)</span><br><span class="line">tf.Tensor([<span class="number">7</span> <span class="number">8</span> <span class="number">9</span>], shape=(<span class="number">3</span>,), dtype=<span class="built_in">int</span>64)</span><br><span class="line">tf.Tensor([ <span class="number">8</span>  <span class="number">9</span> <span class="number">10</span>], shape=(<span class="number">3</span>,), dtype=<span class="built_in">int</span>64)</span><br><span class="line">tf.Tensor([ <span class="number">9</span> <span class="number">10</span> <span class="number">11</span>], shape=(<span class="number">3</span>,), dtype=<span class="built_in">int</span>64)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#shuffle:数据顺序洗牌。</span></span><br><span class="line"></span><br><span class="line">ds = tf.data.Dataset.range(<span class="number">12</span>)</span><br><span class="line">ds_shuffle = ds.shuffle(buffer_size = <span class="number">5</span>)</span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> ds_shuffle:</span><br><span class="line">    print(x)</span><br></pre></td></tr></table></figure><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">tf.<span class="constructor">Tensor(1, <span class="params">shape</span>=()</span>, dtype=<span class="built_in">int64</span>)</span><br><span class="line">tf.<span class="constructor">Tensor(4, <span class="params">shape</span>=()</span>, dtype=<span class="built_in">int64</span>)</span><br><span class="line">tf.<span class="constructor">Tensor(0, <span class="params">shape</span>=()</span>, dtype=<span class="built_in">int64</span>)</span><br><span class="line">tf.<span class="constructor">Tensor(6, <span class="params">shape</span>=()</span>, dtype=<span class="built_in">int64</span>)</span><br><span class="line">tf.<span class="constructor">Tensor(5, <span class="params">shape</span>=()</span>, dtype=<span class="built_in">int64</span>)</span><br><span class="line">tf.<span class="constructor">Tensor(2, <span class="params">shape</span>=()</span>, dtype=<span class="built_in">int64</span>)</span><br><span class="line">tf.<span class="constructor">Tensor(7, <span class="params">shape</span>=()</span>, dtype=<span class="built_in">int64</span>)</span><br><span class="line">tf.<span class="constructor">Tensor(11, <span class="params">shape</span>=()</span>, dtype=<span class="built_in">int64</span>)</span><br><span class="line">tf.<span class="constructor">Tensor(3, <span class="params">shape</span>=()</span>, dtype=<span class="built_in">int64</span>)</span><br><span class="line">tf.<span class="constructor">Tensor(9, <span class="params">shape</span>=()</span>, dtype=<span class="built_in">int64</span>)</span><br><span class="line">tf.<span class="constructor">Tensor(10, <span class="params">shape</span>=()</span>, dtype=<span class="built_in">int64</span>)</span><br><span class="line">tf.<span class="constructor">Tensor(8, <span class="params">shape</span>=()</span>, dtype=<span class="built_in">int64</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#repeat:重复数据若干次，不带参数时，重复无数次。</span></span><br><span class="line"></span><br><span class="line">ds = tf.data.Dataset.range(<span class="number">3</span>)</span><br><span class="line">ds_repeat = ds.repeat(<span class="number">3</span>)</span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> ds_repeat:</span><br><span class="line">    print(x)</span><br></pre></td></tr></table></figure><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">tf.<span class="constructor">Tensor(0, <span class="params">shape</span>=()</span>, dtype=<span class="built_in">int64</span>)</span><br><span class="line">tf.<span class="constructor">Tensor(1, <span class="params">shape</span>=()</span>, dtype=<span class="built_in">int64</span>)</span><br><span class="line">tf.<span class="constructor">Tensor(2, <span class="params">shape</span>=()</span>, dtype=<span class="built_in">int64</span>)</span><br><span class="line">tf.<span class="constructor">Tensor(0, <span class="params">shape</span>=()</span>, dtype=<span class="built_in">int64</span>)</span><br><span class="line">tf.<span class="constructor">Tensor(1, <span class="params">shape</span>=()</span>, dtype=<span class="built_in">int64</span>)</span><br><span class="line">tf.<span class="constructor">Tensor(2, <span class="params">shape</span>=()</span>, dtype=<span class="built_in">int64</span>)</span><br><span class="line">tf.<span class="constructor">Tensor(0, <span class="params">shape</span>=()</span>, dtype=<span class="built_in">int64</span>)</span><br><span class="line">tf.<span class="constructor">Tensor(1, <span class="params">shape</span>=()</span>, dtype=<span class="built_in">int64</span>)</span><br><span class="line">tf.<span class="constructor">Tensor(2, <span class="params">shape</span>=()</span>, dtype=<span class="built_in">int64</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#shard:采样，从某个位置开始隔固定距离采样一个元素。</span></span><br><span class="line"></span><br><span class="line">ds = tf.data.Dataset.range(<span class="number">12</span>)</span><br><span class="line">ds_shard = ds.shard(<span class="number">3</span>,index = <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> ds_shard:</span><br><span class="line">    print(x)</span><br></pre></td></tr></table></figure><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tf.<span class="constructor">Tensor(1, <span class="params">shape</span>=()</span>, dtype=<span class="built_in">int64</span>)</span><br><span class="line">tf.<span class="constructor">Tensor(4, <span class="params">shape</span>=()</span>, dtype=<span class="built_in">int64</span>)</span><br><span class="line">tf.<span class="constructor">Tensor(7, <span class="params">shape</span>=()</span>, dtype=<span class="built_in">int64</span>)</span><br><span class="line">tf.<span class="constructor">Tensor(10, <span class="params">shape</span>=()</span>, dtype=<span class="built_in">int64</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#take:采样，从开始位置取前几个元素。</span></span><br><span class="line"></span><br><span class="line">ds = tf.data.Dataset.range(<span class="number">12</span>)</span><br><span class="line">ds_take = ds.take(<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">list(ds_take.as_numpy_iterator())</span><br></pre></td></tr></table></figure><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>]</span><br></pre></td></tr></table></figure><h4 id="提升管道性能"><a href="#提升管道性能" class="headerlink" title="提升管道性能"></a>提升管道性能</h4><p>训练深度学习模型常常会非常耗时。</p><p>模型训练的耗时主要来自于两个部分，一部分来自<strong>数据准备</strong>，另一部分来自<strong>参数迭代</strong>。</p><p>参数迭代过程的耗时通常依赖于GPU来提升。</p><p>而数据准备过程的耗时则可以通过构建高效的数据管道进行提升。</p><p>以下是一些构建高效数据管道的建议。</p><ul><li><p>使用 prefetch 方法让数据准备和参数迭代两个过程相互并行。</p></li><li><p>使用 interleave 方法可以让数据读取过程多进程执行,并将不同来源数据夹在一起。</p></li><li><p>使用 map 时设置num_parallel_calls 让数据转换过程多进程执行。</p></li><li><p>使用 cache 方法让数据在第一个epoch后缓存到内存中，仅限于数据集不大情形。</p></li><li><p>使用 map转换时，先batch, 然后采用向量化的转换方法对每个batch进行转换。</p></li></ul><p><strong>1，使用 prefetch 方法让数据准备和参数迭代两个过程相互并行。</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment">#打印时间分割线</span></span><br><span class="line"><span class="meta">@tf.function</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">printbar</span><span class="params">()</span>:</span></span><br><span class="line">    ts = tf.timestamp()</span><br><span class="line">    today_ts = ts%(<span class="number">24</span>*<span class="number">60</span>*<span class="number">60</span>)</span><br><span class="line"></span><br><span class="line">    hour = tf.cast(today_ts//<span class="number">3600</span>+<span class="number">8</span>,tf.int32)%tf.constant(<span class="number">24</span>)</span><br><span class="line">    minite = tf.cast((today_ts%<span class="number">3600</span>)//<span class="number">60</span>,tf.int32)</span><br><span class="line">    second = tf.cast(tf.floor(today_ts%<span class="number">60</span>),tf.int32)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">timeformat</span><span class="params">(m)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> tf.strings.length(tf.strings.format(<span class="string">"&#123;&#125;"</span>,m))==<span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span>(tf.strings.format(<span class="string">"0&#123;&#125;"</span>,m))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span>(tf.strings.format(<span class="string">"&#123;&#125;"</span>,m))</span><br><span class="line">    </span><br><span class="line">    timestring = tf.strings.join([timeformat(hour),timeformat(minite),</span><br><span class="line">                timeformat(second)],separator = <span class="string">":"</span>)</span><br><span class="line">    tf.print(<span class="string">"=========="</span>*<span class="number">8</span>,end = <span class="string">""</span>)</span><br><span class="line">    tf.print(timestring)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据准备和参数迭代两个过程默认情况下是串行的。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 模拟数据准备</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generator</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">        <span class="comment">#假设每次准备数据需要2s</span></span><br><span class="line">        time.sleep(<span class="number">2</span>) </span><br><span class="line">        <span class="keyword">yield</span> i </span><br><span class="line">ds = tf.data.Dataset.from_generator(generator,output_types = (tf.int32))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模拟参数迭代</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_step</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment">#假设每一步训练需要1s</span></span><br><span class="line">    time.sleep(<span class="number">1</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 训练过程预计耗时 10*2+10*1 = 30s</span></span><br><span class="line">printbar()</span><br><span class="line">tf.print(tf.constant(<span class="string">"start training..."</span>))</span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> ds:</span><br><span class="line">    train_step()  </span><br><span class="line">printbar()</span><br><span class="line">tf.print(tf.constant(<span class="string">"end training..."</span>))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用 prefetch 方法让数据准备和参数迭代两个过程相互并行。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练过程预计耗时 max(10*2,10*1) = 20s</span></span><br><span class="line">printbar()</span><br><span class="line">tf.print(tf.constant(<span class="string">"start training with prefetch..."</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># tf.data.experimental.AUTOTUNE 可以让程序自动选择合适的参数</span></span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> ds.prefetch(buffer_size = tf.data.experimental.AUTOTUNE):</span><br><span class="line">    train_step()  </span><br><span class="line">    </span><br><span class="line">printbar()</span><br><span class="line">tf.print(tf.constant(<span class="string">"end training..."</span>))</span><br></pre></td></tr></table></figure><p><strong>2，使用 interleave 方法可以让数据读取过程多进程执行,并将不同来源数据夹在一起。</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ds_files = tf.data.Dataset.list_files(<span class="string">"./data/titanic/*.csv"</span>)</span><br><span class="line">ds = ds_files.flat_map(<span class="keyword">lambda</span> x:tf.data.TextLineDataset(x).skip(<span class="number">1</span>))</span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> ds.take(<span class="number">4</span>):</span><br><span class="line">    print(line)</span><br></pre></td></tr></table></figure><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tf.Tensor(b'<span class="number">493</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="string">"Molson, Mr. Harry Markland"</span>,male,<span class="number">55.0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">113787</span>,<span class="number">30.5</span>,C30,S', shape=(), dtype=<span class="type">string</span>)</span><br><span class="line">tf.Tensor(b'<span class="number">53</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="string">"Harper, Mrs. Henry Sleeper (Myna Haxtun)"</span>,female,<span class="number">49.0</span>,<span class="number">1</span>,<span class="number">0</span>,PC <span class="number">17572</span>,<span class="number">76.7292</span>,D33,C', shape=(), dtype=<span class="type">string</span>)</span><br><span class="line">tf.Tensor(b'<span class="number">388</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="string">"Buss, Miss. Kate"</span>,female,<span class="number">36.0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">27849</span>,<span class="number">13.0</span>,,S', shape=(), dtype=<span class="type">string</span>)</span><br><span class="line">tf.Tensor(b'<span class="number">192</span>,<span class="number">0</span>,<span class="number">2</span>,<span class="string">"Carbines, Mr. William"</span>,male,<span class="number">19.0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">28424</span>,<span class="number">13.0</span>,,S', shape=(), dtype=<span class="type">string</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ds_files = tf.data.Dataset.list_files(<span class="string">"./data/titanic/*.csv"</span>)</span><br><span class="line">ds = ds_files.interleave(<span class="keyword">lambda</span> x:tf.data.TextLineDataset(x).skip(<span class="number">1</span>))</span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> ds.take(<span class="number">8</span>):</span><br><span class="line">    print(line)</span><br></pre></td></tr></table></figure><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">tf.Tensor(b'<span class="number">181</span>,<span class="number">0</span>,<span class="number">3</span>,<span class="string">"Sage, Miss. Constance Gladys"</span>,female,,<span class="number">8</span>,<span class="number">2</span>,CA. <span class="number">2343</span>,<span class="number">69.55</span>,,S', shape=(), dtype=<span class="type">string</span>)</span><br><span class="line">tf.Tensor(b'<span class="number">493</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="string">"Molson, Mr. Harry Markland"</span>,male,<span class="number">55.0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">113787</span>,<span class="number">30.5</span>,C30,S', shape=(), dtype=<span class="type">string</span>)</span><br><span class="line">tf.Tensor(b'<span class="number">405</span>,<span class="number">0</span>,<span class="number">3</span>,<span class="string">"Oreskovic, Miss. Marija"</span>,female,<span class="number">20.0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">315096</span>,<span class="number">8.6625</span>,,S', shape=(), dtype=<span class="type">string</span>)</span><br><span class="line">tf.Tensor(b'<span class="number">53</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="string">"Harper, Mrs. Henry Sleeper (Myna Haxtun)"</span>,female,<span class="number">49.0</span>,<span class="number">1</span>,<span class="number">0</span>,PC <span class="number">17572</span>,<span class="number">76.7292</span>,D33,C', shape=(), dtype=<span class="type">string</span>)</span><br><span class="line">tf.Tensor(b'<span class="number">635</span>,<span class="number">0</span>,<span class="number">3</span>,<span class="string">"Skoog, Miss. Mabel"</span>,female,<span class="number">9.0</span>,<span class="number">3</span>,<span class="number">2</span>,<span class="number">347088</span>,<span class="number">27.9</span>,,S', shape=(), dtype=<span class="type">string</span>)</span><br><span class="line">tf.Tensor(b'<span class="number">388</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="string">"Buss, Miss. Kate"</span>,female,<span class="number">36.0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">27849</span>,<span class="number">13.0</span>,,S', shape=(), dtype=<span class="type">string</span>)</span><br><span class="line">tf.Tensor(b'<span class="number">701</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="string">"Astor, Mrs. John Jacob (Madeleine Talmadge Force)"</span>,female,<span class="number">18.0</span>,<span class="number">1</span>,<span class="number">0</span>,PC <span class="number">17757</span>,<span class="number">227.525</span>,C62 C64,C', shape=(), dtype=<span class="type">string</span>)</span><br><span class="line">tf.Tensor(b'<span class="number">192</span>,<span class="number">0</span>,<span class="number">2</span>,<span class="string">"Carbines, Mr. William"</span>,male,<span class="number">19.0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">28424</span>,<span class="number">13.0</span>,,S', shape=(), dtype=<span class="type">string</span>)</span><br></pre></td></tr></table></figure><p><strong>3，使用 map 时设置num_parallel_calls 让数据转换过程多进行执行。</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ds = tf.data.Dataset.list_files(<span class="string">"./data/cifar2/train/*/*.jpg"</span>)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_image</span><span class="params">(img_path,size = <span class="params">(<span class="number">32</span>,<span class="number">32</span>)</span>)</span>:</span></span><br><span class="line">    label = <span class="number">1</span> <span class="keyword">if</span> tf.strings.regex_full_match(img_path,<span class="string">".*/automobile/.*"</span>) <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">    img = tf.io.read_file(img_path)</span><br><span class="line">    img = tf.image.decode_jpeg(img) <span class="comment">#注意此处为jpeg格式</span></span><br><span class="line">    img = tf.image.resize(img,size)</span><br><span class="line">    <span class="keyword">return</span>(img,label)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#单进程转换</span></span><br><span class="line">printbar()</span><br><span class="line">tf.print(tf.constant(<span class="string">"start transformation..."</span>))</span><br><span class="line"></span><br><span class="line">ds_map = ds.map(load_image)</span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> ds_map:</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">printbar()</span><br><span class="line">tf.print(tf.constant(<span class="string">"end transformation..."</span>))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#多进程转换</span></span><br><span class="line">printbar()</span><br><span class="line">tf.print(tf.constant(<span class="string">"start parallel transformation..."</span>))</span><br><span class="line"></span><br><span class="line">ds_map_parallel = ds.map(load_image,num_parallel_calls = tf.data.experimental.AUTOTUNE)</span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> ds_map_parallel:</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">printbar()</span><br><span class="line">tf.print(tf.constant(<span class="string">"end parallel transformation..."</span>))</span><br></pre></td></tr></table></figure><p><strong>4，使用 cache 方法让数据在第一个epoch后缓存到内存中，仅限于数据集不大情形。</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模拟数据准备</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generator</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">5</span>):</span><br><span class="line">        <span class="comment">#假设每次准备数据需要2s</span></span><br><span class="line">        time.sleep(<span class="number">2</span>) </span><br><span class="line">        <span class="keyword">yield</span> i </span><br><span class="line">ds = tf.data.Dataset.from_generator(generator,output_types = (tf.int32))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模拟参数迭代</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_step</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment">#假设每一步训练需要0s</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练过程预计耗时 (5*2+5*0)*3 = 30s</span></span><br><span class="line">printbar()</span><br><span class="line">tf.print(tf.constant(<span class="string">"start training..."</span>))</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> tf.range(<span class="number">3</span>):</span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> ds:</span><br><span class="line">        train_step()  </span><br><span class="line">    printbar()</span><br><span class="line">    tf.print(<span class="string">"epoch ="</span>,epoch,<span class="string">" ended"</span>)</span><br><span class="line">printbar()</span><br><span class="line">tf.print(tf.constant(<span class="string">"end training..."</span>))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模拟数据准备</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generator</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">5</span>):</span><br><span class="line">        <span class="comment">#假设每次准备数据需要2s</span></span><br><span class="line">        time.sleep(<span class="number">2</span>) </span><br><span class="line">        <span class="keyword">yield</span> i </span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用 cache 方法让数据在第一个epoch后缓存到内存中，仅限于数据集不大情形。</span></span><br><span class="line">ds = tf.data.Dataset.from_generator(generator,output_types = (tf.int32)).cache()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模拟参数迭代</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_step</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment">#假设每一步训练需要0s</span></span><br><span class="line">    time.sleep(<span class="number">0</span>) </span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练过程预计耗时 (5*2+5*0)+(5*0+5*0)*2 = 10s</span></span><br><span class="line">printbar()</span><br><span class="line">tf.print(tf.constant(<span class="string">"start training..."</span>))</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> tf.range(<span class="number">3</span>):</span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> ds:</span><br><span class="line">        train_step()  </span><br><span class="line">    printbar()</span><br><span class="line">    tf.print(<span class="string">"epoch ="</span>,epoch,<span class="string">" ended"</span>)</span><br><span class="line">printbar()</span><br><span class="line">tf.print(tf.constant(<span class="string">"end training..."</span>))</span><br></pre></td></tr></table></figure><p><strong>5，使用 map转换时，先batch, 然后采用向量化的转换方法对每个batch进行转换。</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#先map后batch</span></span><br><span class="line">ds = tf.data.Dataset.range(<span class="number">100000</span>)</span><br><span class="line">ds_map_batch = ds.map(<span class="keyword">lambda</span> x:x**<span class="number">2</span>).batch(<span class="number">20</span>)</span><br><span class="line"></span><br><span class="line">printbar()</span><br><span class="line">tf.print(tf.constant(<span class="string">"start scalar transformation..."</span>))</span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> ds_map_batch:</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line">printbar()</span><br><span class="line">tf.print(tf.constant(<span class="string">"end scalar transformation..."</span>))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#先batch后map</span></span><br><span class="line">ds = tf.data.Dataset.range(<span class="number">100000</span>)</span><br><span class="line">ds_batch_map = ds.batch(<span class="number">20</span>).map(<span class="keyword">lambda</span> x:x**<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">printbar()</span><br><span class="line">tf.print(tf.constant(<span class="string">"start vector transformation..."</span>))</span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> ds_batch_map:</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line">printbar()</span><br><span class="line">tf.print(tf.constant(<span class="string">"end vector transformation..."</span>))</span><br></pre></td></tr></table></figure><h3 id="特征列feature-column"><a href="#特征列feature-column" class="headerlink" title="特征列feature_column"></a>特征列feature_column</h3><p>特征列 通常用于对结构化数据实施特征工程时候使用，图像或者文本数据一般不会用到特征列。</p><h4 id="特征列用法概述"><a href="#特征列用法概述" class="headerlink" title="特征列用法概述"></a>特征列用法概述</h4><p>使用特征列可以将类别特征转换为one-hot编码特征，将连续特征构建分桶特征，以及对多个特征生成交叉特征等等。</p><p>要创建特征列，请调用 tf.feature_column 模块的函数。该模块中常用的九个函数如下图所示，所有九个函数都会返回一个 Categorical-Column 或一个<br>Dense-Column 对象，但却不会返回 bucketized_column，后者继承自这两个类。</p><p>注意：所有的Catogorical Column类型最终都要通过indicator_column转换成Dense Column类型才能传入模型！</p><p><img alt data-src="https://github.com/SimpCosm/eat_tensorflow2_in_30_days_ipynbs/raw/master/data/特征列9种.jpg"></p><ul><li>numeric_column 数值列，最常用。</li></ul><ul><li>bucketized_column 分桶列，由数值列生成，可以由一个数值列出多个特征，one-hot编码。</li></ul><ul><li>categorical_column_with_identity 分类标识列，one-hot编码，相当于分桶列每个桶为1个整数的情况。</li></ul><ul><li>categorical_column_with_vocabulary_list 分类词汇列，one-hot编码，由list指定词典。</li></ul><ul><li>categorical_column_with_vocabulary_file 分类词汇列，由文件file指定词典。</li></ul><ul><li>categorical_column_with_hash_bucket 哈希列，整数或词典较大时采用。</li></ul><ul><li>indicator_column 指标列，由Categorical Column生成，one-hot编码</li></ul><ul><li>embedding_column 嵌入列，由Categorical Column生成，嵌入矢量分布参数需要学习。嵌入矢量维数建议取类别数量的 4 次方根。</li></ul><ul><li>crossed_column 交叉列，可以由除categorical_column_with_hash_bucket的任意分类列构成。</li></ul><h4 id="特征列使用范例"><a href="#特征列使用范例" class="headerlink" title="特征列使用范例"></a>特征列使用范例</h4><p>以下是一个使用特征列解决Titanic生存问题的完整范例。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers,models</span><br><span class="line"></span><br><span class="line"><span class="comment">#打印日志</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">printlog</span><span class="params">(info)</span>:</span></span><br><span class="line">    nowtime = datetime.datetime.now().strftime(<span class="string">'%Y-%m-%d %H:%M:%S'</span>)</span><br><span class="line">    print(<span class="string">"\n"</span>+<span class="string">"=========="</span>*<span class="number">8</span> + <span class="string">"%s"</span>%nowtime)</span><br><span class="line">    print(info+<span class="string">'...\n\n'</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#================================================================================</span></span><br><span class="line"><span class="comment"># 一，构建数据管道</span></span><br><span class="line"><span class="comment">#================================================================================</span></span><br><span class="line">printlog(<span class="string">"step1: prepare dataset..."</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">dftrain_raw = pd.read_csv(<span class="string">"./data/titanic/train.csv"</span>)</span><br><span class="line">dftest_raw = pd.read_csv(<span class="string">"./data/titanic/test.csv"</span>)</span><br><span class="line"></span><br><span class="line">dfraw = pd.concat([dftrain_raw,dftest_raw])</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">prepare_dfdata</span><span class="params">(dfraw)</span>:</span></span><br><span class="line">    dfdata = dfraw.copy()</span><br><span class="line">    dfdata.columns = [x.lower() <span class="keyword">for</span> x <span class="keyword">in</span> dfdata.columns]</span><br><span class="line">    dfdata = dfdata.rename(columns=&#123;<span class="string">'survived'</span>:<span class="string">'label'</span>&#125;)</span><br><span class="line">    dfdata = dfdata.drop([<span class="string">'passengerid'</span>,<span class="string">'name'</span>],axis = <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">for</span> col,dtype <span class="keyword">in</span> dict(dfdata.dtypes).items():</span><br><span class="line">        <span class="comment"># 判断是否包含缺失值</span></span><br><span class="line">        <span class="keyword">if</span> dfdata[col].hasnans:</span><br><span class="line">            <span class="comment"># 添加标识是否缺失列</span></span><br><span class="line">            dfdata[col + <span class="string">'_nan'</span>] = pd.isna(dfdata[col]).astype(<span class="string">'int32'</span>)</span><br><span class="line">            <span class="comment"># 填充</span></span><br><span class="line">            <span class="keyword">if</span> dtype <span class="keyword">not</span> <span class="keyword">in</span> [np.object,np.str,np.unicode]:</span><br><span class="line">                dfdata[col].fillna(dfdata[col].mean(),inplace = <span class="literal">True</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                dfdata[col].fillna(<span class="string">''</span>,inplace = <span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span>(dfdata)</span><br><span class="line"></span><br><span class="line">dfdata = prepare_dfdata(dfraw)</span><br><span class="line">dftrain = dfdata.iloc[<span class="number">0</span>:len(dftrain_raw),:]</span><br><span class="line">dftest = dfdata.iloc[len(dftrain_raw):,:]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 从 dataframe 导入数据 </span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">df_to_dataset</span><span class="params">(df, shuffle=True, batch_size=<span class="number">32</span>)</span>:</span></span><br><span class="line">    dfdata = df.copy()</span><br><span class="line">    <span class="keyword">if</span> <span class="string">'label'</span> <span class="keyword">not</span> <span class="keyword">in</span> dfdata.columns:</span><br><span class="line">        ds = tf.data.Dataset.from_tensor_slices(dfdata.to_dict(orient = <span class="string">'list'</span>))</span><br><span class="line">    <span class="keyword">else</span>: </span><br><span class="line">        labels = dfdata.pop(<span class="string">'label'</span>)</span><br><span class="line">        ds = tf.data.Dataset.from_tensor_slices((dfdata.to_dict(orient = <span class="string">'list'</span>), labels))  </span><br><span class="line">    <span class="keyword">if</span> shuffle:</span><br><span class="line">        ds = ds.shuffle(buffer_size=len(dfdata))</span><br><span class="line">    ds = ds.batch(batch_size)</span><br><span class="line">    <span class="keyword">return</span> ds</span><br><span class="line"></span><br><span class="line">ds_train = df_to_dataset(dftrain)</span><br><span class="line">ds_test = df_to_dataset(dftest)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#================================================================================</span></span><br><span class="line"><span class="comment"># 二，定义特征列</span></span><br><span class="line"><span class="comment">#================================================================================</span></span><br><span class="line">printlog(<span class="string">"step2: make feature columns..."</span>)</span><br><span class="line"></span><br><span class="line">feature_columns = []</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数值列</span></span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> [<span class="string">'age'</span>,<span class="string">'fare'</span>,<span class="string">'parch'</span>,<span class="string">'sibsp'</span>] + [</span><br><span class="line">    c <span class="keyword">for</span> c <span class="keyword">in</span> dfdata.columns <span class="keyword">if</span> c.endswith(<span class="string">'_nan'</span>)]:</span><br><span class="line">    feature_columns.append(tf.feature_column.numeric_column(col))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 分桶列</span></span><br><span class="line">age = tf.feature_column.numeric_column(<span class="string">'age'</span>)</span><br><span class="line">age_buckets = tf.feature_column.bucketized_column(age, </span><br><span class="line">             boundaries=[<span class="number">18</span>, <span class="number">25</span>, <span class="number">30</span>, <span class="number">35</span>, <span class="number">40</span>, <span class="number">45</span>, <span class="number">50</span>, <span class="number">55</span>, <span class="number">60</span>, <span class="number">65</span>])</span><br><span class="line">feature_columns.append(age_buckets)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 类别列</span></span><br><span class="line"><span class="comment"># 注意：所有的Catogorical Column类型最终都要通过indicator_column转换成Dense Column类型才能传入模型！！</span></span><br><span class="line">sex = tf.feature_column.indicator_column(</span><br><span class="line">      tf.feature_column.categorical_column_with_vocabulary_list(</span><br><span class="line">      key=<span class="string">'sex'</span>,vocabulary_list=[<span class="string">"male"</span>, <span class="string">"female"</span>]))</span><br><span class="line">feature_columns.append(sex)</span><br><span class="line"></span><br><span class="line">pclass = tf.feature_column.indicator_column(</span><br><span class="line">      tf.feature_column.categorical_column_with_vocabulary_list(</span><br><span class="line">      key=<span class="string">'pclass'</span>,vocabulary_list=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]))</span><br><span class="line">feature_columns.append(pclass)</span><br><span class="line"></span><br><span class="line">ticket = tf.feature_column.indicator_column(</span><br><span class="line">     tf.feature_column.categorical_column_with_hash_bucket(<span class="string">'ticket'</span>,<span class="number">3</span>))</span><br><span class="line">feature_columns.append(ticket)</span><br><span class="line"></span><br><span class="line">embarked = tf.feature_column.indicator_column(</span><br><span class="line">      tf.feature_column.categorical_column_with_vocabulary_list(</span><br><span class="line">      key=<span class="string">'embarked'</span>,vocabulary_list=[<span class="string">'S'</span>,<span class="string">'C'</span>,<span class="string">'B'</span>]))</span><br><span class="line">feature_columns.append(embarked)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 嵌入列</span></span><br><span class="line">cabin = tf.feature_column.embedding_column(</span><br><span class="line">    tf.feature_column.categorical_column_with_hash_bucket(<span class="string">'cabin'</span>,<span class="number">32</span>),<span class="number">2</span>)</span><br><span class="line">feature_columns.append(cabin)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 交叉列</span></span><br><span class="line">pclass_cate = tf.feature_column.categorical_column_with_vocabulary_list(</span><br><span class="line">          key=<span class="string">'pclass'</span>,vocabulary_list=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line"></span><br><span class="line">crossed_feature = tf.feature_column.indicator_column(</span><br><span class="line">    tf.feature_column.crossed_column([age_buckets, pclass_cate],hash_bucket_size=<span class="number">15</span>))</span><br><span class="line"></span><br><span class="line">feature_columns.append(crossed_feature)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#================================================================================</span></span><br><span class="line"><span class="comment"># 三，定义模型</span></span><br><span class="line"><span class="comment">#================================================================================</span></span><br><span class="line">printlog(<span class="string">"step3: define model..."</span>)</span><br><span class="line"></span><br><span class="line">tf.keras.backend.clear_session()</span><br><span class="line">model = tf.keras.Sequential([</span><br><span class="line">  layers.DenseFeatures(feature_columns), <span class="comment">#将特征列放入到tf.keras.layers.DenseFeatures中!!!</span></span><br><span class="line">  layers.Dense(<span class="number">64</span>, activation=<span class="string">'relu'</span>),</span><br><span class="line">  layers.Dense(<span class="number">64</span>, activation=<span class="string">'relu'</span>),</span><br><span class="line">  layers.Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>)</span><br><span class="line">])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#================================================================================</span></span><br><span class="line"><span class="comment"># 四，训练模型</span></span><br><span class="line"><span class="comment">#================================================================================</span></span><br><span class="line">printlog(<span class="string">"step4: train model..."</span>)</span><br><span class="line"></span><br><span class="line">model.compile(optimizer=<span class="string">'adam'</span>,</span><br><span class="line">              loss=<span class="string">'binary_crossentropy'</span>,</span><br><span class="line">              metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line"></span><br><span class="line">history = model.fit(ds_train,</span><br><span class="line">          validation_data=ds_test,</span><br><span class="line">          epochs=<span class="number">10</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#================================================================================</span></span><br><span class="line"><span class="comment"># 五，评估模型</span></span><br><span class="line"><span class="comment">#================================================================================</span></span><br><span class="line">printlog(<span class="string">"step5: eval model..."</span>)</span><br><span class="line"></span><br><span class="line">model.summary()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">%matplotlib inline</span><br><span class="line">%config InlineBackend.figure_format = <span class="string">'svg'</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_metric</span><span class="params">(history, metric)</span>:</span></span><br><span class="line">    train_metrics = history.history[metric]</span><br><span class="line">    val_metrics = history.history[<span class="string">'val_'</span>+metric]</span><br><span class="line">    epochs = range(<span class="number">1</span>, len(train_metrics) + <span class="number">1</span>)</span><br><span class="line">    plt.plot(epochs, train_metrics, <span class="string">'bo--'</span>)</span><br><span class="line">    plt.plot(epochs, val_metrics, <span class="string">'ro-'</span>)</span><br><span class="line">    plt.title(<span class="string">'Training and validation '</span>+ metric)</span><br><span class="line">    plt.xlabel(<span class="string">"Epochs"</span>)</span><br><span class="line">    plt.ylabel(metric)</span><br><span class="line">    plt.legend([<span class="string">"train_"</span>+metric, <span class="string">'val_'</span>+metric])</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">plot_metric(history,<span class="string">"accuracy"</span>)</span><br></pre></td></tr></table></figure><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">Model: "sequential"</span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">Layer (type)                 Output Shape              Param #   </span><br><span class="line">=================================================================</span><br><span class="line">dense_features (DenseFeature multiple                  64        </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">dense (Dense)                multiple                  3008      </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">dense_1 (Dense)              multiple                  4160      </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">dense_2 (Dense)              multiple                  65        </span><br><span class="line">=================================================================</span><br><span class="line">Total params: 7,297</span><br><span class="line">Trainable params: 7,297</span><br><span class="line">Non-trainable params: 0</span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br></pre></td></tr></table></figure><p><img alt data-src="https://github.com/SimpCosm/eat_tensorflow2_in_30_days_ipynbs/raw/master/data/5-2-01-模型评估.jpg"></p><h3 id="激活函数activation"><a href="#激活函数activation" class="headerlink" title="激活函数activation"></a>激活函数activation</h3><p>激活函数在深度学习中扮演着非常重要的角色，它给网络赋予了非线性，从而使得神经网络能够拟合任意复杂的函数。</p><p>如果没有激活函数，无论多复杂的网络，都等价于单一的线性变换，无法对非线性函数进行拟合。</p><p>目前，深度学习中最流行的激活函数为 relu, 但也有些新推出的激活函数，例如 swish、GELU 据称效果优于relu激活函数。</p><p>激活函数的综述介绍可以参考下面两篇文章。</p><p><a href="https://zhuanlan.zhihu.com/p/98472075" target="_blank" rel="external nofollow noopener noreferrer">《一文概览深度学习中的激活函数》</a></p><p><a href="https://zhuanlan.zhihu.com/p/98472075" target="_blank" rel="external nofollow noopener noreferrer">https://zhuanlan.zhihu.com/p/98472075</a></p><p><a href="https://zhuanlan.zhihu.com/p/98863801" target="_blank" rel="external nofollow noopener noreferrer">《从ReLU到GELU,一文概览神经网络中的激活函数》</a></p><p><a href="https://zhuanlan.zhihu.com/p/98863801" target="_blank" rel="external nofollow noopener noreferrer">https://zhuanlan.zhihu.com/p/98863801</a></p><h4 id="常用激活函数"><a href="#常用激活函数" class="headerlink" title="常用激活函数"></a>常用激活函数</h4><ul><li>tf.nn.sigmoid：将实数压缩到0到1之间，一般只在二分类的最后输出层使用。主要缺陷为存在梯度消失问题，计算复杂度高，输出不以0为中心。</li></ul><p><img alt data-src="https://github.com/SimpCosm/eat_tensorflow2_in_30_days_ipynbs/raw/master/data/sigmoid.png"></p><ul><li>tf.nn.softmax：sigmoid的多分类扩展，一般只在多分类问题的最后输出层使用。</li></ul><p><img alt data-src="https://github.com/SimpCosm/eat_tensorflow2_in_30_days_ipynbs/raw/master/data/softmax说明.jpg"></p><ul><li>tf.nn.tanh：将实数压缩到-1到1之间，输出期望为0。主要缺陷为存在梯度消失问题，计算复杂度高。</li></ul><p><img alt data-src="https://github.com/SimpCosm/eat_tensorflow2_in_30_days_ipynbs/raw/master/data/tanh.png"></p><ul><li>tf.nn.relu：修正线性单元，最流行的激活函数。一般隐藏层使用。主要缺陷是：输出不以0为中心，输入小于0时存在梯度消失问题(死亡relu)。</li></ul><p><img alt data-src="https://github.com/SimpCosm/eat_tensorflow2_in_30_days_ipynbs/raw/master/data/relu.png"></p><ul><li>tf.nn.leaky_relu：对修正线性单元的改进，解决了死亡relu问题。</li></ul><p><img alt data-src="https://github.com/SimpCosm/eat_tensorflow2_in_30_days_ipynbs/raw/master/data/leaky_relu.png"></p><ul><li>tf.nn.elu：指数线性单元。对relu的改进，能够缓解死亡relu问题。</li></ul><p><img alt data-src="https://github.com/SimpCosm/eat_tensorflow2_in_30_days_ipynbs/raw/master/data/elu.png"></p><ul><li>tf.nn.selu：扩展型指数线性单元。在权重用tf.keras.initializers.lecun_normal初始化前提下能够对神经网络进行自归一化。不可能出现梯度爆炸或者梯度消失问题。需要和Dropout的变种AlphaDropout一起使用。</li></ul><p><img alt data-src="https://github.com/SimpCosm/eat_tensorflow2_in_30_days_ipynbs/raw/master/data/selu.png"></p><ul><li>tf.nn.swish：自门控激活函数。谷歌出品，相关研究指出用swish替代relu将获得轻微效果提升。</li></ul><p><img alt data-src="https://github.com/SimpCosm/eat_tensorflow2_in_30_days_ipynbs/raw/master/data/swish.png"></p><ul><li>gelu：高斯误差线性单元激活函数。在Transformer中表现最好。tf.nn模块尚没有实现该函数。</li></ul><p><img alt data-src="https://github.com/SimpCosm/eat_tensorflow2_in_30_days_ipynbs/raw/master/data/gelu.png"></p><h4 id="在模型中使用激活函数"><a href="#在模型中使用激活函数" class="headerlink" title="在模型中使用激活函数"></a>在模型中使用激活函数</h4><p>在keras模型中使用激活函数一般有两种方式，一种是作为某些层的activation参数指定，另一种是显式添加layers.Activation激活层。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers,models</span><br><span class="line"></span><br><span class="line">tf.keras.backend.clear_session()</span><br><span class="line"></span><br><span class="line">model = models.Sequential()</span><br><span class="line">model.add(layers.Dense(<span class="number">32</span>,input_shape = (<span class="literal">None</span>,<span class="number">16</span>),activation = tf.nn.relu)) <span class="comment">#通过activation参数指定</span></span><br><span class="line">model.add(layers.Dense(<span class="number">10</span>))</span><br><span class="line">model.add(layers.Activation(tf.nn.softmax))  <span class="comment"># 显式添加layers.Activation激活层</span></span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure><h3 id="模型层layers"><a href="#模型层layers" class="headerlink" title="模型层layers"></a>模型层layers</h3><p>深度学习模型一般由各种模型层组合而成。</p><p>tf.keras.layers内置了非常丰富的各种功能的模型层。例如，</p><p>layers.Dense,layers.Flatten,layers.Input,layers.DenseFeature,layers.Dropout</p><p>layers.Conv2D,layers.MaxPooling2D,layers.Conv1D</p><p>layers.Embedding,layers.GRU,layers.LSTM,layers.Bidirectional等等。</p><p>如果这些内置模型层不能够满足需求，我们也可以通过编写tf.keras.Lambda匿名模型层或继承tf.keras.layers.Layer基类构建自定义的模型层。</p><p>其中tf.keras.Lambda匿名模型层只适用于构造没有学习参数的模型层。</p><h4 id="内置模型层"><a href="#内置模型层" class="headerlink" title="内置模型层"></a>内置模型层</h4><p>一些常用的内置模型层简单介绍如下。</p><p><strong>基础层</strong></p><ul><li><p>Dense：密集连接层。参数个数 = 输入层特征数× 输出层特征数(weight)＋ 输出层特征数(bias)</p></li><li><p>Activation：激活函数层。一般放在Dense层后面，等价于在Dense层中指定activation。</p></li><li><p>Dropout：随机置零层。训练期间以一定几率将输入置0，一种正则化手段。</p></li><li><p>BatchNormalization：批标准化层。通过线性变换将输入批次缩放平移到稳定的均值和标准差。可以增强模型对输入不同分布的适应性，加快模型训练速度，有轻微正则化效果。一般在激活函数之前使用。</p></li><li><p>SpatialDropout2D：空间随机置零层。训练期间以一定几率将整个特征图置0，一种正则化手段，有利于避免特征图之间过高的相关性。</p></li><li><p>Input：输入层。通常使用Functional API方式构建模型时作为第一层。</p></li><li><p>DenseFeature：特征列接入层，用于接收一个特征列列表并产生一个密集连接层。</p></li><li><p>Flatten：压平层，用于将多维张量压成一维。</p></li><li><p>Reshape：形状重塑层，改变输入张量的形状。</p></li><li><p>Concatenate：拼接层，将多个张量在某个维度上拼接。</p></li><li><p>Add：加法层。</p></li><li><p>Subtract： 减法层。</p></li><li><p>Maximum：取最大值层。</p></li><li><p>Minimum：取最小值层。</p></li></ul><p><strong>卷积网络相关层</strong></p><ul><li><p>Conv1D：普通一维卷积，常用于文本。参数个数 = 输入通道数×卷积核尺寸(如3)×卷积核个数</p></li><li><p>Conv2D：普通二维卷积，常用于图像。参数个数 = 输入通道数×卷积核尺寸(如3乘3)×卷积核个数</p></li><li><p>Conv3D：普通三维卷积，常用于视频。参数个数 = 输入通道数×卷积核尺寸(如3乘3乘3)×卷积核个数</p></li><li><p>SeparableConv2D：二维深度可分离卷积层。不同于普通卷积同时对区域和通道操作，深度可分离卷积先操作区域，再操作通道。即先对每个通道做独立卷积操作区域，再用1乘1卷积跨通道组合操作通道。参数个数 = 输入通道数×卷积核尺寸 + 输入通道数×1×1×输出通道数。深度可分离卷积的参数数量一般远小于普通卷积，效果一般也更好。</p></li><li><p>DepthwiseConv2D：二维深度卷积层。仅有SeparableConv2D前半部分操作，即只操作区域，不操作通道，一般输出通道数和输入通道数相同，但也可以通过设置depth_multiplier让输出通道为输入通道的若干倍数。输出通道数 = 输入通道数 × depth_multiplier。参数个数 = 输入通道数×卷积核尺寸× depth_multiplier。</p></li><li><p>Conv2DTranspose：二维卷积转置层，俗称反卷积层。并非卷积的逆操作，但在卷积核相同的情况下，当其输入尺寸是卷积操作输出尺寸的情况下，卷积转置的输出尺寸恰好是卷积操作的输入尺寸。</p></li><li><p>LocallyConnected2D: 二维局部连接层。类似Conv2D，唯一的差别是没有空间上的权值共享，所以其参数个数远高于二维卷积。</p></li><li><p>MaxPool2D: 二维最大池化层。也称作下采样层。池化层无可训练参数，主要作用是降维。</p></li><li><p>AveragePooling2D: 二维平均池化层。</p></li><li><p>GlobalMaxPool2D: 全局最大池化层。每个通道仅保留一个值。一般从卷积层过渡到全连接层时使用，是Flatten的替代方案。</p></li><li><p>GlobalAvgPool2D: 全局平均池化层。每个通道仅保留一个值。</p></li></ul><p><strong>循环网络相关层</strong></p><ul><li><p>Embedding：嵌入层。一种比Onehot更加有效的对离散特征进行编码的方法。一般用于将输入中的单词映射为稠密向量。嵌入层的参数需要学习。</p></li><li><p>LSTM：长短记忆循环网络层。最普遍使用的循环网络层。具有携带轨道，遗忘门，更新门，输出门。可以较为有效地缓解梯度消失问题，从而能够适用长期依赖问题。设置return_sequences = True时可以返回各个中间步骤输出，否则只返回最终输出。</p></li><li><p>GRU：门控循环网络层。LSTM的低配版，不具有携带轨道，参数数量少于LSTM，训练速度更快。</p></li><li><p>SimpleRNN：简单循环网络层。容易存在梯度消失，不能够适用长期依赖问题。一般较少使用。</p></li><li><p>ConvLSTM2D：卷积长短记忆循环网络层。结构上类似LSTM，但对输入的转换操作和对状态的转换操作都是卷积运算。</p></li><li><p>Bidirectional：双向循环网络包装器。可以将LSTM，GRU等层包装成双向循环网络。从而增强特征提取能力。</p></li><li><p>RNN：RNN基本层。接受一个循环网络单元或一个循环单元列表，通过调用tf.keras.backend.rnn函数在序列上进行迭代从而转换成循环网络层。</p></li><li><p>LSTMCell：LSTM单元。和LSTM在整个序列上迭代相比，它仅在序列上迭代一步。可以简单理解LSTM即RNN基本层包裹LSTMCell。</p></li><li><p>GRUCell：GRU单元。和GRU在整个序列上迭代相比，它仅在序列上迭代一步。</p></li><li><p>SimpleRNNCell：SimpleRNN单元。和SimpleRNN在整个序列上迭代相比，它仅在序列上迭代一步。</p></li><li><p>AbstractRNNCell：抽象RNN单元。通过对它的子类化用户可以自定义RNN单元，再通过RNN基本层的包裹实现用户自定义循环网络层。</p></li><li><p>Attention：Dot-product类型注意力机制层。可以用于构建注意力模型。</p></li><li><p>AdditiveAttention：Additive类型注意力机制层。可以用于构建注意力模型。</p></li><li><p>TimeDistributed：时间分布包装器。包装后可以将Dense、Conv2D等作用到每一个时间片段上。</p></li></ul><h4 id="自定义模型层"><a href="#自定义模型层" class="headerlink" title="自定义模型层"></a>自定义模型层</h4><p>如果自定义模型层没有需要被训练的参数，一般推荐使用Lamda层实现。</p><p>如果自定义模型层有需要被训练的参数，则可以通过对Layer基类子类化实现。</p><p>Lambda层由于没有需要被训练的参数，只需要定义正向传播逻辑即可，使用比Layer基类子类化更加简单。</p><p>Lambda层的正向逻辑可以使用Python的lambda函数来表达，也可以用def关键字定义函数来表达。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers,models,regularizers</span><br><span class="line"></span><br><span class="line">mypower = layers.Lambda(<span class="keyword">lambda</span> x:tf.math.pow(x,<span class="number">2</span>))</span><br><span class="line">mypower(tf.range(<span class="number">5</span>))</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;tf.Tensor: shape=(<span class="number">5</span>,), dtype=<span class="built_in">int</span>32, numpy=<span class="built_in">array</span>([ <span class="number">0</span>,  <span class="number">1</span>,  <span class="number">4</span>,  <span class="number">9</span>, <span class="number">16</span>], dtype=<span class="built_in">int</span>32)&gt;</span><br></pre></td></tr></table></figure><p>Layer的子类化一般需要重新实现初始化方法，Build方法和Call方法。下面是一个简化的线性层的范例，类似Dense.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Linear</span><span class="params">(layers.Layer)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, units=<span class="number">32</span>, **kwargs)</span>:</span></span><br><span class="line">        super(Linear, self).__init__(**kwargs)</span><br><span class="line">        self.units = units</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#build方法一般定义Layer需要被训练的参数。    </span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">build</span><span class="params">(self, input_shape)</span>:</span> </span><br><span class="line">        self.w = self.add_weight(<span class="string">"w"</span>,shape=(input_shape[<span class="number">-1</span>], self.units),</span><br><span class="line">                                 initializer=<span class="string">'random_normal'</span>,</span><br><span class="line">                                 trainable=<span class="literal">True</span>) <span class="comment">#注意必须要有参数名称"w",否则会报错</span></span><br><span class="line">        self.b = self.add_weight(<span class="string">"b"</span>,shape=(self.units,),</span><br><span class="line">                                 initializer=<span class="string">'random_normal'</span>,</span><br><span class="line">                                 trainable=<span class="literal">True</span>)</span><br><span class="line">        super(Linear,self).build(input_shape) <span class="comment"># 相当于设置self.built = True</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#call方法一般定义正向传播运算逻辑，__call__方法调用了它。  </span></span><br><span class="line"><span class="meta">    @tf.function</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span><span class="params">(self, inputs)</span>:</span> </span><br><span class="line">        <span class="keyword">return</span> tf.matmul(inputs, self.w) + self.b</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#如果要让自定义的Layer通过Functional API 组合成模型时可以被保存成h5模型，需要自定义get_config方法。</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_config</span><span class="params">(self)</span>:</span>  </span><br><span class="line">        config = super(Linear, self).get_config()</span><br><span class="line">        config.update(&#123;<span class="string">'units'</span>: self.units&#125;)</span><br><span class="line">        <span class="keyword">return</span> config</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">linear = Linear(units = <span class="number">8</span>)</span><br><span class="line">print(linear.built)</span><br><span class="line"><span class="comment">#指定input_shape，显式调用build方法，第0维代表样本数量，用None填充</span></span><br><span class="line">linear.build(input_shape = (<span class="literal">None</span>,<span class="number">16</span>)) </span><br><span class="line">print(linear.built)</span><br></pre></td></tr></table></figure><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="literal">False</span></span><br><span class="line"><span class="literal">True</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">linear = Linear(units = <span class="number">8</span>)</span><br><span class="line">print(linear.built)</span><br><span class="line">linear.build(input_shape = (<span class="literal">None</span>,<span class="number">16</span>)) </span><br><span class="line">print(linear.compute_output_shape(input_shape = (<span class="literal">None</span>,<span class="number">16</span>)))</span><br></pre></td></tr></table></figure><figure class="highlight hy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="literal">False</span></span><br><span class="line">(<span class="name">None</span>, <span class="number">8</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">linear = Linear(units = <span class="number">16</span>)</span><br><span class="line">print(linear.built)</span><br><span class="line"><span class="comment">#如果built = False，调用__call__时会先调用build方法, 再调用call方法。</span></span><br><span class="line">linear(tf.random.uniform((<span class="number">100</span>,<span class="number">64</span>))) </span><br><span class="line">print(linear.built)</span><br><span class="line">config = linear.get_config()</span><br><span class="line">print(config)</span><br></pre></td></tr></table></figure><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="literal">False</span></span><br><span class="line"><span class="literal">True</span></span><br><span class="line"><span class="string">&#123;'name':</span> <span class="string">'linear_3'</span><span class="string">,</span> <span class="attr">'trainable':</span> <span class="literal">True</span><span class="string">,</span> <span class="attr">'dtype':</span> <span class="string">'float32'</span><span class="string">,</span> <span class="attr">'units':</span> <span class="number">16</span><span class="string">&#125;</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">tf.keras.backend.clear_session()</span><br><span class="line"></span><br><span class="line">model = models.Sequential()</span><br><span class="line"><span class="comment">#注意该处的input_shape会被模型加工，无需使用None代表样本数量维</span></span><br><span class="line">model.add(Linear(units = <span class="number">1</span>,input_shape = (<span class="number">2</span>,)))  </span><br><span class="line">print(<span class="string">"model.input_shape: "</span>,model.input_shape)</span><br><span class="line">print(<span class="string">"model.output_shape: "</span>,model.output_shape)</span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">model.input_shape:  (None, 2)</span><br><span class="line">model.output_shape:  (None, 1)</span><br><span class="line">Model: "sequential"</span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">Layer (type)                 Output Shape              Param #   </span><br><span class="line">=================================================================</span><br><span class="line">linear (Linear)              (None, 1)                 3         </span><br><span class="line">=================================================================</span><br><span class="line">Total params: 3</span><br><span class="line">Trainable params: 3</span><br><span class="line">Non-trainable params: 0</span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">model.compile(optimizer = <span class="string">"sgd"</span>,loss = <span class="string">"mse"</span>,metrics=[<span class="string">"mae"</span>])</span><br><span class="line">print(model.predict(tf.constant([[<span class="number">3.0</span>,<span class="number">2.0</span>],[<span class="number">4.0</span>,<span class="number">5.0</span>]])))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存成 h5模型</span></span><br><span class="line">model.save(<span class="string">"./data/linear_model.h5"</span>,save_format = <span class="string">"h5"</span>)</span><br><span class="line">model_loaded_keras = tf.keras.models.load_model(</span><br><span class="line">    <span class="string">"./data/linear_model.h5"</span>,custom_objects=&#123;<span class="string">"Linear"</span>:Linear&#125;)</span><br><span class="line">print(model_loaded_keras.predict(tf.constant([[<span class="number">3.0</span>,<span class="number">2.0</span>],[<span class="number">4.0</span>,<span class="number">5.0</span>]])))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存成 tf模型</span></span><br><span class="line">model.save(<span class="string">"./data/linear_model"</span>,save_format = <span class="string">"tf"</span>)</span><br><span class="line">model_loaded_tf = tf.keras.models.load_model(<span class="string">"./data/linear_model"</span>)</span><br><span class="line">print(model_loaded_tf.predict(tf.constant([[<span class="number">3.0</span>,<span class="number">2.0</span>],[<span class="number">4.0</span>,<span class="number">5.0</span>]])))</span><br></pre></td></tr></table></figure><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">[[-0.04092304]</span></span><br><span class="line"><span class="string"> [-0.06150477]]</span></span><br><span class="line"><span class="string">[[-0.04092304]</span></span><br><span class="line"><span class="string"> [-0.06150477]]</span></span><br><span class="line">INFO:tensorflow:Assets written to: ./data/linear_model/assets</span><br><span class="line"><span class="string">[[-0.04092304]</span></span><br><span class="line"><span class="string"> [-0.06150477]]</span></span><br></pre></td></tr></table></figure><h3 id="损失函数losses"><a href="#损失函数losses" class="headerlink" title="损失函数losses"></a>损失函数losses</h3><p>一般来说，监督学习的目标函数由损失函数和正则化项组成。（Objective = Loss + Regularization）</p><p>对于keras模型，目标函数中的正则化项一般在各层中指定，例如使用Dense的 kernel_regularizer 和 bias_regularizer等参数指定权重使用l1或者l2正则化项，此外还可以用kernel_constraint 和 bias_constraint等参数约束权重的取值范围，这也是一种正则化手段。</p><p>损失函数在模型编译时候指定。对于回归模型，通常使用的损失函数是均方损失函数 mean_squared_error。</p><p>对于二分类模型，通常使用的是二元交叉熵损失函数 binary_crossentropy。</p><p>对于多分类模型，如果label是one-hot编码的，则使用类别交叉熵损失函数 categorical_crossentropy。如果label是类别序号编码的，则需要使用稀疏类别交叉熵损失函数 sparse_categorical_crossentropy。</p><p>如果有需要，也可以自定义损失函数，自定义损失函数需要接收两个张量y_true,y_pred作为输入参数，并输出一个标量作为损失函数值。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers,models,losses,regularizers,constraints</span><br></pre></td></tr></table></figure><h4 id="损失函数和正则化项"><a href="#损失函数和正则化项" class="headerlink" title="损失函数和正则化项"></a>损失函数和正则化项</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">tf.keras.backend.clear_session()</span><br><span class="line"></span><br><span class="line">model = models.Sequential()</span><br><span class="line">model.add(layers.Dense(<span class="number">64</span>, input_dim=<span class="number">64</span>,</span><br><span class="line">                kernel_regularizer=regularizers.l2(<span class="number">0.01</span>), </span><br><span class="line">                activity_regularizer=regularizers.l1(<span class="number">0.01</span>),</span><br><span class="line">                kernel_constraint = constraints.MaxNorm(max_value=<span class="number">2</span>, axis=<span class="number">0</span>))) </span><br><span class="line">model.add(layers.Dense(<span class="number">10</span>,</span><br><span class="line">        kernel_regularizer=regularizers.l1_l2(<span class="number">0.01</span>,<span class="number">0.01</span>),activation = <span class="string">"sigmoid"</span>))</span><br><span class="line">model.compile(optimizer = <span class="string">"rmsprop"</span>,</span><br><span class="line">        loss = <span class="string">"binary_crossentropy"</span>,metrics = [<span class="string">"AUC"</span>])</span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Model: "sequential"</span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">Layer (type)                 Output Shape              Param #   </span><br><span class="line">=================================================================</span><br><span class="line">dense (Dense)                (None, 64)                4160      </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">dense_1 (Dense)              (None, 10)                650       </span><br><span class="line">=================================================================</span><br><span class="line">Total params: 4,810</span><br><span class="line">Trainable params: 4,810</span><br><span class="line">Non-trainable params: 0</span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br></pre></td></tr></table></figure><h4 id="内置损失函数"><a href="#内置损失函数" class="headerlink" title="内置损失函数"></a>内置损失函数</h4><p>内置的损失函数一般有类的实现和函数的实现两种形式。</p><p>如：CategoricalCrossentropy 和 categorical_crossentropy 都是类别交叉熵损失函数，前者是类的实现形式，后者是函数的实现形式。</p><p>常用的一些内置损失函数说明如下。</p><ul><li><p>mean_squared_error（均方误差损失，用于回归，简写为 mse, 类与函数实现形式分别为 MeanSquaredError 和 MSE）</p></li><li><p>mean_absolute_error (平均绝对值误差损失，用于回归，简写为 mae, 类与函数实现形式分别为 MeanAbsoluteError 和 MAE)</p></li><li><p>mean_absolute_percentage_error (平均百分比误差损失，用于回归，简写为 mape, 类与函数实现形式分别为 MeanAbsolutePercentageError 和 MAPE)</p></li><li><p>Huber(Huber损失，只有类实现形式，用于回归，介于mse和mae之间，对异常值比较鲁棒，相对mse有一定的优势)</p></li><li><p>binary_crossentropy(二元交叉熵，用于二分类，类实现形式为 BinaryCrossentropy)</p></li><li><p>categorical_crossentropy(类别交叉熵，用于多分类，要求label为onehot编码，类实现形式为 CategoricalCrossentropy)</p></li><li><p>sparse_categorical_crossentropy(稀疏类别交叉熵，用于多分类，要求label为序号编码形式，类实现形式为 SparseCategoricalCrossentropy)</p></li><li><p>hinge(合页损失函数，用于二分类，最著名的应用是作为支持向量机SVM的损失函数，类实现形式为 Hinge)</p></li><li><p>kld(相对熵损失，也叫KL散度，常用于最大期望算法EM的损失函数，两个概率分布差异的一种信息度量。类与函数实现形式分别为 KLDivergence 或 KLD)</p></li><li><p>cosine_similarity(余弦相似度，可用于多分类，类实现形式为 CosineSimilarity)</p></li></ul><h4 id="自定义损失函数"><a href="#自定义损失函数" class="headerlink" title="自定义损失函数"></a>自定义损失函数</h4><p>自定义损失函数接收两个张量y_true,y_pred作为输入参数，并输出一个标量作为损失函数值。</p><p>也可以对tf.keras.losses.Loss进行子类化，重写call方法实现损失的计算逻辑，从而得到损失函数的类的实现。</p><p>下面是一个Focal Loss的自定义实现示范。Focal Loss是一种对binary_crossentropy的改进损失函数形式。</p><p>它在样本不均衡和存在较多易分类的样本时相比binary_crossentropy具有明显的优势。</p><p>它有两个可调参数，alpha参数和gamma参数。其中alpha参数主要用于衰减负样本的权重，gamma参数主要用于衰减容易训练样本的权重。</p><p>从而让模型更加聚焦在正样本和困难样本上。这就是为什么这个损失函数叫做Focal Loss。</p><p>详见《5分钟理解Focal Loss与GHM——解决样本不平衡利器》</p><p><a href="https://zhuanlan.zhihu.com/p/80594704" target="_blank" rel="external nofollow noopener noreferrer">https://zhuanlan.zhihu.com/p/80594704</a></p><script type="math/tex; mode=display">focal\_loss(y,p) = \begin{cases}-\alpha  (1-p)^{\gamma}\log(p) &\text{if y = 1}\\-(1-\alpha) p^{\gamma}\log(1-p) &\text{if y = 0}\end{cases}</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">focal_loss</span><span class="params">(gamma=<span class="number">2.</span>, alpha=<span class="number">0.75</span>)</span>:</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">focal_loss_fixed</span><span class="params">(y_true, y_pred)</span>:</span></span><br><span class="line">        bce = tf.losses.binary_crossentropy(y_true, y_pred)</span><br><span class="line">        p_t = (y_true * y_pred) + ((<span class="number">1</span> - y_true) * (<span class="number">1</span> - y_pred))</span><br><span class="line">        alpha_factor = y_true * alpha + (<span class="number">1</span> - y_true) * (<span class="number">1</span> - alpha)</span><br><span class="line">        modulating_factor = tf.pow(<span class="number">1.0</span> - p_t, gamma)</span><br><span class="line">        loss = tf.reduce_sum(alpha_factor * modulating_factor * bce,axis = <span class="number">-1</span> )</span><br><span class="line">        <span class="keyword">return</span> loss</span><br><span class="line">    <span class="keyword">return</span> focal_loss_fixed</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FocalLoss</span><span class="params">(tf.keras.losses.Loss)</span>:</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,gamma=<span class="number">2.0</span>,alpha=<span class="number">0.75</span>,name = <span class="string">"focal_loss"</span>)</span>:</span></span><br><span class="line">        self.gamma = gamma</span><br><span class="line">        self.alpha = alpha</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span><span class="params">(self,y_true,y_pred)</span>:</span></span><br><span class="line">        bce = tf.losses.binary_crossentropy(y_true, y_pred)</span><br><span class="line">        p_t = (y_true * y_pred) + ((<span class="number">1</span> - y_true) * (<span class="number">1</span> - y_pred))</span><br><span class="line">        alpha_factor = y_true * self.alpha + (<span class="number">1</span> - y_true) * (<span class="number">1</span> - self.alpha)</span><br><span class="line">        modulating_factor = tf.pow(<span class="number">1.0</span> - p_t, self.gamma)</span><br><span class="line">        loss = tf.reduce_sum(alpha_factor * modulating_factor * bce,axis = <span class="number">-1</span> )</span><br><span class="line">        <span class="keyword">return</span> loss</span><br></pre></td></tr></table></figure><h3 id="评估指标metrics"><a href="#评估指标metrics" class="headerlink" title="评估指标metrics"></a>评估指标metrics</h3><p>损失函数除了作为模型训练时候的优化目标，也能够作为模型好坏的一种评价指标。但通常人们还会从其它角度评估模型的好坏。</p><p>这就是评估指标。通常损失函数都可以作为评估指标，如MAE,MSE,CategoricalCrossentropy等也是常用的评估指标。</p><p>但评估指标不一定可以作为损失函数，例如AUC,Accuracy,Precision。因为评估指标不要求连续可导，而损失函数通常要求连续可导。</p><p>编译模型时，可以通过列表形式指定多个评估指标。</p><p>如果有需要，也可以自定义评估指标。</p><p>自定义评估指标需要接收两个张量y_true,y_pred作为输入参数，并输出一个标量作为评估值。</p><p>也可以对tf.keras.metrics.Metric进行子类化，重写初始化方法, update_state方法, result方法实现评估指标的计算逻辑，从而得到评估指标的类的实现形式。</p><p>由于训练的过程通常是分批次训练的，而评估指标要跑完一个epoch才能够得到整体的指标结果。因此，类形式的评估指标更为常见。即需要编写初始化方法以创建与计算指标结果相关的一些中间变量，编写update_state方法在每个batch后更新相关中间变量的状态，编写result方法输出最终指标结果。</p><p>如果编写函数形式的评估指标，则只能取epoch中各个batch计算的评估指标结果的平均值作为整个epoch上的评估指标结果，这个结果通常会偏离整个epoch数据一次计算的结果。</p><h4 id="常用的内置评估指标"><a href="#常用的内置评估指标" class="headerlink" title="常用的内置评估指标"></a>常用的内置评估指标</h4><ul><li><p>MeanSquaredError（均方误差，用于回归，可以简写为MSE，函数形式为mse）</p></li><li><p>MeanAbsoluteError (平均绝对值误差，用于回归，可以简写为MAE，函数形式为mae)</p></li><li><p>MeanAbsolutePercentageError (平均百分比误差，用于回归，可以简写为MAPE，函数形式为mape)</p></li><li><p>RootMeanSquaredError (均方根误差，用于回归)</p></li><li><p>Accuracy (准确率，用于分类，可以用字符串”Accuracy”表示，Accuracy=(TP+TN)/(TP+TN+FP+FN)，要求y_true和y_pred都为类别序号编码)</p></li><li><p>Precision (精确率，用于二分类，Precision = TP/(TP+FP))</p></li><li><p>Recall (召回率，用于二分类，Recall = TP/(TP+FN))</p></li><li><p>TruePositives (真正例，用于二分类)</p></li><li><p>TrueNegatives (真负例，用于二分类)</p></li><li><p>FalsePositives (假正例，用于二分类)</p></li><li><p>FalseNegatives (假负例，用于二分类)</p></li><li><p>AUC(ROC曲线(TPR vs FPR)下的面积，用于二分类，直观解释为随机抽取一个正样本和一个负样本，正样本的预测值大于负样本的概率)</p></li><li><p>CategoricalAccuracy（分类准确率，与Accuracy含义相同，要求y_true(label)为onehot编码形式）</p></li><li><p>SparseCategoricalAccuracy (稀疏分类准确率，与Accuracy含义相同，要求y_true(label)为序号编码形式)</p></li><li><p>MeanIoU (Intersection-Over-Union，常用于图像分割)</p></li><li><p>TopKCategoricalAccuracy (多分类TopK准确率，要求y_true(label)为onehot编码形式)</p></li><li><p>SparseTopKCategoricalAccuracy (稀疏多分类TopK准确率，要求y_true(label)为序号编码形式)</p></li><li><p>Mean (平均值)</p></li><li><p>Sum (求和)</p></li></ul><h4 id="自定义评估指标"><a href="#自定义评估指标" class="headerlink" title="自定义评估指标"></a>自定义评估指标</h4><p>我们以金融风控领域常用的KS指标为例，示范自定义评估指标。</p><p>KS指标适合二分类问题，其计算方式为 KS=max(TPR-FPR).</p><p>其中TPR=TP/(TP+FN) , FPR = FP/(FP+TN) </p><p>TPR曲线实际上就是正样本的累积分布曲线(CDF)，FPR曲线实际上就是负样本的累积分布曲线(CDF)。</p><p>KS指标就是正样本和负样本累积分布曲线差值的最大值。</p><p><img alt data-src="https://github.com/SimpCosm/eat_tensorflow2_in_30_days_ipynbs/raw/master/data/KS_curve.png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers,models,losses,metrics</span><br><span class="line"></span><br><span class="line"><span class="comment">#函数形式的自定义评估指标</span></span><br><span class="line"><span class="meta">@tf.function</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ks</span><span class="params">(y_true,y_pred)</span>:</span></span><br><span class="line">    y_true = tf.reshape(y_true,(<span class="number">-1</span>,))</span><br><span class="line">    y_pred = tf.reshape(y_pred,(<span class="number">-1</span>,))</span><br><span class="line">    length = tf.shape(y_true)[<span class="number">0</span>]</span><br><span class="line">    t = tf.math.top_k(y_pred,k = length,sorted = <span class="literal">False</span>)</span><br><span class="line">    y_pred_sorted = tf.gather(y_pred,t.indices)</span><br><span class="line">    y_true_sorted = tf.gather(y_true,t.indices)</span><br><span class="line">    cum_positive_ratio = tf.truediv(</span><br><span class="line">        tf.cumsum(y_true_sorted),tf.reduce_sum(y_true_sorted))</span><br><span class="line">    cum_negative_ratio = tf.truediv(</span><br><span class="line">        tf.cumsum(<span class="number">1</span> - y_true_sorted),tf.reduce_sum(<span class="number">1</span> - y_true_sorted))</span><br><span class="line">    ks_value = tf.reduce_max(tf.abs(cum_positive_ratio - cum_negative_ratio)) </span><br><span class="line">    <span class="keyword">return</span> ks_value</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">y_true = tf.constant([[<span class="number">1</span>],[<span class="number">1</span>],[<span class="number">1</span>],[<span class="number">0</span>],[<span class="number">1</span>],[<span class="number">1</span>],[<span class="number">1</span>],[<span class="number">0</span>],[<span class="number">0</span>],[<span class="number">0</span>],[<span class="number">1</span>],[<span class="number">0</span>],[<span class="number">1</span>],[<span class="number">0</span>]])</span><br><span class="line">y_pred = tf.constant([[<span class="number">0.6</span>],[<span class="number">0.1</span>],[<span class="number">0.4</span>],[<span class="number">0.5</span>],[<span class="number">0.7</span>],[<span class="number">0.7</span>],[<span class="number">0.7</span>],</span><br><span class="line">                      [<span class="number">0.4</span>],[<span class="number">0.4</span>],[<span class="number">0.5</span>],[<span class="number">0.8</span>],[<span class="number">0.3</span>],[<span class="number">0.5</span>],[<span class="number">0.3</span>]])</span><br><span class="line">tf.print(ks(y_true,y_pred))</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0.625</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#类形式的自定义评估指标</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">KS</span><span class="params">(metrics.Metric)</span>:</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, name = <span class="string">"ks"</span>, **kwargs)</span>:</span></span><br><span class="line">        super(KS,self).__init__(name=name,**kwargs)</span><br><span class="line">        self.true_positives = self.add_weight(</span><br><span class="line">            name = <span class="string">"tp"</span>,shape = (<span class="number">101</span>,), initializer = <span class="string">"zeros"</span>)</span><br><span class="line">        self.false_positives = self.add_weight(</span><br><span class="line">            name = <span class="string">"fp"</span>,shape = (<span class="number">101</span>,), initializer = <span class="string">"zeros"</span>)</span><br><span class="line">   </span><br><span class="line"><span class="meta">    @tf.function</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">update_state</span><span class="params">(self,y_true,y_pred)</span>:</span></span><br><span class="line">        y_true = tf.cast(tf.reshape(y_true,(<span class="number">-1</span>,)),tf.bool)</span><br><span class="line">        y_pred = tf.cast(<span class="number">100</span>*tf.reshape(y_pred,(<span class="number">-1</span>,)),tf.int32)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> tf.range(<span class="number">0</span>,tf.shape(y_true)[<span class="number">0</span>]):</span><br><span class="line">            <span class="keyword">if</span> y_true[i]:</span><br><span class="line">                self.true_positives[y_pred[i]].assign(</span><br><span class="line">                    self.true_positives[y_pred[i]]+<span class="number">1.0</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                self.false_positives[y_pred[i]].assign(</span><br><span class="line">                    self.false_positives[y_pred[i]]+<span class="number">1.0</span>)</span><br><span class="line">        <span class="keyword">return</span> (self.true_positives,self.false_positives)</span><br><span class="line">    </span><br><span class="line"><span class="meta">    @tf.function</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">result</span><span class="params">(self)</span>:</span></span><br><span class="line">        cum_positive_ratio = tf.truediv(</span><br><span class="line">            tf.cumsum(self.true_positives),tf.reduce_sum(self.true_positives))</span><br><span class="line">        cum_negative_ratio = tf.truediv(</span><br><span class="line">            tf.cumsum(self.false_positives),tf.reduce_sum(self.false_positives))</span><br><span class="line">        ks_value = tf.reduce_max(tf.abs(cum_positive_ratio - cum_negative_ratio)) </span><br><span class="line">        <span class="keyword">return</span> ks_value</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">y_true = tf.constant([[<span class="number">1</span>],[<span class="number">1</span>],[<span class="number">1</span>],[<span class="number">0</span>],[<span class="number">1</span>],[<span class="number">1</span>],[<span class="number">1</span>],[<span class="number">0</span>],[<span class="number">0</span>],[<span class="number">0</span>],[<span class="number">1</span>],[<span class="number">0</span>],[<span class="number">1</span>],[<span class="number">0</span>]])</span><br><span class="line">y_pred = tf.constant([[<span class="number">0.6</span>],[<span class="number">0.1</span>],[<span class="number">0.4</span>],[<span class="number">0.5</span>],[<span class="number">0.7</span>],[<span class="number">0.7</span>],</span><br><span class="line">                      [<span class="number">0.7</span>],[<span class="number">0.4</span>],[<span class="number">0.4</span>],[<span class="number">0.5</span>],[<span class="number">0.8</span>],[<span class="number">0.3</span>],[<span class="number">0.5</span>],[<span class="number">0.3</span>]])</span><br><span class="line"></span><br><span class="line">myks = KS()</span><br><span class="line">myks.update_state(y_true,y_pred)</span><br><span class="line">tf.print(myks.result())</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0.625</span></span><br></pre></td></tr></table></figure><h3 id="回调函数callbacks"><a href="#回调函数callbacks" class="headerlink" title="回调函数callbacks"></a>回调函数callbacks</h3><p>tf.keras的回调函数实际上是一个类，一般是在model.fit时作为参数指定，用于控制在训练过程开始或者在训练过程结束，在每个epoch训练开始或者训练结束，在每个batch训练开始或者训练结束时执行一些操作，例如收集一些日志信息，改变学习率等超参数，提前终止训练过程等等。</p><p>同样地，针对model.evaluate或者model.predict也可以指定callbacks参数，用于控制在评估或预测开始或者结束时，在每个batch开始或者结束时执行一些操作，但这种用法相对少见。</p><p>大部分时候，keras.callbacks子模块中定义的回调函数类已经足够使用了，如果有特定的需要，我们也可以通过对keras.callbacks.Callbacks实施子类化构造自定义的回调函数。</p><p>所有回调函数都继承至 keras.callbacks.Callbacks基类，拥有params和model这两个属性。</p><p>其中params 是一个dict，记录了训练相关参数 (例如 verbosity, batch size, number of epochs 等等)。</p><p>model即当前关联的模型的引用。</p><p>此外，对于回调类中的一些方法如on_epoch_begin,on_batch_end，还会有一个输入参数logs, 提供有关当前epoch或者batch的一些信息，并能够记录计算结果，如果model.fit指定了多个回调函数类，这些logs变量将在这些回调函数类的同名函数间依顺序传递。</p><h4 id="内置回调函数"><a href="#内置回调函数" class="headerlink" title="内置回调函数"></a>内置回调函数</h4><ul><li><p>BaseLogger： 收集每个epoch上metrics在各个batch上的平均值，对stateful_metrics参数中的带中间状态的指标直接拿最终值无需对各个batch平均，指标均值结果将添加到logs变量中。该回调函数被所有模型默认添加，且是第一个被添加的。</p></li><li><p>History： 将BaseLogger计算的各个epoch的metrics结果记录到history这个dict变量中，并作为model.fit的返回值。该回调函数被所有模型默认添加，在BaseLogger之后被添加。</p></li><li><p>EarlyStopping： 当被监控指标在设定的若干个epoch后没有提升，则提前终止训练。</p></li><li><p>TensorBoard： 为Tensorboard可视化保存日志信息。支持评估指标，计算图，模型参数等的可视化。</p></li><li><p>ModelCheckpoint： 在每个epoch后保存模型。</p></li><li><p>ReduceLROnPlateau：如果监控指标在设定的若干个epoch后没有提升，则以一定的因子减少学习率。</p></li><li><p>TerminateOnNaN：如果遇到loss为NaN，提前终止训练。</p></li><li><p>LearningRateScheduler：学习率控制器。给定学习率lr和epoch的函数关系，根据该函数关系在每个epoch前调整学习率。</p></li><li><p>CSVLogger：将每个epoch后的logs结果记录到CSV文件中。</p></li><li><p>ProgbarLogger：将每个epoch后的logs结果打印到标准输出流中。</p></li></ul><h4 id="自定义回调函数"><a href="#自定义回调函数" class="headerlink" title="自定义回调函数"></a>自定义回调函数</h4><p>可以使用callbacks.LambdaCallback编写较为简单的回调函数，也可以通过对callbacks.Callback子类化编写更加复杂的回调函数逻辑。</p><p>如果需要深入学习tf.Keras中的回调函数，不要犹豫阅读内置回调函数的源代码。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers,models,losses,metrics,callbacks</span><br><span class="line"><span class="keyword">import</span> tensorflow.keras.backend <span class="keyword">as</span> K</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 示范使用LambdaCallback编写较为简单的回调函数</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line">json_log = open(<span class="string">'./data/keras_log.json'</span>, mode=<span class="string">'wt'</span>, buffering=<span class="number">1</span>)</span><br><span class="line">json_logging_callback = callbacks.LambdaCallback(</span><br><span class="line">    on_epoch_end=<span class="keyword">lambda</span> epoch, logs: json_log.write(</span><br><span class="line">        json.dumps(dict(epoch = epoch,**logs)) + <span class="string">'\n'</span>),</span><br><span class="line">    on_train_end=<span class="keyword">lambda</span> logs: json_log.close()</span><br><span class="line">)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 示范通过Callback子类化编写回调函数（LearningRateScheduler的源代码）</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LearningRateScheduler</span><span class="params">(callbacks.Callback)</span>:</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, schedule, verbose=<span class="number">0</span>)</span>:</span></span><br><span class="line">        super(LearningRateScheduler, self).__init__()</span><br><span class="line">        self.schedule = schedule</span><br><span class="line">        self.verbose = verbose</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">on_epoch_begin</span><span class="params">(self, epoch, logs=None)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> hasattr(self.model.optimizer, <span class="string">'lr'</span>):</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">'Optimizer must have a "lr" attribute.'</span>)</span><br><span class="line">        <span class="keyword">try</span>:  </span><br><span class="line">            lr = float(K.get_value(self.model.optimizer.lr))</span><br><span class="line">            lr = self.schedule(epoch, lr)</span><br><span class="line">        <span class="keyword">except</span> TypeError:  <span class="comment"># Support for old API for backward compatibility</span></span><br><span class="line">            lr = self.schedule(epoch)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> isinstance(lr, (tf.Tensor, float, np.float32, np.float64)):</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">'The output of the "schedule" function '</span></span><br><span class="line">                             <span class="string">'should be float.'</span>)</span><br><span class="line">        <span class="keyword">if</span> isinstance(lr, ops.Tensor) <span class="keyword">and</span> <span class="keyword">not</span> lr.dtype.is_floating:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">'The dtype of Tensor should be float'</span>)</span><br><span class="line">        K.set_value(self.model.optimizer.lr, K.get_value(lr))</span><br><span class="line">        <span class="keyword">if</span> self.verbose &gt; <span class="number">0</span>:</span><br><span class="line">            print(<span class="string">'\nEpoch %05d: LearningRateScheduler reducing learning '</span></span><br><span class="line">                 <span class="string">'rate to %s.'</span> % (epoch + <span class="number">1</span>, lr))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">on_epoch_end</span><span class="params">(self, epoch, logs=None)</span>:</span></span><br><span class="line">        logs = logs <span class="keyword">or</span> &#123;&#125;</span><br><span class="line">        logs[<span class="string">'lr'</span>] = K.get_value(self.model.optimizer.lr)</span><br></pre></td></tr></table></figure><h2 id="高阶API"><a href="#高阶API" class="headerlink" title="高阶API"></a>高阶API</h2><p>TensorFlow的高阶API主要是tensorflow.keras.models.</p><p>本章我们主要详细介绍tensorflow.keras.models相关的以下内容。</p><ul><li>模型的构建（Sequential、functional API、Model子类化）</li><li>模型的训练（内置fit方法、内置train_on_batch方法、自定义训练循环、单GPU训练模型、多GPU训练模型、TPU训练模型）</li><li>模型的部署（tensorflow serving部署模型、使用spark(scala)调用tensorflow模型）</li></ul><h3 id="构建模型的3种方法"><a href="#构建模型的3种方法" class="headerlink" title="构建模型的3种方法"></a>构建模型的3种方法</h3><p>可以使用以下3种方式构建模型：</p><ul><li>使用Sequential按层顺序构建模型，适合于顺序结构的模型</li><li>使用函数式API构建任意结构模型，如果模型有多输入或者多输出，或者模型需要共享权重，或者模型具有残差连接等非顺序结构，推荐使用函数式API进行创建</li><li>继承Model基类构建自定义模型，如果无特定必要，尽可能避免使用Model子类化的方式构建模型，这种方式提供了极大的灵活性，但也有更大的概率出错。</li></ul><p>下面以IMDB电影评论的分类问题为例，演示3种创建模型的方法。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm </span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">train_token_path = <span class="string">"./data/imdb/train_token.csv"</span></span><br><span class="line">test_token_path = <span class="string">"./data/imdb/test_token.csv"</span></span><br><span class="line"></span><br><span class="line">MAX_WORDS = <span class="number">10000</span>  <span class="comment"># We will only consider the top 10,000 words in the dataset</span></span><br><span class="line">MAX_LEN = <span class="number">200</span>  <span class="comment"># We will cut reviews after 200 words</span></span><br><span class="line">BATCH_SIZE = <span class="number">20</span> </span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建管道</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_line</span><span class="params">(line)</span>:</span></span><br><span class="line">    t = tf.strings.split(line,<span class="string">"\t"</span>)</span><br><span class="line">    label = tf.reshape(tf.cast(tf.strings.to_number(t[<span class="number">0</span>]),tf.int32),(<span class="number">-1</span>,))</span><br><span class="line">    features = tf.cast(tf.strings.to_number(tf.strings.split(t[<span class="number">1</span>],<span class="string">" "</span>)),tf.int32)</span><br><span class="line">    <span class="keyword">return</span> (features,label)</span><br><span class="line"></span><br><span class="line">ds_train=  tf.data.TextLineDataset(filenames = [train_token_path]) \</span><br><span class="line">   .map(parse_line,num_parallel_calls = tf.data.experimental.AUTOTUNE) \</span><br><span class="line">   .shuffle(buffer_size = <span class="number">1000</span>).batch(BATCH_SIZE) \</span><br><span class="line">   .prefetch(tf.data.experimental.AUTOTUNE)</span><br><span class="line"></span><br><span class="line">ds_test=  tf.data.TextLineDataset(filenames = [test_token_path]) \</span><br><span class="line">   .map(parse_line,num_parallel_calls = tf.data.experimental.AUTOTUNE) \</span><br><span class="line">   .shuffle(buffer_size = <span class="number">1000</span>).batch(BATCH_SIZE) \</span><br><span class="line">   .prefetch(tf.data.experimental.AUTOTUNE)</span><br></pre></td></tr></table></figure><h4 id="Sequential按层顺序创建模型"><a href="#Sequential按层顺序创建模型" class="headerlink" title="Sequential按层顺序创建模型"></a>Sequential按层顺序创建模型</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">tf.keras.backend.clear_session()</span><br><span class="line"></span><br><span class="line">model = models.Sequential()</span><br><span class="line"></span><br><span class="line">model.add(layers.Embedding(MAX_WORDS,<span class="number">7</span>,input_length=MAX_LEN))</span><br><span class="line">model.add(layers.Conv1D(filters = <span class="number">64</span>,kernel_size = <span class="number">5</span>,activation = <span class="string">"relu"</span>))</span><br><span class="line">model.add(layers.MaxPool1D(<span class="number">2</span>))</span><br><span class="line">model.add(layers.Conv1D(filters = <span class="number">32</span>,kernel_size = <span class="number">3</span>,activation = <span class="string">"relu"</span>))</span><br><span class="line">model.add(layers.MaxPool1D(<span class="number">2</span>))</span><br><span class="line">model.add(layers.Flatten())</span><br><span class="line">model.add(layers.Dense(<span class="number">1</span>,activation = <span class="string">"sigmoid"</span>))</span><br><span class="line"></span><br><span class="line">model.compile(optimizer=<span class="string">'Nadam'</span>,</span><br><span class="line">            loss=<span class="string">'binary_crossentropy'</span>,</span><br><span class="line">            metrics=[<span class="string">'accuracy'</span>,<span class="string">"AUC"</span>])</span><br><span class="line"></span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure><p><img alt data-src="https://github.com/SimpCosm/eat_tensorflow2_in_30_days_ipynbs/raw/master/data/Sequential模型结构.png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line">baselogger = callbacks.BaseLogger(stateful_metrics=[<span class="string">"AUC"</span>])</span><br><span class="line">logdir = <span class="string">"./data/keras_model/"</span> + datetime.datetime.now().strftime(<span class="string">"%Y%m%d-%H%M%S"</span>)</span><br><span class="line">tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=<span class="number">1</span>)</span><br><span class="line">history = model.fit(ds_train,validation_data = ds_test,</span><br><span class="line">        epochs = <span class="number">6</span>,callbacks=[baselogger,tensorboard_callback])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line">%config InlineBackend.figure_format = <span class="string">'svg'</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_metric</span><span class="params">(history, metric)</span>:</span></span><br><span class="line">    train_metrics = history.history[metric]</span><br><span class="line">    val_metrics = history.history[<span class="string">'val_'</span>+metric]</span><br><span class="line">    epochs = range(<span class="number">1</span>, len(train_metrics) + <span class="number">1</span>)</span><br><span class="line">    plt.plot(epochs, train_metrics, <span class="string">'bo--'</span>)</span><br><span class="line">    plt.plot(epochs, val_metrics, <span class="string">'ro-'</span>)</span><br><span class="line">    plt.title(<span class="string">'Training and validation '</span>+ metric)</span><br><span class="line">    plt.xlabel(<span class="string">"Epochs"</span>)</span><br><span class="line">    plt.ylabel(metric)</span><br><span class="line">    plt.legend([<span class="string">"train_"</span>+metric, <span class="string">'val_'</span>+metric])</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_metric(history,<span class="string">"AUC"</span>)</span><br></pre></td></tr></table></figure><p><img alt data-src="https://github.com/SimpCosm/eat_tensorflow2_in_30_days_ipynbs/raw/master/data/6-1-fit模型.jpg"></p><h4 id="函数式API创建任意结构模型"><a href="#函数式API创建任意结构模型" class="headerlink" title="函数式API创建任意结构模型"></a>函数式API创建任意结构模型</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">tf.keras.backend.clear_session()</span><br><span class="line"></span><br><span class="line">inputs = layers.Input(shape=[MAX_LEN])</span><br><span class="line">x  = layers.Embedding(MAX_WORDS,<span class="number">7</span>)(inputs)</span><br><span class="line"></span><br><span class="line">branch1 = layers.SeparableConv1D(<span class="number">64</span>,<span class="number">3</span>,activation=<span class="string">"relu"</span>)(x)</span><br><span class="line">branch1 = layers.MaxPool1D(<span class="number">3</span>)(branch1)</span><br><span class="line">branch1 = layers.SeparableConv1D(<span class="number">32</span>,<span class="number">3</span>,activation=<span class="string">"relu"</span>)(branch1)</span><br><span class="line">branch1 = layers.GlobalMaxPool1D()(branch1)</span><br><span class="line"></span><br><span class="line">branch2 = layers.SeparableConv1D(<span class="number">64</span>,<span class="number">5</span>,activation=<span class="string">"relu"</span>)(x)</span><br><span class="line">branch2 = layers.MaxPool1D(<span class="number">5</span>)(branch2)</span><br><span class="line">branch2 = layers.SeparableConv1D(<span class="number">32</span>,<span class="number">5</span>,activation=<span class="string">"relu"</span>)(branch2)</span><br><span class="line">branch2 = layers.GlobalMaxPool1D()(branch2)</span><br><span class="line"></span><br><span class="line">branch3 = layers.SeparableConv1D(<span class="number">64</span>,<span class="number">7</span>,activation=<span class="string">"relu"</span>)(x)</span><br><span class="line">branch3 = layers.MaxPool1D(<span class="number">7</span>)(branch3)</span><br><span class="line">branch3 = layers.SeparableConv1D(<span class="number">32</span>,<span class="number">7</span>,activation=<span class="string">"relu"</span>)(branch3)</span><br><span class="line">branch3 = layers.GlobalMaxPool1D()(branch3)</span><br><span class="line"></span><br><span class="line">concat = layers.Concatenate()([branch1,branch2,branch3])</span><br><span class="line">outputs = layers.Dense(<span class="number">1</span>,activation = <span class="string">"sigmoid"</span>)(concat)</span><br><span class="line"></span><br><span class="line">model = models.Model(inputs = inputs,outputs = outputs)</span><br><span class="line"></span><br><span class="line">model.compile(optimizer=<span class="string">'Nadam'</span>,</span><br><span class="line">            loss=<span class="string">'binary_crossentropy'</span>,</span><br><span class="line">            metrics=[<span class="string">'accuracy'</span>,<span class="string">"AUC"</span>])</span><br><span class="line"></span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">Model: "model"</span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="emphasis">___</span></span><br><span class="line">Layer (type)                    Output Shape         Param #     Connected to                     </span><br><span class="line">==================================================================================================</span><br><span class="line">input_1 (InputLayer)            [(None, 200)]        0                                            </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="emphasis">___</span></span><br><span class="line">embedding (Embedding)           (None, 200, 7)       70000       input_1[<span class="string">0</span>][<span class="symbol">0</span>]                    </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="emphasis">___</span></span><br><span class="line">separable_conv1d (SeparableConv (None, 198, 64)      533         embedding[<span class="string">0</span>][<span class="symbol">0</span>]                  </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="emphasis">___</span></span><br><span class="line">separable<span class="emphasis">_conv1d_</span>2 (SeparableCo (None, 196, 64)      547         embedding[<span class="string">0</span>][<span class="symbol">0</span>]                  </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="emphasis">___</span></span><br><span class="line">separable<span class="emphasis">_conv1d_</span>4 (SeparableCo (None, 194, 64)      561         embedding[<span class="string">0</span>][<span class="symbol">0</span>]                  </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="emphasis">___</span></span><br><span class="line">max<span class="emphasis">_pooling1d (MaxPooling1D)    (None, 66, 64)       0           separable_</span>conv1d[<span class="string">0</span>][<span class="symbol">0</span>]           </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="emphasis">___</span></span><br><span class="line">max<span class="emphasis">_pooling1d_</span>1 (MaxPooling1D)  (None, 39, 64)       0           separable<span class="emphasis">_conv1d_</span>2[<span class="string">0</span>][<span class="symbol">0</span>]         </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="emphasis">___</span></span><br><span class="line">max<span class="emphasis">_pooling1d_</span>2 (MaxPooling1D)  (None, 27, 64)       0           separable<span class="emphasis">_conv1d_</span>4[<span class="string">0</span>][<span class="symbol">0</span>]         </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="emphasis">___</span></span><br><span class="line">separable<span class="emphasis">_conv1d_</span>1 (SeparableCo (None, 64, 32)       2272        max_pooling1d[<span class="string">0</span>][<span class="symbol">0</span>]              </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="emphasis">___</span></span><br><span class="line">separable<span class="emphasis">_conv1d_</span>3 (SeparableCo (None, 35, 32)       2400        max<span class="emphasis">_pooling1d_</span>1[<span class="string">0</span>][<span class="symbol">0</span>]            </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="emphasis">___</span></span><br><span class="line">separable<span class="emphasis">_conv1d_</span>5 (SeparableCo (None, 21, 32)       2528        max<span class="emphasis">_pooling1d_</span>2[<span class="string">0</span>][<span class="symbol">0</span>]            </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="emphasis">___</span></span><br><span class="line">global<span class="emphasis">_max_</span>pooling1d (GlobalMax (None, 32)           0           separable<span class="emphasis">_conv1d_</span>1[<span class="string">0</span>][<span class="symbol">0</span>]         </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="emphasis">___</span></span><br><span class="line">global<span class="emphasis">_max_</span>pooling1d<span class="emphasis">_1 (GlobalM (None, 32)           0           separable_</span>conv1d_3[<span class="string">0</span>][<span class="symbol">0</span>]         </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="emphasis">___</span></span><br><span class="line">global<span class="emphasis">_max_</span>pooling1d<span class="emphasis">_2 (GlobalM (None, 32)           0           separable_</span>conv1d_5[<span class="string">0</span>][<span class="symbol">0</span>]         </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="emphasis">___</span></span><br><span class="line">concatenate (Concatenate)       (None, 96)           0           global<span class="emphasis">_max_</span>pooling1d[<span class="string">0</span>][<span class="symbol">0</span>]       </span><br><span class="line"><span class="code">                                                                 global_max_pooling1d_1[0][0]     </span></span><br><span class="line"><span class="code">                                                                 global_max_pooling1d_2[0][0]     </span></span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="emphasis">___</span></span><br><span class="line">dense (Dense)                   (None, 1)            97          concatenate[<span class="string">0</span>][<span class="symbol">0</span>]                </span><br><span class="line">==================================================================================================</span><br><span class="line">Total params: 78,938</span><br><span class="line">Trainable params: 78,938</span><br><span class="line">Non-trainable params: 0</span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="emphasis">___</span></span><br></pre></td></tr></table></figure><p><img alt data-src="https://github.com/SimpCosm/eat_tensorflow2_in_30_days_ipynbs/raw/master/data/FunctionalAPI模型结构.png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line">logdir = <span class="string">"./data/keras_model/"</span> + datetime.datetime.now().strftime(<span class="string">"%Y%m%d-%H%M%S"</span>)</span><br><span class="line">tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=<span class="number">1</span>)</span><br><span class="line">history = model.fit(ds_train,validation_data = ds_test,epochs = <span class="number">6</span>,callbacks=[tensorboard_callback])</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Epoch <span class="number">1</span>/<span class="number">6</span></span><br><span class="line"><span class="number">1000</span>/<span class="number">1000</span> [==============================] - <span class="number">32</span>s <span class="number">32</span>ms/step - loss: <span class="number">0.5527</span> - accuracy: <span class="number">0.6758</span> - AUC: <span class="number">0.7731</span> - val_loss: <span class="number">0.3646</span> - val_accuracy: <span class="number">0.8426</span> - val_AUC: <span class="number">0.9192</span></span><br><span class="line">Epoch <span class="number">2</span>/<span class="number">6</span></span><br><span class="line"><span class="number">1000</span>/<span class="number">1000</span> [==============================] - <span class="number">24</span>s <span class="number">24</span>ms/step - loss: <span class="number">0.3024</span> - accuracy: <span class="number">0.8737</span> - AUC: <span class="number">0.9444</span> - val_loss: <span class="number">0.3281</span> - val_accuracy: <span class="number">0.8644</span> - val_AUC: <span class="number">0.9350</span></span><br><span class="line">Epoch <span class="number">3</span>/<span class="number">6</span></span><br><span class="line"><span class="number">1000</span>/<span class="number">1000</span> [==============================] - <span class="number">24</span>s <span class="number">24</span>ms/step - loss: <span class="number">0.2158</span> - accuracy: <span class="number">0.9159</span> - AUC: <span class="number">0.9715</span> - val_loss: <span class="number">0.3461</span> - val_accuracy: <span class="number">0.8666</span> - val_AUC: <span class="number">0.9363</span></span><br><span class="line">Epoch <span class="number">4</span>/<span class="number">6</span></span><br><span class="line"><span class="number">1000</span>/<span class="number">1000</span> [==============================] - <span class="number">24</span>s <span class="number">24</span>ms/step - loss: <span class="number">0.1492</span> - accuracy: <span class="number">0.9464</span> - AUC: <span class="number">0.9859</span> - val_loss: <span class="number">0.4017</span> - val_accuracy: <span class="number">0.8568</span> - val_AUC: <span class="number">0.9311</span></span><br><span class="line">Epoch <span class="number">5</span>/<span class="number">6</span></span><br><span class="line"><span class="number">1000</span>/<span class="number">1000</span> [==============================] - <span class="number">24</span>s <span class="number">24</span>ms/step - loss: <span class="number">0.0944</span> - accuracy: <span class="number">0.9696</span> - AUC: <span class="number">0.9939</span> - val_loss: <span class="number">0.4998</span> - val_accuracy: <span class="number">0.8550</span> - val_AUC: <span class="number">0.9233</span></span><br><span class="line">Epoch <span class="number">6</span>/<span class="number">6</span></span><br><span class="line"><span class="number">1000</span>/<span class="number">1000</span> [==============================] - <span class="number">26</span>s <span class="number">26</span>ms/step - loss: <span class="number">0.0526</span> - accuracy: <span class="number">0.9865</span> - AUC: <span class="number">0.9977</span> - val_loss: <span class="number">0.6463</span> - val_accuracy: <span class="number">0.8462</span> - val_AUC: <span class="number">0.9138</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_metric(history,<span class="string">"AUC"</span>)</span><br></pre></td></tr></table></figure><p><img alt data-src="https://github.com/SimpCosm/eat_tensorflow2_in_30_days_ipynbs/raw/master/data/6-1-2-train.jpg"></p><h4 id="Model子类化创建自定义模型"><a href="#Model子类化创建自定义模型" class="headerlink" title="Model子类化创建自定义模型"></a>Model子类化创建自定义模型</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 先自定义一个残差模块，为自定义Layer</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ResBlock</span><span class="params">(layers.Layer)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, kernel_size, **kwargs)</span>:</span></span><br><span class="line">        super(ResBlock, self).__init__(**kwargs)</span><br><span class="line">        self.kernel_size = kernel_size</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">build</span><span class="params">(self,input_shape)</span>:</span></span><br><span class="line">        self.conv1 = layers.Conv1D(filters=<span class="number">64</span>,kernel_size=self.kernel_size,</span><br><span class="line">                                   activation = <span class="string">"relu"</span>,padding=<span class="string">"same"</span>)</span><br><span class="line">        self.conv2 = layers.Conv1D(filters=<span class="number">32</span>,kernel_size=self.kernel_size,</span><br><span class="line">                                   activation = <span class="string">"relu"</span>,padding=<span class="string">"same"</span>)</span><br><span class="line">        self.conv3 = layers.Conv1D(filters=input_shape[<span class="number">-1</span>],</span><br><span class="line">                                   kernel_size=self.kernel_size,activation = <span class="string">"relu"</span>,padding=<span class="string">"same"</span>)</span><br><span class="line">        self.maxpool = layers.MaxPool1D(<span class="number">2</span>)</span><br><span class="line">        super(ResBlock,self).build(input_shape) <span class="comment"># 相当于设置self.built = True</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span><span class="params">(self, inputs)</span>:</span></span><br><span class="line">        x = self.conv1(inputs)</span><br><span class="line">        x = self.conv2(x)</span><br><span class="line">        x = self.conv3(x)</span><br><span class="line">        x = layers.Add()([inputs,x])</span><br><span class="line">        x = self.maxpool(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#如果要让自定义的Layer通过Functional API 组合成模型时可以序列化，需要自定义get_config方法。</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_config</span><span class="params">(self)</span>:</span>  </span><br><span class="line">        config = super(ResBlock, self).get_config()</span><br><span class="line">        config.update(&#123;<span class="string">'kernel_size'</span>: self.kernel_size&#125;)</span><br><span class="line">        <span class="keyword">return</span> config</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 测试ResBlock</span></span><br><span class="line">resblock = ResBlock(kernel_size = <span class="number">3</span>)</span><br><span class="line">resblock.build(input_shape = (<span class="literal">None</span>,<span class="number">200</span>,<span class="number">7</span>))</span><br><span class="line">resblock.compute_output_shape(input_shape=(<span class="literal">None</span>,<span class="number">200</span>,<span class="number">7</span>))</span><br></pre></td></tr></table></figure><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="title">TensorShape</span><span class="params">([None, <span class="number">100</span>, <span class="number">7</span>])</span></span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 自定义模型，实际上也可以使用Sequential或者FunctionalAPI</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ImdbModel</span><span class="params">(models.Model)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(ImdbModel, self).__init__()</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">build</span><span class="params">(self,input_shape)</span>:</span></span><br><span class="line">        self.embedding = layers.Embedding(MAX_WORDS,<span class="number">7</span>)</span><br><span class="line">        self.block1 = ResBlock(<span class="number">7</span>)</span><br><span class="line">        self.block2 = ResBlock(<span class="number">5</span>)</span><br><span class="line">        self.dense = layers.Dense(<span class="number">1</span>,activation = <span class="string">"sigmoid"</span>)</span><br><span class="line">        super(ImdbModel,self).build(input_shape)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = self.embedding(x)</span><br><span class="line">        x = self.block1(x)</span><br><span class="line">        x = self.block2(x)</span><br><span class="line">        x = layers.Flatten()(x)</span><br><span class="line">        x = self.dense(x)</span><br><span class="line">        <span class="keyword">return</span>(x)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">tf.keras.backend.clear_session()</span><br><span class="line"></span><br><span class="line">model = ImdbModel()</span><br><span class="line">model.build(input_shape =(<span class="literal">None</span>,<span class="number">200</span>))</span><br><span class="line">model.summary()</span><br><span class="line"></span><br><span class="line">model.compile(optimizer=<span class="string">'Nadam'</span>,</span><br><span class="line">            loss=<span class="string">'binary_crossentropy'</span>,</span><br><span class="line">            metrics=[<span class="string">'accuracy'</span>,<span class="string">"AUC"</span>])</span><br></pre></td></tr></table></figure><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">Model: "imdb_model"</span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">Layer (type)                 Output Shape              Param #   </span><br><span class="line">=================================================================</span><br><span class="line">embedding (Embedding)        multiple                  70000     </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">res_block (ResBlock)         multiple                  19143     </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">res<span class="emphasis">_block_</span>1 (ResBlock)       multiple                  13703     </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">dense (Dense)                multiple                  351       </span><br><span class="line">=================================================================</span><br><span class="line">Total params: 103,197</span><br><span class="line">Trainable params: 103,197</span><br><span class="line">Non-trainable params: 0</span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br></pre></td></tr></table></figure><p><img alt data-src="https://github.com/SimpCosm/eat_tensorflow2_in_30_days_ipynbs/raw/master/data/Model子类化模型结构.png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"></span><br><span class="line">logdir = <span class="string">"./tflogs/keras_model/"</span> + datetime.datetime.now().strftime(<span class="string">"%Y%m%d-%H%M%S"</span>)</span><br><span class="line">tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=<span class="number">1</span>)</span><br><span class="line">history = model.fit(ds_train,validation_data = ds_test,</span><br><span class="line">                    epochs = <span class="number">6</span>,callbacks=[tensorboard_callback])</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Epoch <span class="number">1</span>/<span class="number">6</span></span><br><span class="line"><span class="number">1000</span>/<span class="number">1000</span> [==============================] - <span class="number">47</span>s <span class="number">47</span>ms/step - loss: <span class="number">0.5629</span> - accuracy: <span class="number">0.6618</span> - AUC: <span class="number">0.7548</span> - val_loss: <span class="number">0.3422</span> - val_accuracy: <span class="number">0.8510</span> - val_AUC: <span class="number">0.9286</span></span><br><span class="line">Epoch <span class="number">2</span>/<span class="number">6</span></span><br><span class="line"><span class="number">1000</span>/<span class="number">1000</span> [==============================] - <span class="number">43</span>s <span class="number">43</span>ms/step - loss: <span class="number">0.2648</span> - accuracy: <span class="number">0.8903</span> - AUC: <span class="number">0.9576</span> - val_loss: <span class="number">0.3276</span> - val_accuracy: <span class="number">0.8650</span> - val_AUC: <span class="number">0.9410</span></span><br><span class="line">Epoch <span class="number">3</span>/<span class="number">6</span></span><br><span class="line"><span class="number">1000</span>/<span class="number">1000</span> [==============================] - <span class="number">42</span>s <span class="number">42</span>ms/step - loss: <span class="number">0.1573</span> - accuracy: <span class="number">0.9439</span> - AUC: <span class="number">0.9846</span> - val_loss: <span class="number">0.3861</span> - val_accuracy: <span class="number">0.8682</span> - val_AUC: <span class="number">0.9390</span></span><br><span class="line">Epoch <span class="number">4</span>/<span class="number">6</span></span><br><span class="line"><span class="number">1000</span>/<span class="number">1000</span> [==============================] - <span class="number">42</span>s <span class="number">42</span>ms/step - loss: <span class="number">0.0849</span> - accuracy: <span class="number">0.9706</span> - AUC: <span class="number">0.9950</span> - val_loss: <span class="number">0.5324</span> - val_accuracy: <span class="number">0.8616</span> - val_AUC: <span class="number">0.9292</span></span><br><span class="line">Epoch <span class="number">5</span>/<span class="number">6</span></span><br><span class="line"><span class="number">1000</span>/<span class="number">1000</span> [==============================] - <span class="number">43</span>s <span class="number">43</span>ms/step - loss: <span class="number">0.0393</span> - accuracy: <span class="number">0.9876</span> - AUC: <span class="number">0.9986</span> - val_loss: <span class="number">0.7693</span> - val_accuracy: <span class="number">0.8566</span> - val_AUC: <span class="number">0.9132</span></span><br><span class="line">Epoch <span class="number">6</span>/<span class="number">6</span></span><br><span class="line"><span class="number">1000</span>/<span class="number">1000</span> [==============================] - <span class="number">44</span>s <span class="number">44</span>ms/step - loss: <span class="number">0.0222</span> - accuracy: <span class="number">0.9926</span> - AUC: <span class="number">0.9994</span> - val_loss: <span class="number">0.9328</span> - val_accuracy: <span class="number">0.8584</span> - val_AUC: <span class="number">0.9052</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_metric(history,<span class="string">"AUC"</span>)</span><br></pre></td></tr></table></figure><p><img alt data-src="https://github.com/SimpCosm/eat_tensorflow2_in_30_days_ipynbs/raw/master/data/6-1-3-fit模型.jpg"></p><h3 id="训练模型的3种方法"><a href="#训练模型的3种方法" class="headerlink" title="训练模型的3种方法"></a>训练模型的3种方法</h3><p>模型的训练主要有内置fit方法、内置tran_on_batch方法、自定义训练循环。</p><p>注：fit_generator方法在tf.keras中不推荐使用，其功能已经被fit包含。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> * </span><br><span class="line"></span><br><span class="line"><span class="comment">#打印时间分割线</span></span><br><span class="line"><span class="meta">@tf.function</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">printbar</span><span class="params">()</span>:</span></span><br><span class="line">    today_ts = tf.timestamp()%(<span class="number">24</span>*<span class="number">60</span>*<span class="number">60</span>)</span><br><span class="line"></span><br><span class="line">    hour = tf.cast(today_ts//<span class="number">3600</span>+<span class="number">8</span>,tf.int32)%tf.constant(<span class="number">24</span>)</span><br><span class="line">    minite = tf.cast((today_ts%<span class="number">3600</span>)//<span class="number">60</span>,tf.int32)</span><br><span class="line">    second = tf.cast(tf.floor(today_ts%<span class="number">60</span>),tf.int32)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">timeformat</span><span class="params">(m)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> tf.strings.length(tf.strings.format(<span class="string">"&#123;&#125;"</span>,m))==<span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span>(tf.strings.format(<span class="string">"0&#123;&#125;"</span>,m))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span>(tf.strings.format(<span class="string">"&#123;&#125;"</span>,m))</span><br><span class="line">    </span><br><span class="line">    timestring = tf.strings.join([timeformat(hour),timeformat(minite),</span><br><span class="line">                timeformat(second)],separator = <span class="string">":"</span>)</span><br><span class="line">    tf.print(<span class="string">"=========="</span>*<span class="number">8</span>+timestring)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">MAX_LEN = <span class="number">300</span></span><br><span class="line">BATCH_SIZE = <span class="number">32</span></span><br><span class="line">(x_train,y_train),(x_test,y_test) = datasets.reuters.load_data()</span><br><span class="line">x_train = preprocessing.sequence.pad_sequences(x_train,maxlen=MAX_LEN)</span><br><span class="line">x_test = preprocessing.sequence.pad_sequences(x_test,maxlen=MAX_LEN)</span><br><span class="line"></span><br><span class="line">MAX_WORDS = x_train.max()+<span class="number">1</span></span><br><span class="line">CAT_NUM = y_train.max()+<span class="number">1</span></span><br><span class="line"></span><br><span class="line">ds_train = tf.data.Dataset.from_tensor_slices((x_train,y_train)) \</span><br><span class="line">          .shuffle(buffer_size = <span class="number">1000</span>).batch(BATCH_SIZE) \</span><br><span class="line">          .prefetch(tf.data.experimental.AUTOTUNE).cache()</span><br><span class="line">   </span><br><span class="line">ds_test = tf.data.Dataset.from_tensor_slices((x_test,y_test)) \</span><br><span class="line">          .shuffle(buffer_size = <span class="number">1000</span>).batch(BATCH_SIZE) \</span><br><span class="line">          .prefetch(tf.data.experimental.AUTOTUNE).cache()</span><br></pre></td></tr></table></figure><h4 id="内置fit方法"><a href="#内置fit方法" class="headerlink" title="内置fit方法"></a>内置fit方法</h4><p>该方法功能非常强大, 支持对numpy array, tf.data.Dataset以及 Python generator数据进行训练。</p><p>并且可以通过设置回调函数实现对训练过程的复杂控制逻辑。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">tf.keras.backend.clear_session()</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_model</span><span class="params">()</span>:</span></span><br><span class="line">    </span><br><span class="line">    model = models.Sequential()</span><br><span class="line">    model.add(layers.Embedding(MAX_WORDS,<span class="number">7</span>,input_length=MAX_LEN))</span><br><span class="line">    model.add(layers.Conv1D(filters = <span class="number">64</span>,kernel_size = <span class="number">5</span>,activation = <span class="string">"relu"</span>))</span><br><span class="line">    model.add(layers.MaxPool1D(<span class="number">2</span>))</span><br><span class="line">    model.add(layers.Conv1D(filters = <span class="number">32</span>,kernel_size = <span class="number">3</span>,activation = <span class="string">"relu"</span>))</span><br><span class="line">    model.add(layers.MaxPool1D(<span class="number">2</span>))</span><br><span class="line">    model.add(layers.Flatten())</span><br><span class="line">    model.add(layers.Dense(CAT_NUM,activation = <span class="string">"softmax"</span>))</span><br><span class="line">    <span class="keyword">return</span>(model)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compile_model</span><span class="params">(model)</span>:</span></span><br><span class="line">    model.compile(optimizer=optimizers.Nadam(),</span><br><span class="line">                loss=losses.SparseCategoricalCrossentropy(),</span><br><span class="line">                metrics=[metrics.SparseCategoricalAccuracy(),metrics.SparseTopKCategoricalAccuracy(<span class="number">5</span>)]) </span><br><span class="line">    <span class="keyword">return</span>(model)</span><br><span class="line"> </span><br><span class="line">model = create_model()</span><br><span class="line">model.summary()</span><br><span class="line">model = compile_model(model)</span><br></pre></td></tr></table></figure><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">Model: "sequential"</span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">Layer (type)                 Output Shape              Param #   </span><br><span class="line">=================================================================</span><br><span class="line">embedding (Embedding)        (None, 300, 7)            216874    </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">conv1d (Conv1D)              (None, 296, 64)           2304      </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">max_pooling1d (MaxPooling1D) (None, 148, 64)           0         </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">conv1d_1 (Conv1D)            (None, 146, 32)           6176      </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">max<span class="emphasis">_pooling1d_</span>1 (MaxPooling1 (None, 73, 32)            0         </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">flatten (Flatten)            (None, 2336)              0         </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">dense (Dense)                (None, 46)                107502    </span><br><span class="line">=================================================================</span><br><span class="line">Total params: 332,856</span><br><span class="line">Trainable params: 332,856</span><br><span class="line">Non-trainable params: 0</span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">history = model.fit(ds_train,validation_data = ds_test,epochs = <span class="number">10</span>)</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">Train <span class="keyword">for</span> <span class="number">281</span> steps, validate <span class="keyword">for</span> <span class="number">71</span> steps</span><br><span class="line">Epoch <span class="number">1</span>/<span class="number">10</span></span><br><span class="line"><span class="number">281</span>/<span class="number">281</span> [==============================] - <span class="number">11</span>s <span class="number">37</span>ms/step - loss: <span class="number">2.0231</span> - sparse_categorical_accuracy: <span class="number">0.4636</span> - sparse_top_k_categorical_accuracy: <span class="number">0.7450</span> - val_loss: <span class="number">1.7346</span> - val_sparse_categorical_accuracy: <span class="number">0.5534</span> - val_sparse_top_k_categorical_accuracy: <span class="number">0.7560</span></span><br><span class="line">Epoch <span class="number">2</span>/<span class="number">10</span></span><br><span class="line"><span class="number">281</span>/<span class="number">281</span> [==============================] - <span class="number">9</span>s <span class="number">31</span>ms/step - loss: <span class="number">1.5079</span> - sparse_categorical_accuracy: <span class="number">0.6091</span> - sparse_top_k_categorical_accuracy: <span class="number">0.7901</span> - val_loss: <span class="number">1.5475</span> - val_sparse_categorical_accuracy: <span class="number">0.6109</span> - val_sparse_top_k_categorical_accuracy: <span class="number">0.7792</span></span><br><span class="line">Epoch <span class="number">3</span>/<span class="number">10</span></span><br><span class="line"><span class="number">281</span>/<span class="number">281</span> [==============================] - <span class="number">9</span>s <span class="number">33</span>ms/step - loss: <span class="number">1.2204</span> - sparse_categorical_accuracy: <span class="number">0.6823</span> - sparse_top_k_categorical_accuracy: <span class="number">0.8448</span> - val_loss: <span class="number">1.5455</span> - val_sparse_categorical_accuracy: <span class="number">0.6367</span> - val_sparse_top_k_categorical_accuracy: <span class="number">0.8001</span></span><br><span class="line">Epoch <span class="number">4</span>/<span class="number">10</span></span><br><span class="line"><span class="number">281</span>/<span class="number">281</span> [==============================] - <span class="number">9</span>s <span class="number">33</span>ms/step - loss: <span class="number">0.9382</span> - sparse_categorical_accuracy: <span class="number">0.7543</span> - sparse_top_k_categorical_accuracy: <span class="number">0.9075</span> - val_loss: <span class="number">1.6780</span> - val_sparse_categorical_accuracy: <span class="number">0.6398</span> - val_sparse_top_k_categorical_accuracy: <span class="number">0.8032</span></span><br><span class="line">Epoch <span class="number">5</span>/<span class="number">10</span></span><br><span class="line"><span class="number">281</span>/<span class="number">281</span> [==============================] - <span class="number">10</span>s <span class="number">34</span>ms/step - loss: <span class="number">0.6791</span> - sparse_categorical_accuracy: <span class="number">0.8255</span> - sparse_top_k_categorical_accuracy: <span class="number">0.9513</span> - val_loss: <span class="number">1.9426</span> - val_sparse_categorical_accuracy: <span class="number">0.6376</span> - val_sparse_top_k_categorical_accuracy: <span class="number">0.7956</span></span><br><span class="line">Epoch <span class="number">6</span>/<span class="number">10</span></span><br><span class="line"><span class="number">281</span>/<span class="number">281</span> [==============================] - <span class="number">9</span>s <span class="number">33</span>ms/step - loss: <span class="number">0.5063</span> - sparse_categorical_accuracy: <span class="number">0.8762</span> - sparse_top_k_categorical_accuracy: <span class="number">0.9716</span> - val_loss: <span class="number">2.2141</span> - val_sparse_categorical_accuracy: <span class="number">0.6291</span> - val_sparse_top_k_categorical_accuracy: <span class="number">0.7947</span></span><br><span class="line">Epoch <span class="number">7</span>/<span class="number">10</span></span><br><span class="line"><span class="number">281</span>/<span class="number">281</span> [==============================] - <span class="number">10</span>s <span class="number">37</span>ms/step - loss: <span class="number">0.4031</span> - sparse_categorical_accuracy: <span class="number">0.9050</span> - sparse_top_k_categorical_accuracy: <span class="number">0.9817</span> - val_loss: <span class="number">2.4126</span> - val_sparse_categorical_accuracy: <span class="number">0.6264</span> - val_sparse_top_k_categorical_accuracy: <span class="number">0.7947</span></span><br><span class="line">Epoch <span class="number">8</span>/<span class="number">10</span></span><br><span class="line"><span class="number">281</span>/<span class="number">281</span> [==============================] - <span class="number">10</span>s <span class="number">35</span>ms/step - loss: <span class="number">0.3380</span> - sparse_categorical_accuracy: <span class="number">0.9205</span> - sparse_top_k_categorical_accuracy: <span class="number">0.9881</span> - val_loss: <span class="number">2.5366</span> - val_sparse_categorical_accuracy: <span class="number">0.6242</span> - val_sparse_top_k_categorical_accuracy: <span class="number">0.7974</span></span><br><span class="line">Epoch <span class="number">9</span>/<span class="number">10</span></span><br><span class="line"><span class="number">281</span>/<span class="number">281</span> [==============================] - <span class="number">10</span>s <span class="number">36</span>ms/step - loss: <span class="number">0.2921</span> - sparse_categorical_accuracy: <span class="number">0.9299</span> - sparse_top_k_categorical_accuracy: <span class="number">0.9909</span> - val_loss: <span class="number">2.6564</span> - val_sparse_categorical_accuracy: <span class="number">0.6242</span> - val_sparse_top_k_categorical_accuracy: <span class="number">0.7983</span></span><br><span class="line">Epoch <span class="number">10</span>/<span class="number">10</span></span><br><span class="line"><span class="number">281</span>/<span class="number">281</span> [==============================] - <span class="number">9</span>s <span class="number">30</span>ms/step - loss: <span class="number">0.2613</span> - sparse_categorical_accuracy: <span class="number">0.9334</span> - sparse_top_k_categorical_accuracy: <span class="number">0.9947</span> - val_loss: <span class="number">2.7365</span> - val_sparse_categorical_accuracy: <span class="number">0.6220</span> - val_sparse_top_k_categorical_accuracy: <span class="number">0.8005</span></span><br></pre></td></tr></table></figure><h4 id="内置train-on-batch方法"><a href="#内置train-on-batch方法" class="headerlink" title="内置train_on_batch方法"></a>内置train_on_batch方法</h4><p>该内置方法相比较fit方法更加灵活，可以不通过回调函数而直接在批次层次上更加精细地控制训练的过程。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">tf.keras.backend.clear_session()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_model</span><span class="params">()</span>:</span></span><br><span class="line">    model = models.Sequential()</span><br><span class="line"></span><br><span class="line">    model.add(layers.Embedding(MAX_WORDS,<span class="number">7</span>,input_length=MAX_LEN))</span><br><span class="line">    model.add(layers.Conv1D(filters = <span class="number">64</span>,kernel_size = <span class="number">5</span>,activation = <span class="string">"relu"</span>))</span><br><span class="line">    model.add(layers.MaxPool1D(<span class="number">2</span>))</span><br><span class="line">    model.add(layers.Conv1D(filters = <span class="number">32</span>,kernel_size = <span class="number">3</span>,activation = <span class="string">"relu"</span>))</span><br><span class="line">    model.add(layers.MaxPool1D(<span class="number">2</span>))</span><br><span class="line">    model.add(layers.Flatten())</span><br><span class="line">    model.add(layers.Dense(CAT_NUM,activation = <span class="string">"softmax"</span>))</span><br><span class="line">    <span class="keyword">return</span>(model)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compile_model</span><span class="params">(model)</span>:</span></span><br><span class="line">    model.compile(optimizer=optimizers.Nadam(),</span><br><span class="line">                loss=losses.SparseCategoricalCrossentropy(),</span><br><span class="line">                metrics=[metrics.SparseCategoricalAccuracy(),metrics.SparseTopKCategoricalAccuracy(<span class="number">5</span>)]) </span><br><span class="line">    <span class="keyword">return</span>(model)</span><br><span class="line"> </span><br><span class="line">model = create_model()</span><br><span class="line">model.summary()</span><br><span class="line">model = compile_model(model)</span><br></pre></td></tr></table></figure><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">Model: "sequential"</span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">Layer (type)                 Output Shape              Param #   </span><br><span class="line">=================================================================</span><br><span class="line">embedding (Embedding)        (None, 300, 7)            216874    </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">conv1d (Conv1D)              (None, 296, 64)           2304      </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">max_pooling1d (MaxPooling1D) (None, 148, 64)           0         </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">conv1d_1 (Conv1D)            (None, 146, 32)           6176      </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">max<span class="emphasis">_pooling1d_</span>1 (MaxPooling1 (None, 73, 32)            0         </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">flatten (Flatten)            (None, 2336)              0         </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">dense (Dense)                (None, 46)                107502    </span><br><span class="line">=================================================================</span><br><span class="line">Total params: 332,856</span><br><span class="line">Trainable params: 332,856</span><br><span class="line">Non-trainable params: 0</span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_model</span><span class="params">(model,ds_train,ds_valid,epoches)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> tf.range(<span class="number">1</span>,epoches+<span class="number">1</span>):</span><br><span class="line">        model.reset_metrics()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 在后期降低学习率</span></span><br><span class="line">        <span class="keyword">if</span> epoch == <span class="number">5</span>:</span><br><span class="line">            model.optimizer.lr.assign(model.optimizer.lr/<span class="number">2.0</span>)</span><br><span class="line">            tf.print(<span class="string">"Lowering optimizer Learning Rate...\n\n"</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> x, y <span class="keyword">in</span> ds_train:</span><br><span class="line">            train_result = model.train_on_batch(x, y)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> x, y <span class="keyword">in</span> ds_valid:</span><br><span class="line">            valid_result = model.test_on_batch(x, y,reset_metrics=<span class="literal">False</span>)</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">if</span> epoch%<span class="number">1</span> ==<span class="number">0</span>:</span><br><span class="line">            printbar()</span><br><span class="line">            tf.print(<span class="string">"epoch = "</span>,epoch)</span><br><span class="line">            print(<span class="string">"train:"</span>,dict(zip(model.metrics_names,train_result)))</span><br><span class="line">            print(<span class="string">"valid:"</span>,dict(zip(model.metrics_names,valid_result)))</span><br><span class="line">            print(<span class="string">""</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_model(model,ds_train,ds_test,<span class="number">10</span>)</span><br></pre></td></tr></table></figure><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">================================================================================13:09:19</span></span><br><span class="line"><span class="string">epoch</span> <span class="string">=</span>  <span class="number">1</span></span><br><span class="line"><span class="attr">train:</span> <span class="string">&#123;'loss':</span> <span class="number">0.82411176</span><span class="string">,</span> <span class="attr">'sparse_categorical_accuracy':</span> <span class="number">0.77272725</span><span class="string">,</span> <span class="attr">'sparse_top_k_categorical_accuracy':</span> <span class="number">0.8636364</span><span class="string">&#125;</span></span><br><span class="line"><span class="attr">valid:</span> <span class="string">&#123;'loss':</span> <span class="number">1.9265995</span><span class="string">,</span> <span class="attr">'sparse_categorical_accuracy':</span> <span class="number">0.5743544</span><span class="string">,</span> <span class="attr">'sparse_top_k_categorical_accuracy':</span> <span class="number">0.75779164</span><span class="string">&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="string">================================================================================13:09:27</span></span><br><span class="line"><span class="string">epoch</span> <span class="string">=</span>  <span class="number">2</span></span><br><span class="line"><span class="attr">train:</span> <span class="string">&#123;'loss':</span> <span class="number">0.6006621</span><span class="string">,</span> <span class="attr">'sparse_categorical_accuracy':</span> <span class="number">0.90909094</span><span class="string">,</span> <span class="attr">'sparse_top_k_categorical_accuracy':</span> <span class="number">0.95454544</span><span class="string">&#125;</span></span><br><span class="line"><span class="attr">valid:</span> <span class="string">&#123;'loss':</span> <span class="number">1.844159</span><span class="string">,</span> <span class="attr">'sparse_categorical_accuracy':</span> <span class="number">0.6126447</span><span class="string">,</span> <span class="attr">'sparse_top_k_categorical_accuracy':</span> <span class="number">0.7920748</span><span class="string">&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="string">================================================================================13:09:35</span></span><br><span class="line"><span class="string">epoch</span> <span class="string">=</span>  <span class="number">3</span></span><br><span class="line"><span class="attr">train:</span> <span class="string">&#123;'loss':</span> <span class="number">0.36935613</span><span class="string">,</span> <span class="attr">'sparse_categorical_accuracy':</span> <span class="number">0.90909094</span><span class="string">,</span> <span class="attr">'sparse_top_k_categorical_accuracy':</span> <span class="number">0.95454544</span><span class="string">&#125;</span></span><br><span class="line"><span class="attr">valid:</span> <span class="string">&#123;'loss':</span> <span class="number">2.163433</span><span class="string">,</span> <span class="attr">'sparse_categorical_accuracy':</span> <span class="number">0.63312554</span><span class="string">,</span> <span class="attr">'sparse_top_k_categorical_accuracy':</span> <span class="number">0.8045414</span><span class="string">&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="string">================================================================================13:09:42</span></span><br><span class="line"><span class="string">epoch</span> <span class="string">=</span>  <span class="number">4</span></span><br><span class="line"><span class="attr">train:</span> <span class="string">&#123;'loss':</span> <span class="number">0.2304088</span><span class="string">,</span> <span class="attr">'sparse_categorical_accuracy':</span> <span class="number">0.90909094</span><span class="string">,</span> <span class="attr">'sparse_top_k_categorical_accuracy':</span> <span class="number">1.0</span><span class="string">&#125;</span></span><br><span class="line"><span class="attr">valid:</span> <span class="string">&#123;'loss':</span> <span class="number">2.8911984</span><span class="string">,</span> <span class="attr">'sparse_categorical_accuracy':</span> <span class="number">0.6344613</span><span class="string">,</span> <span class="attr">'sparse_top_k_categorical_accuracy':</span> <span class="number">0.7978629</span><span class="string">&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="string">Lowering</span> <span class="string">optimizer</span> <span class="string">Learning</span> <span class="string">Rate...</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">================================================================================13:09:51</span></span><br><span class="line"><span class="string">epoch</span> <span class="string">=</span>  <span class="number">5</span></span><br><span class="line"><span class="attr">train:</span> <span class="string">&#123;'loss':</span> <span class="number">0.111194365</span><span class="string">,</span> <span class="attr">'sparse_categorical_accuracy':</span> <span class="number">0.95454544</span><span class="string">,</span> <span class="attr">'sparse_top_k_categorical_accuracy':</span> <span class="number">1.0</span><span class="string">&#125;</span></span><br><span class="line"><span class="attr">valid:</span> <span class="string">&#123;'loss':</span> <span class="number">3.6431572</span><span class="string">,</span> <span class="attr">'sparse_categorical_accuracy':</span> <span class="number">0.6295637</span><span class="string">,</span> <span class="attr">'sparse_top_k_categorical_accuracy':</span> <span class="number">0.7978629</span><span class="string">&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="string">================================================================================13:09:59</span></span><br><span class="line"><span class="string">epoch</span> <span class="string">=</span>  <span class="number">6</span></span><br><span class="line"><span class="attr">train:</span> <span class="string">&#123;'loss':</span> <span class="number">0.07741702</span><span class="string">,</span> <span class="attr">'sparse_categorical_accuracy':</span> <span class="number">0.95454544</span><span class="string">,</span> <span class="attr">'sparse_top_k_categorical_accuracy':</span> <span class="number">1.0</span><span class="string">&#125;</span></span><br><span class="line"><span class="attr">valid:</span> <span class="string">&#123;'loss':</span> <span class="number">4.074161</span><span class="string">,</span> <span class="attr">'sparse_categorical_accuracy':</span> <span class="number">0.6255565</span><span class="string">,</span> <span class="attr">'sparse_top_k_categorical_accuracy':</span> <span class="number">0.794301</span><span class="string">&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="string">================================================================================13:10:07</span></span><br><span class="line"><span class="string">epoch</span> <span class="string">=</span>  <span class="number">7</span></span><br><span class="line"><span class="attr">train:</span> <span class="string">&#123;'loss':</span> <span class="number">0.056113098</span><span class="string">,</span> <span class="attr">'sparse_categorical_accuracy':</span> <span class="number">1.0</span><span class="string">,</span> <span class="attr">'sparse_top_k_categorical_accuracy':</span> <span class="number">1.0</span><span class="string">&#125;</span></span><br><span class="line"><span class="attr">valid:</span> <span class="string">&#123;'loss':</span> <span class="number">4.4461513</span><span class="string">,</span> <span class="attr">'sparse_categorical_accuracy':</span> <span class="number">0.6273375</span><span class="string">,</span> <span class="attr">'sparse_top_k_categorical_accuracy':</span> <span class="number">0.79652715</span><span class="string">&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="string">================================================================================13:10:17</span></span><br><span class="line"><span class="string">epoch</span> <span class="string">=</span>  <span class="number">8</span></span><br><span class="line"><span class="attr">train:</span> <span class="string">&#123;'loss':</span> <span class="number">0.043448802</span><span class="string">,</span> <span class="attr">'sparse_categorical_accuracy':</span> <span class="number">1.0</span><span class="string">,</span> <span class="attr">'sparse_top_k_categorical_accuracy':</span> <span class="number">1.0</span><span class="string">&#125;</span></span><br><span class="line"><span class="attr">valid:</span> <span class="string">&#123;'loss':</span> <span class="number">4.7687583</span><span class="string">,</span> <span class="attr">'sparse_categorical_accuracy':</span> <span class="number">0.6224399</span><span class="string">,</span> <span class="attr">'sparse_top_k_categorical_accuracy':</span> <span class="number">0.79741764</span><span class="string">&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="string">================================================================================13:10:26</span></span><br><span class="line"><span class="string">epoch</span> <span class="string">=</span>  <span class="number">9</span></span><br><span class="line"><span class="attr">train:</span> <span class="string">&#123;'loss':</span> <span class="number">0.035002146</span><span class="string">,</span> <span class="attr">'sparse_categorical_accuracy':</span> <span class="number">1.0</span><span class="string">,</span> <span class="attr">'sparse_top_k_categorical_accuracy':</span> <span class="number">1.0</span><span class="string">&#125;</span></span><br><span class="line"><span class="attr">valid:</span> <span class="string">&#123;'loss':</span> <span class="number">5.130505</span><span class="string">,</span> <span class="attr">'sparse_categorical_accuracy':</span> <span class="number">0.6175423</span><span class="string">,</span> <span class="attr">'sparse_top_k_categorical_accuracy':</span> <span class="number">0.794301</span><span class="string">&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="string">================================================================================13:10:34</span></span><br><span class="line"><span class="string">epoch</span> <span class="string">=</span>  <span class="number">10</span></span><br><span class="line"><span class="attr">train:</span> <span class="string">&#123;'loss':</span> <span class="number">0.028303564</span><span class="string">,</span> <span class="attr">'sparse_categorical_accuracy':</span> <span class="number">1.0</span><span class="string">,</span> <span class="attr">'sparse_top_k_categorical_accuracy':</span> <span class="number">1.0</span><span class="string">&#125;</span></span><br><span class="line"><span class="attr">valid:</span> <span class="string">&#123;'loss':</span> <span class="number">5.4559293</span><span class="string">,</span> <span class="attr">'sparse_categorical_accuracy':</span> <span class="number">0.6148709</span><span class="string">,</span> <span class="attr">'sparse_top_k_categorical_accuracy':</span> <span class="number">0.7947462</span><span class="string">&#125;</span></span><br></pre></td></tr></table></figure><h4 id="自定义训练循环"><a href="#自定义训练循环" class="headerlink" title="自定义训练循环"></a>自定义训练循环</h4><p>自定义训练循环无需编译模型，直接利用优化器根据损失函数反向传播迭代参数，拥有最高的灵活性。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">tf.keras.backend.clear_session()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_model</span><span class="params">()</span>:</span></span><br><span class="line">    </span><br><span class="line">    model = models.Sequential()</span><br><span class="line"></span><br><span class="line">    model.add(layers.Embedding(MAX_WORDS,<span class="number">7</span>,input_length=MAX_LEN))</span><br><span class="line">    model.add(layers.Conv1D(filters = <span class="number">64</span>,kernel_size = <span class="number">5</span>,activation = <span class="string">"relu"</span>))</span><br><span class="line">    model.add(layers.MaxPool1D(<span class="number">2</span>))</span><br><span class="line">    model.add(layers.Conv1D(filters = <span class="number">32</span>,kernel_size = <span class="number">3</span>,activation = <span class="string">"relu"</span>))</span><br><span class="line">    model.add(layers.MaxPool1D(<span class="number">2</span>))</span><br><span class="line">    model.add(layers.Flatten())</span><br><span class="line">    model.add(layers.Dense(CAT_NUM,activation = <span class="string">"softmax"</span>))</span><br><span class="line">    <span class="keyword">return</span>(model)</span><br><span class="line"></span><br><span class="line">model = create_model()</span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line">optimizer = optimizers.Nadam()</span><br><span class="line">loss_func = losses.SparseCategoricalCrossentropy()</span><br><span class="line"></span><br><span class="line">train_loss = metrics.Mean(name=<span class="string">'train_loss'</span>)</span><br><span class="line">train_metric = metrics.SparseCategoricalAccuracy(name=<span class="string">'train_accuracy'</span>)</span><br><span class="line"></span><br><span class="line">valid_loss = metrics.Mean(name=<span class="string">'valid_loss'</span>)</span><br><span class="line">valid_metric = metrics.SparseCategoricalAccuracy(name=<span class="string">'valid_accuracy'</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">@tf.function</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_step</span><span class="params">(model, features, labels)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">        predictions = model(features,training = <span class="literal">True</span>)</span><br><span class="line">        loss = loss_func(labels, predictions)</span><br><span class="line">    gradients = tape.gradient(loss, model.trainable_variables)</span><br><span class="line">    optimizer.apply_gradients(zip(gradients, model.trainable_variables))</span><br><span class="line"></span><br><span class="line">    train_loss.update_state(loss)</span><br><span class="line">    train_metric.update_state(labels, predictions)</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="meta">@tf.function</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">valid_step</span><span class="params">(model, features, labels)</span>:</span></span><br><span class="line">    predictions = model(features)</span><br><span class="line">    batch_loss = loss_func(labels, predictions)</span><br><span class="line">    valid_loss.update_state(batch_loss)</span><br><span class="line">    valid_metric.update_state(labels, predictions)</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_model</span><span class="params">(model,ds_train,ds_valid,epochs)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> tf.range(<span class="number">1</span>,epochs+<span class="number">1</span>):</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> features, labels <span class="keyword">in</span> ds_train:</span><br><span class="line">            train_step(model,features,labels)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> features, labels <span class="keyword">in</span> ds_valid:</span><br><span class="line">            valid_step(model,features,labels)</span><br><span class="line"></span><br><span class="line">        logs = <span class="string">'Epoch=&#123;&#125;,Loss:&#123;&#125;,Accuracy:&#123;&#125;,Valid Loss:&#123;&#125;,Valid Accuracy:&#123;&#125;'</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> epoch%<span class="number">1</span> ==<span class="number">0</span>:</span><br><span class="line">            printbar()</span><br><span class="line">            tf.print(tf.strings.format(logs,</span><br><span class="line">            (epoch,train_loss.result(),train_metric.result(),valid_loss.result(),valid_metric.result())))</span><br><span class="line">            tf.print(<span class="string">""</span>)</span><br><span class="line">            </span><br><span class="line">        train_loss.reset_states()</span><br><span class="line">        valid_loss.reset_states()</span><br><span class="line">        train_metric.reset_states()</span><br><span class="line">        valid_metric.reset_states()</span><br><span class="line"></span><br><span class="line">train_model(model,ds_train,ds_test,<span class="number">10</span>)</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">================================================================================<span class="number">13</span>:<span class="number">12</span>:<span class="number">03</span></span><br><span class="line">Epoch=<span class="number">1</span>,Loss:<span class="number">2.02051544</span>,Accuracy:<span class="number">0.460253835</span>,Valid Loss:<span class="number">1.75700927</span>,Valid Accuracy:<span class="number">0.536954582</span></span><br><span class="line"></span><br><span class="line">================================================================================<span class="number">13</span>:<span class="number">12</span>:<span class="number">09</span></span><br><span class="line">Epoch=<span class="number">2</span>,Loss:<span class="number">1.510795</span>,Accuracy:<span class="number">0.610665798</span>,Valid Loss:<span class="number">1.55349839</span>,Valid Accuracy:<span class="number">0.616206586</span></span><br><span class="line"></span><br><span class="line">================================================================================<span class="number">13</span>:<span class="number">12</span>:<span class="number">17</span></span><br><span class="line">Epoch=<span class="number">3</span>,Loss:<span class="number">1.19221532</span>,Accuracy:<span class="number">0.696170092</span>,Valid Loss:<span class="number">1.52315605</span>,Valid Accuracy:<span class="number">0.651380241</span></span><br><span class="line"></span><br><span class="line">================================================================================<span class="number">13</span>:<span class="number">12</span>:<span class="number">23</span></span><br><span class="line">Epoch=<span class="number">4</span>,Loss:<span class="number">0.90101546</span>,Accuracy:<span class="number">0.766310394</span>,Valid Loss:<span class="number">1.68327653</span>,Valid Accuracy:<span class="number">0.648263574</span></span><br><span class="line"></span><br><span class="line">================================================================================<span class="number">13</span>:<span class="number">12</span>:<span class="number">30</span></span><br><span class="line">Epoch=<span class="number">5</span>,Loss:<span class="number">0.655430496</span>,Accuracy:<span class="number">0.831329346</span>,Valid Loss:<span class="number">1.90872383</span>,Valid Accuracy:<span class="number">0.641139805</span></span><br><span class="line"></span><br><span class="line">================================================================================<span class="number">13</span>:<span class="number">12</span>:<span class="number">37</span></span><br><span class="line">Epoch=<span class="number">6</span>,Loss:<span class="number">0.492730737</span>,Accuracy:<span class="number">0.877866864</span>,Valid Loss:<span class="number">2.09966016</span>,Valid Accuracy:<span class="number">0.63223511</span></span><br><span class="line"></span><br><span class="line">================================================================================<span class="number">13</span>:<span class="number">12</span>:<span class="number">44</span></span><br><span class="line">Epoch=<span class="number">7</span>,Loss:<span class="number">0.391238362</span>,Accuracy:<span class="number">0.904030263</span>,Valid Loss:<span class="number">2.27431226</span>,Valid Accuracy:<span class="number">0.625111282</span></span><br><span class="line"></span><br><span class="line">================================================================================<span class="number">13</span>:<span class="number">12</span>:<span class="number">51</span></span><br><span class="line">Epoch=<span class="number">8</span>,Loss:<span class="number">0.327761739</span>,Accuracy:<span class="number">0.922066331</span>,Valid Loss:<span class="number">2.42568827</span>,Valid Accuracy:<span class="number">0.617542326</span></span><br><span class="line"></span><br><span class="line">================================================================================<span class="number">13</span>:<span class="number">12</span>:<span class="number">58</span></span><br><span class="line">Epoch=<span class="number">9</span>,Loss:<span class="number">0.285573095</span>,Accuracy:<span class="number">0.930527747</span>,Valid Loss:<span class="number">2.55942106</span>,Valid Accuracy:<span class="number">0.612644672</span></span><br><span class="line"></span><br><span class="line">================================================================================<span class="number">13</span>:<span class="number">13</span>:<span class="number">05</span></span><br><span class="line">Epoch=<span class="number">10</span>,Loss:<span class="number">0.255482465</span>,Accuracy:<span class="number">0.936094403</span>,Valid Loss:<span class="number">2.67789412</span>,Valid Accuracy:<span class="number">0.612199485</span></span><br></pre></td></tr></table></figure><h3 id="使用单GPU训练模型"><a href="#使用单GPU训练模型" class="headerlink" title="使用单GPU训练模型"></a>使用单GPU训练模型</h3><p>深度学习的训练过程常常非常耗时，一个模型训练几个小时是家常便饭，训练几天也是常有的事情，有时候甚至要训练几十天。</p><p>训练过程的耗时主要来自于两个部分，一部分来自数据准备，另一部分来自参数迭代。</p><p>当数据准备过程还是模型训练时间的主要瓶颈时，我们可以使用更多进程来准备数据。</p><p>当参数迭代过程成为训练时间的主要瓶颈时，我们通常的方法是应用GPU或者Google的TPU来进行加速。</p><p>详见《用GPU加速Keras模型——Colab免费GPU使用攻略》</p><p><a href="https://zhuanlan.zhihu.com/p/68509398" target="_blank" rel="external nofollow noopener noreferrer">https://zhuanlan.zhihu.com/p/68509398</a></p><p>无论是内置fit方法，还是自定义训练循环，从CPU切换成单GPU训练模型都是非常方便的，无需更改任何代码。当存在可用的GPU时，如果不特意指定device，tensorflow会自动优先选择使用GPU来创建张量和执行张量计算。</p><p>但如果是在公司或者学校实验室的服务器环境，存在多个GPU和多个使用者时，为了不让单个同学的任务占用全部GPU资源导致其他同学无法使用（tensorflow默认获取全部GPU的全部内存资源权限，但实际上只使用一个GPU的部分资源），我们通常会在开头增加以下几行代码以控制每个任务使用的GPU编号和显存大小，以便其他同学也能够同时训练模型。</p><p>在Colab笔记本中：修改-&gt;笔记本设置-&gt;硬件加速器 中选择 GPU</p><p>注：以下代码只能在Colab 上才能正确执行。</p><p>可通过以下colab链接测试效果《tf_单GPU》：</p><p><a href="https://colab.research.google.com/drive/1r5dLoeJq5z01sU72BX2M5UiNSkuxsEFe" target="_blank" rel="external nofollow noopener noreferrer">https://colab.research.google.com/drive/1r5dLoeJq5z01sU72BX2M5UiNSkuxsEFe</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># tensorflow_version 2.x</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">print(tf.__version__)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> * </span><br><span class="line"></span><br><span class="line"><span class="comment">#打印时间分割线</span></span><br><span class="line"><span class="meta">@tf.function</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">printbar</span><span class="params">()</span>:</span></span><br><span class="line">    today_ts = tf.timestamp()%(<span class="number">24</span>*<span class="number">60</span>*<span class="number">60</span>)</span><br><span class="line"></span><br><span class="line">    hour = tf.cast(today_ts//<span class="number">3600</span>+<span class="number">8</span>,tf.int32)%tf.constant(<span class="number">24</span>)</span><br><span class="line">    minite = tf.cast((today_ts%<span class="number">3600</span>)//<span class="number">60</span>,tf.int32)</span><br><span class="line">    second = tf.cast(tf.floor(today_ts%<span class="number">60</span>),tf.int32)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">timeformat</span><span class="params">(m)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> tf.strings.length(tf.strings.format(<span class="string">"&#123;&#125;"</span>,m))==<span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span>(tf.strings.format(<span class="string">"0&#123;&#125;"</span>,m))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span>(tf.strings.format(<span class="string">"&#123;&#125;"</span>,m))</span><br><span class="line">    </span><br><span class="line">    timestring = tf.strings.join([timeformat(hour),timeformat(minite),</span><br><span class="line">                timeformat(second)],separator = <span class="string">":"</span>)</span><br><span class="line">    tf.print(<span class="string">"=========="</span>*<span class="number">8</span>+timestring)</span><br></pre></td></tr></table></figure><h4 id="GPU设置"><a href="#GPU设置" class="headerlink" title="GPU设置"></a>GPU设置</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">gpus = tf.config.list_physical_devices(<span class="string">"GPU"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> gpus:</span><br><span class="line">    gpu0 = gpus[<span class="number">0</span>] <span class="comment">#如果有多个GPU，仅使用第0个GPU</span></span><br><span class="line">    tf.config.experimental.set_memory_growth(gpu0, <span class="literal">True</span>) <span class="comment">#设置GPU显存用量按需使用</span></span><br><span class="line">    <span class="comment"># 或者也可以设置GPU显存为固定使用量(例如：4G)</span></span><br><span class="line">    <span class="comment">#tf.config.experimental.set_virtual_device_configuration(gpu0,</span></span><br><span class="line">    <span class="comment">#    [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)]) </span></span><br><span class="line">    tf.config.set_visible_devices([gpu0],<span class="string">"GPU"</span>)</span><br></pre></td></tr></table></figure><p>比较GPU和CPU的计算速度</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">printbar()</span><br><span class="line"><span class="keyword">with</span> tf.device(<span class="string">"/gpu:0"</span>):</span><br><span class="line">    tf.random.set_seed(<span class="number">0</span>)</span><br><span class="line">    a = tf.random.uniform((<span class="number">10000</span>,<span class="number">100</span>),minval = <span class="number">0</span>,maxval = <span class="number">3.0</span>)</span><br><span class="line">    b = tf.random.uniform((<span class="number">100</span>,<span class="number">100000</span>),minval = <span class="number">0</span>,maxval = <span class="number">3.0</span>)</span><br><span class="line">    c = a@b</span><br><span class="line">    tf.print(tf.reduce_sum(tf.reduce_sum(c,axis = <span class="number">0</span>),axis=<span class="number">0</span>))</span><br><span class="line">printbar()</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">================================================================================<span class="number">17</span>:<span class="number">37</span>:<span class="number">01</span></span><br><span class="line"><span class="number">2.24953778e+11</span></span><br><span class="line">================================================================================<span class="number">17</span>:<span class="number">37</span>:<span class="number">01</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">printbar()</span><br><span class="line"><span class="keyword">with</span> tf.device(<span class="string">"/cpu:0"</span>):</span><br><span class="line">    tf.random.set_seed(<span class="number">0</span>)</span><br><span class="line">    a = tf.random.uniform((<span class="number">10000</span>,<span class="number">100</span>),minval = <span class="number">0</span>,maxval = <span class="number">3.0</span>)</span><br><span class="line">    b = tf.random.uniform((<span class="number">100</span>,<span class="number">100000</span>),minval = <span class="number">0</span>,maxval = <span class="number">3.0</span>)</span><br><span class="line">    c = a@b</span><br><span class="line">    tf.print(tf.reduce_sum(tf.reduce_sum(c,axis = <span class="number">0</span>),axis=<span class="number">0</span>))</span><br><span class="line">printbar()</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">================================================================================<span class="number">17</span>:<span class="number">37</span>:<span class="number">34</span></span><br><span class="line"><span class="number">2.24953795e+11</span></span><br><span class="line">================================================================================<span class="number">17</span>:<span class="number">37</span>:<span class="number">40</span></span><br></pre></td></tr></table></figure><h4 id="准备数据-10"><a href="#准备数据-10" class="headerlink" title="准备数据"></a>准备数据</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">MAX_LEN = <span class="number">300</span></span><br><span class="line">BATCH_SIZE = <span class="number">32</span></span><br><span class="line">(x_train,y_train),(x_test,y_test) = datasets.reuters.load_data()</span><br><span class="line">x_train = preprocessing.sequence.pad_sequences(x_train,maxlen=MAX_LEN)</span><br><span class="line">x_test = preprocessing.sequence.pad_sequences(x_test,maxlen=MAX_LEN)</span><br><span class="line"></span><br><span class="line">MAX_WORDS = x_train.max()+<span class="number">1</span></span><br><span class="line">CAT_NUM = y_train.max()+<span class="number">1</span></span><br><span class="line"></span><br><span class="line">ds_train = tf.data.Dataset.from_tensor_slices((x_train,y_train)) \</span><br><span class="line">          .shuffle(buffer_size = <span class="number">1000</span>).batch(BATCH_SIZE) \</span><br><span class="line">          .prefetch(tf.data.experimental.AUTOTUNE).cache()</span><br><span class="line">   </span><br><span class="line">ds_test = tf.data.Dataset.from_tensor_slices((x_test,y_test)) \</span><br><span class="line">          .shuffle(buffer_size = <span class="number">1000</span>).batch(BATCH_SIZE) \</span><br><span class="line">          .prefetch(tf.data.experimental.AUTOTUNE).cache()</span><br></pre></td></tr></table></figure><h4 id="定义模型-10"><a href="#定义模型-10" class="headerlink" title="定义模型"></a>定义模型</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">tf.keras.backend.clear_session()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_model</span><span class="params">()</span>:</span></span><br><span class="line">    </span><br><span class="line">    model = models.Sequential()</span><br><span class="line"></span><br><span class="line">    model.add(layers.Embedding(MAX_WORDS,<span class="number">7</span>,input_length=MAX_LEN))</span><br><span class="line">    model.add(layers.Conv1D(filters = <span class="number">64</span>,kernel_size = <span class="number">5</span>,activation = <span class="string">"relu"</span>))</span><br><span class="line">    model.add(layers.MaxPool1D(<span class="number">2</span>))</span><br><span class="line">    model.add(layers.Conv1D(filters = <span class="number">32</span>,kernel_size = <span class="number">3</span>,activation = <span class="string">"relu"</span>))</span><br><span class="line">    model.add(layers.MaxPool1D(<span class="number">2</span>))</span><br><span class="line">    model.add(layers.Flatten())</span><br><span class="line">    model.add(layers.Dense(CAT_NUM,activation = <span class="string">"softmax"</span>))</span><br><span class="line">    <span class="keyword">return</span>(model)</span><br><span class="line"></span><br><span class="line">model = create_model()</span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">Model: "sequential"</span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">Layer (type)                 Output Shape              Param #   </span><br><span class="line">=================================================================</span><br><span class="line">embedding (Embedding)        (None, 300, 7)            216874    </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">conv1d (Conv1D)              (None, 296, 64)           2304      </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">max_pooling1d (MaxPooling1D) (None, 148, 64)           0         </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">conv1d_1 (Conv1D)            (None, 146, 32)           6176      </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">max<span class="emphasis">_pooling1d_</span>1 (MaxPooling1 (None, 73, 32)            0         </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">flatten (Flatten)            (None, 2336)              0         </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">dense (Dense)                (None, 46)                107502    </span><br><span class="line">=================================================================</span><br><span class="line">Total params: 332,856</span><br><span class="line">Trainable params: 332,856</span><br><span class="line">Non-trainable params: 0</span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br></pre></td></tr></table></figure><h4 id="训练模型-10"><a href="#训练模型-10" class="headerlink" title="训练模型"></a>训练模型</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">optimizer = optimizers.Nadam()</span><br><span class="line">loss_func = losses.SparseCategoricalCrossentropy()</span><br><span class="line"></span><br><span class="line">train_loss = metrics.Mean(name=<span class="string">'train_loss'</span>)</span><br><span class="line">train_metric = metrics.SparseCategoricalAccuracy(name=<span class="string">'train_accuracy'</span>)</span><br><span class="line"></span><br><span class="line">valid_loss = metrics.Mean(name=<span class="string">'valid_loss'</span>)</span><br><span class="line">valid_metric = metrics.SparseCategoricalAccuracy(name=<span class="string">'valid_accuracy'</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">@tf.function</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_step</span><span class="params">(model, features, labels)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">        predictions = model(features,training = <span class="literal">True</span>)</span><br><span class="line">        loss = loss_func(labels, predictions)</span><br><span class="line">    gradients = tape.gradient(loss, model.trainable_variables)</span><br><span class="line">    optimizer.apply_gradients(zip(gradients, model.trainable_variables))</span><br><span class="line"></span><br><span class="line">    train_loss.update_state(loss)</span><br><span class="line">    train_metric.update_state(labels, predictions)</span><br><span class="line">    </span><br><span class="line"><span class="meta">@tf.function</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">valid_step</span><span class="params">(model, features, labels)</span>:</span></span><br><span class="line">    predictions = model(features)</span><br><span class="line">    batch_loss = loss_func(labels, predictions)</span><br><span class="line">    valid_loss.update_state(batch_loss)</span><br><span class="line">    valid_metric.update_state(labels, predictions)</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_model</span><span class="params">(model,ds_train,ds_valid,epochs)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> tf.range(<span class="number">1</span>,epochs+<span class="number">1</span>):</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> features, labels <span class="keyword">in</span> ds_train:</span><br><span class="line">            train_step(model,features,labels)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> features, labels <span class="keyword">in</span> ds_valid:</span><br><span class="line">            valid_step(model,features,labels)</span><br><span class="line"></span><br><span class="line">        logs = <span class="string">'Epoch=&#123;&#125;,Loss:&#123;&#125;,Accuracy:&#123;&#125;,Valid Loss:&#123;&#125;,Valid Accuracy:&#123;&#125;'</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> epoch%<span class="number">1</span> ==<span class="number">0</span>:</span><br><span class="line">            printbar()</span><br><span class="line">            tf.print(tf.strings.format(logs,</span><br><span class="line">            (epoch,train_loss.result(),train_metric.result(),valid_loss.result(),valid_metric.result())))</span><br><span class="line">            tf.print(<span class="string">""</span>)</span><br><span class="line">            </span><br><span class="line">        train_loss.reset_states()</span><br><span class="line">        valid_loss.reset_states()</span><br><span class="line">        train_metric.reset_states()</span><br><span class="line">        valid_metric.reset_states()</span><br><span class="line"></span><br><span class="line">train_model(model,ds_train,ds_test,<span class="number">10</span>)</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">================================================================================<span class="number">17</span>:<span class="number">13</span>:<span class="number">26</span></span><br><span class="line">Epoch=<span class="number">1</span>,Loss:<span class="number">1.96735072</span>,Accuracy:<span class="number">0.489200622</span>,Valid Loss:<span class="number">1.64124215</span>,Valid Accuracy:<span class="number">0.582813919</span></span><br><span class="line"></span><br><span class="line">================================================================================<span class="number">17</span>:<span class="number">13</span>:<span class="number">28</span></span><br><span class="line">Epoch=<span class="number">2</span>,Loss:<span class="number">1.4640888</span>,Accuracy:<span class="number">0.624805152</span>,Valid Loss:<span class="number">1.5559175</span>,Valid Accuracy:<span class="number">0.607747078</span></span><br><span class="line"></span><br><span class="line">================================================================================<span class="number">17</span>:<span class="number">13</span>:<span class="number">30</span></span><br><span class="line">Epoch=<span class="number">3</span>,Loss:<span class="number">1.20681274</span>,Accuracy:<span class="number">0.68581605</span>,Valid Loss:<span class="number">1.58494771</span>,Valid Accuracy:<span class="number">0.622439921</span></span><br><span class="line"></span><br><span class="line">================================================================================<span class="number">17</span>:<span class="number">13</span>:<span class="number">31</span></span><br><span class="line">Epoch=<span class="number">4</span>,Loss:<span class="number">0.937500894</span>,Accuracy:<span class="number">0.75361836</span>,Valid Loss:<span class="number">1.77466083</span>,Valid Accuracy:<span class="number">0.621994674</span></span><br><span class="line"></span><br><span class="line">================================================================================<span class="number">17</span>:<span class="number">13</span>:<span class="number">33</span></span><br><span class="line">Epoch=<span class="number">5</span>,Loss:<span class="number">0.693960547</span>,Accuracy:<span class="number">0.822199941</span>,Valid Loss:<span class="number">2.00267363</span>,Valid Accuracy:<span class="number">0.6197685</span></span><br><span class="line"></span><br><span class="line">================================================================================<span class="number">17</span>:<span class="number">13</span>:<span class="number">35</span></span><br><span class="line">Epoch=<span class="number">6</span>,Loss:<span class="number">0.519614</span>,Accuracy:<span class="number">0.870296121</span>,Valid Loss:<span class="number">2.23463202</span>,Valid Accuracy:<span class="number">0.613980412</span></span><br><span class="line"></span><br><span class="line">================================================================================<span class="number">17</span>:<span class="number">13</span>:<span class="number">37</span></span><br><span class="line">Epoch=<span class="number">7</span>,Loss:<span class="number">0.408562034</span>,Accuracy:<span class="number">0.901246965</span>,Valid Loss:<span class="number">2.46969271</span>,Valid Accuracy:<span class="number">0.612199485</span></span><br><span class="line"></span><br><span class="line">================================================================================<span class="number">17</span>:<span class="number">13</span>:<span class="number">39</span></span><br><span class="line">Epoch=<span class="number">8</span>,Loss:<span class="number">0.339028627</span>,Accuracy:<span class="number">0.920062363</span>,Valid Loss:<span class="number">2.68585229</span>,Valid Accuracy:<span class="number">0.615316093</span></span><br><span class="line"></span><br><span class="line">================================================================================<span class="number">17</span>:<span class="number">13</span>:<span class="number">41</span></span><br><span class="line">Epoch=<span class="number">9</span>,Loss:<span class="number">0.293798745</span>,Accuracy:<span class="number">0.92930305</span>,Valid Loss:<span class="number">2.88995624</span>,Valid Accuracy:<span class="number">0.613535166</span></span><br><span class="line"></span><br><span class="line">================================================================================<span class="number">17</span>:<span class="number">13</span>:<span class="number">43</span></span><br><span class="line">Epoch=<span class="number">10</span>,Loss:<span class="number">0.263130337</span>,Accuracy:<span class="number">0.936651051</span>,Valid Loss:<span class="number">3.09705234</span>,Valid Accuracy:<span class="number">0.612644672</span></span><br></pre></td></tr></table></figure><h3 id="使用多GPU训练模型"><a href="#使用多GPU训练模型" class="headerlink" title="使用多GPU训练模型"></a>使用多GPU训练模型</h3><p>如果使用多GPU训练模型，推荐使用内置fit方法，较为方便，仅需添加2行代码。</p><p>在Colab笔记本中：修改-&gt;笔记本设置-&gt;硬件加速器 中选择 GPU</p><p>注：以下代码只能在Colab 上才能正确执行。</p><p>可通过以下colab链接测试效果《tf_多GPU》：</p><p><a href="https://colab.research.google.com/drive/1j2kp_t0S_cofExSN7IyJ4QtMscbVlXU-" target="_blank" rel="external nofollow noopener noreferrer">https://colab.research.google.com/drive/1j2kp_t0S_cofExSN7IyJ4QtMscbVlXU-</a></p><p>MirroredStrategy过程简介：</p><ul><li>训练开始前，该策略在所有 N 个计算设备上均各复制一份完整的模型；</li><li>每次训练传入一个批次的数据时，将数据分成 N 份，分别传入 N 个计算设备（即数据并行）；</li><li>N 个计算设备使用本地变量（镜像变量）分别计算自己所获得的部分数据的梯度；</li><li>使用分布式计算的 All-reduce 操作，在计算设备间高效交换梯度数据并进行求和，使得最终每个设备都有了所有设备的梯度之和；</li><li>使用梯度求和的结果更新本地变量（镜像变量）；</li><li>当所有设备均更新本地变量后，进行下一轮训练（即该并行策略是同步的）。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">%tensorflow_version <span class="number">2.</span>x</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">print(tf.__version__)</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> *</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#此处在colab上使用1个GPU模拟出两个逻辑GPU进行多GPU训练</span></span><br><span class="line">gpus = tf.config.experimental.list_physical_devices(<span class="string">'GPU'</span>)</span><br><span class="line"><span class="keyword">if</span> gpus:</span><br><span class="line">    <span class="comment"># 设置两个逻辑GPU模拟多GPU训练</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        tf.config.experimental.set_virtual_device_configuration(gpus[<span class="number">0</span>],</span><br><span class="line">            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=<span class="number">1024</span>),</span><br><span class="line">             tf.config.experimental.VirtualDeviceConfiguration(memory_limit=<span class="number">1024</span>)])</span><br><span class="line">        logical_gpus = tf.config.experimental.list_logical_devices(<span class="string">'GPU'</span>)</span><br><span class="line">        print(len(gpus), <span class="string">"Physical GPU,"</span>, len(logical_gpus), <span class="string">"Logical GPUs"</span>)</span><br><span class="line">    <span class="keyword">except</span> RuntimeError <span class="keyword">as</span> e:</span><br><span class="line">        print(e)</span><br></pre></td></tr></table></figure><h4 id="准备数据-11"><a href="#准备数据-11" class="headerlink" title="准备数据"></a>准备数据</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">MAX_LEN = <span class="number">300</span></span><br><span class="line">BATCH_SIZE = <span class="number">32</span></span><br><span class="line">(x_train,y_train),(x_test,y_test) = datasets.reuters.load_data()</span><br><span class="line">x_train = preprocessing.sequence.pad_sequences(x_train,maxlen=MAX_LEN)</span><br><span class="line">x_test = preprocessing.sequence.pad_sequences(x_test,maxlen=MAX_LEN)</span><br><span class="line"></span><br><span class="line">MAX_WORDS = x_train.max()+<span class="number">1</span></span><br><span class="line">CAT_NUM = y_train.max()+<span class="number">1</span></span><br><span class="line"></span><br><span class="line">ds_train = tf.data.Dataset.from_tensor_slices((x_train,y_train)) \</span><br><span class="line">          .shuffle(buffer_size = <span class="number">1000</span>).batch(BATCH_SIZE) \</span><br><span class="line">          .prefetch(tf.data.experimental.AUTOTUNE).cache()</span><br><span class="line">   </span><br><span class="line">ds_test = tf.data.Dataset.from_tensor_slices((x_test,y_test)) \</span><br><span class="line">          .shuffle(buffer_size = <span class="number">1000</span>).batch(BATCH_SIZE) \</span><br><span class="line">          .prefetch(tf.data.experimental.AUTOTUNE).cache()</span><br></pre></td></tr></table></figure><h4 id="定义模型-11"><a href="#定义模型-11" class="headerlink" title="定义模型"></a>定义模型</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">tf.keras.backend.clear_session()</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_model</span><span class="params">()</span>:</span></span><br><span class="line">    </span><br><span class="line">    model = models.Sequential()</span><br><span class="line"></span><br><span class="line">    model.add(layers.Embedding(MAX_WORDS,<span class="number">7</span>,input_length=MAX_LEN))</span><br><span class="line">    model.add(layers.Conv1D(filters = <span class="number">64</span>,kernel_size = <span class="number">5</span>,activation = <span class="string">"relu"</span>))</span><br><span class="line">    model.add(layers.MaxPool1D(<span class="number">2</span>))</span><br><span class="line">    model.add(layers.Conv1D(filters = <span class="number">32</span>,kernel_size = <span class="number">3</span>,activation = <span class="string">"relu"</span>))</span><br><span class="line">    model.add(layers.MaxPool1D(<span class="number">2</span>))</span><br><span class="line">    model.add(layers.Flatten())</span><br><span class="line">    model.add(layers.Dense(CAT_NUM,activation = <span class="string">"softmax"</span>))</span><br><span class="line">    <span class="keyword">return</span>(model)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compile_model</span><span class="params">(model)</span>:</span></span><br><span class="line">    model.compile(optimizer=optimizers.Nadam(),</span><br><span class="line">                loss=losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">True</span>),</span><br><span class="line">                metrics=[metrics.SparseCategoricalAccuracy(),metrics.SparseTopKCategoricalAccuracy(<span class="number">5</span>)]) </span><br><span class="line">    <span class="keyword">return</span>(model)</span><br></pre></td></tr></table></figure><h4 id="训练模型-11"><a href="#训练模型-11" class="headerlink" title="训练模型"></a>训练模型</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#增加以下两行代码</span></span><br><span class="line">strategy = tf.distribute.MirroredStrategy()  </span><br><span class="line"><span class="keyword">with</span> strategy.scope(): </span><br><span class="line">    model = create_model()</span><br><span class="line">    model.summary()</span><br><span class="line">    model = compile_model(model)</span><br><span class="line">    </span><br><span class="line">history = model.fit(ds_train,validation_data = ds_test,epochs = <span class="number">10</span>)</span><br></pre></td></tr></table></figure><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">WARNING</span>:tensorflow:NCCL <span class="keyword">is</span> <span class="keyword">not</span> supported <span class="keyword">when</span> <span class="keyword">using</span> virtual GPUs, fallingback <span class="keyword">to</span> reduction <span class="keyword">to</span> one device</span><br><span class="line"><span class="keyword">INFO</span>:tensorflow:<span class="keyword">Using</span> MirroredStrategy <span class="keyword">with</span> devices (<span class="string">'/job:localhost/replica:0/task:0/device:GPU:0'</span>, <span class="string">'/job:localhost/replica:0/task:0/device:GPU:1'</span>)</span><br><span class="line">Model: "sequential"</span><br><span class="line">_________________________________________________________________</span><br><span class="line">Layer (<span class="keyword">type</span>)                 Output Shape              Param #   </span><br><span class="line">=================================================================</span><br><span class="line">embedding (Embedding)        (<span class="keyword">None</span>, <span class="number">300</span>, <span class="number">7</span>)            <span class="number">216874</span>    </span><br><span class="line">_________________________________________________________________</span><br><span class="line">conv1d (Conv1D)              (<span class="keyword">None</span>, <span class="number">296</span>, <span class="number">64</span>)           <span class="number">2304</span>      </span><br><span class="line">_________________________________________________________________</span><br><span class="line">max_pooling1d (MaxPooling1D) (<span class="keyword">None</span>, <span class="number">148</span>, <span class="number">64</span>)           <span class="number">0</span>         </span><br><span class="line">_________________________________________________________________</span><br><span class="line">conv1d_1 (Conv1D)            (<span class="keyword">None</span>, <span class="number">146</span>, <span class="number">32</span>)           <span class="number">6176</span>      </span><br><span class="line">_________________________________________________________________</span><br><span class="line">max_pooling1d_1 (MaxPooling1 (<span class="keyword">None</span>, <span class="number">73</span>, <span class="number">32</span>)            <span class="number">0</span>         </span><br><span class="line">_________________________________________________________________</span><br><span class="line">flatten (Flatten)            (<span class="keyword">None</span>, <span class="number">2336</span>)              <span class="number">0</span>         </span><br><span class="line">_________________________________________________________________</span><br><span class="line">dense (Dense)                (<span class="keyword">None</span>, <span class="number">46</span>)                <span class="number">107502</span>    </span><br><span class="line">=================================================================</span><br><span class="line">Total params: <span class="number">332</span>,<span class="number">856</span></span><br><span class="line">Trainable params: <span class="number">332</span>,<span class="number">856</span></span><br><span class="line">Non-trainable params: <span class="number">0</span></span><br><span class="line">_________________________________________________________________</span><br><span class="line"><span class="keyword">INFO</span>:tensorflow:Reduce <span class="keyword">to</span> /job:localhost/<span class="keyword">replica</span>:<span class="number">0</span>/task:<span class="number">0</span>/device:CPU:<span class="number">0</span> <span class="keyword">then</span> broadcast <span class="keyword">to</span> (<span class="string">'/job:localhost/replica:0/task:0/device:CPU:0'</span>,).</span><br><span class="line"><span class="keyword">INFO</span>:tensorflow:Reduce <span class="keyword">to</span> /job:localhost/<span class="keyword">replica</span>:<span class="number">0</span>/task:<span class="number">0</span>/device:CPU:<span class="number">0</span> <span class="keyword">then</span> broadcast <span class="keyword">to</span> (<span class="string">'/job:localhost/replica:0/task:0/device:CPU:0'</span>,).</span><br><span class="line"><span class="keyword">INFO</span>:tensorflow:Reduce <span class="keyword">to</span> /job:localhost/<span class="keyword">replica</span>:<span class="number">0</span>/task:<span class="number">0</span>/device:CPU:<span class="number">0</span> <span class="keyword">then</span> broadcast <span class="keyword">to</span> (<span class="string">'/job:localhost/replica:0/task:0/device:CPU:0'</span>,).</span><br><span class="line"><span class="keyword">INFO</span>:tensorflow:Reduce <span class="keyword">to</span> /job:localhost/<span class="keyword">replica</span>:<span class="number">0</span>/task:<span class="number">0</span>/device:CPU:<span class="number">0</span> <span class="keyword">then</span> broadcast <span class="keyword">to</span> (<span class="string">'/job:localhost/replica:0/task:0/device:CPU:0'</span>,).</span><br><span class="line">Train <span class="keyword">for</span> <span class="number">281</span> steps, <span class="keyword">validate</span> <span class="keyword">for</span> <span class="number">71</span> steps</span><br><span class="line">Epoch <span class="number">1</span>/<span class="number">10</span></span><br><span class="line"><span class="keyword">INFO</span>:tensorflow:Reduce <span class="keyword">to</span> /job:localhost/<span class="keyword">replica</span>:<span class="number">0</span>/task:<span class="number">0</span>/device:GPU:<span class="number">0</span> <span class="keyword">then</span> broadcast <span class="keyword">to</span> (<span class="string">'/job:localhost/replica:0/task:0/device:GPU:0'</span>, <span class="string">'/job:localhost/replica:0/task:0/device:GPU:1'</span>).</span><br><span class="line"><span class="keyword">INFO</span>:tensorflow:Reduce <span class="keyword">to</span> /job:localhost/<span class="keyword">replica</span>:<span class="number">0</span>/task:<span class="number">0</span>/device:GPU:<span class="number">0</span> <span class="keyword">then</span> broadcast <span class="keyword">to</span> (<span class="string">'/job:localhost/replica:0/task:0/device:GPU:0'</span>, <span class="string">'/job:localhost/replica:0/task:0/device:GPU:1'</span>).</span><br><span class="line"><span class="keyword">INFO</span>:tensorflow:Reduce <span class="keyword">to</span> /job:localhost/<span class="keyword">replica</span>:<span class="number">0</span>/task:<span class="number">0</span>/device:GPU:<span class="number">0</span> <span class="keyword">then</span> broadcast <span class="keyword">to</span> (<span class="string">'/job:localhost/replica:0/task:0/device:GPU:0'</span>, <span class="string">'/job:localhost/replica:0/task:0/device:GPU:1'</span>).</span><br><span class="line"><span class="keyword">INFO</span>:tensorflow:Reduce <span class="keyword">to</span> /job:localhost/<span class="keyword">replica</span>:<span class="number">0</span>/task:<span class="number">0</span>/device:GPU:<span class="number">0</span> <span class="keyword">then</span> broadcast <span class="keyword">to</span> (<span class="string">'/job:localhost/replica:0/task:0/device:GPU:0'</span>, <span class="string">'/job:localhost/replica:0/task:0/device:GPU:1'</span>).</span><br><span class="line"><span class="keyword">INFO</span>:tensorflow:Reduce <span class="keyword">to</span> /job:localhost/<span class="keyword">replica</span>:<span class="number">0</span>/task:<span class="number">0</span>/device:GPU:<span class="number">0</span> <span class="keyword">then</span> broadcast <span class="keyword">to</span> (<span class="string">'/job:localhost/replica:0/task:0/device:GPU:0'</span>, <span class="string">'/job:localhost/replica:0/task:0/device:GPU:1'</span>).</span><br><span class="line"><span class="keyword">INFO</span>:tensorflow:Reduce <span class="keyword">to</span> /job:localhost/<span class="keyword">replica</span>:<span class="number">0</span>/task:<span class="number">0</span>/device:GPU:<span class="number">0</span> <span class="keyword">then</span> broadcast <span class="keyword">to</span> (<span class="string">'/job:localhost/replica:0/task:0/device:GPU:0'</span>, <span class="string">'/job:localhost/replica:0/task:0/device:GPU:1'</span>).</span><br><span class="line"><span class="keyword">INFO</span>:tensorflow:Reduce <span class="keyword">to</span> /job:localhost/<span class="keyword">replica</span>:<span class="number">0</span>/task:<span class="number">0</span>/device:GPU:<span class="number">0</span> <span class="keyword">then</span> broadcast <span class="keyword">to</span> (<span class="string">'/job:localhost/replica:0/task:0/device:GPU:0'</span>, <span class="string">'/job:localhost/replica:0/task:0/device:GPU:1'</span>).</span><br><span class="line"><span class="keyword">INFO</span>:tensorflow:Reduce <span class="keyword">to</span> /job:localhost/<span class="keyword">replica</span>:<span class="number">0</span>/task:<span class="number">0</span>/device:CPU:<span class="number">0</span> <span class="keyword">then</span> broadcast <span class="keyword">to</span> (<span class="string">'/job:localhost/replica:0/task:0/device:CPU:0'</span>,).</span><br><span class="line"><span class="keyword">INFO</span>:tensorflow:Reduce <span class="keyword">to</span> /job:localhost/<span class="keyword">replica</span>:<span class="number">0</span>/task:<span class="number">0</span>/device:CPU:<span class="number">0</span> <span class="keyword">then</span> broadcast <span class="keyword">to</span> (<span class="string">'/job:localhost/replica:0/task:0/device:CPU:0'</span>,).</span><br><span class="line"><span class="keyword">INFO</span>:tensorflow:Reduce <span class="keyword">to</span> /job:localhost/<span class="keyword">replica</span>:<span class="number">0</span>/task:<span class="number">0</span>/device:CPU:<span class="number">0</span> <span class="keyword">then</span> broadcast <span class="keyword">to</span> (<span class="string">'/job:localhost/replica:0/task:0/device:CPU:0'</span>,).</span><br><span class="line"><span class="keyword">INFO</span>:tensorflow:Reduce <span class="keyword">to</span> /job:localhost/<span class="keyword">replica</span>:<span class="number">0</span>/task:<span class="number">0</span>/device:CPU:<span class="number">0</span> <span class="keyword">then</span> broadcast <span class="keyword">to</span> (<span class="string">'/job:localhost/replica:0/task:0/device:CPU:0'</span>,).</span><br><span class="line"><span class="keyword">INFO</span>:tensorflow:Reduce <span class="keyword">to</span> /job:localhost/<span class="keyword">replica</span>:<span class="number">0</span>/task:<span class="number">0</span>/device:CPU:<span class="number">0</span> <span class="keyword">then</span> broadcast <span class="keyword">to</span> (<span class="string">'/job:localhost/replica:0/task:0/device:CPU:0'</span>,).</span><br><span class="line"><span class="keyword">INFO</span>:tensorflow:Reduce <span class="keyword">to</span> /job:localhost/<span class="keyword">replica</span>:<span class="number">0</span>/task:<span class="number">0</span>/device:CPU:<span class="number">0</span> <span class="keyword">then</span> broadcast <span class="keyword">to</span> (<span class="string">'/job:localhost/replica:0/task:0/device:CPU:0'</span>,).</span><br><span class="line"><span class="keyword">INFO</span>:tensorflow:Reduce <span class="keyword">to</span> /job:localhost/<span class="keyword">replica</span>:<span class="number">0</span>/task:<span class="number">0</span>/device:GPU:<span class="number">0</span> <span class="keyword">then</span> broadcast <span class="keyword">to</span> (<span class="string">'/job:localhost/replica:0/task:0/device:GPU:0'</span>, <span class="string">'/job:localhost/replica:0/task:0/device:GPU:1'</span>).</span><br><span class="line"><span class="keyword">INFO</span>:tensorflow:Reduce <span class="keyword">to</span> /job:localhost/<span class="keyword">replica</span>:<span class="number">0</span>/task:<span class="number">0</span>/device:GPU:<span class="number">0</span> <span class="keyword">then</span> broadcast <span class="keyword">to</span> (<span class="string">'/job:localhost/replica:0/task:0/device:GPU:0'</span>, <span class="string">'/job:localhost/replica:0/task:0/device:GPU:1'</span>).</span><br><span class="line"><span class="keyword">INFO</span>:tensorflow:Reduce <span class="keyword">to</span> /job:localhost/<span class="keyword">replica</span>:<span class="number">0</span>/task:<span class="number">0</span>/device:GPU:<span class="number">0</span> <span class="keyword">then</span> broadcast <span class="keyword">to</span> (<span class="string">'/job:localhost/replica:0/task:0/device:GPU:0'</span>, <span class="string">'/job:localhost/replica:0/task:0/device:GPU:1'</span>).</span><br><span class="line"><span class="number">281</span>/<span class="number">281</span> [==============================] - <span class="number">15</span>s <span class="number">53</span>ms/step - loss: <span class="number">2.0270</span> - sparse_categorical_accuracy: <span class="number">0.4653</span> - sparse_top_k_categorical_accuracy: <span class="number">0.7481</span> - val_loss: <span class="number">1.7517</span> - val_sparse_categorical_accuracy: <span class="number">0.5481</span> - val_sparse_top_k_categorical_accuracy: <span class="number">0.7578</span></span><br><span class="line">Epoch <span class="number">2</span>/<span class="number">10</span></span><br><span class="line"><span class="number">281</span>/<span class="number">281</span> [==============================] - <span class="number">4</span>s <span class="number">14</span>ms/step - loss: <span class="number">1.5206</span> - sparse_categorical_accuracy: <span class="number">0.6045</span> - sparse_top_k_categorical_accuracy: <span class="number">0.7938</span> - val_loss: <span class="number">1.5715</span> - val_sparse_categorical_accuracy: <span class="number">0.5993</span> - val_sparse_top_k_categorical_accuracy: <span class="number">0.7983</span></span><br><span class="line">Epoch <span class="number">3</span>/<span class="number">10</span></span><br><span class="line"><span class="number">281</span>/<span class="number">281</span> [==============================] - <span class="number">4</span>s <span class="number">14</span>ms/step - loss: <span class="number">1.2178</span> - sparse_categorical_accuracy: <span class="number">0.6843</span> - sparse_top_k_categorical_accuracy: <span class="number">0.8547</span> - val_loss: <span class="number">1.5232</span> - val_sparse_categorical_accuracy: <span class="number">0.6327</span> - val_sparse_top_k_categorical_accuracy: <span class="number">0.8112</span></span><br><span class="line">Epoch <span class="number">4</span>/<span class="number">10</span></span><br><span class="line"><span class="number">281</span>/<span class="number">281</span> [==============================] - <span class="number">4</span>s <span class="number">13</span>ms/step - loss: <span class="number">0.9127</span> - sparse_categorical_accuracy: <span class="number">0.7648</span> - sparse_top_k_categorical_accuracy: <span class="number">0.9113</span> - val_loss: <span class="number">1.6527</span> - val_sparse_categorical_accuracy: <span class="number">0.6296</span> - val_sparse_top_k_categorical_accuracy: <span class="number">0.8201</span></span><br><span class="line">Epoch <span class="number">5</span>/<span class="number">10</span></span><br><span class="line"><span class="number">281</span>/<span class="number">281</span> [==============================] - <span class="number">4</span>s <span class="number">14</span>ms/step - loss: <span class="number">0.6606</span> - sparse_categorical_accuracy: <span class="number">0.8321</span> - sparse_top_k_categorical_accuracy: <span class="number">0.9525</span> - val_loss: <span class="number">1.8791</span> - val_sparse_categorical_accuracy: <span class="number">0.6158</span> - val_sparse_top_k_categorical_accuracy: <span class="number">0.8219</span></span><br><span class="line">Epoch <span class="number">6</span>/<span class="number">10</span></span><br><span class="line"><span class="number">281</span>/<span class="number">281</span> [==============================] - <span class="number">4</span>s <span class="number">14</span>ms/step - loss: <span class="number">0.4919</span> - sparse_categorical_accuracy: <span class="number">0.8799</span> - sparse_top_k_categorical_accuracy: <span class="number">0.9725</span> - val_loss: <span class="number">2.1282</span> - val_sparse_categorical_accuracy: <span class="number">0.6037</span> - val_sparse_top_k_categorical_accuracy: <span class="number">0.8112</span></span><br><span class="line">Epoch <span class="number">7</span>/<span class="number">10</span></span><br><span class="line"><span class="number">281</span>/<span class="number">281</span> [==============================] - <span class="number">4</span>s <span class="number">14</span>ms/step - loss: <span class="number">0.3947</span> - sparse_categorical_accuracy: <span class="number">0.9051</span> - sparse_top_k_categorical_accuracy: <span class="number">0.9814</span> - val_loss: <span class="number">2.3033</span> - val_sparse_categorical_accuracy: <span class="number">0.6046</span> - val_sparse_top_k_categorical_accuracy: <span class="number">0.8094</span></span><br><span class="line">Epoch <span class="number">8</span>/<span class="number">10</span></span><br><span class="line"><span class="number">281</span>/<span class="number">281</span> [==============================] - <span class="number">4</span>s <span class="number">14</span>ms/step - loss: <span class="number">0.3335</span> - sparse_categorical_accuracy: <span class="number">0.9207</span> - sparse_top_k_categorical_accuracy: <span class="number">0.9863</span> - val_loss: <span class="number">2.4255</span> - val_sparse_categorical_accuracy: <span class="number">0.5993</span> - val_sparse_top_k_categorical_accuracy: <span class="number">0.8099</span></span><br><span class="line">Epoch <span class="number">9</span>/<span class="number">10</span></span><br><span class="line"><span class="number">281</span>/<span class="number">281</span> [==============================] - <span class="number">4</span>s <span class="number">14</span>ms/step - loss: <span class="number">0.2919</span> - sparse_categorical_accuracy: <span class="number">0.9304</span> - sparse_top_k_categorical_accuracy: <span class="number">0.9911</span> - val_loss: <span class="number">2.5571</span> - val_sparse_categorical_accuracy: <span class="number">0.6020</span> - val_sparse_top_k_categorical_accuracy: <span class="number">0.8126</span></span><br><span class="line">Epoch <span class="number">10</span>/<span class="number">10</span></span><br><span class="line"><span class="number">281</span>/<span class="number">281</span> [==============================] - <span class="number">4</span>s <span class="number">14</span>ms/step - loss: <span class="number">0.2617</span> - sparse_categorical_accuracy: <span class="number">0.9342</span> - sparse_top_k_categorical_accuracy: <span class="number">0.9937</span> - val_loss: <span class="number">2.6700</span> - val_sparse_categorical_accuracy: <span class="number">0.6077</span> - val_sparse_top_k_categorical_accuracy: <span class="number">0.8148</span></span><br><span class="line">CPU times: <span class="keyword">user</span> <span class="number">1</span>min <span class="number">2</span>s, sys: <span class="number">8.59</span> s, total: <span class="number">1</span>min <span class="number">10</span>s</span><br><span class="line">Wall <span class="type">time</span>: <span class="number">58.5</span> s</span><br></pre></td></tr></table></figure><h3 id="使用TPU训练模型"><a href="#使用TPU训练模型" class="headerlink" title="使用TPU训练模型"></a>使用TPU训练模型</h3><p>如果想尝试使用Google Colab上的TPU来训练模型，也是非常方便，仅需添加6行代码。</p><p>在Colab笔记本中：修改-&gt;笔记本设置-&gt;硬件加速器 中选择 TPU</p><p>注：以下代码只能在Colab 上才能正确执行。</p><p>可通过以下colab链接测试效果《tf_TPU》：</p><p><a href="https://colab.research.google.com/drive/1XCIhATyE1R7lq6uwFlYlRsUr5d9_-r1s" target="_blank" rel="external nofollow noopener noreferrer">https://colab.research.google.com/drive/1XCIhATyE1R7lq6uwFlYlRsUr5d9_-r1s</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">%tensorflow_version <span class="number">2.</span>x</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">print(tf.__version__)</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> *</span><br></pre></td></tr></table></figure><h4 id="准备数据-12"><a href="#准备数据-12" class="headerlink" title="准备数据"></a>准备数据</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">MAX_LEN = <span class="number">300</span></span><br><span class="line">BATCH_SIZE = <span class="number">32</span></span><br><span class="line">(x_train,y_train),(x_test,y_test) = datasets.reuters.load_data()</span><br><span class="line">x_train = preprocessing.sequence.pad_sequences(x_train,maxlen=MAX_LEN)</span><br><span class="line">x_test = preprocessing.sequence.pad_sequences(x_test,maxlen=MAX_LEN)</span><br><span class="line"></span><br><span class="line">MAX_WORDS = x_train.max()+<span class="number">1</span></span><br><span class="line">CAT_NUM = y_train.max()+<span class="number">1</span></span><br><span class="line"></span><br><span class="line">ds_train = tf.data.Dataset.from_tensor_slices((x_train,y_train)) \</span><br><span class="line">          .shuffle(buffer_size = <span class="number">1000</span>).batch(BATCH_SIZE) \</span><br><span class="line">          .prefetch(tf.data.experimental.AUTOTUNE).cache()</span><br><span class="line">   </span><br><span class="line">ds_test = tf.data.Dataset.from_tensor_slices((x_test,y_test)) \</span><br><span class="line">          .shuffle(buffer_size = <span class="number">1000</span>).batch(BATCH_SIZE) \</span><br><span class="line">          .prefetch(tf.data.experimental.AUTOTUNE).cache()</span><br></pre></td></tr></table></figure><h4 id="定义模型-12"><a href="#定义模型-12" class="headerlink" title="定义模型"></a>定义模型</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">tf.keras.backend.clear_session()</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_model</span><span class="params">()</span>:</span></span><br><span class="line">    </span><br><span class="line">    model = models.Sequential()</span><br><span class="line"></span><br><span class="line">    model.add(layers.Embedding(MAX_WORDS,<span class="number">7</span>,input_length=MAX_LEN))</span><br><span class="line">    model.add(layers.Conv1D(filters = <span class="number">64</span>,kernel_size = <span class="number">5</span>,activation = <span class="string">"relu"</span>))</span><br><span class="line">    model.add(layers.MaxPool1D(<span class="number">2</span>))</span><br><span class="line">    model.add(layers.Conv1D(filters = <span class="number">32</span>,kernel_size = <span class="number">3</span>,activation = <span class="string">"relu"</span>))</span><br><span class="line">    model.add(layers.MaxPool1D(<span class="number">2</span>))</span><br><span class="line">    model.add(layers.Flatten())</span><br><span class="line">    model.add(layers.Dense(CAT_NUM,activation = <span class="string">"softmax"</span>))</span><br><span class="line">    <span class="keyword">return</span>(model)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compile_model</span><span class="params">(model)</span>:</span></span><br><span class="line">    model.compile(optimizer=optimizers.Nadam(),</span><br><span class="line">                loss=losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">True</span>),</span><br><span class="line">                metrics=[metrics.SparseCategoricalAccuracy(),metrics.SparseTopKCategoricalAccuracy(<span class="number">5</span>)]) </span><br><span class="line">    <span class="keyword">return</span>(model)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="训练模型-12"><a href="#训练模型-12" class="headerlink" title="训练模型"></a>训练模型</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#增加以下6行代码</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=<span class="string">'grpc://'</span> + os.environ[<span class="string">'COLAB_TPU_ADDR'</span>])</span><br><span class="line">tf.config.experimental_connect_to_cluster(resolver)</span><br><span class="line">tf.tpu.experimental.initialize_tpu_system(resolver)</span><br><span class="line">strategy = tf.distribute.experimental.TPUStrategy(resolver)</span><br><span class="line"><span class="keyword">with</span> strategy.scope():</span><br><span class="line">    model = create_model()</span><br><span class="line">    model.summary()</span><br><span class="line">    model = compile_model(model)</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line">WARNING:tensorflow:TPU system <span class="number">10.26</span><span class="number">.134</span><span class="number">.242</span>:<span class="number">8470</span> has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.</span><br><span class="line">WARNING:tensorflow:TPU system <span class="number">10.26</span><span class="number">.134</span><span class="number">.242</span>:<span class="number">8470</span> has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.</span><br><span class="line">INFO:tensorflow:Initializing the TPU system: <span class="number">10.26</span><span class="number">.134</span><span class="number">.242</span>:<span class="number">8470</span></span><br><span class="line">INFO:tensorflow:Initializing the TPU system: <span class="number">10.26</span><span class="number">.134</span><span class="number">.242</span>:<span class="number">8470</span></span><br><span class="line">INFO:tensorflow:Clearing <span class="keyword">out</span> eager caches</span><br><span class="line">INFO:tensorflow:Clearing <span class="keyword">out</span> eager caches</span><br><span class="line">INFO:tensorflow:Finished initializing TPU system.</span><br><span class="line">INFO:tensorflow:Finished initializing TPU system.</span><br><span class="line">INFO:tensorflow:Found TPU system:</span><br><span class="line">INFO:tensorflow:Found TPU system:</span><br><span class="line">INFO:tensorflow:*** Num TPU Cores: <span class="number">8</span></span><br><span class="line">INFO:tensorflow:*** Num TPU Cores: <span class="number">8</span></span><br><span class="line">INFO:tensorflow:*** Num TPU Workers: <span class="number">1</span></span><br><span class="line">INFO:tensorflow:*** Num TPU Workers: <span class="number">1</span></span><br><span class="line">INFO:tensorflow:*** Num TPU Cores Per Worker: <span class="number">8</span></span><br><span class="line">INFO:tensorflow:*** Num TPU Cores Per Worker: <span class="number">8</span></span><br><span class="line">INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:<span class="number">0</span>/task:<span class="number">0</span>/device:CPU:<span class="number">0</span>, CPU, <span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:<span class="number">0</span>/task:<span class="number">0</span>/device:CPU:<span class="number">0</span>, CPU, <span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:<span class="number">0</span>/task:<span class="number">0</span>/device:XLA_CPU:<span class="number">0</span>, XLA_CPU, <span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:<span class="number">0</span>/task:<span class="number">0</span>/device:XLA_CPU:<span class="number">0</span>, XLA_CPU, <span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:<span class="number">0</span>/task:<span class="number">0</span>/device:CPU:<span class="number">0</span>, CPU, <span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:<span class="number">0</span>/task:<span class="number">0</span>/device:CPU:<span class="number">0</span>, CPU, <span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:<span class="number">0</span>/task:<span class="number">0</span>/device:TPU:<span class="number">0</span>, TPU, <span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:<span class="number">0</span>/task:<span class="number">0</span>/device:TPU:<span class="number">0</span>, TPU, <span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:<span class="number">0</span>/task:<span class="number">0</span>/device:TPU:<span class="number">1</span>, TPU, <span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:<span class="number">0</span>/task:<span class="number">0</span>/device:TPU:<span class="number">1</span>, TPU, <span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:<span class="number">0</span>/task:<span class="number">0</span>/device:TPU:<span class="number">2</span>, TPU, <span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:<span class="number">0</span>/task:<span class="number">0</span>/device:TPU:<span class="number">2</span>, TPU, <span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:<span class="number">0</span>/task:<span class="number">0</span>/device:TPU:<span class="number">3</span>, TPU, <span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:<span class="number">0</span>/task:<span class="number">0</span>/device:TPU:<span class="number">3</span>, TPU, <span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:<span class="number">0</span>/task:<span class="number">0</span>/device:TPU:<span class="number">4</span>, TPU, <span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:<span class="number">0</span>/task:<span class="number">0</span>/device:TPU:<span class="number">4</span>, TPU, <span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:<span class="number">0</span>/task:<span class="number">0</span>/device:TPU:<span class="number">5</span>, TPU, <span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:<span class="number">0</span>/task:<span class="number">0</span>/device:TPU:<span class="number">5</span>, TPU, <span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:<span class="number">0</span>/task:<span class="number">0</span>/device:TPU:<span class="number">6</span>, TPU, <span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:<span class="number">0</span>/task:<span class="number">0</span>/device:TPU:<span class="number">6</span>, TPU, <span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:<span class="number">0</span>/task:<span class="number">0</span>/device:TPU:<span class="number">7</span>, TPU, <span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:<span class="number">0</span>/task:<span class="number">0</span>/device:TPU:<span class="number">7</span>, TPU, <span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:<span class="number">0</span>/task:<span class="number">0</span>/device:TPU_SYSTEM:<span class="number">0</span>, TPU_SYSTEM, <span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:<span class="number">0</span>/task:<span class="number">0</span>/device:TPU_SYSTEM:<span class="number">0</span>, TPU_SYSTEM, <span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:<span class="number">0</span>/task:<span class="number">0</span>/device:XLA_CPU:<span class="number">0</span>, XLA_CPU, <span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:<span class="number">0</span>/task:<span class="number">0</span>/device:XLA_CPU:<span class="number">0</span>, XLA_CPU, <span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">Model: <span class="string">"sequential"</span></span><br><span class="line">_________________________________________________________________</span><br><span class="line">Layer (type)                 Output Shape              Param #   </span><br><span class="line">=================================================================</span><br><span class="line">embedding (Embedding)        (None, <span class="number">300</span>, <span class="number">7</span>)            <span class="number">216874</span>    </span><br><span class="line">_________________________________________________________________</span><br><span class="line">conv1d (Conv1D)              (None, <span class="number">296</span>, <span class="number">64</span>)           <span class="number">2304</span>      </span><br><span class="line">_________________________________________________________________</span><br><span class="line">max_pooling1d (MaxPooling1D) (None, <span class="number">148</span>, <span class="number">64</span>)           <span class="number">0</span>         </span><br><span class="line">_________________________________________________________________</span><br><span class="line">conv1d_1 (Conv1D)            (None, <span class="number">146</span>, <span class="number">32</span>)           <span class="number">6176</span>      </span><br><span class="line">_________________________________________________________________</span><br><span class="line">max_pooling1d_1 (MaxPooling1 (None, <span class="number">73</span>, <span class="number">32</span>)            <span class="number">0</span>         </span><br><span class="line">_________________________________________________________________</span><br><span class="line">flatten (Flatten)            (None, <span class="number">2336</span>)              <span class="number">0</span>         </span><br><span class="line">_________________________________________________________________</span><br><span class="line">dense (Dense)                (None, <span class="number">46</span>)                <span class="number">107502</span>    </span><br><span class="line">=================================================================</span><br><span class="line">Total params: <span class="number">332</span>,<span class="number">856</span></span><br><span class="line">Trainable params: <span class="number">332</span>,<span class="number">856</span></span><br><span class="line">Non-trainable params: <span class="number">0</span></span><br><span class="line">_________________________________________________________________</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">history = model.fit(ds_train,validation_data = ds_test,epochs = <span class="number">10</span>)</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">Train <span class="keyword">for</span> <span class="number">281</span> steps, validate <span class="keyword">for</span> <span class="number">71</span> steps</span><br><span class="line">Epoch <span class="number">1</span>/<span class="number">10</span></span><br><span class="line"><span class="number">281</span>/<span class="number">281</span> [==============================] - <span class="number">12</span>s <span class="number">43</span>ms/step - loss: <span class="number">3.4466</span> - sparse_categorical_accuracy: <span class="number">0.4332</span> - sparse_top_k_categorical_accuracy: <span class="number">0.7180</span> - val_loss: <span class="number">3.3179</span> - val_sparse_categorical_accuracy: <span class="number">0.5352</span> - val_sparse_top_k_categorical_accuracy: <span class="number">0.7195</span></span><br><span class="line">Epoch <span class="number">2</span>/<span class="number">10</span></span><br><span class="line"><span class="number">281</span>/<span class="number">281</span> [==============================] - <span class="number">6</span>s <span class="number">20</span>ms/step - loss: <span class="number">3.3251</span> - sparse_categorical_accuracy: <span class="number">0.5405</span> - sparse_top_k_categorical_accuracy: <span class="number">0.7302</span> - val_loss: <span class="number">3.3082</span> - val_sparse_categorical_accuracy: <span class="number">0.5463</span> - val_sparse_top_k_categorical_accuracy: <span class="number">0.7235</span></span><br><span class="line">Epoch <span class="number">3</span>/<span class="number">10</span></span><br><span class="line"><span class="number">281</span>/<span class="number">281</span> [==============================] - <span class="number">6</span>s <span class="number">20</span>ms/step - loss: <span class="number">3.2961</span> - sparse_categorical_accuracy: <span class="number">0.5729</span> - sparse_top_k_categorical_accuracy: <span class="number">0.7280</span> - val_loss: <span class="number">3.3026</span> - val_sparse_categorical_accuracy: <span class="number">0.5499</span> - val_sparse_top_k_categorical_accuracy: <span class="number">0.7217</span></span><br><span class="line">Epoch <span class="number">4</span>/<span class="number">10</span></span><br><span class="line"><span class="number">281</span>/<span class="number">281</span> [==============================] - <span class="number">5</span>s <span class="number">19</span>ms/step - loss: <span class="number">3.2751</span> - sparse_categorical_accuracy: <span class="number">0.5924</span> - sparse_top_k_categorical_accuracy: <span class="number">0.7276</span> - val_loss: <span class="number">3.2957</span> - val_sparse_categorical_accuracy: <span class="number">0.5543</span> - val_sparse_top_k_categorical_accuracy: <span class="number">0.7217</span></span><br><span class="line">Epoch <span class="number">5</span>/<span class="number">10</span></span><br><span class="line"><span class="number">281</span>/<span class="number">281</span> [==============================] - <span class="number">5</span>s <span class="number">19</span>ms/step - loss: <span class="number">3.2655</span> - sparse_categorical_accuracy: <span class="number">0.6008</span> - sparse_top_k_categorical_accuracy: <span class="number">0.7290</span> - val_loss: <span class="number">3.3022</span> - val_sparse_categorical_accuracy: <span class="number">0.5490</span> - val_sparse_top_k_categorical_accuracy: <span class="number">0.7231</span></span><br><span class="line">Epoch <span class="number">6</span>/<span class="number">10</span></span><br><span class="line"><span class="number">281</span>/<span class="number">281</span> [==============================] - <span class="number">5</span>s <span class="number">19</span>ms/step - loss: <span class="number">3.2616</span> - sparse_categorical_accuracy: <span class="number">0.6041</span> - sparse_top_k_categorical_accuracy: <span class="number">0.7295</span> - val_loss: <span class="number">3.3015</span> - val_sparse_categorical_accuracy: <span class="number">0.5503</span> - val_sparse_top_k_categorical_accuracy: <span class="number">0.7235</span></span><br><span class="line">Epoch <span class="number">7</span>/<span class="number">10</span></span><br><span class="line"><span class="number">281</span>/<span class="number">281</span> [==============================] - <span class="number">6</span>s <span class="number">21</span>ms/step - loss: <span class="number">3.2595</span> - sparse_categorical_accuracy: <span class="number">0.6059</span> - sparse_top_k_categorical_accuracy: <span class="number">0.7322</span> - val_loss: <span class="number">3.3064</span> - val_sparse_categorical_accuracy: <span class="number">0.5454</span> - val_sparse_top_k_categorical_accuracy: <span class="number">0.7266</span></span><br><span class="line">Epoch <span class="number">8</span>/<span class="number">10</span></span><br><span class="line"><span class="number">281</span>/<span class="number">281</span> [==============================] - <span class="number">6</span>s <span class="number">21</span>ms/step - loss: <span class="number">3.2591</span> - sparse_categorical_accuracy: <span class="number">0.6063</span> - sparse_top_k_categorical_accuracy: <span class="number">0.7327</span> - val_loss: <span class="number">3.3025</span> - val_sparse_categorical_accuracy: <span class="number">0.5481</span> - val_sparse_top_k_categorical_accuracy: <span class="number">0.7231</span></span><br><span class="line">Epoch <span class="number">9</span>/<span class="number">10</span></span><br><span class="line"><span class="number">281</span>/<span class="number">281</span> [==============================] - <span class="number">5</span>s <span class="number">19</span>ms/step - loss: <span class="number">3.2588</span> - sparse_categorical_accuracy: <span class="number">0.6062</span> - sparse_top_k_categorical_accuracy: <span class="number">0.7332</span> - val_loss: <span class="number">3.2992</span> - val_sparse_categorical_accuracy: <span class="number">0.5521</span> - val_sparse_top_k_categorical_accuracy: <span class="number">0.7257</span></span><br><span class="line">Epoch <span class="number">10</span>/<span class="number">10</span></span><br><span class="line"><span class="number">281</span>/<span class="number">281</span> [==============================] - <span class="number">5</span>s <span class="number">18</span>ms/step - loss: <span class="number">3.2577</span> - sparse_categorical_accuracy: <span class="number">0.6073</span> - sparse_top_k_categorical_accuracy: <span class="number">0.7363</span> - val_loss: <span class="number">3.2981</span> - val_sparse_categorical_accuracy: <span class="number">0.5516</span> - val_sparse_top_k_categorical_accuracy: <span class="number">0.7306</span></span><br><span class="line">CPU times: user <span class="number">18.9</span> s, sys: <span class="number">3.86</span> s, total: <span class="number">22.7</span> s</span><br><span class="line">Wall time: <span class="number">1</span>min <span class="number">1</span>s</span><br></pre></td></tr></table></figure><h3 id="使用tensorflow-serving部署模型"><a href="#使用tensorflow-serving部署模型" class="headerlink" title="使用tensorflow-serving部署模型"></a>使用tensorflow-serving部署模型</h3><p>TensorFlow训练好的模型以tensorflow原生方式保存成protobuf文件后可以用许多方式部署运行。</p><p>例如：通过 tensorflow-js 可以用javascrip脚本加载模型并在浏览器中运行模型。</p><p>通过 tensorflow-lite 可以在移动和嵌入式设备上加载并运行TensorFlow模型。</p><p>通过 tensorflow-serving 可以加载模型后提供网络接口API服务，通过任意编程语言发送网络请求都可以获取模型预测结果。</p><p>通过 tensorFlow for Java接口，可以在Java或者spark(scala)中调用tensorflow模型进行预测。</p><p>我们主要介绍tensorflow serving部署模型、使用spark(scala)调用tensorflow模型的方法。</p><h4 id="tensorflow-serving模型部署概述"><a href="#tensorflow-serving模型部署概述" class="headerlink" title="tensorflow serving模型部署概述"></a>tensorflow serving模型部署概述</h4><p>使用 tensorflow serving 部署模型要完成以下步骤。</p><ul><li><p>准备protobuf模型文件。</p></li><li><p>安装tensorflow serving。</p></li><li><p>启动tensorflow serving 服务。</p></li><li><p>向API服务发送请求，获取预测结果。</p></li></ul><p>可通过以下colab链接测试效果《tf_serving》：<br><a href="https://colab.research.google.com/drive/1vS5LAYJTEn-H0GDb1irzIuyRB8E3eWc8" target="_blank" rel="external nofollow noopener noreferrer">https://colab.research.google.com/drive/1vS5LAYJTEn-H0GDb1irzIuyRB8E3eWc8</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">%tensorflow_version <span class="number">2.</span>x</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">print(tf.__version__)</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> *</span><br></pre></td></tr></table></figure><h4 id="准备protobuf模型文件"><a href="#准备protobuf模型文件" class="headerlink" title="准备protobuf模型文件"></a>准备protobuf模型文件</h4><p>我们使用tf.keras 训练一个简单的线性回归模型，并保存成protobuf文件。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> models,layers,optimizers</span><br><span class="line"></span><br><span class="line"><span class="comment">## 样本数量</span></span><br><span class="line">n = <span class="number">800</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 生成测试用数据集</span></span><br><span class="line">X = tf.random.uniform([n,<span class="number">2</span>],minval=<span class="number">-10</span>,maxval=<span class="number">10</span>) </span><br><span class="line">w0 = tf.constant([[<span class="number">2.0</span>],[<span class="number">-1.0</span>]])</span><br><span class="line">b0 = tf.constant(<span class="number">3.0</span>)</span><br><span class="line"></span><br><span class="line">Y = X@w0 + b0 + tf.random.normal([n,<span class="number">1</span>],</span><br><span class="line">    mean = <span class="number">0.0</span>,stddev= <span class="number">2.0</span>) <span class="comment"># @表示矩阵乘法,增加正态扰动</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 建立模型</span></span><br><span class="line">tf.keras.backend.clear_session()</span><br><span class="line">inputs = layers.Input(shape = (<span class="number">2</span>,),name =<span class="string">"inputs"</span>) <span class="comment">#设置输入名字为inputs</span></span><br><span class="line">outputs = layers.Dense(<span class="number">1</span>, name = <span class="string">"outputs"</span>)(inputs) <span class="comment">#设置输出名字为outputs</span></span><br><span class="line">linear = models.Model(inputs = inputs,outputs = outputs)</span><br><span class="line">linear.summary()</span><br><span class="line"></span><br><span class="line"><span class="comment">## 使用fit方法进行训练</span></span><br><span class="line">linear.compile(optimizer=<span class="string">"rmsprop"</span>,loss=<span class="string">"mse"</span>,metrics=[<span class="string">"mae"</span>])</span><br><span class="line">linear.fit(X,Y,batch_size = <span class="number">8</span>,epochs = <span class="number">100</span>)  </span><br><span class="line"></span><br><span class="line">tf.print(<span class="string">"w = "</span>,linear.layers[<span class="number">1</span>].kernel)</span><br><span class="line">tf.print(<span class="string">"b = "</span>,linear.layers[<span class="number">1</span>].bias)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 将模型保存成pb格式文件</span></span><br><span class="line">export_path = <span class="string">"./data/linear_model/"</span></span><br><span class="line">version = <span class="string">"1"</span>       <span class="comment">#后续可以通过版本号进行模型版本迭代与管理</span></span><br><span class="line">linear.save(export_path+version, save_format=<span class="string">"tf"</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#查看保存的模型文件</span></span><br><span class="line">!ls &#123;export_path+version&#125;</span><br></pre></td></tr></table></figure><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">assets</span><span class="selector-tag">saved_model</span><span class="selector-class">.pb</span><span class="selector-tag">variables</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看模型文件相关信息</span></span><br><span class="line">!saved_model_cli show --dir &#123;export_path+str(version)&#125; --all</span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line">MetaGraphDef <span class="keyword">with</span> tag-<span class="keyword">set</span>: <span class="string">'serve'</span> contains the <span class="keyword">following</span> SignatureDefs:</span><br><span class="line"></span><br><span class="line">signature_def[<span class="string">'__saved_model_init_op'</span>]:</span><br><span class="line">  The given SavedModel SignatureDef contains the <span class="keyword">following</span> <span class="keyword">input</span>(s):</span><br><span class="line">  The given SavedModel SignatureDef contains the <span class="keyword">following</span> <span class="keyword">output</span>(s):</span><br><span class="line">    outputs[<span class="string">'__saved_model_init_op'</span>] tensor_info:</span><br><span class="line">        dtype: DT_INVALID</span><br><span class="line">        shape: unknown_rank</span><br><span class="line">        <span class="keyword">name</span>: NoOp</span><br><span class="line">  Method <span class="keyword">name</span> <span class="keyword">is</span>: </span><br><span class="line"></span><br><span class="line">signature_def[<span class="string">'serving_default'</span>]:</span><br><span class="line">  The given SavedModel SignatureDef contains the <span class="keyword">following</span> <span class="keyword">input</span>(s):</span><br><span class="line">    inputs[<span class="string">'inputs'</span>] tensor_info:</span><br><span class="line">        dtype: DT_FLOAT</span><br><span class="line">        shape: (<span class="number">-1</span>, <span class="number">2</span>)</span><br><span class="line">        <span class="keyword">name</span>: serving_default_inputs:<span class="number">0</span></span><br><span class="line">  The given SavedModel SignatureDef contains the <span class="keyword">following</span> <span class="keyword">output</span>(s):</span><br><span class="line">    outputs[<span class="string">'outputs'</span>] tensor_info:</span><br><span class="line">        dtype: DT_FLOAT</span><br><span class="line">        shape: (<span class="number">-1</span>, <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">name</span>: StatefulPartitionedCall:<span class="number">0</span></span><br><span class="line">  Method <span class="keyword">name</span> <span class="keyword">is</span>: tensorflow/serving/predict</span><br><span class="line"><span class="keyword">WARNING</span>:tensorflow:<span class="keyword">From</span> /tensorflow<span class="number">-2.1</span><span class="number">.0</span>/python3<span class="number">.6</span>/tensorflow_core/python/ops/resource_variable_ops.py:<span class="number">1786</span>: <span class="keyword">calling</span> BaseResourceVariable.__init__ (<span class="keyword">from</span> tensorflow.python.ops.resource_variable_ops) <span class="keyword">with</span> <span class="keyword">constraint</span> <span class="keyword">is</span> deprecated <span class="keyword">and</span> will be removed <span class="keyword">in</span> a future version.</span><br><span class="line">Instructions <span class="keyword">for</span> updating:</span><br><span class="line"><span class="keyword">If</span> <span class="keyword">using</span> Keras pass *_constraint arguments <span class="keyword">to</span> layers.</span><br><span class="line"></span><br><span class="line">Defined Functions:</span><br><span class="line">  <span class="keyword">Function</span> <span class="keyword">Name</span>: <span class="string">'__call__'</span></span><br><span class="line">    <span class="keyword">Option</span> <span class="comment">#1</span></span><br><span class="line">      Callable <span class="keyword">with</span>:</span><br><span class="line">        Argument <span class="comment">#1</span></span><br><span class="line">          inputs: TensorSpec(shape=(<span class="keyword">None</span>, <span class="number">2</span>), dtype=tf.float32, <span class="keyword">name</span>=<span class="string">'inputs'</span>)</span><br><span class="line">        Argument <span class="comment">#2</span></span><br><span class="line">          DType: <span class="built_in">bool</span></span><br><span class="line">          <span class="keyword">Value</span>: <span class="literal">False</span></span><br><span class="line">        Argument <span class="comment">#3</span></span><br><span class="line">          DType: NoneType</span><br><span class="line">          <span class="keyword">Value</span>: <span class="keyword">None</span></span><br><span class="line">    <span class="keyword">Option</span> <span class="comment">#2</span></span><br><span class="line">      Callable <span class="keyword">with</span>:</span><br><span class="line">        Argument <span class="comment">#1</span></span><br><span class="line">          inputs: TensorSpec(shape=(<span class="keyword">None</span>, <span class="number">2</span>), dtype=tf.float32, <span class="keyword">name</span>=<span class="string">'inputs'</span>)</span><br><span class="line">        Argument <span class="comment">#2</span></span><br><span class="line">          DType: <span class="built_in">bool</span></span><br><span class="line">          <span class="keyword">Value</span>: <span class="literal">True</span></span><br><span class="line">        Argument <span class="comment">#3</span></span><br><span class="line">          DType: NoneType</span><br><span class="line">          <span class="keyword">Value</span>: <span class="keyword">None</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">Function</span> <span class="keyword">Name</span>: <span class="string">'_default_save_signature'</span></span><br><span class="line">    <span class="keyword">Option</span> <span class="comment">#1</span></span><br><span class="line">      Callable <span class="keyword">with</span>:</span><br><span class="line">        Argument <span class="comment">#1</span></span><br><span class="line">          inputs: TensorSpec(shape=(<span class="keyword">None</span>, <span class="number">2</span>), dtype=tf.float32, <span class="keyword">name</span>=<span class="string">'inputs'</span>)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">Function</span> <span class="keyword">Name</span>: <span class="string">'call_and_return_all_conditional_losses'</span></span><br><span class="line">    <span class="keyword">Option</span> <span class="comment">#1</span></span><br><span class="line">      Callable <span class="keyword">with</span>:</span><br><span class="line">        Argument <span class="comment">#1</span></span><br><span class="line">          inputs: TensorSpec(shape=(<span class="keyword">None</span>, <span class="number">2</span>), dtype=tf.float32, <span class="keyword">name</span>=<span class="string">'inputs'</span>)</span><br><span class="line">        Argument <span class="comment">#2</span></span><br><span class="line">          DType: <span class="built_in">bool</span></span><br><span class="line">          <span class="keyword">Value</span>: <span class="literal">True</span></span><br><span class="line">        Argument <span class="comment">#3</span></span><br><span class="line">          DType: NoneType</span><br><span class="line">          <span class="keyword">Value</span>: <span class="keyword">None</span></span><br><span class="line">    <span class="keyword">Option</span> <span class="comment">#2</span></span><br><span class="line">      Callable <span class="keyword">with</span>:</span><br><span class="line">        Argument <span class="comment">#1</span></span><br><span class="line">          inputs: TensorSpec(shape=(<span class="keyword">None</span>, <span class="number">2</span>), dtype=tf.float32, <span class="keyword">name</span>=<span class="string">'inputs'</span>)</span><br><span class="line">        Argument <span class="comment">#2</span></span><br><span class="line">          DType: <span class="built_in">bool</span></span><br><span class="line">          <span class="keyword">Value</span>: <span class="literal">False</span></span><br><span class="line">        Argument <span class="comment">#3</span></span><br><span class="line">          DType: NoneType</span><br><span class="line">          <span class="keyword">Value</span>: <span class="keyword">None</span></span><br></pre></td></tr></table></figure><h4 id="安装-tensorflow-serving"><a href="#安装-tensorflow-serving" class="headerlink" title="安装 tensorflow serving"></a>安装 tensorflow serving</h4><p>安装 tensorflow serving 有2种主要方法：通过Docker镜像安装，通过apt安装。</p><p>通过Docker镜像安装是最简单，最直接的方法，推荐采用。</p><p>Docker可以理解成一种容器，其上面可以给各种不同的程序提供独立的运行环境。</p><p>一般业务中用到tensorflow的企业都会有运维同学通过Docker 搭建 tensorflow serving.</p><p>无需算法工程师同学动手安装，以下安装过程仅供参考。</p><p>不同操作系统机器上安装Docker的方法可以参照以下链接。</p><p>Windows: <a href="https://www.runoob.com/docker/windows-docker-install.html" target="_blank" rel="external nofollow noopener noreferrer">https://www.runoob.com/docker/windows-docker-install.html</a></p><p>MacOs: <a href="https://www.runoob.com/docker/macos-docker-install.html" target="_blank" rel="external nofollow noopener noreferrer">https://www.runoob.com/docker/macos-docker-install.html</a></p><p>CentOS: <a href="https://www.runoob.com/docker/centos-docker-install.html" target="_blank" rel="external nofollow noopener noreferrer">https://www.runoob.com/docker/centos-docker-install.html</a></p><p>安装Docker成功后，使用如下命令加载 tensorflow/serving 镜像到Docker中</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pull tensorflow/serving</span><br></pre></td></tr></table></figure><h4 id="启动-tensorflow-serving-服务"><a href="#启动-tensorflow-serving-服务" class="headerlink" title="启动 tensorflow serving 服务"></a>启动 tensorflow serving 服务</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">!docker run -t --rm -p <span class="number">8501</span>:<span class="number">8501</span> \</span><br><span class="line">    -v <span class="string">"/Users/.../data/linear_model/"</span> \</span><br><span class="line">    -e MODEL_NAME=linear_model \</span><br><span class="line">    tensorflow/serving &amp; &gt;server.log <span class="number">2</span>&gt;&amp;<span class="number">1</span></span><br></pre></td></tr></table></figure><h4 id="向API服务发送请求"><a href="#向API服务发送请求" class="headerlink" title="向API服务发送请求"></a>向API服务发送请求</h4><p>可以使用任何编程语言的http功能发送请求，下面示范linux的 curl 命令发送请求，以及Python的requests库发送请求。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">!curl -d <span class="string">'&#123;"instances": [[1.0, 2.0], [5.0,7.0]]&#125;'</span> \</span><br><span class="line">    -X POST http://localhost:<span class="number">8501</span>/v1/models/linear_model:predict</span><br></pre></td></tr></table></figure><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"predictions"</span>: [[<span class="number">3.06546211</span>], [<span class="number">6.02843142</span>]</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json,requests</span><br><span class="line"></span><br><span class="line">data = json.dumps(&#123;<span class="string">"signature_name"</span>: <span class="string">"serving_default"</span>, <span class="string">"instances"</span>: [[<span class="number">1.0</span>, <span class="number">2.0</span>], [<span class="number">5.0</span>,<span class="number">7.0</span>]]&#125;)</span><br><span class="line">headers = &#123;<span class="string">"content-type"</span>: <span class="string">"application/json"</span>&#125;</span><br><span class="line">json_response = requests.post(<span class="string">'http://localhost:8501/v1/models/linear_model:predict'</span>, </span><br><span class="line">        data=data, headers=headers)</span><br><span class="line">predictions = json.loads(json_response.text)[<span class="string">"predictions"</span>]</span><br><span class="line">print(predictions)</span><br></pre></td></tr></table></figure><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">3.06546211</span>], [<span class="number">6.02843142</span>]]</span><br></pre></td></tr></table></figure><h3 id="使用spark-scala调用tensorflow2-0训练好的模型"><a href="#使用spark-scala调用tensorflow2-0训练好的模型" class="headerlink" title="使用spark-scala调用tensorflow2.0训练好的模型"></a>使用spark-scala调用tensorflow2.0训练好的模型</h3><p>本篇文章介绍在spark中调用训练好的tensorflow模型进行预测的方法。</p><p>本文内容的学习需要一定的spark和scala基础。</p><p>如果使用pyspark的话会比较简单，只需要在每个executor上用Python加载模型分别预测就可以了。</p><p>但工程上为了性能考虑，通常使用的是scala版本的spark。</p><p>本篇文章我们通过TensorFlow for Java 在spark中调用训练好的tensorflow模型。</p><p>利用spark的分布式计算能力，从而可以让训练好的tensorflow模型在成百上千的机器上分布式并行执行模型推断。</p><h4 id="spark-scala调用tensorflow模型概述"><a href="#spark-scala调用tensorflow模型概述" class="headerlink" title="spark-scala调用tensorflow模型概述"></a>spark-scala调用tensorflow模型概述</h4><p>在spark(scala)中调用tensorflow模型进行预测需要完成以下几个步骤。</p><p>（1）准备protobuf模型文件</p><p>（2）创建spark(scala)项目，在项目中添加java版本的tensorflow对应的jar包依赖</p><p>（3）在spark(scala)项目中driver端加载tensorflow模型调试成功</p><p>（4）在spark(scala)项目中通过RDD在executor上加载tensorflow模型调试成功</p><p>（5） 在spark(scala)项目中通过DataFrame在executor上加载tensorflow模型调试成功</p><h4 id="准备protobuf模型文件-1"><a href="#准备protobuf模型文件-1" class="headerlink" title="准备protobuf模型文件"></a>准备protobuf模型文件</h4><p>我们使用tf.keras 训练一个简单的线性回归模型，并保存成protobuf文件。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> models,layers,optimizers</span><br><span class="line"></span><br><span class="line"><span class="comment">## 样本数量</span></span><br><span class="line">n = <span class="number">800</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 生成测试用数据集</span></span><br><span class="line">X = tf.random.uniform([n,<span class="number">2</span>],minval=<span class="number">-10</span>,maxval=<span class="number">10</span>) </span><br><span class="line">w0 = tf.constant([[<span class="number">2.0</span>],[<span class="number">-1.0</span>]])</span><br><span class="line">b0 = tf.constant(<span class="number">3.0</span>)</span><br><span class="line"></span><br><span class="line">Y = X@w0 + b0 + tf.random.normal([n,<span class="number">1</span>],mean = <span class="number">0.0</span>,stddev= <span class="number">2.0</span>)  <span class="comment"># @表示矩阵乘法,增加正态扰动</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 建立模型</span></span><br><span class="line">tf.keras.backend.clear_session()</span><br><span class="line">inputs = layers.Input(shape = (<span class="number">2</span>,),name =<span class="string">"inputs"</span>) <span class="comment">#设置输入名字为inputs</span></span><br><span class="line">outputs = layers.Dense(<span class="number">1</span>, name = <span class="string">"outputs"</span>)(inputs) <span class="comment">#设置输出名字为outputs</span></span><br><span class="line">linear = models.Model(inputs = inputs,outputs = outputs)</span><br><span class="line">linear.summary()</span><br><span class="line"></span><br><span class="line"><span class="comment">## 使用fit方法进行训练</span></span><br><span class="line">linear.compile(optimizer=<span class="string">"rmsprop"</span>,loss=<span class="string">"mse"</span>,metrics=[<span class="string">"mae"</span>])</span><br><span class="line">linear.fit(X,Y,batch_size = <span class="number">8</span>,epochs = <span class="number">100</span>)  </span><br><span class="line"></span><br><span class="line">tf.print(<span class="string">"w = "</span>,linear.layers[<span class="number">1</span>].kernel)</span><br><span class="line">tf.print(<span class="string">"b = "</span>,linear.layers[<span class="number">1</span>].bias)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 将模型保存成pb格式文件</span></span><br><span class="line">export_path = <span class="string">"./data/linear_model/"</span></span><br><span class="line">version = <span class="string">"1"</span>       <span class="comment">#后续可以通过版本号进行模型版本迭代与管理</span></span><br><span class="line">linear.save(export_path+version, save_format=<span class="string">"tf"</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!ls &#123;export_path+version&#125;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看模型文件相关信息</span></span><br><span class="line">!saved_model_cli show --dir &#123;export_path+str(version)&#125; --all</span><br></pre></td></tr></table></figure><p>模型文件信息中这些标红的部分都是后面有可能会用到的。</p><p><img alt data-src="https://github.com/SimpCosm/eat_tensorflow2_in_30_days_ipynbs/raw/master/data/模型文件信息.png"></p><h4 id="创建spark-scala-项目，在项目中添加java版本的tensorflow对应的jar包依赖"><a href="#创建spark-scala-项目，在项目中添加java版本的tensorflow对应的jar包依赖" class="headerlink" title="创建spark(scala)项目，在项目中添加java版本的tensorflow对应的jar包依赖"></a>创建spark(scala)项目，在项目中添加java版本的tensorflow对应的jar包依赖</h4><p>如果使用maven管理项目，需要添加如下 jar包依赖</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.tensorflow/tensorflow --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.tensorflow<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>tensorflow<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.15.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><p>也可以从下面网址中直接下载 org.tensorflow.tensorflow的jar包</p><p>以及其依赖的org.tensorflow.libtensorflow 和 org.tensorflowlibtensorflow_jni的jar包 放到项目中。</p><p><a href="https://mvnrepository.com/artifact/org.tensorflow/tensorflow/1.15.0" target="_blank" rel="external nofollow noopener noreferrer">https://mvnrepository.com/artifact/org.tensorflow/tensorflow/1.15.0</a></p><h4 id="在spark-scala-项目中driver端加载tensorflow模型调试成功"><a href="#在spark-scala-项目中driver端加载tensorflow模型调试成功" class="headerlink" title="在spark(scala)项目中driver端加载tensorflow模型调试成功"></a>在spark(scala)项目中driver端加载tensorflow模型调试成功</h4><p>我们的示范代码在jupyter notebook中进行演示，需要安装toree以支持spark(scala)。</p><!-- #region --><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scala.collection.mutable.<span class="type">WrappedArray</span></span><br><span class="line"><span class="keyword">import</span> org.&#123;tensorflow=&gt;tf&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//注：load函数的第二个参数一般都是“serve”，可以从模型文件相关信息中找到</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> bundle = tf.<span class="type">SavedModelBundle</span> </span><br><span class="line">   .load(<span class="string">"/Users/liangyun/CodeFiles/eat_tensorflow2_in_30_days/data/linear_model/1"</span>,<span class="string">"serve"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">//注：在java版本的tensorflow中还是类似tensorflow1.0中静态计算图的模式，需要建立Session, 指定feed的数据和fetch的结果, 然后 run.</span></span><br><span class="line"><span class="comment">//注：如果有多个数据需要喂入，可以连续使用多个feed方法</span></span><br><span class="line"><span class="comment">//注：输入必须是float类型</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> sess = bundle.session()</span><br><span class="line"><span class="keyword">val</span> x = tf.<span class="type">Tensor</span>.create(<span class="type">Array</span>(<span class="type">Array</span>(<span class="number">1.0</span>f,<span class="number">2.0</span>f),<span class="type">Array</span>(<span class="number">2.0</span>f,<span class="number">3.0</span>f)))</span><br><span class="line"><span class="keyword">val</span> y =  sess.runner().feed(<span class="string">"serving_default_inputs:0"</span>, x)</span><br><span class="line">         .fetch(<span class="string">"StatefulPartitionedCall:0"</span>).run().get(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> result = <span class="type">Array</span>.ofDim[<span class="type">Float</span>](y.shape()(<span class="number">0</span>).toInt,y.shape()(<span class="number">1</span>).toInt)</span><br><span class="line">y.copyTo(result)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span>(x != <span class="literal">null</span>) x.close()</span><br><span class="line"><span class="keyword">if</span>(y != <span class="literal">null</span>) y.close()</span><br><span class="line"><span class="keyword">if</span>(sess != <span class="literal">null</span>) sess.close()</span><br><span class="line"><span class="keyword">if</span>(bundle != <span class="literal">null</span>) bundle.close()  </span><br><span class="line"></span><br><span class="line">result</span><br></pre></td></tr></table></figure><!-- #endregion --><p>输出如下：</p><figure class="highlight lisp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Array(<span class="name">Array</span>(<span class="number">3.019596</span>), Array(<span class="number">3.9878292</span>))</span><br></pre></td></tr></table></figure><p><img alt data-src="https://github.com/SimpCosm/eat_tensorflow2_in_30_days_ipynbs/raw/master/data/TfDriver.png"></p><h4 id="在spark-scala-项目中通过RDD在executor上加载tensorflow模型调试成功"><a href="#在spark-scala-项目中通过RDD在executor上加载tensorflow模型调试成功" class="headerlink" title="在spark(scala)项目中通过RDD在executor上加载tensorflow模型调试成功"></a>在spark(scala)项目中通过RDD在executor上加载tensorflow模型调试成功</h4><p>下面我们通过广播机制将Driver端加载的TensorFlow模型传递到各个executor上，并在executor上分布式地调用模型进行推断。</p><!-- #region --><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.<span class="type">SparkSession</span></span><br><span class="line"><span class="keyword">import</span> scala.collection.mutable.<span class="type">WrappedArray</span></span><br><span class="line"><span class="keyword">import</span> org.&#123;tensorflow=&gt;tf&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> spark = <span class="type">SparkSession</span></span><br><span class="line">    .builder()</span><br><span class="line">    .appName(<span class="string">"TfRDD"</span>)</span><br><span class="line">    .enableHiveSupport()</span><br><span class="line">    .getOrCreate()</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> sc = spark.sparkContext</span><br><span class="line"></span><br><span class="line"><span class="comment">//在Driver端加载模型</span></span><br><span class="line"><span class="keyword">val</span> bundle = tf.<span class="type">SavedModelBundle</span> </span><br><span class="line">   .load(<span class="string">"/Users/liangyun/CodeFiles/master_tensorflow2_in_20_hours/data/linear_model/1"</span>,<span class="string">"serve"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">//利用广播将模型发送到executor上</span></span><br><span class="line"><span class="keyword">val</span> broads = sc.broadcast(bundle)</span><br><span class="line"></span><br><span class="line"><span class="comment">//构造数据集</span></span><br><span class="line"><span class="keyword">val</span> rdd_data = sc.makeRDD(<span class="type">List</span>(<span class="type">Array</span>(<span class="number">1.0</span>f,<span class="number">2.0</span>f),<span class="type">Array</span>(<span class="number">3.0</span>f,<span class="number">5.0</span>f),<span class="type">Array</span>(<span class="number">6.0</span>f,<span class="number">7.0</span>f),<span class="type">Array</span>(<span class="number">8.0</span>f,<span class="number">3.0</span>f)))</span><br><span class="line"></span><br><span class="line"><span class="comment">//通过mapPartitions调用模型进行批量推断</span></span><br><span class="line"><span class="keyword">val</span> rdd_result = rdd_data.mapPartitions(iter =&gt; &#123;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">val</span> arr = iter.toArray</span><br><span class="line">    <span class="keyword">val</span> model = broads.value</span><br><span class="line">    <span class="keyword">val</span> sess = model.session()</span><br><span class="line">    <span class="keyword">val</span> x = tf.<span class="type">Tensor</span>.create(arr)</span><br><span class="line">    <span class="keyword">val</span> y =  sess.runner().feed(<span class="string">"serving_default_inputs:0"</span>, x)</span><br><span class="line">             .fetch(<span class="string">"StatefulPartitionedCall:0"</span>).run().get(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//将预测结果拷贝到相同shape的Float类型的Array中</span></span><br><span class="line">    <span class="keyword">val</span> result = <span class="type">Array</span>.ofDim[<span class="type">Float</span>](y.shape()(<span class="number">0</span>).toInt,y.shape()(<span class="number">1</span>).toInt)</span><br><span class="line">    y.copyTo(result)</span><br><span class="line">    result.iterator</span><br><span class="line">    </span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">rdd_result.take(<span class="number">5</span>)</span><br><span class="line">bundle.close</span><br></pre></td></tr></table></figure><!-- #endregion --><p>输出如下：</p><figure class="highlight lisp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Array(<span class="name">Array</span>(<span class="number">3.019596</span>), Array(<span class="number">3.9264367</span>), Array(<span class="number">7.8607616</span>), Array(<span class="number">15.974984</span>))</span><br></pre></td></tr></table></figure><p><img alt data-src="https://github.com/SimpCosm/eat_tensorflow2_in_30_days_ipynbs/raw/master/data/TfRDD.png"></p><h4 id="在spark-scala-项目中通过DataFrame在executor上加载tensorflow模型调试成功"><a href="#在spark-scala-项目中通过DataFrame在executor上加载tensorflow模型调试成功" class="headerlink" title="在spark(scala)项目中通过DataFrame在executor上加载tensorflow模型调试成功"></a>在spark(scala)项目中通过DataFrame在executor上加载tensorflow模型调试成功</h4><p>除了可以在Spark的RDD数据上调用tensorflow模型进行分布式推断，</p><p>我们也可以在DataFrame数据上调用tensorflow模型进行分布式推断。</p><p>主要思路是将推断方法注册成为一个sparkSQL函数。</p><!-- #region --><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.<span class="type">SparkSession</span></span><br><span class="line"><span class="keyword">import</span> scala.collection.mutable.<span class="type">WrappedArray</span></span><br><span class="line"><span class="keyword">import</span> org.&#123;tensorflow=&gt;tf&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">TfDataFrame</span> <span class="keyword">extends</span> <span class="title">Serializable</span></span>&#123;</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args:<span class="type">Array</span>[<span class="type">String</span>]):<span class="type">Unit</span> = &#123;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">val</span> spark = <span class="type">SparkSession</span></span><br><span class="line">        .builder()</span><br><span class="line">        .appName(<span class="string">"TfDataFrame"</span>)</span><br><span class="line">        .enableHiveSupport()</span><br><span class="line">        .getOrCreate()</span><br><span class="line">        <span class="keyword">val</span> sc = spark.sparkContext</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">        <span class="keyword">import</span> spark.implicits._</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> bundle = tf.<span class="type">SavedModelBundle</span> </span><br><span class="line">           .load(<span class="string">"/Users/liangyun/CodeFiles/master_tensorflow2_in_20_hours/data/linear_model/1"</span>,<span class="string">"serve"</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> broads = sc.broadcast(bundle)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">//构造预测函数，并将其注册成sparkSQL的udf</span></span><br><span class="line">        <span class="keyword">val</span> tfpredict = (features:<span class="type">WrappedArray</span>[<span class="type">Float</span>])  =&gt; &#123;</span><br><span class="line">            <span class="keyword">val</span> bund = broads.value</span><br><span class="line">            <span class="keyword">val</span> sess = bund.session()</span><br><span class="line">            <span class="keyword">val</span> x = tf.<span class="type">Tensor</span>.create(<span class="type">Array</span>(features.toArray))</span><br><span class="line">            <span class="keyword">val</span> y =  sess.runner().feed(<span class="string">"serving_default_inputs:0"</span>, x)</span><br><span class="line">                     .fetch(<span class="string">"StatefulPartitionedCall:0"</span>).run().get(<span class="number">0</span>)</span><br><span class="line">            <span class="keyword">val</span> result = <span class="type">Array</span>.ofDim[<span class="type">Float</span>](y.shape()(<span class="number">0</span>).toInt,y.shape()(<span class="number">1</span>).toInt)</span><br><span class="line">            y.copyTo(result)</span><br><span class="line">            <span class="keyword">val</span> y_pred = result(<span class="number">0</span>)(<span class="number">0</span>)</span><br><span class="line">            y_pred</span><br><span class="line">        &#125;</span><br><span class="line">        spark.udf.register(<span class="string">"tfpredict"</span>,tfpredict)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">//构造DataFrame数据集，将features放到一列中</span></span><br><span class="line">        <span class="keyword">val</span> dfdata = sc.parallelize(<span class="type">List</span>(<span class="type">Array</span>(<span class="number">1.0</span>f,<span class="number">2.0</span>f),<span class="type">Array</span>(<span class="number">3.0</span>f,<span class="number">5.0</span>f),<span class="type">Array</span>(<span class="number">7.0</span>f,<span class="number">8.0</span>f))).toDF(<span class="string">"features"</span>)</span><br><span class="line">        dfdata.show </span><br><span class="line">        </span><br><span class="line">        <span class="comment">//调用sparkSQL预测函数，增加一个新的列作为y_preds</span></span><br><span class="line">        <span class="keyword">val</span> dfresult = dfdata.selectExpr(<span class="string">"features"</span>,<span class="string">"tfpredict(features) as y_preds"</span>)</span><br><span class="line">        dfresult.show </span><br><span class="line">        bundle.close</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><!-- #endregion --><!-- #region --><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">TfDataFrame</span>.main(<span class="type">Array</span>())</span><br></pre></td></tr></table></figure><!-- #endregion --><figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="code">+----------+</span></span><br><span class="line">|  features|</span><br><span class="line"><span class="code">+----------+</span></span><br><span class="line">|[1.0, 2.0]|</span><br><span class="line">|[3.0, 5.0]|</span><br><span class="line">|[7.0, 8.0]|</span><br><span class="line"><span class="code">+----------+</span></span><br><span class="line"></span><br><span class="line"><span class="code">+----------+</span>---------+</span><br><span class="line">|  features|  y<span class="emphasis">_preds|</span></span><br><span class="line"><span class="emphasis">+----------+---------+</span></span><br><span class="line"><span class="emphasis">|[1.0, 2.0]| 3.019596|</span></span><br><span class="line"><span class="emphasis">|[3.0, 5.0]|3.9264367|</span></span><br><span class="line"><span class="emphasis">|[7.0, 8.0]| 8.828995|</span></span><br><span class="line"><span class="emphasis">+----------+---------+</span></span><br></pre></td></tr></table></figure><p>以上我们分别在spark 的RDD数据结构和DataFrame数据结构上实现了调用一个tf.keras实现的线性回归模型进行分布式模型推断。</p><p>在本例基础上稍作修改则可以用spark调用训练好的各种复杂的神经网络模型进行分布式模型推断。</p><p>但实际上tensorflow并不仅仅适合实现神经网络，其底层的计算图语言可以表达各种数值计算过程。</p><p>利用其丰富的低阶API，我们可以在tensorflow2.0上实现任意机器学习模型，</p><p>结合tf.Module提供的便捷的封装功能，我们可以将训练好的任意机器学习模型导出成模型文件并在spark上分布式调用执行。</p><p>这无疑为我们的工程应用提供了巨大的想象空间。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://github.com/lyhue1991/eat_tensorflow2_in_30_days" target="_blank" rel="external nofollow noopener noreferrer">eat_tensorflow2_in_30_days</a></li><li><a href="https://github.com/snowkylin/tensorflow-handbook" target="_blank" rel="external nofollow noopener noreferrer">简单粗暴Tensorflow2</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;近年来，深度神经网络技术被大规模地使用在搜索、推荐、广告、翻译、语音、图像和视频等领域。与此同时，深度学习也在推动一些人类最重大的工程挑战，比如自动驾驶技术、医疗诊断和预测、个性化学习、加速科学发展（比如天文发现）、跨语言的自由交流（比如实时翻译），更通用的人工智能系统（比如 AlphaGo）等。&lt;/p&gt;
&lt;p&gt;TensorFlow 是开源的端到端的机器学习平台，提供了丰富的工具链，推动了机器学习的前沿研究，支撑了大规模生产使用，支持多平台灵活部署。2019年10月，谷歌正式发布TensorFlow 2.0，相比于TensorFlow 1.0，TensorFlow 2 重点关注易用性，默认推荐使用 Keras 作为高阶 API，同时兼具可扩展性和高性能，默认为动态图方式执行。本文作为 Tensorflow2 学习笔记，主要参考&lt;a href=&quot;https://github.com/lyhue1991/eat_tensorflow2_in_30_days&quot; target=&quot;_blank&quot; rel=&quot;external nofollow noopener noreferrer&quot;&gt;eat_tensorflow2_in_30_days&lt;/a&gt;，对照着原教程在Docker环境下对于TensorFlow2进行学习，感谢原作者的贡献。&lt;/p&gt;
    
    </summary>
    
    <content src="http://houmin.cc/https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2021-01-05_tf_logo_social.png" type="image" />
    
    
      <category term="术业专攻" scheme="http://houmin.cc/categories/%E6%9C%AF%E4%B8%9A%E4%B8%93%E6%94%BB/"/>
    
    
      <category term="tensorflow" scheme="http://houmin.cc/tags/tensorflow/"/>
    
      <category term="深度学习" scheme="http://houmin.cc/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>【深度学习】卷积神经网络</title>
    <link href="http://houmin.cc/posts/77a2fe8f/"/>
    <id>http://houmin.cc/posts/77a2fe8f/</id>
    <published>2020-12-15T12:00:44.000Z</published>
    <updated>2021-01-07T09:22:20.779Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>在 <a href="https://houmin.cc/posts/e1b7513f/">人工神经网络</a> 中我们介绍了人工神经网络这样的全连接网络，它是深度学习的基础。然而，全连接网络存在着参数数量过多等问题，本文将介绍 <strong>卷积神经网络(Convolutional Neural Network, CNN)</strong> 。</p><a id="more"></a><h2 id="核心思想"><a href="#核心思想" class="headerlink" title="核心思想"></a>核心思想</h2><h3 id="局部感知"><a href="#局部感知" class="headerlink" title="局部感知"></a>局部感知</h3><h3 id="权值共享"><a href="#权值共享" class="headerlink" title="权值共享"></a>权值共享</h3><h3 id="下采样操作"><a href="#下采样操作" class="headerlink" title="下采样操作"></a>下采样操作</h3><h2 id="基本组成"><a href="#基本组成" class="headerlink" title="基本组成"></a>基本组成</h2><h3 id="Convolution-Layer"><a href="#Convolution-Layer" class="headerlink" title="Convolution Layer"></a>Convolution Layer</h3><p>卷积层的运算过程如下图，用一个卷积核扫完整张图片：</p><p><img alt="卷积层运算过程" data-src="https://easy-ai.oss-cn-shanghai.aliyuncs.com/2019-06-19-juanji.gif"></p><p>这个过程我们可以理解为我们使用一个过滤器（卷积核）来过滤图像的各个小区域，从而得到这些小区域的特征值。</p><p>在具体应用中，往往有多个卷积核，可以认为，每个卷积核代表了一种图像模式，如果某个图像块与此卷积核卷积出的值大，则认为此图像块十分接近于此卷积核。如果我们设计了6个卷积核，可以理解：我们认为这个图像上有6种底层纹理模式，也就是我们用6中基础模式就能描绘出一副图像。以下就是25种不同的卷积核的示例：</p><p><img alt="25种不同的卷积核" data-src="https://easy-ai.oss-cn-shanghai.aliyuncs.com/2019-06-19-150926.jpg"></p><p><strong>总结：卷积层的通过卷积核的过滤提取出图片中局部的特征，跟上面提到的人类视觉的特征提取类似。</strong></p><p>这一层就是卷积神经网络最重要的一个层次，也是“卷积神经网络”的名字来源。<br> 在这个卷积层，有两个关键操作：</p><ul><li>局部关联。每个神经元看做一个滤波器(filter)</li><li>窗口(receptive field)滑动， filter对局部数据计算</li></ul><p>先介绍卷积层遇到的几个名词：</p><ul><li>深度/depth（解释见下图）</li><li>步长/stride （窗口一次滑动的长度）</li><li>填充值/zero-padding</li></ul><p><img alt="img" data-src="https:////upload-images.jianshu.io/upload_images/1845730-cf4779043e6ceba1.png"></p><p>填充值是什么呢？以下图为例子，比如有这么一个5 <em> 5的图片（一个格子一个像素），我们滑动窗口取2</em>2，步长取2，那么我们发现还剩下1个像素没法滑完，那怎么办呢？</p><p><img alt="img" data-src="https:////upload-images.jianshu.io/upload_images/1845730-b23ec0c9735cc013.png"></p><p>那我们在原先的矩阵加了一层填充值，使得变成6*6的矩阵，那么窗口就可以刚好把所有像素遍历完。这就是填充值的作用。</p><p><img alt="img" data-src="https:////upload-images.jianshu.io/upload_images/1845730-4155a0952c380247.png"></p><p>卷积的计算（注意，下面蓝色矩阵周围有一圈灰色的框，那些就是上面所说到的填充值）</p><p><img alt="img" data-src="https:////upload-images.jianshu.io/upload_images/1845730-549acda410aa48fe.jpg"></p><p> 这里的蓝色矩阵就是输入的图像，粉色矩阵就是<strong>卷积层的神经元</strong>，这里表示了有两个神经元（w0,w1）。<strong>绿色矩阵就是经过卷积运算后的输出矩阵</strong>，这里的步长设置为2。</p><p><img alt="img" data-src="https:////upload-images.jianshu.io/upload_images/1845730-54d90dad81065a59.jpg"></p><p>蓝色的矩阵(输入图像)对粉色的矩阵（filter）进行矩阵内积计算并将三个内积运算的结果与偏置值b相加（比如上面图的计算：2+（-2+1-2）+（1-2-2） + 1= 2 - 3 - 3 + 1 = -3），计算后的值就是绿框矩阵的一个元素。</p><p><img alt="img" data-src="https:////upload-images.jianshu.io/upload_images/1845730-e3a757491994589f.png"></p><p>下面的动态图形象地展示了卷积层的计算过程：</p><p><img alt="img" data-src="https:////upload-images.jianshu.io/upload_images/1845730-5ca69abe03f57d72.gif"></p><p><strong>参数共享机制</strong></p><ul><li>在卷积层中每个神经元连接数据窗的权重是固定的，每个神经元只关注一个特性。神经元就是图像处理中的滤波器，比如边缘检测专用的Sobel滤波器，即卷积层的每个滤波器都会有自己所关注一个图像特征，比如垂直边缘，水平边缘，颜色，纹理等等，这些所有神经元加起来就好比就是整张图像的特征提取器集合。</li><li>需要估算的权重个数减少: AlexNet 1亿 =&gt; 3.5w</li><li>一组固定的权重和不同窗口内数据做内积: 卷积</li></ul><p><img alt="img" data-src="https:////upload-images.jianshu.io/upload_images/1845730-7b4cfaa9f9cf2930.png"></p><h3 id="Pooling-Layer"><a href="#Pooling-Layer" class="headerlink" title="Pooling Layer"></a>Pooling Layer</h3><p>池化层简单说就是下采样，他可以大大降低数据的维度。其过程如下：</p><p><img alt="池化层过程" data-src="https://easy-ai.oss-cn-shanghai.aliyuncs.com/2019-06-19-chihua.gif"></p><p>上图中，我们可以看到，原始图片是20×20的，我们对其进行下采样，采样窗口为10×10，最终将其下采样成为一个2×2大小的特征图。</p><p>之所以这么做的原因，是因为即使做完了卷积，图像仍然很大（因为卷积核比较小），所以为了降低数据维度，就进行下采样。</p><p><strong>总结：池化层相比卷积层可以更有效的降低数据维度，这么做不但可以大大减少运算量，还可以有效的避免过拟合。</strong></p><p>池化层夹在连续的卷积层中间， 用于压缩数据和参数的量，减小过拟合。<br> 简而言之，<strong>如果输入是图像的话，那么池化层的最主要作用就是压缩图像</strong>。</p><p>这里再展开叙述池化层的具体作用。</p><ol><li><p>特征不变性，也就是我们在图像处理中经常提到的特征的尺度不变性，池化操作就是图像的resize，平时一张狗的图像被缩小了一倍我们还能认出这是一张狗的照片，这说明这张图像中仍保留着狗最重要的特征，我们一看就能判断图像中画的是一只狗，图像压缩时去掉的信息只是一些无关紧要的信息，而留下的信息则是具有尺度不变性的特征，是最能表达图像的特征。</p></li><li><p>特征降维，我们知道一幅图像含有的信息是很大的，特征也很多，但是有些信息对于我们做图像任务时没有太多用途或者有重复，我们可以把这类冗余信息去除，把最重要的特征抽取出来，这也是池化操作的一大作用。</p></li><li><p>在一定程度上防止过拟合，更方便优化。</p><p><img alt="img" data-src="https:////upload-images.jianshu.io/upload_images/1845730-3fb425fc223b853a.jpg"></p><p>池化层用的方法有Max pooling 和 average pooling，而实际用的较多的是Max pooling。<br> 这里就说一下Max pooling，其实思想非常简单。</p><p><img alt="img" data-src="https:////upload-images.jianshu.io/upload_images/1845730-9338f08f69f43297.jpg"></p><p>对于每个2 <em> 2的窗口选出最大的数作为输出矩阵的相应元素的值，比如输入矩阵第一个2 </em> 2窗口中最大的数是6，那么输出矩阵的第一个元素就是6，如此类推。</p></li></ol><h3 id="ReLU-Layer"><a href="#ReLU-Layer" class="headerlink" title="ReLU Layer"></a>ReLU Layer</h3><p>把卷积层输出结果做非线性映射。</p><p><img alt="img" data-src="https:////upload-images.jianshu.io/upload_images/1845730-6eafbff92d32d7d9.jpg"></p><p>CNN采用的激励函数一般为ReLU(The Rectified Linear Unit/修正线性单元)，它的特点是收敛快，求梯度简单，但较脆弱，图像如下。</p><p><img alt="img" data-src="https:////upload-images.jianshu.io/upload_images/1845730-8898029e12b1bcf6.png"></p><p>激励层的实践经验：<br> ①不要用sigmoid！不要用sigmoid！不要用sigmoid！<br> ② 首先试RELU，因为快，但要小心点<br> ③ 如果2失效，请用Leaky ReLU或者Maxout<br> ④ 某些情况下tanh倒是有不错的结果，但是很少</p><h2 id><a href="#" class="headerlink" title=" "></a> </h2><h3 id="Fully-Connected-Layer"><a href="#Fully-Connected-Layer" class="headerlink" title="Fully Connected Layer"></a>Fully Connected Layer</h3><p>这个部分就是最后一步了，经过卷积层和池化层处理过的数据输入到全连接层，得到最终想要的结果。</p><p>经过卷积层和池化层降维过的数据，全连接层才能”跑得动”，不然数据量太大，计算成本高，效率低下。</p><p><img alt="全连接层" data-src="https://easy-ai.oss-cn-shanghai.aliyuncs.com/2019-06-19-quanlianjie.png"></p><p>典型的 CNN 并非只是上面提到的3层结构，而是多层结构，例如 LeNet-5 的结构就如下图所示：</p><p><strong>卷积层 – 池化层- 卷积层 – 池化层 – 卷积层 – 全连接层</strong></p><p><strong><img alt="LeNet-5网络结构" data-src="https://easy-ai.oss-cn-shanghai.aliyuncs.com/2019-06-19-lenet.png"></strong></p><h3 id="Loss-Layer"><a href="#Loss-Layer" class="headerlink" title="Loss Layer"></a>Loss Layer</h3><h2 id="一般CNN结构依次为"><a href="#一般CNN结构依次为" class="headerlink" title="一般CNN结构依次为"></a>一般CNN结构依次为</h2><p>1.INPUT<br>2.[[CONV -&gt; RELU]<em>N -&gt; POOL?]</em>M<br>3.[FC -&gt; RELU]*K<br>4.FC</p><h2 id="经典网络"><a href="#经典网络" class="headerlink" title="经典网络"></a>经典网络</h2><h3 id="LeNet-5"><a href="#LeNet-5" class="headerlink" title="LeNet-5"></a>LeNet-5</h3><h3 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a>AlexNet</h3><h3 id="VGGNet"><a href="#VGGNet" class="headerlink" title="VGGNet"></a>VGGNet</h3><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://docs.google.com/presentation/d/1N5EgIfY9nst75cq20M27SjOSiSG1c7uAhZ0RngwGVzc/edit#slide=id.g27caba1471_82_12" target="_blank" rel="external nofollow noopener noreferrer">https://docs.google.com/presentation/d/1N5EgIfY9nst75cq20M27SjOSiSG1c7uAhZ0RngwGVzc/edit#slide=id.g27caba1471_82_12</a></li><li><a href="https://cuijiahua.com/blog/2018/12/dl-10.html" target="_blank" rel="external nofollow noopener noreferrer">https://cuijiahua.com/blog/2018/12/dl-10.html</a></li><li><a href="https://nndl.github.io/" target="_blank" rel="external nofollow noopener noreferrer">https://nndl.github.io/</a></li><li><a href="https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53" target="_blank" rel="external nofollow noopener noreferrer">https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53</a></li><li><a href="https://en.wikipedia.org/wiki/Convolutional_neural_network" target="_blank" rel="external nofollow noopener noreferrer">https://en.wikipedia.org/wiki/Convolutional_neural_network</a></li><li><a href="https://cloud.tencent.com/developer/article/1005137" target="_blank" rel="external nofollow noopener noreferrer">https://cloud.tencent.com/developer/article/1005137</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在 &lt;a href=&quot;https://houmin.cc/posts/e1b7513f/&quot;&gt;人工神经网络&lt;/a&gt; 中我们介绍了人工神经网络这样的全连接网络，它是深度学习的基础。然而，全连接网络存在着参数数量过多等问题，本文将介绍 &lt;strong&gt;卷积神经网络(Convolutional Neural Network, CNN)&lt;/strong&gt; 。&lt;/p&gt;
    
    </summary>
    
    <content src="http://houmin.cc/https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2021-01-03_convolutional-neural-network.png" type="image" />
    
    
      <category term="术业专攻" scheme="http://houmin.cc/categories/%E6%9C%AF%E4%B8%9A%E4%B8%93%E6%94%BB/"/>
    
    
      <category term="深度学习" scheme="http://houmin.cc/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="卷积" scheme="http://houmin.cc/tags/%E5%8D%B7%E7%A7%AF/"/>
    
      <category term="神经网络" scheme="http://houmin.cc/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="CNN" scheme="http://houmin.cc/tags/CNN/"/>
    
  </entry>
  
  <entry>
    <title>【深度学习】人工神经网络</title>
    <link href="http://houmin.cc/posts/e1b7513f/"/>
    <id>http://houmin.cc/posts/e1b7513f/</id>
    <published>2020-12-14T12:00:30.000Z</published>
    <updated>2021-01-03T09:18:07.023Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>除了SVM、决策树等算法，人工神经网络是机器学习的另一个重要分支，它是深度学习的基础。人工神经网络是通过模仿生物神经网络系统结构和功能，提出了一种 <strong>非线性统计性模型</strong> ，用于对函数的近似和估计。人工神经网络以其独特的网络结构和处理信息的方法，在自动控制领域、组合优化问题、模式识别、图形处理、自然语言处理等诸多领域，已经取得了辉煌的成绩，本文将介绍其基本模型和核心算法实现。</p><a id="more"></a><h2 id="神经网络概述"><a href="#神经网络概述" class="headerlink" title="神经网络概述"></a>神经网络概述</h2><h3 id="神经元"><a href="#神经元" class="headerlink" title="神经元"></a>神经元</h3><p>神经网络最早的设计思路来自于生物学中的神经元，从结构、实现机理和功能上模拟神经网络系统：</p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-12-31_dl-neuron.png"></p><p>回想下高中生物知识，传统的神经元模型由树突、细胞核、细胞体、突触和神经末梢组成：</p><ul><li>突触前（神经元）细胞的树突或细胞体接受刺激，产生兴奋或抑制。</li><li>动作电位传到神经末梢，导致神经递质释放。</li><li>使突触后（神经元）细胞的树突或细胞体接受刺激。</li></ul><p>对于人工神经网络，神经元的输入 $x_i$ 对应于生物神经元的树突，输入 $x_i$ 向细胞体传播脉冲，相当于输入权值 $w_i$，通过细胞核对输入的数据和权值参数进行加权求和。传播细胞体的脉冲相当于人工神经元的激活函数，最终输出结果 $y$ 作为下一个神经元的输入。</p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-12-31_dl-neuron2.png"></p><p>可以看到人工神经网络最基本的处理单元 —— 神经元的基本组成单位为：</p><ul><li>连接 Connetion：神经元中数据流动的表达方式</li><li>求和节点 Summation Node ：对输入信号和权值的乘积进行求和</li><li>激活函数 Activate Function：一个非线性函数，对输出信号进行控制</li></ul><p>将上述模型进行抽象，得到神经元基本模型：</p><ul><li>$x_1, x_2, …, x_n$ 为输入信号的各个分量</li><li>$w_1, w_2, …, w_n$ 为神经元各个突触的权值</li><li>$b$  为神经元的偏置参数</li><li>$\sum$  为求和节点，$ z = \sum_{i=1}^n w_i * x_i  + b $</li><li>$f$ 为激活函数，一般为非线性函数</li><li>$y$ 为该神经元的输出</li></ul><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-12-31_dp-neuron3.svg"></p><p>该神经元模型的数学表达式为：</p><script type="math/tex; mode=display">y = f (\sum_{i=1}^n w_i * x_i  + b )</script><p>可以看到，神经元模型就是一个基本的函数，本质上做的是数据的映射，$ \mathbf{X} $ 为输入向量，$y$ 为输出变量，神经元对应着 $y = \varphi(\mathbf{X})$ ，而 $\mathbf{W}$ 和 $b$ 则是这个函数的参数。单个神经元如果没有加上激活函数，可以看作是一个线性模型，而 $\mathbf{W}$ 和 $b$ 则是这个线性模型的参数。</p><script type="math/tex; mode=display">y = \mathbf{W}^\mathsf{T} \mathbf{X} + b</script><p>回想下本科的线性几何课程，<strong>线性模型的任何组合仍然是线性模型</strong>。但是对于现实数据而言，很多数据都是<strong>线性不可分</strong>的，需要的是<strong>非线性模型</strong>。另外，对于一个拥有很多特征的复杂数据集进行线性回归是代价很高的，需要高昂的计算代价。因此，我们需要在神经元模型中引入一个 <strong>非线性单元</strong>，也就是这里的 <strong>激活函数</strong>，使得神经元模型能够更好的解决复杂的数据分布问题。</p><h3 id="多层神经网络"><a href="#多层神经网络" class="headerlink" title="多层神经网络"></a>多层神经网络</h3><p>人工神经网络由许多神经元组合而成，神经元组成的信息处理网络具有并行分布结构，因此有了更复杂的人工神经网络。一个多层人工神经网络 ANN 由输入层、隐藏层、输出层组成，第 <code>k-1</code> 层网络神经元的输出是第 <code>k</code> 层神经元的输入。下面是一个简单的两层神经网络，我们将输入层称为第零层：</p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-12-31_dp-back-propagation.svg"></p><p>人工神经网络的输入层与输出层的节点数往往固定，这取决于我们的输入和输出，而隐层数和隐层节点则可以自由指定。人工神经网络的关键不是节点而是连接，每层的神经元与下一层的多个神经元相连接，每条连接线都有独自的权重参数，这些参数往往通过训练得到。</p><p>在这个图中，$w_{ij}$ 表示第 $k-1$ 层的第 $i$ 个节点到的权重第 $k$ 层的第 $j$ 个节点</p><p>根据上面的公式，我们可以容易得出：</p><script type="math/tex; mode=display">o_1 = f(w_{11} * x_1 + w_{21} * x_2 + w_{31} * x_3 + b_1) \\o_2 = f(w_{12} * x_1 + w_{22} * x_2 + w_{32} * x_3 + b_2) \\o_3 = f(w_{13} * x_1 + w_{23} * x_2 + w_{33} * x_3 + b_3) \\o_3 = f(w_{14} * x_1 + w_{24} * x_2 + w_{34} * x_3 + b_4)</script><p>令</p><script type="math/tex; mode=display">\mathbf{X} = \begin{bmatrix}x_1\\ x_2\\ x_3 \end{bmatrix},\mathbf{w_1} = \begin{bmatrix}w_{11}\\ w_{21}\\ w_{31} \end{bmatrix},\mathbf{w_2} = \begin{bmatrix}w_{12}\\ w_{22}\\ w_{32} \end{bmatrix},\mathbf{w_3} = \begin{bmatrix}w_{13}\\ w_{23}\\ w_{33} \end{bmatrix},\mathbf{w_4} = \begin{bmatrix}w_{14}\\ w_{24}\\ w_{34} \end{bmatrix}</script><p>则</p><script type="math/tex; mode=display">o_1 = f(\mathbf{w_1}^\mathsf{T} \mathbf{X} + b_1)\\o_2 = f(\mathbf{w_2}^\mathsf{T} \mathbf{X} + b_2)\\o_3 = f(\mathbf{w_3}^\mathsf{T} \mathbf{X} + b_3)\\o_4 = f(\mathbf{w_4}^\mathsf{T} \mathbf{X} + b_4)\\</script><p>令</p><script type="math/tex; mode=display">\mathbf{o} = \begin{bmatrix} o_1\\ o_2\\ o_3\\ o_4 \end{bmatrix}, \mathbf{W} = \begin{bmatrix} \mathbf{w_1}^\mathsf{T} \\ \mathbf{w_2}^\mathsf{T}\\ \mathbf{w_3}^\mathsf{T}\\ \mathbf{w_4}^\mathsf{T} \end{bmatrix} = \begin{bmatrix}w_{11}, w_{21}, w_{31} \\w_{12}, w_{22}, w_{32}\\w_{13}, w_{23}, w_{33}\\w_{14}, w_{24}, w_{34} \end{bmatrix},\mathbf{B} = \begin{bmatrix}b_1\\ b_2\\ b_3\\ b_4 \end{bmatrix}\\f(\begin{bmatrix} o_1\\ o_2\\ o_3\\ o_4 \end{bmatrix}) = \begin{bmatrix} f(o_1)\\ f(o_2)\\ f(o_3)\\ f(o_4) \end{bmatrix}</script><p>则有，</p><script type="math/tex; mode=display">\mathbf{o} = f ( \mathbf{W} \mathbf{X} + \mathbf{B})</script><p>在这个公式说明神经网络的每一层的作用实际上就是先将输入向量<strong>左乘</strong>一个数组进行线性变换，得到一个新的向量，然后再对这个向量<strong>逐元素</strong>应用一个激活函数，其中每个变量的定义如下：</p><ul><li>$f$ 是激活函数</li><li>$\mathbf{W}$ 是第 $k$ 层的权重矩阵<ul><li>它的每一个行向量对应着第 $k$ 层的每个节点，也就是说如果第 $k$ 层的有 $N$ 个节点，则 $\mathbf{W}$ 共有 $N$ 个行向量</li><li>如果第$k-1$层有 $M$ 个节点，则 $\mathbf{W}$ 的每个行向量的长度为 $M$ ，对应着第$k-1$层$M$ 个节点的求和</li></ul></li><li>$B$ 是第 $k$ 层的偏置向量，其长度与第 $k$ 层的节点数相同</li><li>$\mathbf{X}$ 是第 $k$ 层的输入向量，也正是第 $k-1$ 层的输出向量</li><li>$\mathbf{o}$ 是第 $k$ 层输出向量</li></ul><p>因此，如果我们将上面的简单神经网络增加层数到4层，如下图所示（注意，这里画图有点偷懒，中间应该是全连接网络，为了简单这里没有全部连起来）</p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-12-31_dl-multi-layer-ann.svg"></p><p>则我们可以算出每一层的输出向量如下：</p><script type="math/tex; mode=display">\mathbf{o_1} = f ( \mathbf{W_1} \mathbf{X} + \mathbf{B_1}) \\\mathbf{o_2} = f ( \mathbf{W_2} \mathbf{o_1} + \mathbf{B_2}) \\\mathbf{o_3} = f ( \mathbf{W_3} \mathbf{o_2} + \mathbf{B_3}) \\\mathbf{Y} = f ( \mathbf{W_4} \mathbf{o_3} + \mathbf{B_4}) \\</script><h2 id="训练与预测"><a href="#训练与预测" class="headerlink" title="训练与预测"></a>训练与预测</h2><h3 id="前向传播算法"><a href="#前向传播算法" class="headerlink" title="前向传播算法"></a>前向传播算法</h3><p>OK，假设我们现在根据某个应用场景，构建了一个多层神经网络的模型，并且根据训练数据获得了网络的所有参数（输入层、输出层、隐层的节点数、权重矩阵 $W$ 和偏置向量 $B$）。如果这个模型参数合理的话，那么对于新的输入数据，这个模型能够预测出合理的输出结果。所谓的预测，就是将向量化的数据从神经网络的输入层开始输入，顺着数据流动的方向在网络中计算，直到数据传输到输出层并输出，这也就是 <strong>前向传播算法</strong>。</p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-12-31_dp-forward-propagation.svg"></p><p>假设我们有如下定义：</p><ul><li>$w_{ij}^k$：第 $k$ 层的第 $j$ 个节点对于来自第 $k-1$层的第 $i$ 个节点的权重</li><li>$b_j^k$：第 $k$ 层的第 $j$ 个节点的偏置</li><li>$net_j^k$：第 $k$ 层的第 $j$ 个节点的 <code>net input value</code>，也就是激活函数的输入</li><li>$o_j^k$：第 $k$ 层的第 $j$ 个节点的输出，也就是激活函数的输出</li><li>$r_k$：第 $k$ 层的节点数目</li><li>$M$：神经网络输入向量 $X$ 的大小，即 $r_0 = M$</li><li>$L$：全连接神经网络的层数，最简单的神经元的层数为 $1$</li><li>$N$：神经网络输出向量 $Y$ 的大小，即 $r_L = N$</li></ul><p>则对于第 $k$ 层的第 $j$ 个节点，有</p><script type="math/tex; mode=display">net_j^k = \sum_{i=1}^{r_{k-1}} w_{ij}^{k}o_i^{k-1} + b_j^k</script><p>也就是说，第 $k$ 层的第 $j$ 个节点的净输入为第 $k-1$ 层的所有节点输出值的加权和再加上第 $k$ 层第 $j$ 个节点的偏置。</p><ul><li>当 $k=1$时，第 $k-1=0$ 层的输出向量 $O^0$ 就是输入向量 $X$，此时 $\begin{bmatrix}o_1^0, o_2^0, \dots, o_M^0 \end{bmatrix} = \begin{bmatrix}x_1, x_2, \dots, x_M \end{bmatrix} $</li><li>当 $k = L$时，也即是最后一层的输出向量 $O^L$ 就是输出向量 $Y$，此时 $\begin{bmatrix}o_1^L, o_2^L, \dots, o_N^L \end{bmatrix} = \begin{bmatrix}y_1, y_2, \dots, y_N \end{bmatrix} $</li></ul><p>因此，一旦确定了神经网络的参数，就可以通过上述公式迭代算出神经网络的输出：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward_propagation</span><span class="params">(network_structure, weight, bias)</span>:</span></span><br><span class="line">  <span class="keyword">for</span> j = <span class="number">1.</span>..M</span><br><span class="line">  o[<span class="number">0</span>][j] = x[j]</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> k = <span class="number">1.</span>..L</span><br><span class="line">    <span class="keyword">for</span> j = <span class="number">1.</span>..r[k]</span><br><span class="line">      net[k][j] = bias[k][j]</span><br><span class="line">      <span class="keyword">for</span> i = <span class="number">1.</span>..r[k<span class="number">-1</span>]</span><br><span class="line">        net[k][j] += weight[k][i][j] * o[k<span class="number">-1</span>][i] </span><br><span class="line">      o[k][j] = f(net[k][j])</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">for</span> j = <span class="number">1.</span>..N</span><br><span class="line">    y[j] = o[L][j]</span><br></pre></td></tr></table></figure><h3 id="梯度下降算法"><a href="#梯度下降算法" class="headerlink" title="梯度下降算法"></a>梯度下降算法</h3><p>如上所说，一旦确定好神经网络模型中的权值矩阵 $W$ 和偏置向量 $B$ ，就可以基于模型进行预测了。现在的问题是，如何得到这些参数的值呢？这就要通过原始数据<strong>训练</strong>得到了。神经网络的训练实际上是通过算法不算修改权值矩阵$W$ 和偏置向量 $B$ ，使其尽可能与真实模型逼近，以使得整个神经网络的预测效果最佳。具体做法如下：</p><ol><li>给所有权值矩阵$W$ 和偏置向量 $B$ 赋予随机值</li><li>利用前向传播算法基于随机的权值矩阵$W$ 和偏置向量 $B$ 来得到训练样本的预测值 $\hat{y}$</li><li>计算损失函数 $loss = (\hat{y} - y)^2$，优化目标是改变神经网络中的参数，使得损失函数的值最小</li></ol><p>因此，对于神经网络的优化问题就转换为对参数的优化，减少损失直至损失收敛，当损失函数收敛到一定程度时就可以结束训练，保存训练后神经网络的参数。</p><p>在微积分中，对多元函数的参数求偏导，求得参数的偏导数以向量的形式表达就是 <strong>梯度</strong>。如下图所示，对于损失函数 $loss$ 的参数 $\theta$ 求梯度即是 $\frac{\partial{loss}}{\partial{\theta}}$ 。在数学上，梯度越大，则函数的变化越大。也就是说，沿着梯度向量的方向函数增加最快，易于找到函数的最大值；沿着与梯度向量相反的方向函数减少最快，易于找到函数的最小值。</p><p>对于损失函数来说，为了找到其最小值，需要沿着与梯度向量相反的方向 $-\frac{\partial{loss}}{\partial{\theta}}$ 更新参数 $\theta$，这样可以使得梯度减少最快，直至损失收敛至最小值。这即是 <strong>梯度下降算法 （Gradient Descent）</strong>，其基本公式为：</p><script type="math/tex; mode=display">\theta = \theta - \alpha \frac{\partial{loss}}{\partial{\theta}}</script><p>其中，$\alpha \in \mathbf{R}$ 为学习率，用于控制梯度下降的幅度。我们可以将损失函数看成是参数 $\theta$ 的函数，优化的目的就是找到参数 $\theta_x$ 使得损失函数最小。具体的做法就是，每次计算参数 $\theta_i$ 在当前位置时函数的梯度，然后让参数 $\theta_i$ 顺着梯度的反方向前进一段距离，不断重复该过程，直到梯度趋近于零的时候，算法认为找到的损失函数的最小值并停止计算。此时的参数即是目标 $\theta_x$ 神经网络的参数。</p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2021-01-02_gradient-descent.png"></p><p>梯度下降的算法变种有很多，下面对常用的梯度下降算法进行介绍。</p><h4 id="批量梯度下降算法-BGD"><a href="#批量梯度下降算法-BGD" class="headerlink" title="批量梯度下降算法 BGD"></a>批量梯度下降算法 BGD</h4><p>批量梯度下降算法 <strong>Batch Gradient Descent</strong> 中，所有样本都参与参数 $w$ 的更新。假设有 $m$ 个样本，$m$ 个样本都参与调整参数 $w$，因此得到一个标准的梯度。</p><ul><li>优点：易于得到全局最优解，总体迭代次数不多</li><li>缺点：当样本数目很多时，训练时间过长，收敛速度变慢</li></ul><h4 id="随机梯度下降算法-SGD"><a href="#随机梯度下降算法-SGD" class="headerlink" title="随机梯度下降算法 SGD"></a>随机梯度下降算法 SGD</h4><p>随机梯度下降算法 <strong>Stochastic Gradient Descent</strong> 中，梯度是从 $m$ 个样本中随机抽取 $n$ 个样本进行求解的</p><ul><li>优点：训练速度快，每次迭代计算量少</li><li>缺点：准确度下降，得到的不一定是全局最优，总体迭代次数比较多</li></ul><h4 id="小批量随机梯度下降算法-Min-batch-SGD"><a href="#小批量随机梯度下降算法-Min-batch-SGD" class="headerlink" title="小批量随机梯度下降算法 Min-batch SGD"></a>小批量随机梯度下降算法 Min-batch SGD</h4><p>小批量随机梯度下降算法是对BGD和SGD的折衷方法：每次随机从 $m$ 个样本中抽取 $k$ 进行迭代求梯度，每一次迭代的抽取方式都是随机的，因此部分样本会重复。这样做的好处是，计算梯度时让数据和数据之间产生关联，避免数据最终只能收敛到局部最优解。</p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2021-01-02_sgd-bgd.jpg"></p><h3 id="反向传播算法"><a href="#反向传播算法" class="headerlink" title="反向传播算法"></a>反向传播算法</h3><p>反向传播算法，全称是 <strong>back propagation of errors</strong>，本质上就是利用梯度下降算法来计算神经网络的参数，它从输出层开始向输入层的方向一层一层往前算起，计算出每一层误差的梯度，从而更新神经网络的参数，下面将从数学上推导反向传播算法的具体实现。</p><p>假设我们有以下定义：</p><ul><li>$w_{ij}^k$：第 $k$ 层的第 $j$ 个节点对于来自第 $k-1$层的第 $i$ 个节点的权重</li><li>$b_j^k$：第 $k$ 层的第 $j$ 个节点的偏置</li><li>$net_j^k$：第 $k$ 层的第 $j$ 个节点的 <code>net input value</code>，也就是激活函数的输入</li><li>$o_j^k$：第 $k$ 层的第 $j$ 个节点的输出，也就是激活函数的输出</li><li>$r_k$：第 $k$ 层的节点数目</li><li>$M$：神经网络输入向量 $X$ 的大小，即 $r_0 = M$</li><li>$L$：全连接神经网络的层数，最简单的神经元的层数为 $1$</li><li>$N$：神经网络输出向量 $Y$ 的大小，即 $r_L = N$</li><li>前馈神经网络，其中 $\theta$ 是网络的参数，对应的就是权值 $w_{ij}^k$ 和偏置 $b_j^k$</li><li>$E(\theta)$：神经网络的预测值与实际值的误差函数</li><li>$f$：激活函数</li><li>$f_o$：输出层的激活函数</li></ul><p>根据梯度下降算法，我们的目标是找到最佳的网络参数，使得误差函数最小：</p><script type="math/tex; mode=display">\theta^{t+1} = \theta^t - \alpha \frac{\partial E(\theta)}{\partial \theta}</script><p>其中 $\theta^t$ 是神经网络在计算梯度的第 $t$ 次迭代中的参数。</p><p>根据最小均方误差，我们可以得到</p><script type="math/tex; mode=display">E(\theta) = \frac{1}{2N} \sum_{i=1}^N (\hat{y_i} - y_i)^2</script><h4 id="计算梯度"><a href="#计算梯度" class="headerlink" title="计算梯度"></a>计算梯度</h4><p>计算梯度</p><script type="math/tex; mode=display">\frac{\partial E(\theta)}{\partial w_{ij}^k} = \frac{1}{N} \sum_{d=1}^N \frac{\partial}{\partial w_{ij}^k} ( \frac{1}{2} (\hat{y_d} - y_d)^2 ) = \frac{1}{N} \sum_{d=1}^N \frac{\partial E_d}{\partial w_{ij}^k}</script><p>其中，</p><script type="math/tex; mode=display">E = \frac{1}{2} (\hat{y} - y)^2</script><p>这里为了表达方便，省略了 $E_d$, $\hat{y_d}$, $y_d$ 中的下标 $d$</p><p>也就是说，总的误差函数梯度是输出层每一个节点误差梯度的算术平均值，接下来我们看如何计算 $\frac{\partial E}{\partial w_{ij}^k}$</p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-12-31_dp-forward-propagation.svg"></p><p>根据链式法则，</p><script type="math/tex; mode=display">\frac{\partial E}{\partial w_{ij}^k} = \frac{\partial E}{\partial net_{j}^k} \frac{\partial net_{j}^k}{\partial w_{ij}^k}</script><p>我们将右式第一项记作误差，也就是第 $k$ 层第 $j$ 个节点的误差</p><script type="math/tex; mode=display">\delta_j^k = \frac{\partial E}{\partial net_{j}^k}</script><p>对于右式第二项，我们先回顾前向传播算法有</p><script type="math/tex; mode=display">net_j^k = \sum_{i=1}^{r_{k-1}} w_{ij}^{k}o_i^{k-1} + b_j^k \\</script><p>为了简化数学表达，我们可以把第 $k$ 层第 $j$ 个节点的偏置视作来自第$k-1$ 层的节点0的输入，其中$o_0^{k-1} = 1$，则</p><script type="math/tex; mode=display">b_j^k = w_{0j}^k =  w_{0j}^k * o_0^{k-1}</script><p> 故</p><script type="math/tex; mode=display">net_j^k = \sum_{i=1}^{r_{k-1}} w_{ij}^{k}o_i^{k-1} + b_j^k = \sum_{i=0}^{r_{k-1}} w_{ij}^{k}o_i^{k-1}</script><p>所以计算梯度简化如下</p><script type="math/tex; mode=display">\frac{\partial net_{j}^k}{\partial w_{ij}^k} = \frac{\partial}{\partial w_{ij}^k} (\sum_{l=0}^{r_{k-1}} w_{lj}^{k}o_l^{k-1}) = \sum_{l=0}^{r_{k-1}} \frac{\partial}{\partial w_{ij}^k} (w_{lj}^{k}o_l^{k-1}) = 0 + \dots + \frac{\partial}{\partial w_{ij}^k} (w_{ij}^{k}o_i^{k-1}) + \dots + 0 = o_i^{k-1}</script><p>综上，</p><script type="math/tex; mode=display">\frac{\partial E}{\partial w_{ij}^k} = \delta_j^k o_i^{k-1}</script><p>得到梯度的表达式之后，可以根据是输出层还是隐藏层具体计算。</p><h4 id="输出层"><a href="#输出层" class="headerlink" title="输出层"></a>输出层</h4><p>如向所述，我们将通过梯度下降的方法来迭代计算神经网络的参数，首先看输出层，我们需要计算出 $\delta_j^L$。</p><script type="math/tex; mode=display">\delta_j^L = \frac{\partial E}{\partial net_{j}^L}</script><p>而</p><script type="math/tex; mode=display">E = \frac{1}{2} (\hat{y} - y) ^ 2 = \frac{1}{2} (f_o(net_j) - y)^2 \\</script><p>则有</p><script type="math/tex; mode=display">\delta_j^L = \frac{\partial E}{\partial net_{j}^L} = (f_o(net_j) - y)f_o^\prime(net_j) = (\hat{y} - y)f_o^\prime(net_j)</script><p>于是得到梯度的计算公式：</p><script type="math/tex; mode=display">\frac{\partial E}{\partial w_{ij}^L} = \delta_j^L o_i^{L-1} = (\hat{y} - y)f_o^\prime(net_j) o_i^{L-1}</script><h4 id="隐藏层"><a href="#隐藏层" class="headerlink" title="隐藏层"></a>隐藏层</h4><p>对于隐藏层，我们也需要算出第 $k$ 层第 $j$ 个节点的误差 $\delta_j^k$ ，它将通过影响第 $k+1$ 层所有节点的净输入 $net_i^{k+1}$来影响最终的误差$E$。</p><p>因此，我们通过链式法则将 $E$ 先对第 $k+1$ 层所有节点的净输入 $net_i^{k+1}$ 求导，然后再将 $net_i^{k+1}$ 对 $net_i^{k}$  求导：</p><script type="math/tex; mode=display">\delta_j^k = \frac{\partial E}{\partial net_j^k} = \sum_{l=1}^{r_{k+1}}  \frac{\partial E}{\partial net_l^{k+1}}  \frac{\partial net_l^{k+1}}{\partial net_j^k}</script><p>注意这里的 $l$ 范围是 1 到 $r^{k+1}$，$l$ 没有从$0$开始是因为，第 $k+1$ 层的净输入 $net_0^{k+1}$ 实际上为第 $k$ 层节点$0$的输出 $o_{0}^{k}$ 乘以权值 $ w_{0j}^{k+1} $ 是固定的，它不取决于第 $k$ 层的输出。</p><p>我们知道，上式的第一个偏微分已经在第 $k+1$ 层计算误差得到，</p><script type="math/tex; mode=display">\frac{\partial E}{\partial net_l^{k+1}}  =  \delta_l^{k+1}</script><p>而对于第二个偏微分，我们将 $net_l^{k+1}$ 展开，</p><script type="math/tex; mode=display">net_l^{k+1} = \sum_{j=0}^{r_{k}} w_{jl}^{k+1}o_j^{k} = \sum_{j=0}^{r_{k}} w_{jl}^{k+1}f(net_j^k)</script><p>这里的 $f(x)$ 是隐藏层的激活函数，所以可以得到第二个偏微分的公式，</p><script type="math/tex; mode=display">\frac{\partial net_l^{k+1}}{\partial net_j^k} = \frac{\partial}{\partial net_j^k}\sum_{j=0}^{r_{k}} w_{jl}^{k+1}f(net_j^k) = w_{jl}^{k+1}f^\prime(net_j^k)</script><p>故我们得到了反向传播公式，</p><script type="math/tex; mode=display">\delta_j^k = \frac{\partial E}{\partial net_j^k} = \sum_{l=1}^{r_{k+1}}  \frac{\partial E}{\partial net_l^{k+1}}  \frac{\partial net_l^{k+1}}{\partial net_j^k} = f^\prime(net_j^k)\sum_{l=1}^{r_{k+1}} \delta_l^{k+1} w_{jl}^{k+1}</script><p>因此，可以从 $\delta_l^{k+1}$ 迭代计算出 $\delta_j^k$ ，换句话说，第 $k$ 层的误差 $\delta_j^k$ 依赖于第 $k+1$ 层的误差 $\delta_l^{k+1}$计算而来。这就是反向传播名称的来源，误差沿着神经网络反向流动，从最后一层流向第一层。一旦计算出了输出层的误差，我们就可以沿着神经网络迭代算出隐藏层的误差，通过乘上一个系数 $f^\prime(net_j^k)$。</p><p>计算出误差之后，我们就可以得到梯度的公式，</p><script type="math/tex; mode=display">\frac{\partial E}{\partial w_{ij}^k} = \delta_j^L o_i^{k-1} = g^\prime(net_j^k)o_i^{k-1}\sum_{l=1}^{r_{k+1}} \delta_l^{k+1} w_{jl}^{k+1}</script><p>注意到在这个公式中，我们需要知道 $net_j^k$ 和 $o_i^{k-1}$，这些需要在前向传播的时候计算并保存。也就是说，每一次迭代中，</p><ul><li>首先进行前向传播的计算，根据设定的模型参数，从输入层到输出层，同时保存每一层的 $net_j^k$ 和 $o_j^k$</li><li>然后进行反向传播的计算，从输出层开始，以输出层的误差作为输入，计算每一层每个节点中误差的梯度</li><li>最后我们通过算出的梯度更新参数的值，然后进入下一次迭代</li></ul><h4 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h4><p>最后在这里梳理下上面推导的公式和整个算法的流程。</p><p>对于梯度计算：</p><script type="math/tex; mode=display">\begin{equation}\frac{\partial E}{\partial w_{ij}^k} = \delta_j^k o_i^{k-1}\end{equation}</script><p>对于输出层的误差计算：</p><script type="math/tex; mode=display">\begin{equation}\delta_j^L = f_o^\prime(net_j) (\hat{y} - y)\end{equation}</script><p>对于隐藏层的误差计算：</p><script type="math/tex; mode=display">\begin{equation}\delta_j^k = g_0^\prime(net_{j}^k) \sum_{l=1}^{r^{k+1}} w_{jl}^{k+1} \delta_l^{k+1}\end{equation}</script><p>将所有的误差结合起来：</p><script type="math/tex; mode=display">\begin{equation}\frac{\partial E(\theta)}{\partial w_{ij}^k} = \frac{1}{N} \sum_{d=1}^N \frac{\partial}{\partial w_{ij}^k} ( \frac{1}{2} (\hat{y_d} - y_d)^2 ) = \frac{1}{N} \sum_{d=1}^N \frac{\partial E_d}{\partial w_{ij}^k}\end{equation}</script><p>更新参数：</p><script type="math/tex; mode=display">\begin{equation}\Delta w_{ij}^k = -\alpha \frac{\partial E(\theta)}{\partial w_{ij}^k}\end{equation}</script><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2021-01-02_back-propagation.svg"></p><p>整体流程如下：</p><ol><li><p>随机初始化权值参数 $w_{ij}^k$</p></li><li><p><strong>前向传播计算</strong>，从输入层到输出层，对于第 $k$ 层的第 $j$ 个节点，基于 $w_{ij}^k$ 计算出 $net_j^k$，$o_j^k$ 和 $\hat{y_d}$</p></li><li><p><strong>反向传播计算</strong>，从输出层到输入层，对于第 $k$ 层的第 $j$ 个节点，通过公式2和公式3计算出 $\delta_j^k$，</p><p>然后通过公式1计算出梯度 $\frac{\partial E}{\partial w_{ij}^k}$</p></li><li><p><strong>将所有节点的误差结合起来</strong>，通过公式4将所有的输出节点的误差结合起来</p></li><li><p><strong>更新权值参数</strong>，根据公式5更新权值参数，然后进入第2步进行下一轮迭代计算，直到误差收敛</p></li></ol><h2 id="调参与正则化优化"><a href="#调参与正则化优化" class="headerlink" title="调参与正则化优化"></a>调参与正则化优化</h2><p>上一小节中，我们介绍了神经网络的训练与预测：在明确了神经网络的模型后，我们就可以通过定义合理的损失函数，模型根据反向传播算法和随机梯度下降算法，自动地修正网络模型的参数（$W$ 和 $b$ ），并对训练数据的特征进行学习。</p><p>但是，这里似乎还有很多问题没有解决：</p><ul><li>神经网络应该有多少层</li><li>每一层应该有多少隐藏单元</li><li>学习速率应该是多少</li><li>各层应该采用哪些激活函数</li><li>应该选用哪种损失函数</li><li>梯度下降算法的参数应该如何选择</li><li>……</li></ul><p>所有的这些超参数不可能在一开始就预测出来，实际上通常的情况是，首先有个初步想法，比如构建一个含有特定层数、隐藏单元等等的神经网络，然后在运行和测试中得到该神经网络的运行结果，并不断迭代更新自己的方案。</p><h3 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h3><h4 id="线性函数"><a href="#线性函数" class="headerlink" title="线性函数"></a>线性函数</h4><p>线性函数是最基本的激活函数，其因变量与自变量有直接的比例关系，因此线性变换类似于线性回归。</p><script type="math/tex; mode=display">f(x) = ax + b</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">linear</span><span class="params">(x, a, b)</span>:</span></span><br><span class="line">  <span class="keyword">return</span> a * x + b</span><br></pre></td></tr></table></figure><h4 id="Sigmoid-函数"><a href="#Sigmoid-函数" class="headerlink" title="Sigmoid 函数"></a>Sigmoid 函数</h4><p><code>Sigmoid</code> 函数是一种在不删除数据的情况下，减少数据的极值或异常值的函数。</p><script type="math/tex; mode=display">s(x) = \frac{1}{1 + e^{-ax}}</script><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-12-21_sigmoid.png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(x, w = <span class="number">1</span>)</span>:</span></span><br><span class="line">  <span class="keyword">return</span> <span class="number">1</span> / (<span class="number">1</span> + np.sum(np.exp(-wx))</span><br></pre></td></tr></table></figure><h4 id="双曲正切函数"><a href="#双曲正切函数" class="headerlink" title="双曲正切函数"></a>双曲正切函数</h4><p>双曲正切函数 <code>tanh</code> 与 <code>sigmoid</code> 函数蕾丝，不同的是，<code>tanh</code> 的归一范围是 -1 到 1，而不是 0 到 1，因此 tanh 的优点是可以更容易地处理附属。</p><script type="math/tex; mode=display">tanh(x) = \frac{sinh(x)}{cosh(x)} = \frac{e^x - e^{-x}}{e^x + e^{-x}}</script><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-12-21_tanh.png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tanh</span><span class="params">(x)</span>:</span></span><br><span class="line">  <span class="keyword">return</span> np.tanh(h)</span><br></pre></td></tr></table></figure><h4 id="ReLU-函数"><a href="#ReLU-函数" class="headerlink" title="ReLU 函数"></a>ReLU 函数</h4><p><code>ReLU</code> 函数满足仿生学中的稀疏性，只有当输入值高于一定数目时才激活该神经元节点。当输入值低于0时进行限制，当输入值上升到某一阈值以上时，函数中的自变量与因变量成线性关系。</p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-12-21_relu.png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">relu</span><span class="params">(x)</span>:</span></span><br><span class="line">  <span class="keyword">return</span> x <span class="keyword">if</span> x &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="number">0</span></span><br></pre></td></tr></table></figure><h4 id="Softmax-函数"><a href="#Softmax-函数" class="headerlink" title="Softmax 函数"></a>Softmax 函数</h4><p><code>Softmax</code> 函数的本质是将一个 K 维的任意实数向量，映射成另一个 K 维的实数向量，其中向量中的每一个元素取值都介于（0，1）范围内。</p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-12-21_softmax.jpg"></p><script type="math/tex; mode=display">softmax(x_j) = \frac{e^{x_j}}{\sum_{k=1}^K e^{x_k}} j \in [1, K]</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">softmax</span><span class="params">(x)</span>:</span></span><br><span class="line">  <span class="keyword">return</span> np.exp(x) / np.sum(np.exp(x))</span><br></pre></td></tr></table></figure><h4 id="激活函数的选择"><a href="#激活函数的选择" class="headerlink" title="激活函数的选择"></a>激活函数的选择</h4><h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><p>在神经网络中，损失函数用来评价网络模型输出的预测值 $\hat{\vec{Y}} = f(\vec{X})$ 与真实值 $\vec{Y}$ 之间的差异。这里使用 $L(\vec{Y}, \hat{\vec{Y}})$ 来表示损失函数，它是一个非负值函数。损失值越小，网络模型的性能就越好，所以优化算法目的就是让损失函数尽可能的小。</p><h4 id="损失函数的定义"><a href="#损失函数的定义" class="headerlink" title="损失函数的定义"></a>损失函数的定义</h4><p>假设网络模型中有 N 个样本，样本的输入和输出向量为 $(\vec{X}, \vec{Y}) = (x_i, y_i), i \in [1, N]$ ，那么总损失函数  $L(\vec{Y}, \hat{\vec{Y}})$ 为每一个输出预测值与真实值的误差之和。</p><script type="math/tex; mode=display">L(\vec{Y}, \hat{\vec{Y}}) = \sum_{i=0}^N l(y, \hat{y_i})</script><p>值得注意的是，机器学习问题主要分为回归和分类问题，对分类模型和回归模型进行评估时会使用不同的损失函数，下面将分别对回归模型和分类模型的损失函数进行介绍。</p><h4 id="回归损失函数"><a href="#回归损失函数" class="headerlink" title="回归损失函数"></a>回归损失函数</h4><h5 id="均方误差损失函数，MSE"><a href="#均方误差损失函数，MSE" class="headerlink" title="均方误差损失函数，MSE"></a>均方误差损失函数，MSE</h5><h5 id="平均绝对误差损失函数，MAE"><a href="#平均绝对误差损失函数，MAE" class="headerlink" title="平均绝对误差损失函数，MAE"></a>平均绝对误差损失函数，MAE</h5><h5 id="均方误差对数损失函数，MSLE"><a href="#均方误差对数损失函数，MSLE" class="headerlink" title="均方误差对数损失函数，MSLE"></a>均方误差对数损失函数，MSLE</h5><h4 id="分类损失函数"><a href="#分类损失函数" class="headerlink" title="分类损失函数"></a>分类损失函数</h4><h5 id="Logistic-损失函数"><a href="#Logistic-损失函数" class="headerlink" title="Logistic 损失函数"></a>Logistic 损失函数</h5><h5 id="负对数似然损失函数"><a href="#负对数似然损失函数" class="headerlink" title="负对数似然损失函数"></a>负对数似然损失函数</h5><h5 id="交叉熵损失函数"><a href="#交叉熵损失函数" class="headerlink" title="交叉熵损失函数"></a>交叉熵损失函数</h5><h5 id="Hinge损失函数"><a href="#Hinge损失函数" class="headerlink" title="Hinge损失函数"></a>Hinge损失函数</h5><h5 id="指数损失函数"><a href="#指数损失函数" class="headerlink" title="指数损失函数"></a>指数损失函数</h5><h4 id="常用的损失函数"><a href="#常用的损失函数" class="headerlink" title="常用的损失函数"></a>常用的损失函数</h4><h3 id="超参数"><a href="#超参数" class="headerlink" title="超参数"></a>超参数</h3><h4 id="学习率"><a href="#学习率" class="headerlink" title="学习率"></a>学习率</h4><h4 id="动量"><a href="#动量" class="headerlink" title="动量"></a>动量</h4><h3 id="数据集准备"><a href="#数据集准备" class="headerlink" title="数据集准备"></a>数据集准备</h3><h3 id="数据集扩展"><a href="#数据集扩展" class="headerlink" title="数据集扩展"></a>数据集扩展</h3><h3 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h3><h4 id="Zero-Centralization"><a href="#Zero-Centralization" class="headerlink" title="Zero Centralization"></a>Zero Centralization</h4><h4 id="Normalization"><a href="#Normalization" class="headerlink" title="Normalization"></a>Normalization</h4><h4 id="Principal-Component-Analysis-PCA"><a href="#Principal-Component-Analysis-PCA" class="headerlink" title="Principal Component Analysis, PCA"></a>Principal Component Analysis, PCA</h4><h4 id="Whitening"><a href="#Whitening" class="headerlink" title="Whitening"></a>Whitening</h4><h4 id="网络初始化"><a href="#网络初始化" class="headerlink" title="网络初始化"></a>网络初始化</h4><h3 id="网络过度拟合"><a href="#网络过度拟合" class="headerlink" title="网络过度拟合"></a>网络过度拟合</h3><h3 id="正则化方法"><a href="#正则化方法" class="headerlink" title="正则化方法"></a>正则化方法</h3><p>正则化的最大作用是防止过度拟合，提高网络模型的泛化能力，具体实现方法是在损失函数中增加惩罚因子。</p><h4 id="L2正则化"><a href="#L2正则化" class="headerlink" title="L2正则化"></a>L2正则化</h4><h4 id="L1正则化"><a href="#L1正则化" class="headerlink" title="L1正则化"></a>L1正则化</h4><h4 id="最大约束范式"><a href="#最大约束范式" class="headerlink" title="最大约束范式"></a>最大约束范式</h4><h4 id="Dropout-层"><a href="#Dropout-层" class="headerlink" title="Dropout 层"></a>Dropout 层</h4><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://brilliant.org/wiki/backpropagation" target="_blank" rel="external nofollow noopener noreferrer">Back Propagation Explained</a></li><li><a href="https://en.wikipedia.org/wiki/Backpropagation" target="_blank" rel="external nofollow noopener noreferrer">WikiPedia: Back Propagation</a></li><li><a href="http://www.ai-start.com/dl2017/" target="_blank" rel="external nofollow noopener noreferrer">深度学习笔记</a></li><li><a href="https://nndl.github.io/" target="_blank" rel="external nofollow noopener noreferrer">https://nndl.github.io/</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;除了SVM、决策树等算法，人工神经网络是机器学习的另一个重要分支，它是深度学习的基础。人工神经网络是通过模仿生物神经网络系统结构和功能，提出了一种 &lt;strong&gt;非线性统计性模型&lt;/strong&gt; ，用于对函数的近似和估计。人工神经网络以其独特的网络结构和处理信息的方法，在自动控制领域、组合优化问题、模式识别、图形处理、自然语言处理等诸多领域，已经取得了辉煌的成绩，本文将介绍其基本模型和核心算法实现。&lt;/p&gt;
    
    </summary>
    
    <content src="http://houmin.cc/https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-12-31_dp-forward-propagation.svg" type="image" />
    
    
      <category term="术业专攻" scheme="http://houmin.cc/categories/%E6%9C%AF%E4%B8%9A%E4%B8%93%E6%94%BB/"/>
    
    
      <category term="深度学习" scheme="http://houmin.cc/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="神经网络" scheme="http://houmin.cc/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="反向传播" scheme="http://houmin.cc/tags/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD/"/>
    
      <category term="梯度下降" scheme="http://houmin.cc/tags/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D/"/>
    
      <category term="前向传播" scheme="http://houmin.cc/tags/%E5%89%8D%E5%90%91%E4%BC%A0%E6%92%AD/"/>
    
  </entry>
  
  <entry>
    <title>十字路口</title>
    <link href="http://houmin.cc/posts/64c2f65e/"/>
    <id>http://houmin.cc/posts/64c2f65e/</id>
    <published>2020-12-12T11:23:16.000Z</published>
    <updated>2020-12-13T11:31:32.452Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>改变的路总是很难走，尽管有挫折，但是仍要努力向前。这里是2020年「朝花夕拾」第二十八期 <code>十字路口</code>，这应该是 2020 年 「朝花夕拾」倒数第二期了。就在今天，北京又迎来了小雪，虽然只有不到两个小时，仍然给人带来些许欣喜。十字路口，尽管前面存在着各种不确定，唯一确定的是你希望找到一个更加自洽的自我。</p>    <div id="aplayer-gJEBtkCn" class="aplayer aplayer-tag-marker meting-tag-marker" data-id="346836" data-server="netease" data-type="song" data-mode="circulation" data-autoplay="false" data-mutex="true" data-listmaxheight="340px" data-preload="auto" data-theme="#555"></div><a id="more"></a><h2 id="记录"><a href="#记录" class="headerlink" title="记录"></a>记录</h2><p>很久没有出门啦，说好的二十四节气好久没有进展，北京大冬天的真的就想一个人呆在家里。好啦，继续看数据吧：</p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-12-12_rescue-time.png"></p><p>这周感觉工作效率一般般，因为没有制定一周规划，整个星期都显得目标不明确。现在越工作越感觉自己知道的东西太少了，在专业上还有很多很多需要去学习和努力的地方。</p><p>接下来是 <code>Forest</code> 和 <code>Running</code>，这周跑步很不在状态，虽然也跑了三次，但是还是没有找到跑步的状态：</p><div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img alt="Forest - Nov 29 ~ Dec 05, 2020" data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-12-12_forest.jpg"></div><div class="group-picture-column" style="width: 50%;"><img alt="Running - Nov 29 ~ Dec 05, 2020" data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-12-12_running.jpg"></div></div></div></div><p>下面是睡眠数据总结，可以看到上周的周三晚上过了一点半才睡觉，第二天整天都昏昏沉沉的，导致当天都没有跑步。回忆了一下，那天是看《褚时健传》看的兴起，一下子就看到了很晚，这个太要不得了，下周要避免。另外一个就是，周五晚上普遍睡的比较晚，周六早上也起的很晚，比如这周到11点才从床上爬起来，这个太难受了。</p><div id="echarts1993" style="width: 100%;height: 600px;margin: 0 auto"></div><script type="text/javascript" src="https://cdn.bootcss.com/echarts/4.2.0-rc.2/echarts.min.js"></script><script type="text/javascript" src="http://gallery.echartsjs.com/dep/echarts/map/js/china.js"></script><script type="text/javascript">  // 基于准备好的dom，初始化echarts实例  var myChart = echarts.init(document.getElementById('echarts1993'));  // 指定图表的配置项和数据  var dateTime = ['2020-11-29', '2020-11-30', '2020-12-01', '2020-12-02', '2020-12-03', '2020-12-04', '2020-12-05', '2020-12-06', '2020-12-07', '2020-12-08', '2020-12-09', '2020-12-10', '2020-12-11', '2020-12-12', '2020-12-13'];var sleepTime = [-0.95, -0.18, 4.03, -0.55, 0.58, 0.38, 1.13, -0.08, 1.37, -0.08, 1.7, -0.38, 0.57, 1.05, -0.93];var awakeTime = [7.8, 8.67, 7.72, 7.83, 6.82, 4.85, 9.28, 7.38, 7.23, 4.7, 8.2, 4.95, 8.17, 11.45, 6.7];var awakeTimeBar = [];for (let i = 0; i < sleepTime.length; ++i) {    var awakeTimeValue = awakeTime[i];    if (sleepTime[i] > 0) {        awakeTimeValue = awakeTime[i] - sleepTime[i];    }    awakeTimeBar.push(awakeTimeValue);}option = {    title: {        text: '睡眠监控'     },    tooltip: {        trigger: 'axis',        formatter: function(params) {            function getHourMinute(timeValue) {                if (timeValue < 0) timeValue = 24 + timeValue;                var m = Math.floor((timeValue % 1) * 60);                m = m.toString().padStart(2, '0');                var h = Math.floor(timeValue);                return {                    hour: h,                    minute: m                }            }            var sleepValue = params[0].data;            var awakeValue = params[1].data;            var sleepTime = getHourMinute(sleepValue);            var awakeTime = getHourMinute(awakeValue);            var totalTime = getHourMinute(awakeValue - sleepValue);            return params[0].name + '<br />'                + params[0].seriesName + ": " + sleepTime.hour + ":" + sleepTime.minute + '<br />'                + params[1].seriesName + ": " + awakeTime.hour + ":" + awakeTime.minute + '<br />'                +  "睡眠时长: " + totalTime.hour + ":" + totalTime.minute;        }    },    toolbox: {        feature: {            dataView: {show: true, readOnly: false},            restore: {show: true},            saveAsImage: {show: true}        }    },    legend: {        data: ['入睡时间', '起床时间', '睡眠时间']    },    xAxis: [        {            type: 'category',            data: dateTime,            axisPointer: {                type: 'shadow'            }        }    ],    yAxis: [        {            type: 'value',            axisLine: {                show: false            },            name: '时间',            axisLabel: {                formatter: function (h) {                    h = Math.floor(h);                    if (h < 0) {                        return h + 24 + ':00';                    } else {                        return h + ':00';                    }                 },                 margin: 20            }        }    ],    series: [        {            name: '入睡时间',            type: 'line',            data: sleepTime        },        {            name: '起床时间',            type: 'line',            data: awakeTime        },        {            type: 'bar',            stack: '总量',            data: sleepTime,            itemStyle: {                normal: {                    color: function(params) {                        if (params.data > 0) return 'rgba(0,0,0,0)';                        else return '#2F4554'                    }                }            }        },        {            type: 'bar',            stack: '总量',            data: awakeTimeBar,            itemStyle: {                normal: {                    color: function(params) {                       return '#2F4554'                    }                }            }        }    ]};  // 使用刚指定的配置项和数据显示图表。  myChart.setOption(option);</script><h2 id="世界"><a href="#世界" class="headerlink" title="世界"></a>世界</h2><h2 id="回归"><a href="#回归" class="headerlink" title="回归"></a>回归</h2>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;改变的路总是很难走，尽管有挫折，但是仍要努力向前。这里是2020年「朝花夕拾」第二十八期 &lt;code&gt;十字路口&lt;/code&gt;，这应该是 2020 年 「朝花夕拾」倒数第二期了。就在今天，北京又迎来了小雪，虽然只有不到两个小时，仍然给人带来些许欣喜。十字路口，尽管前面存在着各种不确定，唯一确定的是你希望找到一个更加自洽的自我。&lt;/p&gt;

    &lt;div id=&quot;aplayer-gJEBtkCn&quot; class=&quot;aplayer aplayer-tag-marker meting-tag-marker&quot; data-id=&quot;346836&quot; data-server=&quot;netease&quot; data-type=&quot;song&quot; data-mode=&quot;circulation&quot; data-autoplay=&quot;false&quot; data-mutex=&quot;true&quot; data-listmaxheight=&quot;340px&quot; data-preload=&quot;auto&quot; data-theme=&quot;#555&quot;&gt;&lt;/div&gt;
    
    </summary>
    
    <content src="http://houmin.cc/https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-12-13_cross.png" type="image" />
    
    
      <category term="朝花夕拾" scheme="http://houmin.cc/categories/%E6%9C%9D%E8%8A%B1%E5%A4%95%E6%8B%BE/"/>
    
    
      <category term="十字路口" scheme="http://houmin.cc/tags/%E5%8D%81%E5%AD%97%E8%B7%AF%E5%8F%A3/"/>
    
  </entry>
  
  <entry>
    <title>远离他们</title>
    <link href="http://houmin.cc/posts/36fc760d/"/>
    <id>http://houmin.cc/posts/36fc760d/</id>
    <published>2020-12-05T11:23:16.000Z</published>
    <updated>2020-12-13T10:38:03.322Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>像燃烧的火球在天边下坠，这是今天旁晚的晚霞，从没拍到过这样的烟云。这里是「朝花夕拾」第二十七期 <code>远离他们</code>，原谅我的起名无能，我只是觉得这首歌很好听。最近开始捡起了阅读，不再是刷着手机睡觉，而是看着Kindle入眠。相比之前，感觉自己的状态好了很多，也越来越觉得以前从信息流中漫无目的滑过的浅薄。远离他们，远离浮躁、远离喧嚣、远离无用的信息流，沉淀下来，做些有意义的事情（强行点题，手工狗头） </p>    <div id="aplayer-DpfFUHZl" class="aplayer aplayer-tag-marker meting-tag-marker" data-id="1447573210" data-server="netease" data-type="song" data-mode="circulation" data-autoplay="false" data-mutex="true" data-listmaxheight="340px" data-preload="auto" data-theme="#555"></div><a id="more"></a><h2 id="记录"><a href="#记录" class="headerlink" title="记录"></a>记录</h2><p><img alt="坠落烟云" data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-12-05_drop.png"></p><p>例行数据回顾，首先是 <code>RescueTime</code>：</p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-12-05_rescue-time.png"></p><p>这周记录的时间相对上周要少，因为周日出去浪了，所以基本没有碰电脑。总体来说，这周的企业微信用的比上周要多，因为多了一些沟通的事情，这周主要的事情也就是在自己学习 <code>k8s</code>，总结自己的博客中。还是继续坚持之前的做法，用固定的时间来去解决沟通的问题。</p><p>接下来是 <code>Forest</code> 和 <code>Running</code>，现在工作的时候很少刷手机了，只有在吃饭的时候刷刷手机，但是就在那一个小时也容易一直拖拉，需要进一步改变。跑步方面，这周坚持了四次，比上周数据有所增加，但是说实话一直还没有找到跑步的感觉，继续加油叭。之前大四跑步疯狂的时候，说自己要跑马拉松，但是最后鸽了，这次看能不能跑上明年的北马呢？</p><div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img alt="Forest - Nov 29 ~ Dec 05, 2020" data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-12-05_forest.jpg"></div><div class="group-picture-column" style="width: 50%;"><img alt="Running - Nov 29 ~ Dec 05, 2020" data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-12-05_running.jpg"></div></div></div></div><p>接下来是睡眠数据总结，这里我更新了处理数据的 <code>Python</code> 脚本，主要的展示逻辑放在了 <code>ECharts</code> 里面：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/env python3</span><br><span class="line"># -*- coding: UTF<span class="number">-8</span> -*-</span><br><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"></span><br><span class="line">datafile = <span class="string">"sleep.csv"</span></span><br><span class="line"></span><br><span class="line">def get_time_value(timeArray):</span><br><span class="line">    <span class="keyword">return</span> timeArray.tm_hour + round(float(timeArray.tm_min) / float(<span class="number">60</span>), <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">def get_time(timestamp):</span><br><span class="line">    timeStamp = float(timestamp)</span><br><span class="line">    timeArray = time.localtime(timeStamp)</span><br><span class="line">    <span class="keyword">return</span> timeArray</span><br><span class="line"></span><br><span class="line">def parse_csv(datafile):</span><br><span class="line">    dateTime = []</span><br><span class="line">    sleepTime = []</span><br><span class="line">    awakeTime = []</span><br><span class="line">    with open(datafile, <span class="string">"r"</span>) as f:</span><br><span class="line">        r = csv.DictReader(f)</span><br><span class="line">        <span class="keyword">for</span> line in r:</span><br><span class="line">            start, stop = line[<span class="string">"start"</span>], line[<span class="string">"stop"</span>]</span><br><span class="line">            pStart = get_time(start)</span><br><span class="line">            pStop = get_time(stop)</span><br><span class="line">            pDate = time.strftime(<span class="string">"%Y-%m-%d"</span>, pStop)</span><br><span class="line">            dateTime.<span class="built_in">append</span>(pDate)</span><br><span class="line"></span><br><span class="line">            sleepTimeValue = get_time_value(pStart)</span><br><span class="line">            awakeTimeValue = get_time_value(pStop)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> sleepTimeValue &gt; <span class="number">20</span>:</span><br><span class="line">                sleepTimeValue = round(sleepTimeValue - <span class="number">24.0</span>, <span class="number">2</span>)</span><br><span class="line">            sleepTime.<span class="built_in">append</span>(sleepTimeValue)</span><br><span class="line">            awakeTime.<span class="built_in">append</span>(awakeTimeValue)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dateTime, sleepTime, awakeTime</span><br></pre></td></tr></table></figure><p>数据涵盖了 <code>2020-10-19</code> 到 <code>2020-12-06</code> 的数据，可以看到我的睡眠分布非常不均衡，不仅仅是入睡时间的不均衡，起床时间的不均衡，还包括睡眠时长的不均衡。另外，大多数的入睡时间都在12点以后，很少在12点前就睡了的，这个一方面是之前作息极度不规律，另一方面现在有时候看书容易看晚了。</p><p>所以12月的一个任务是，将整个图形向下拉一个小时，以11点为起点，7点为终点的睡眠时间，而且两条曲线应该日渐平缓，方差不要过大，让自己的睡眠真正的规律起来。</p><div id="echarts9928" style="width: 100%;height: 600px;margin: 0 auto"></div><script type="text/javascript" src="https://cdn.bootcss.com/echarts/4.2.0-rc.2/echarts.min.js"></script><script type="text/javascript" src="http://gallery.echartsjs.com/dep/echarts/map/js/china.js"></script><script type="text/javascript">  // 基于准备好的dom，初始化echarts实例  var myChart = echarts.init(document.getElementById('echarts9928'));  // 指定图表的配置项和数据  var dateTime = ['2020-10-19', '2020-10-20', '2020-10-21', '2020-10-22', '2020-10-23', '2020-10-24', '2020-10-25', '2020-10-26', '2020-10-27', '2020-10-28', '2020-10-29', '2020-10-30', '2020-10-31', '2020-11-01', '2020-11-01', '2020-11-03', '2020-11-17', '2020-11-19', '2020-11-20', '2020-11-21', '2020-11-22', '2020-11-23', '2020-11-24', '2020-11-25', '2020-11-26', '2020-11-27', '2020-11-28', '2020-11-29', '2020-11-30', '2020-12-01', '2020-12-02', '2020-12-03', '2020-12-04', '2020-12-05', '2020-12-06'];var sleepTime = [-0.17, 0.57, 1.13, -0.88, 0.65, 0.77, 1.62, 0.1, 0.8, 0.95, 1.12, 0.27, 0.62, -0.05, 0.0, -1.63, 0.0, -0.55, 3.12, 0.33, 1.77, -0.7, 0.28, -0.2, 1.42, 0.38, -1.0, -0.95, -0.18, 4.03, -0.55, 0.58, 0.38, 1.13, -0.08];var awakeTime = [8.78, 5.13, 8.9, 3.32, 8.38, 10.77, 9.32, 6.15, 6.92, 8.32, 9.27, 6.62, 4.18, 3.87, 0.0, 3.5300000000000002, 0.0, 7.57, 7.95, 7.08, 9.85, 7.13, 5.42, 3.52, 8.3, 8.52, 8.03, 7.8, 8.67, 7.72, 7.83, 6.82, 4.85, 9.28, 7.38];var awakeTimeBar = [];for (let i = 0; i < sleepTime.length; ++i) {    var awakeTimeValue = awakeTime[i];    if (sleepTime[i] > 0) {        awakeTimeValue = awakeTime[i] - sleepTime[i];     }    awakeTimeBar.push(awakeTimeValue);}option = {    title: {        text: '睡眠监控'     },    tooltip: {        trigger: 'axis',        formatter: function(params) {            function getHourMinute(timeValue) {                if (timeValue < 0) timeValue = 24 + timeValue;                var m = Math.floor((timeValue % 1) * 60);                m = m.toString().padStart(2, '0');                var h = Math.floor(timeValue);                return {                    hour: h,                     minute: m                }            }                        var sleepValue = params[0].data;            var awakeValue = params[1].data;            if (sleepValue > 0) {                awakeValue = sleepValue + awakeValue;            }            var sleepTime = getHourMinute(sleepValue);            var awakeTime = getHourMinute(awakeValue);            var totalTime = getHourMinute(awakeValue - sleepValue);            return params[0].name + '<br />'                + params[0].seriesName + ": " + sleepTime.hour + ":" + sleepTime.minute + '<br />'                + params[1].seriesName + ": " + awakeTime.hour + ":" + awakeTime.minute + '<br />'                +  "睡眠时长: " + totalTime.hour + ":" + totalTime.minute;        }    },    toolbox: {        feature: {            dataView: {show: true, readOnly: false},            restore: {show: true},            saveAsImage: {show: true}        }    },    legend: {        data: ['入睡时间', '起床时间', '睡眠时间']    },    xAxis: [        {            type: 'category',            data: dateTime,            axisPointer: {                type: 'shadow'            }        }    ],    yAxis: [        {            type: 'value',            axisLine: {                show: false            },            name: '时间',            axisLabel: {                formatter: function (h) {                    h = Math.floor(h);                    if (h < 0) {                        return h + 24 + ':00';                    } else {                         return h + ':00';                    }                 },                 margin: 20            }        },        {            type: 'value',            axisLine: {            show: false            },            min: 0,            max: 10,            name: '时长/小时'        }    ],    series: [        {            name: '入睡时间',            type: 'line',            data: sleepTime        },        {            name: '起床时间',            type: 'line',            data: awakeTime        },        {            type: 'bar',            stack: '总量',            data: sleepTime,            itemStyle: {                normal: {                    color: function(params) {                        if (params.data > 0) return 'rgba(0,0,0,0)';                        else return '#2F4554'                    }                }            }        },        {            type: 'bar',            stack: '总量',            data: awakeTimeBar,            itemStyle: {                normal: {                    color: function(params) {                       return '#2F4554'                    }                }            }        }    ]};  // 使用刚指定的配置项和数据显示图表。  myChart.setOption(option);</script><h2 id="世界"><a href="#世界" class="headerlink" title="世界"></a>世界</h2><h3 id="Salesforce-收购-Slack"><a href="#Salesforce-收购-Slack" class="headerlink" title="Salesforce 收购 Slack"></a>Salesforce 收购 Slack</h3><h3 id="深圳新房代持"><a href="#深圳新房代持" class="headerlink" title="深圳新房代持"></a>深圳新房代持</h3><h3 id="孟晚舟被捕两周年"><a href="#孟晚舟被捕两周年" class="headerlink" title="孟晚舟被捕两周年"></a>孟晚舟被捕两周年</h3><h3 id="Gartner-发布报告"><a href="#Gartner-发布报告" class="headerlink" title="Gartner 发布报告"></a>Gartner 发布报告</h3><h3 id="社区买菜热战正酣"><a href="#社区买菜热战正酣" class="headerlink" title="社区买菜热战正酣"></a>社区买菜热战正酣</h3><p>阿里充值十绘团</p><p>美团财报出炉</p><h3 id="虾米音乐将关闭"><a href="#虾米音乐将关闭" class="headerlink" title="虾米音乐将关闭"></a>虾米音乐将关闭</h3><h3 id="11月PMI发布"><a href="#11月PMI发布" class="headerlink" title="11月PMI发布"></a>11月PMI发布</h3><h3 id="华晨债务风波"><a href="#华晨债务风波" class="headerlink" title="华晨债务风波"></a>华晨债务风波</h3><h3 id="量子计算九章发布"><a href="#量子计算九章发布" class="headerlink" title="量子计算九章发布"></a>量子计算九章发布</h3><h2 id="回归"><a href="#回归" class="headerlink" title="回归"></a>回归</h2>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;像燃烧的火球在天边下坠，这是今天旁晚的晚霞，从没拍到过这样的烟云。这里是「朝花夕拾」第二十七期 &lt;code&gt;远离他们&lt;/code&gt;，原谅我的起名无能，我只是觉得这首歌很好听。最近开始捡起了阅读，不再是刷着手机睡觉，而是看着Kindle入眠。相比之前，感觉自己的状态好了很多，也越来越觉得以前从信息流中漫无目的滑过的浅薄。远离他们，远离浮躁、远离喧嚣、远离无用的信息流，沉淀下来，做些有意义的事情（强行点题，手工狗头） &lt;/p&gt;

    &lt;div id=&quot;aplayer-DpfFUHZl&quot; class=&quot;aplayer aplayer-tag-marker meting-tag-marker&quot; data-id=&quot;1447573210&quot; data-server=&quot;netease&quot; data-type=&quot;song&quot; data-mode=&quot;circulation&quot; data-autoplay=&quot;false&quot; data-mutex=&quot;true&quot; data-listmaxheight=&quot;340px&quot; data-preload=&quot;auto&quot; data-theme=&quot;#555&quot;&gt;&lt;/div&gt;
    
    </summary>
    
    <content src="http://houmin.cc/https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-12-05_drop.png" type="image" />
    
    
      <category term="朝花夕拾" scheme="http://houmin.cc/categories/%E6%9C%9D%E8%8A%B1%E5%A4%95%E6%8B%BE/"/>
    
    
      <category term="阅读" scheme="http://houmin.cc/tags/%E9%98%85%E8%AF%BB/"/>
    
      <category term="量子计算" scheme="http://houmin.cc/tags/%E9%87%8F%E5%AD%90%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>晚安</title>
    <link href="http://houmin.cc/posts/74fda535/"/>
    <id>http://houmin.cc/posts/74fda535/</id>
    <published>2020-11-28T11:23:16.000Z</published>
    <updated>2020-12-06T16:11:55.246Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>遵守上周的约定，这周总算是定期发布了2020年「朝花夕拾」的第二十六期 <code>晚安</code>，在上期的记录中，我告诉自己要搭建起自己的睡眠数据监控系统，这周我来介绍下我是如何折腾的。封面来自今天在家拍摄的晚霞，晚安，希望大家都能够睡个好觉。</p>    <div id="aplayer-huwwUZxF" class="aplayer aplayer-tag-marker meting-tag-marker" data-id="439122551" data-server="netease" data-type="song" data-mode="circulation" data-autoplay="false" data-mutex="true" data-listmaxheight="340px" data-preload="auto" data-theme="#555"></div><a id="more"></a><h2 id="记录"><a href="#记录" class="headerlink" title="记录"></a>记录</h2><p>在例行每周数据回顾之前，先来看看这周拍摄的光影，仍旧没有出门，但是天朗气清留下了美丽的晚霞，并且抓到了太阳落山的全程。</p><p><img alt="白昼越来越短，黑夜越来越长，下午四点半在家里拍摄，不一会儿太阳就开始触碰山尖" data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-11-28_sunset-3.png"></p><p><img alt="知春西里一号楼十六层，这个机位也还不错，但是如果能够上楼顶就更好了，下次问问" data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-11-28_sunset-2.png"></p><p><img alt="将近五点，太阳已经全部落山，整个过程就两三分钟" data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-11-28_sunset-1.png"></p><p><img alt="落日的同时，人间烟火，我就在这样的小格子里面的一间" data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-11-28_smoke.png"></p><p>接下来，继续每周的数据回顾，首先是 <code>RescueTime</code>：</p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-11-28_rescue-time.png"></p><p>可以看到，相比于上周，这周总的生产力是要提升的。这周基本实践了上周的策略，工作时间专门找独立时间来处理企业微信上面的消息，而不是一直在线。因为如果真的有什么很要紧的工作的话，打我电话啊，反正我也在企业微信上面置顶了信息。真的，要求时刻在线，时刻能够回复消息对于精力的耗费太大了，这个方法继续坚持。</p><p>因为临近月末，对于每个数据监控，现在也增加月末的数据总结，我们看看 <code>RescueTime</code> 的 11月数据：</p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-11-28_rescue-time-nov.png"></p><p>可以看到，<code>Distracting Time</code> 从月初相对较大的比例，到月末有了一个明显的减少。这是为什么呢？因为我的 <code>Kindle</code> 到货了 ：）开个玩笑，其实从一个多月以前开始，就一直想着要减少自己无意义刷手机的行为。我对自己的这个行为深恶痛绝，但是一直没有根治过，也许是为了放松，但是经常性的在几个App之间切换而无所得，反而有的是巨大的空虚感。其中尤其以微博、微信朋友圈等App为甚。其实也是能够从这些渠道获取一些有效信息的，但是在我看来成本太大，所以我关闭了微信朋友圈、卸载了微博，并不是永远不再使用，至少这个冬天，我想要让自己沉下心来，扎扎实实做一些记录，做一些积淀。</p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-11-28_rescue-time-sep.png"></p><p>如果说11月份的数据还不够明显的话，可以看看9月份的数据，在工作之余，微博、微信、B站这几个是耗时最多的应用（10月因为有段时间去旅行了，所以数据并没有那么明显）。虽然卸载了微博、关闭了朋友圈，但是像 <code>The Social Dilemma</code> 中描述的很像，这个过程有一个戒断反应，有时候你会控制不住自己去把它们找回来。每次这个时候你要想一想，那里到底有什么那么重要的东西，让你不得不去开启它们呢？现在的我仍然处于戒断反应之中，过去的一个星期重新下载了微博一次、重新开启了朋友圈5次，虽然之后都卸载关闭了，但是仍然在和自己较量中。加油吧，希望下周总结的时候这个数据能够有改进。</p><p>不刷微博微信后，你的信息源何来呢？当我问出这个问题的时候，足以反映出一个问题：你是多么的害怕和这个世界隔离。但是真的会隔离吗，我依旧会在休息空隙看微信订阅号。但是下班回家后我不会再看手机消息了，因为平时下班比较晚，到家基本上就10点了，如果像以前那样每次都刷刷手机，基本上一个小时就过去了。这看起来是一个还可以接受的时间，实际上随着自己每天心情的状态改变，加上各种杂七杂八的事情，经常会拖到凌晨十二点半，甚至有时候到一两点。现在的做法很简单，到家后直接手机关机，直接拿起 Kindle 看书，看累了就睡觉。</p><p>关于 Kindle 看书，实际上还有很多问题没有解决。因为很久没有专门的时间看书了（读研后？），现在看书也没有一个明确的门类清单，有时候也没能够很专注其中。关于这个问题，希望下周能够有一个决断。</p><p>话题扯远了，我们继续回顾数据，<code>Google Calendar</code> 的每日总结现在仍然搁置，下周得有个交代了，你拖更太久了 ：）接下来看 <code>Forest</code>，</p><div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img alt="Forest - Nov 22 ~ Nov 28, 2020" data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-11-28_forest.jpg"></div><div class="group-picture-column" style="width: 50%;"><img alt="Forest November" data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-11-28_forest-nov.jpg"></div></div></div></div><p>健身是另一大事宜，这周跑步情况与上周相比基本持平，还在找回节奏的过程中，下周希望可以破四。回顾十一月的跑步情况，在数据监控回归之后总算维持了稳定。</p><div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img alt="Running - Nov 22 ~ Nov 28, 2020" data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-11-28_running.jpg"></div><div class="group-picture-column" style="width: 50%;"><img alt="Running November" data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-11-28_running-nov.jpg"></div></div></div></div><hr><h2 id="世界"><a href="#世界" class="headerlink" title="世界"></a>世界</h2><h3 id="嫦娥五号发射成功"><a href="#嫦娥五号发射成功" class="headerlink" title="嫦娥五号发射成功"></a>嫦娥五号发射成功</h3><ul><li>背景：2020年11月24日，中国的首个月球采样返回任务「嫦娥五号」发射成功</li><li>分析：这是中国的第六次探月人物，也是人类时隔44年将再次从月球带回岩石和土壤样品，上一次月球采样返回任务，还是1976年苏联的月球24号。</li></ul><h3 id="伊朗核科学家被暗杀"><a href="#伊朗核科学家被暗杀" class="headerlink" title="伊朗核科学家被暗杀"></a>伊朗核科学家被暗杀</h3><ul><li>背景：2020年11月27日，伊朗核计划负责人<strong>法赫里扎德</strong>近被暗杀身亡。据路透社报道，伊朗当天在写给联合国秘书长古特雷斯和联合国安理会的信中称，有“强烈迹象表明以色列对暗杀一名伊朗科学家负有责任”，伊朗保留自卫的权利。</li><li>跟进：西方普遍认为，这是美国和以色列主使，具体执行的是以色列情报机构<strong>摩萨德</strong></li><li>分析：这是继年初<strong>苏莱曼尼</strong>被美军无人机导弹猎杀后，伊朗核心人物遭到暗杀事件。拜登政府已经表态重返伊朗核协议，也就是说相对于特朗普政府美国的中东政策将会大幅转变。这个关头以色列暗杀<strong>法赫里扎德</strong>，再加上几天前 <strong>内塔尼亚胡</strong> <a href="https://link.zhihu.com/?target=https%3A//www.guancha.cn/internation/2020_11_28_572864.shtml" rel="external nofollow noopener noreferrer" target="_blank">访问了沙特阿拉伯</a>，舆论分析是 <strong>内塔尼亚胡</strong> 在给美国新一任政府传递信息，希望美国能够继续遏制伊朗。</li></ul><h2 id="回归"><a href="#回归" class="headerlink" title="回归"></a>回归</h2><p>总算聊到了今天的主题「睡眠」，其实刚才也在社交网络戒断的时候也提到了无意义刷手机对于睡眠的影响。为了有一个更加健康的睡眠，为了自己的生活更有节奏，还是希望自己能够记录自己的睡眠数据，从而能够更好的指导自己的生活。</p><p>睡眠数据中，最最基本的维度就是每天何时入睡、何时苏醒。当然你可以自己手动记录在相应的手机App上，但是这种方法太考验人的毅力了，我们需要一种无侵入式的记录方式。那么这种情况下的解决思路就是智能穿戴设备，比如智能手环、智能手表等，通过再添加一些传感器让硬件来解放人。</p><p>令人开心的是，事实上我已经佩戴 <code>小米手环3</code> 将近两年了，而小米也有 <code>小米运动</code> App 来对数据做专门的统计。然而令人失望的是，小米运动的睡眠数据统计做的极烂，我想要看到一周的每天何时起床何时苏醒都看不到，只能够看到一些可能都不是很准的深睡时间、浅睡时间。也许这些数据以后会很有用，但是我现阶段只想看入睡和苏醒时间。</p><p>接下来我又找到了小米手机自带的 <code>健康</code> 和 <code>小米穿戴</code> 两个应用，这两个数据统计做的还不错，但是不支持 <code>小米手环3</code>，只支持小米手环4和小米手环5。雷布斯你个倒霉孩子，又想骗我买新设备，还真别说我还真动了这个念头，毕竟也不贵。可是最重要的是过去两年的数据啊。哼哼，雷布斯你难不倒我的，我在 <a href="https://www.zhihu.com/question/34255518/answer/1187679143" target="_blank" rel="external nofollow noopener noreferrer">知乎的这个回答</a> 发现了这个 <a href="https://user.huami.com/hm_account/2.0.0/index.html?v=3.7.38&amp;platform_app=com.xiaomi.hm.health#/chooseDestory" target="_blank" rel="external nofollow noopener noreferrer">链接</a> ，在这里你可以导出你手环中所有的数据。</p><p>话不多说，睡眠数据以CSV格式保存，格式如下，我的数据是从 <code>2019年11月21日</code> 开始算起的：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">date,lastSyncTime,deepSleepTime,shallowSleepTime,wakeTime,start,stop</span><br><span class="line">2019-01-21,1548087470,119,372,22,1547998080,1548028860</span><br><span class="line">2019-01-22,1548173888,114,388,40,1548084300,1548116820</span><br><span class="line">2019-01-23,1548260294,120,347,45,1548174000,1548204720</span><br><span class="line">2019-01-24,1548346721,95,145,16,1548263280,1548278640</span><br></pre></td></tr></table></figure><p>其中的几个字段意义如下：</p><ul><li>lastSyncTime：上次数据同步时间</li><li><code>deepSleepTime</code>：深睡的时间</li><li><code>shallowSleepTime</code>：浅睡的时间</li><li><code>wakeTime</code>：清醒的时间</li><li><code>start</code>：每天晚上的入睡时间</li><li><code>stop</code>：每天早上起来的时间</li></ul><p>其中最关键的就是 <code>start</code> 和 <code>stop</code> 字段，有了这两个数据，我就可以基本统计出过去两年里面的睡眠模式了。<a href="http://zhangwenli.com/blog/2015/12/26/sleeping-analysis/" target="_blank" rel="external nofollow noopener noreferrer">这里</a> 是一个程序媛小姐姐在五年前（嗯很久远了）统计的睡眠数据，还用 <code>ECharts</code> 很漂亮的可视化了出来。</p><p>【今天晚上又到了睡觉的时间，明天早上补完后面的部分吧，我一定会回来的！—— 2020.11.28 22:00】</p><p>雷布斯你放心，下一款最新的小米手环我一定会支持你的。</p><p>【周日出去浪了，今天把上期朝花夕拾剩余的部分给补起来 —— 2020.11.30 17:00】</p><p>参考 <a href="http://zhangwenli.com/blog/2015/12/26/sleeping-analysis/" target="_blank" rel="external nofollow noopener noreferrer">这里</a>  的数据可视化，我简单的分析了入睡时间和起床时间，代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/bin/env python3</span></span><br><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">from</span> pyecharts.charts <span class="keyword">import</span> Scatter</span><br><span class="line"><span class="keyword">from</span> pyecharts <span class="keyword">import</span> options <span class="keyword">as</span> opts</span><br><span class="line"></span><br><span class="line">datafile = <span class="string">"sleep.csv"</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_time</span><span class="params">(timestamp)</span>:</span></span><br><span class="line">    timeStamp = float(timestamp)</span><br><span class="line">    timeArray = time.localtime(timeStamp)</span><br><span class="line">    sleepDate = time.strftime(<span class="string">"%Y-%m-%d"</span>, timeArray)</span><br><span class="line">    <span class="keyword">return</span> sleepDate, timeArray.tm_hour</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_csv</span><span class="params">(datafile)</span>:</span></span><br><span class="line">    dateTime = []</span><br><span class="line">    sleepTime = []</span><br><span class="line">    awakeTime = []</span><br><span class="line">    <span class="keyword">with</span> open(datafile, <span class="string">"r"</span>) <span class="keyword">as</span> f:</span><br><span class="line">        r = csv.DictReader(f)</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> r:</span><br><span class="line">            <span class="keyword">if</span> line[<span class="string">"deepSleepTime"</span>] == <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            start, stop = line[<span class="string">"start"</span>], line[<span class="string">"stop"</span>]</span><br><span class="line">            _, pStart = get_time(start)</span><br><span class="line">            pDate, pStop = get_time(stop)</span><br><span class="line">            dateTime.append(pDate)</span><br><span class="line">            sleepTime.append(pStart)</span><br><span class="line">            awakeTime.append(pStop)</span><br><span class="line">    <span class="keyword">return</span> dateTime, sleepTime, awakeTime</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    dateTime, sleepTime, awakeTime = parse_csv(datafile)</span><br><span class="line">    scatter = Scatter()</span><br><span class="line">    scatter.add_xaxis(dateTime)</span><br><span class="line">    <span class="comment">#scatter.add_yaxis("入睡时间", sleepTime)</span></span><br><span class="line">    scatter.add_yaxis(<span class="string">"起床时间"</span>, awakeTime)</span><br><span class="line">    scatter.set_global_opts(title_opts=opts.TitleOpts(title=<span class="string">"睡眠时间统计"</span>))</span><br><span class="line">    scatter.render()</span><br></pre></td></tr></table></figure><p>这里的数据分析非常浅显，首先入睡时间和起床时间只是从小时维度做了分析，粒度很粗。然后也没有进一步的按周、按月来分析，没有分析每天的睡眠时间，下次有时间搞一搞吧。</p><p>首先看入睡时间，可以看到，入睡时间分布最多的就是0点，也就是凌晨的时候，其次23点和1点也很频繁。11点之前睡很少很少，居然还有21点睡的？我不记得有过这种时刻，难道是手环统计误差？</p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-11-30_sleep-time.png"></p><p>接下来看起床时间，最广泛的分布是在早上8点-9点这个范围，9点和10点的数据也不少，最可怕的是居然有一天睡到了12点，看了下那是 <code>2019-12-21</code>，那是周六的早上，你真的挺懒的：）</p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-11-30_awake-time.png"></p><p>检讨下自己，这个作息真的不太健康，完全暴露了你的懒惰：）下周开始，每周的睡眠数据将会更新到「记录」模块，看看自己能不能做的更好。</p><p>【2020.12.06】更新了画图脚本，得出过去两年睡眠数据可视化如下：</p><div id="echarts8443" style="width: 100%;height: 600px;margin: 0 auto"></div><script type="text/javascript" src="https://cdn.bootcss.com/echarts/4.2.0-rc.2/echarts.min.js"></script><script type="text/javascript" src="http://gallery.echartsjs.com/dep/echarts/map/js/china.js"></script><script type="text/javascript">  // 基于准备好的dom，初始化echarts实例  var myChart = echarts.init(document.getElementById('echarts8443'));  // 指定图表的配置项和数据  option = {    title: {        text: '睡眠监控'     },    tooltip: {        trigger: 'axis',        formatter: function(params) {            function getHourMinute(timeValue) {                if (timeValue < 0) timeValue = 24 + timeValue;                var m = Math.floor((timeValue % 1) * 60);                m = m.toString().padStart(2, '0');                var h = Math.floor(timeValue);                return {                    hour: h,                     minute: m                }            }                        var sleepTime = getHourMinute(params[0].data)            var awakeTime = getHourMinute(params[1].data)            return params[0].seriesName + ": " + sleepTime.hour + ":" + sleepTime.minute + '<br />'                + params[1].seriesName + ": " + awakeTime.hour + ":" + awakeTime.minute + '<br />'                +  params[2].seriesName + ": " + params[2].data + '小时';        }    },    toolbox: {        feature: {            dataView: {show: true, readOnly: false},            restore: {show: true},            saveAsImage: {show: true}        }    },    legend: {        data: ['入睡时间', '起床时间']    },    xAxis: [        {            type: 'category',            data: ['2019-01-15', '2019-01-16', '2019-01-17', '2019-01-18', '2019-01-19', '2019-01-21', '2019-01-22', '2019-01-23', '2019-01-24', '2019-01-25', '2019-01-26', '2019-01-27', '2019-01-28', '2019-01-28', '2019-01-30', '2019-01-31', '2019-01-31', '2019-02-02', '2019-02-03', '2019-02-04', '2019-02-05', '2019-02-05', '2019-02-06', '2019-02-07', '2019-02-08', '2019-02-09', '2019-02-10', '2019-02-11', '2019-02-13', '2019-02-14', '2019-02-15', '2019-02-16', '2019-02-17', '2019-02-18', '2019-02-19', '2019-02-20', '2019-02-21', '2019-02-22', '2019-02-23', '2019-02-24', '2019-02-25', '2019-02-26', '2019-02-27', '2019-02-28', '2019-03-01', '2019-03-02', '2019-03-03', '2019-03-04', '2019-03-05', '2019-03-06', '2019-03-07', '2019-03-08', '2019-03-09', '2019-03-10', '2019-03-11', '2019-03-12', '2019-03-13', '2019-03-14', '2019-03-15', '2019-03-16', '2019-03-17', '2019-03-18', '2019-03-19', '2019-03-20', '2019-03-21', '2019-03-22', '2019-03-23', '2019-03-24', '2019-03-25', '2019-03-26', '2019-03-27', '2019-03-28', '2019-03-29', '2019-03-30', '2019-03-31', '2019-04-01', '2019-04-02', '2019-04-02', '2019-04-04', '2019-04-04', '2019-04-05', '2019-04-07', '2019-04-08', '2019-04-09', '2019-04-10', '2019-04-11', '2019-04-12', '2019-04-13', '2019-04-14', '2019-04-15', '2019-04-15', '2019-04-17', '2019-04-18', '2019-04-19', '2019-04-20', '2019-04-21', '2019-04-21', '2019-04-23', '2019-04-24', '2019-04-25', '2019-04-26', '2019-04-27', '2019-04-28', '2019-04-28', '2019-04-30', '2019-05-01', '2019-05-02', '2019-05-03', '2019-05-04', '2019-05-05', '2019-05-05', '2019-05-07', '2019-05-07', '2019-05-09', '2019-05-09', '2019-05-10', '2019-05-11', '2019-05-13', '2019-05-14', '2019-05-15', '2019-05-16', '2019-05-16', '2019-05-18', '2019-05-19', '2019-05-20', '2019-05-21', '2019-05-22', '2019-05-23', '2019-05-24', '2019-05-24', '2019-05-26', '2019-05-27', '2019-05-27', '2019-05-29', '2019-05-29', '2019-05-31', '2019-06-01', '2019-06-02', '2019-06-03', '2019-06-04', '2019-06-05', '2019-06-06', '2019-06-07', '2019-06-08', '2019-06-09', '2019-06-10', '2019-06-11', '2019-06-12', '2019-06-13', '2019-06-14', '2019-06-15', '2019-06-16', '2019-06-17', '2019-06-18', '2019-06-19', '2019-06-19', '2019-06-21', '2019-06-21', '2019-06-22', '2019-06-24', '2019-06-25', '2019-06-26', '2019-06-26', '2019-06-28', '2019-06-29', '2019-06-30', '2019-07-01', '2019-07-02', '2019-07-03', '2019-07-04', '2019-07-05', '2019-07-06', '2019-07-07', '2019-07-08', '2019-07-08', '2019-07-09', '2019-07-11', '2019-07-12', '2019-07-13', '2019-07-14', '2019-07-15', '2019-07-16', '2019-07-17', '2019-07-18', '2019-07-18', '2019-07-20', '2019-07-30', '2019-08-01', '2019-08-02', '2019-08-03', '2019-08-04', '2019-08-04', '2019-08-06', '2019-08-07', '2019-08-08', '2019-08-09', '2019-08-10', '2019-08-10', '2019-08-12', '2019-08-13', '2019-08-14', '2019-08-15', '2019-08-15', '2019-08-17', '2019-08-18', '2019-08-19', '2019-08-19', '2019-08-21', '2019-08-22', '2019-08-22', '2019-08-24', '2019-08-25', '2019-08-26', '2019-08-27', '2019-08-27', '2019-08-29', '2019-08-30', '2019-08-31', '2019-09-01', '2019-09-02', '2019-09-02', '2019-09-04', '2019-09-04', '2019-09-05', '2019-09-07', '2019-09-08', '2019-09-09', '2019-09-09', '2019-09-11', '2019-09-12', '2019-09-13', '2019-09-14', '2019-09-15', '2019-09-16', '2019-09-17', '2019-09-17', '2019-09-19', '2019-09-19', '2019-09-21', '2019-09-22', '2019-09-23', '2019-09-24', '2019-09-24', '2019-09-26', '2019-09-26', '2019-09-28', '2019-09-29', '2019-09-30', '2019-10-01', '2019-10-01', '2019-10-02', '2019-10-03', '2019-10-04', '2019-10-14', '2019-10-15', '2019-10-17', '2019-10-18', '2019-10-19', '2019-10-20', '2019-10-21', '2019-10-22', '2019-10-23', '2019-10-24', '2019-10-25', '2019-10-26', '2019-10-27', '2019-10-28', '2019-10-29', '2019-10-30', '2019-10-31', '2019-11-01', '2019-11-02', '2019-11-03', '2019-11-04', '2019-11-05', '2019-11-06', '2019-11-07', '2019-11-07', '2019-11-09', '2019-11-10', '2019-11-11', '2019-11-11', '2019-11-13', '2019-11-14', '2019-11-15', '2019-11-16', '2019-11-17', '2019-11-18', '2019-11-19', '2019-11-20', '2019-11-21', '2019-11-22', '2019-11-23', '2019-11-24', '2019-11-25', '2019-11-26', '2019-11-27', '2019-11-28', '2019-11-29', '2019-11-30', '2019-12-01', '2019-12-02', '2019-12-03', '2019-12-04', '2019-12-05', '2019-12-06', '2019-12-07', '2019-12-08', '2019-12-09', '2019-12-10', '2019-12-11', '2019-12-11', '2019-12-13', '2019-12-14', '2019-12-15', '2019-12-16', '2019-12-17', '2019-12-18', '2019-12-19', '2019-12-20', '2019-12-21', '2019-12-22', '2019-12-22', '2019-12-24', '2019-12-25', '2019-12-26', '2019-12-27', '2019-12-28', '2019-12-29', '2019-12-29', '2019-12-31', '2020-01-01', '2020-01-02', '2020-01-03', '2020-01-04', '2020-01-05', '2020-01-06', '2020-01-07', '2020-01-08', '2020-01-09', '2020-01-09', '2020-01-11', '2020-01-12', '2020-01-13', '2020-01-14', '2020-01-15', '2020-01-16', '2020-01-17', '2020-01-18', '2020-01-19', '2020-01-20', '2020-01-21', '2020-01-22', '2020-01-23', '2020-01-24', '2020-01-25', '2020-01-26', '2020-01-27', '2020-01-28', '2020-01-29', '2020-01-30', '2020-01-31', '2020-02-01', '2020-02-02', '2020-02-02', '2020-02-03', '2020-02-04', '2020-06-30', '2020-07-01', '2020-07-02', '2020-07-02', '2020-07-03', '2020-07-05', '2020-07-05', '2020-07-06', '2020-07-07', '2020-07-08', '2020-07-10', '2020-07-10', '2020-07-11', '2020-07-12', '2020-07-13', '2020-07-14', '2020-07-15', '2020-07-16', '2020-07-17', '2020-07-18', '2020-07-19', '2020-07-20', '2020-07-21', '2020-07-22', '2020-07-23', '2020-07-24', '2020-07-25', '2020-07-26', '2020-07-27', '2020-07-28', '2020-07-29', '2020-07-30', '2020-07-31', '2020-08-01', '2020-08-02', '2020-08-03', '2020-08-04', '2020-08-06', '2020-08-06', '2020-08-07', '2020-08-08', '2020-08-09', '2020-08-11', '2020-08-12', '2020-08-12', '2020-08-13', '2020-08-14', '2020-08-15', '2020-08-17', '2020-08-18', '2020-08-18', '2020-08-19', '2020-08-20', '2020-08-21', '2020-08-22', '2020-08-23', '2020-08-24', '2020-08-25', '2020-08-27', '2020-08-27', '2020-08-29', '2020-08-29', '2020-08-30', '2020-08-31', '2020-09-01', '2020-09-02', '2020-09-03', '2020-09-05', '2020-09-05', '2020-09-07', '2020-09-07', '2020-09-08', '2020-09-10', '2020-09-11', '2020-09-12', '2020-09-13', '2020-09-13', '2020-09-15', '2020-09-15', '2020-09-17', '2020-09-18', '2020-09-19', '2020-09-19', '2020-09-20', '2020-09-21', '2020-09-22', '2020-09-23', '2020-09-24', '2020-09-25', '2020-09-26', '2020-09-27', '2020-09-29', '2020-09-30', '2020-09-30', '2020-10-02', '2020-10-03', '2020-10-03', '2020-10-05', '2020-10-05', '2020-10-06', '2020-10-08', '2020-10-09', '2020-10-09', '2020-10-11', '2020-10-11', '2020-10-13', '2020-10-14', '2020-10-15', '2020-10-16', '2020-10-17', '2020-10-17', '2020-10-19', '2020-10-20', '2020-10-21', '2020-10-22', '2020-10-23', '2020-10-24', '2020-10-25', '2020-10-26', '2020-10-27', '2020-10-28', '2020-10-29', '2020-10-30', '2020-10-31', '2020-11-01', '2020-11-01', '2020-11-03', '2020-11-17', '2020-11-19', '2020-11-20', '2020-11-21', '2020-11-22', '2020-11-23', '2020-11-24', '2020-11-25', '2020-11-26', '2020-11-27', '2020-11-28'],            axisPointer: {                type: 'shadow'            }        }    ],    yAxis: [        {            type: 'value',            axisLine: {                show: false            },            name: '小时',            axisLabel: {                formatter: function (h) {                    h = Math.floor(h);                    if (h < 0) {                        return h + 24 + ':00';                    } else {                         return h + ':00';                    }                 },                 margin: 20            }        }    ],    series: [        {            name: '入睡时间',            type: 'line',            data: [0.0, 0.0, 0.0, 0.0, 0.0, -0.53, -0.58, 0.33, 1.13, 0.2, -0.27, 2.82, -0.67, 0.0, 0.8, 1.98, 0.0, -2.05, 0.58, 0.07, 0.17, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.57, 1.9300000000000002, 0.83, 0.12, 0.37, 0.57, 0.1, 0.47, 0.33, 1.92, 1.72, 0.35, 0.67, 0.35, 0.57, 0.93, 1.07, 1.17, -0.72, 0.95, -0.32, 0.18, 0.45, 0.27, 0.0, 1.37, -0.1, 0.22, 0.52, 0.42, 0.85, 0.88, 0.32, 0.1, -0.17, -1.08, 1.83, -0.8, 0.02, -0.25, -0.07, -0.72, -0.93, 0.0, 0.72, -0.77, 0.07, 0.52, -0.35, 0.0, -1.97, 0.0, 0.0, -1.77, 1.45, 0.3, 0.17, 3.98, 0.1, 0.58, -0.67, -0.45, 0.0, 2.02, -0.3, 0.78, 0.63, 0.33, 0.0, 2.32, -0.17, 1.33, -0.9, 1.83, 0.32, 0.0, -0.48, -0.42, 0.6, -1.3, 1.08, 0.48, 0.0, 3.1, 0.0, 1.5, 0.0, 0.0, 0.0, 1.67, -0.22, 0.47, 1.37, 0.0, -0.87, -0.8, -0.47, -0.48, 0.33, 0.0, 0.33, 0.0, -1.52, 0.98, 0.0, 0.17, 0.0, 0.55, 2.2800000000000002, -0.72, -0.32, -0.15, 0.87, 1.1, 1.9300000000000002, 0.35, -3.52, 1.05, 0.53, 0.33, 0.28, 3.0, 0.5, 1.22, 0.82, 1.28, 1.87, 0.0, -0.4, 0.0, 0.0, -0.27, -1.53, 1.08, 0.0, -0.12, 1.48, 0.37, 0.35, -0.22, 0.48, -0.03, 0.53, 1.33, -0.93, 0.27, 0.0, 0.0, 0.73, 0.58, 0.7, 0.62, 0.42, 0.82, 0.68, 0.67, 0.0, 0.62, 0.0, 0.63, 0.12, 1.07, 1.48, 0.0, 0.85, 0.75, 0.62, 0.65, 0.6, 0.0, 1.03, 1.22, 0.63, 0.87, 0.0, 0.97, 1.78, 1.55, 0.0, 0.38, 0.78, 0.0, 3.12, 0.9, 0.73, 0.57, 0.0, 0.72, 0.08, 0.58, 1.1, 0.7, 0.0, -0.17, 0.0, 0.0, -2.13, 2.7800000000000002, 0.37, 0.0, 0.63, 1.43, -2.12, 0.57, 0.85, 2.27, 1.8, 0.0, -3.08, 0.0, 2.38, 1.45, 3.65, 0.58, 0.0, 0.87, 0.0, 1.65, -0.6, 0.15, 1.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.62, 2.27, 2.1, 0.28, -0.48, -1.08, 1.35, 1.3, 1.62, -0.2, 0.47, -0.1, 1.28, 0.93, 2.0, 1.25, -0.32, 0.65, 1.27, 2.03, 3.92, 1.13, 0.0, 0.75, 0.85, 0.82, 0.0, 0.87, 0.53, 1.13, 0.62, 2.58, 1.55, 0.8, 1.3, 1.3, 0.87, 0.57, 2.92, 1.37, 0.02, 0.3, 1.42, -0.37, 0.93, 2.18, 1.18, 1.38, 0.57, 0.38, -0.35, 0.8, 0.45, 1.5699999999999998, 0.82, 0.98, 0.0, 1.17, 0.5, 0.93, 0.92, 4.65, 0.23, 5.32, -0.47, 2.25, 0.67, 0.0, 0.37, 2.08, 1.83, 1.12, 0.45, -0.6, 0.0, 1.42, 4.35, -0.42, 1.43, -0.08, 0.42, 0.73, 0.75, 1.17, 0.82, 0.0, 2.67, 2.83, 0.93, 0.8, -0.28, -0.15, 0.65, 1.2, 0.17, -2.05, 0.55, 0.33, 0.48, 0.75, 1.63, -0.77, 1.87, 1.33, 1.5, 0.9, 0.97, 0.22, 0.47, 0.0, 0.0, 0.0, 0.7, -0.42, -0.1, 0.0, 0.0, 4.1, 0.0, 0.0, 0.0, 0.0, 0.13, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.82, 0.0, 0.0, 0.0, 0.0, -0.38, -0.72, 0.0, 0.0, 0.0, 0.0, 0.27, -0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18, 0.0, -0.15, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.82, 0.0, -1.68, 0.0, 0.0, -0.07, 0.65, 0.32, -0.68, 0.0, 5.12, 0.0, -0.17, -0.53, 5.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.07, 2.07, 0.0, 1.13, 3.45, 0.0, -1.65, 0.0, 0.0, 0.75, 1.25, 0.0, 3.45, 0.0, 0.25, 1.22, 1.62, 0.43, 1.98, 0.0, -0.17, 0.57, 1.13, -0.88, 0.65, 0.77, 1.62, 0.1, 0.8, 0.95, 1.12, 0.27, 0.62, -0.05, 0.0, -1.63, 0.0, -0.55, 3.12, 0.33, 1.77, -0.7, 0.28, -0.2, 1.42, 0.38, -1.0]        },        {            name: '起床时间',            type: 'line',            data: [0.0, 0.0, 0.0, 0.0, 0.0, 8.02, 8.45, 8.87, 5.4, 8.72, 9.37, 9.87, 8.38, 0.0, 5.58, 6.42, 0.0, 7.63, 7.1, 8.1, 7.6, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.92, 8.7, 5.33, 8.27, 8.8, 8.93, 6.02, 8.15, 8.92, 7.82, 9.03, 9.03, 9.38, 6.32, 8.68, 8.78, 9.25, 7.52, 9.2, 7.6, 3.9, 8.25, 8.27, 8.5, 8.9, 8.53, 9.07, 7.93, 9.13, 5.88, 9.05, 6.6, 8.88, 9.17, 8.52, 8.98, 8.95, 4.98, 8.22, 8.83, 6.77, 9.37, 7.4, 8.27, 8.15, 9.12, 10.33, 9.03, 6.32, 0.0, 6.0, 0.0, 0.0, 7.15, 7.92, 7.72, 7.9, 8.57, 8.23, 7.58, 8.5, 8.45, 0.0, 8.07, 8.3, 8.3, 9.12, 8.3, 0.0, 8.32, 8.37, 7.85, 7.13, 8.63, 5.38, 0.0, 8.78, 4.78, 6.93, 6.93, 7.9, 9.02, 0.0, 7.97, 0.0, 7.82, 0.0, 0.0, 0.0, 8.48, 6.97, 8.22, 8.3, 0.0, 6.93, 6.93, 5.42, 7.65, 7.1, 7.38, 5.38, 0.0, 4.43, 7.62, 0.0, 8.17, 0.0, 6.92, 10.38, 9.58, 7.8, 7.92, 7.67, 8.13, 10.55, 8.87, 5.08, 4.77, 5.63, 8.02, 8.6, 8.87, 8.9, 8.95, 8.57, 8.88, 8.77, 0.0, 3.67, 0.0, 0.0, 8.23, 8.07, 7.97, 0.0, 8.53, 7.92, 8.57, 3.7199999999999998, 4.82, 8.0, 3.92, 9.17, 7.38, 8.88, 8.83, 0.0, 0.0, 8.4, 8.93, 9.0, 8.25, 8.73, 8.85, 8.72, 8.88, 0.0, 9.77, 0.0, 7.83, 8.92, 8.78, 5.02, 0.0, 6.75, 4.43, 9.13, 5.75, 8.68, 0.0, 8.43, 8.93, 6.22, 5.47, 0.0, 8.55, 6.65, 6.13, 0.0, 5.82, 5.8, 0.0, 8.65, 10.42, 8.95, 8.55, 0.0, 8.35, 8.5, 8.7, 9.02, 8.88, 0.0, 3.7, 0.0, 0.0, 8.78, 6.63, 8.05, 0.0, 8.32, 8.08, 4.5, 8.55, 7.98, 4.87, 5.68, 0.0, 0.17, 0.0, 7.32, 9.15, 8.7, 8.67, 0.0, 5.57, 0.0, 9.0, 4.72, 6.9, 4.18, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.92, 8.97, 6.05, 9.75, 8.48, 7.73, 5.62, 5.53, 9.67, 9.05, 5.38, 8.98, 7.43, 4.47, 8.92, 4.28, 6.08, 8.8, 5.7, 10.05, 10.03, 9.93, 0.0, 9.35, 8.93, 9.47, 0.0, 7.83, 7.93, 5.25, 8.87, 5.6, 9.87, 4.25, 6.68, 4.18, 8.95, 7.0, 5.38, 3.9, 9.52, 8.9, 10.72, 7.62, 10.82, 11.45, 9.47, 10.97, 6.85, 9.75, 8.42, 5.63, 9.2, 9.8, 10.12, 5.4, 0.0, 6.2, 5.55, 4.65, 5.75, 8.95, 9.03, 10.73, 7.02, 12.83, 6.92, 0.0, 9.48, 6.0, 10.53, 9.1, 8.72, 8.05, 0.0, 11.12, 6.82, 9.53, 5.73, 9.83, 8.43, 6.15, 8.65, 8.55, 9.0, 0.0, 10.68, 9.75, 9.45, 6.43, 6.08, 9.23, 8.38, 10.33, 4.88, 8.08, 5.87, 7.75, 10.05, 9.32, 10.97, 8.52, 10.28, 10.65, 6.47, 6.13, 9.75, 7.83, 9.83, 0.0, 0.0, 0.0, 7.53, 6.78, 4.05, 0.0, 0.0, 6.45, 0.0, 0.0, 0.0, 0.0, 3.52, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.17, 0.0, 0.0, 0.0, 0.0, 8.03, 7.7, 0.0, 0.0, 0.0, 0.0, 7.8, 7.85, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.42, 0.0, 7.75, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.18, 0.0, 0.9, 0.0, 0.0, 8.32, 8.18, 3.68, 4.12, 0.0, 6.67, 0.0, 8.7, 8.15, 8.42, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.42, 8.13, 0.0, 4.42, 5.77, 0.0, 6.87, 0.0, 0.0, 6.12, 9.52, 0.0, 9.68, 0.0, 8.58, 9.02, 5.87, 8.78, 8.85, 0.0, 8.78, 5.13, 8.9, 3.32, 8.38, 10.77, 9.32, 6.15, 6.92, 8.32, 9.27, 6.62, 4.18, 3.87, 0.0, 3.5300000000000002, 0.0, 7.57, 7.95, 7.08, 9.85, 7.13, 5.42, 3.52, 8.3, 8.52, 8.03]        }    ]};  // 使用刚指定的配置项和数据显示图表。  myChart.setOption(option);</script><h2 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h2><p>有研究表明人睡眠存在一个生物节律，即由4-5个睡眠周期组成，每一个周期又分为5个阶段，由两个时相组成：非快速眼动睡眠相NREM（前4期）和快速眼动睡眠REM（在睡眠70-90分钟后出现）。每个周期持续90分钟左右，每晚可出现4-5个周期。</p><h3 id="非快速眼动睡眠相NREM"><a href="#非快速眼动睡眠相NREM" class="headerlink" title="非快速眼动睡眠相NREM"></a>非快速眼动睡眠相NREM</h3><p>此睡眠相主要由入眠期、浅睡和中睡期组成，可以伴有少量的深睡期。</p><h4 id="入睡期"><a href="#入睡期" class="headerlink" title="入睡期"></a>入睡期</h4><p>是睡眠的开始，昏昏欲睡的感觉就属于这一阶段。此时脑波开始变化，频率渐缓，振幅渐小。此阶段是清醒和睡眠之间的转换期，人非常容易醒来，约占睡眠总时间的10%。</p><h4 id="浅睡期和中睡期"><a href="#浅睡期和中睡期" class="headerlink" title="浅睡期和中睡期"></a>浅睡期和中睡期</h4><p>开始正式睡眠。此时脑波渐呈不规律进行，频率与振幅忽大忽小，其中偶尔会出现被称为“睡眠锭”的高频、大波幅脑波，以及被称为“K结”的低频、很大波幅脑波。此期容易觉醒，入睡困难者，常自行惊醒，约占整个睡眠期的50%。</p><h4 id="深睡期"><a href="#深睡期" class="headerlink" title="深睡期"></a>深睡期</h4><p>沉睡阶段，被试不易被叫醒。此时脑波变化很大，频率只有每秒1~2周，为<strong>慢波睡眠</strong>，但振幅增加较大，呈现变化缓慢的曲线。此期睡眠深，觉醒相当困难，在每个睡眠周期中约持续30分钟，然后进入快速眼动睡眠。</p><p>这四个阶段的睡眠均不出现眼球快速跳动现象，故统称为<strong>非快速眼动睡眠</strong>（non－rapideyemovementsleep，简称<strong>NREM</strong>。</p><p><img alt="睡眠周期" data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-11-30_sleep-hypnogram.svg"></p><h3 id="快速动眼期REM"><a href="#快速动眼期REM" class="headerlink" title="快速动眼期REM"></a>快速动眼期REM</h3><p>这一阶段以深睡眠为主，脑波迅速改变，出现与清醒状态时的脑波相似的高频率、低波幅脑波，但其中会有特点鲜明的锯齿状波。睡眠者通常会有翻身的动作，并很容易惊醒，似乎又进入阶段1的睡眠，但实际是进入了一个被称为<strong>快速眼动睡眠</strong>（rapideyemovementsleep，简称<strong>REM</strong>）的睡眠阶段。因为，此时除了脑波的改变之外，被试的眼球会呈现快速跳动现象。如果此时将其唤醒，大部分人报告说正在做梦。因此，REM就成为睡眠第五个阶段的重要特征，也成为心理学家研究做梦的重要根据。</p><p>在整个睡眠周期中，NREM与REM有规律地交替出现，两种不同时相睡眠各出现一次为一个睡眠期。入睡后必须先经过NREM阶段，才能进入REM阶段，而人体只有在经过了REM阶段后才有真正睡过觉的感觉，体能才能得到很好的恢复。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;遵守上周的约定，这周总算是定期发布了2020年「朝花夕拾」的第二十六期 &lt;code&gt;晚安&lt;/code&gt;，在上期的记录中，我告诉自己要搭建起自己的睡眠数据监控系统，这周我来介绍下我是如何折腾的。封面来自今天在家拍摄的晚霞，晚安，希望大家都能够睡个好觉。&lt;/p&gt;

    &lt;div id=&quot;aplayer-huwwUZxF&quot; class=&quot;aplayer aplayer-tag-marker meting-tag-marker&quot; data-id=&quot;439122551&quot; data-server=&quot;netease&quot; data-type=&quot;song&quot; data-mode=&quot;circulation&quot; data-autoplay=&quot;false&quot; data-mutex=&quot;true&quot; data-listmaxheight=&quot;340px&quot; data-preload=&quot;auto&quot; data-theme=&quot;#555&quot;&gt;&lt;/div&gt;
    
    </summary>
    
    <content src="http://houmin.cc/https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-11-28_sunset-2.png" type="image" />
    
    
      <category term="朝花夕拾" scheme="http://houmin.cc/categories/%E6%9C%9D%E8%8A%B1%E5%A4%95%E6%8B%BE/"/>
    
    
      <category term="sleep" scheme="http://houmin.cc/tags/sleep/"/>
    
      <category term="嫦娥五号" scheme="http://houmin.cc/tags/%E5%AB%A6%E5%A8%A5%E4%BA%94%E5%8F%B7/"/>
    
  </entry>
  
  <entry>
    <title>【Service Mesh】Envoy 入门</title>
    <link href="http://houmin.cc/posts/7beb34d2/"/>
    <id>http://houmin.cc/posts/7beb34d2/</id>
    <published>2020-11-25T04:15:08.000Z</published>
    <updated>2020-12-15T11:25:17.458Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p><code>Envoy</code> 是一款由 Lyft 开源的高性能数据和服务代理软件，使用现代 C++ 开发，提供四层和七层网络代理能力。尽管在设计之初 <code>Envoy</code>没有将性能作为最终的目标，而是更加强调模块化、易测试、易开发等特性，可它仍旧拥有足可媲美 Nginx 等经典代理软件的超高性能。在保证性能的同时，<code>Envoy</code>也提供了强大的流量治理能力和可观察性。其独创的 xDS 协议则成为了构建 Service Mesh 通用数据面 API（UPDA）的基石。</p><a id="more"></a><h2 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h2><p><img alt="Envoy Architecture" data-src="https://cdn.jsdelivr.net/gh/yangchuansheng/imghosting/img/20200504160047.png"></p><p>首先介绍Envoy中的一些基本概念：</p><ul><li>Downstream：下游主机，指连接到Envoy的主机，这些主机用来发送请求并接受响应。</li><li>Upstream：上游主机，指接收来自Envoy连接和请求的主机，并返回响应。</li><li>Listener：服务或程序的监听器， Envoy暴露一个或多个监听器监听下游主机的请求，当监听到请求时，通过Filter Chain把对请求的处理全部抽象为Filter， 例如ReadFilter、WriteFilter、HttpFilter等。</li><li>Cluster：服务提供集群，指Envoy连接的一组逻辑相同的上游主机。Envoy通过服务发现功能来发现集群内的成员，通过负载均衡功能将流量路由到集群的各个成员。</li><li>xDS：xDS中的x是一个代词，类似云计算里的XaaS可以指代IaaS、PaaS、SaaS等。DS为Discovery Service，即发现服务的意思。xDS包括CDS（cluster discovery service）、RDS（route discovery service）、EDS（endpoint discovery service）、ADS（aggregated discovery service），其中ADS称为聚合的发现服务，是对CDS、RDS、LDS、EDS服务的统一封装，解决CDS、RDS、LDS、EDS信息更新顺序依赖的问题，从而保证以一定的顺序同步各类配置信息。以上Endpoint、Cluster、Route的概念介绍如下：<ul><li>Endpoint：一个具体的“应用实例”，类似于Kubernetes中的一个Pod；</li><li>Cluster：可以理解“应用集群”，对应提供相同服务的一个或多个Endpoint， 类似Kubernetes中Service概念，即一个Service提供多个相同服务的Pod；</li><li>Route：当我们做金丝雀发布部署时，同一个服务会有多个版本，这时需要Route规则规定请求如何路由到其中的某个版本上。</li></ul></li></ul><p>xDS模块的功能是通过Envoy API V1（基于HTTP）或V2（基于gRPC）实现一个服务端将配置信息暴露给上游主机，等待上游主机的拉取。</p><p>Envoy正常的工作流程为Host A（下游主机）发送请求至上游主机（Host B、Host C、Host D等），Envoy通过Listener监听到有下游主机的请求，收到请求后的Envoy将所有请求流量劫持至Envoy内部，并将请求内容抽象为Filter Chains路由至某个上游主机中从而实现路由转发及负载均衡能力。</p><p>Envoy为了实现流量代理能力通常需要一个统一的配置文件来记录信息以便启动时加载，在Envoy中启动配置文件有静态配置和动态配置两种方式。静态配置是将配置信息写入文件中，启动时直接加载，动态配置通过xDS实现一个Envoy的服务端（可以理解为以API接口对外实现服务发现能力）。</p><h3 id="Network-Topology"><a href="#Network-Topology" class="headerlink" title="Network Topology"></a>Network Topology</h3><p>Envoy作为Service Mesh中的 sidecar 代理，请求可以通过 ingress 或者 egress listener 到达 envoy。</p><ul><li>Ingress Listener 负责从服务网格中其他节点接受请求，并将请求转发到本地应用。本地应用的响应之后通过 Envoy 转发到 downstream。</li><li>Egress Listener 负责从本地应用接受请求，并将请求转发到服务网格中的其他节点。</li></ul><p><img alt="Service Mesh" data-src="https://www.envoyproxy.io/docs/envoy/latest/_images/lor-topology-service-mesh.svg"></p><p>除了服务网格外，Envoy还可以用作很多其他的请求，比如作为内部的负载均衡器：</p><p><img alt="Internal Load Balancer" data-src="https://www.envoyproxy.io/docs/envoy/latest/_images/lor-topology-ilb.svg"></p><p>或者作为网络边缘的 <code>ingress/egress</code> 代理：</p><p><img alt="Ingress/Egress Proxy on Network Edge" data-src="https://www.envoyproxy.io/docs/envoy/latest/_images/lor-topology-edge.svg"></p><p>在实际应用中，Envoy一般会发挥上述多种功能，一个网络请求路径中可能会通过多个Envoy：</p><p><img alt="Hybrid Envoy" data-src="https://www.envoyproxy.io/docs/envoy/latest/_images/lor-topology-hybrid.svg"></p><p>为了可靠性和可扩充性，Envoy可能会被配置成多层拓扑的形式：</p><p><img alt="Envoy Tiered" data-src="https://www.envoyproxy.io/docs/envoy/latest/_images/lor-topology-tiered.svg"></p><h3 id="High-Level-Architecture"><a href="#High-Level-Architecture" class="headerlink" title="High Level Architecture"></a>High Level Architecture</h3><p>Envoy中服务请求处理过程可以大致分为两个部分：</p><ul><li>Listener 子系统：处理来自 downstream 的请求。</li><li>Cluster 子系统：负责选择和配置 upstream 连接。</li></ul><p><img alt="High Level Architecture" data-src="https://www.envoyproxy.io/docs/envoy/latest/_images/lor-architecture.svg"></p><p>Envoy采用了基于事件的线程模型：</p><ul><li>一个主线程负责server的生命周期，配置处理，统计等</li><li>多个worker线程负责处理请求。</li></ul><p>所有的线程都运行在一个基于 <a href="https://libevent.org/" target="_blank" rel="external nofollow noopener noreferrer">libevent</a> 的事件循环中，任何 downstream 的 TCP连接都会被分配一个 work 线程来处理</p><h3 id="过滤器"><a href="#过滤器" class="headerlink" title="过滤器"></a>过滤器</h3><p>Envoy 进程中运行着一系列 <code>Inbound/Outbound</code> 监听器（Listener），<code>Inbound</code> 代理入站流量，<code>Outbound</code> 代理出站流量。Listener 的核心就是过滤器链（FilterChain），链中每个过滤器都能够控制流量的处理流程。过滤器链中的过滤器分为两个类别：</p><ul><li><strong>网络过滤器</strong>（Network Filters）: 工作在 <code>L3/L4</code>，是 Envoy 网络连接处理的核心，处理的是原始字节，分为 <code>Read</code>、<code>Write</code> 和 <code>Read/Write</code> 三类。</li><li><strong>HTTP 过滤器</strong>（HTTP Filters）: 工作在 <code>L7</code>，由特殊的网络过滤器 <code>HTTP connection manager</code> 管理，专门处理 <code>HTTP1/HTTP2/gRPC</code> 请求。它将原始字节转换成 <code>HTTP</code> 格式，从而可以对 <code>HTTP</code> 协议进行精确控制。</li></ul><p>除了 <code>HTTP connection manager</code> 之外，还有一种特别的网络过滤器叫 <code>Thrift Proxy</code>。<code>Thrift</code> 是一套包含序列化功能和支持服务通信的 RPC 框架，详情参考<a href="https://zh.wikipedia.org/wiki/Thrift" target="_blank" rel="external nofollow noopener noreferrer">维基百科</a>。Thrift Proxy 管理了两个 Filter：<a href="https://www.envoyproxy.io/docs/envoy/latest/configuration/other_protocols/thrift_filters/router_filter" target="_blank" rel="external nofollow noopener noreferrer">Router</a> 和 <a href="https://www.envoyproxy.io/docs/envoy/latest/configuration/other_protocols/thrift_filters/rate_limit_filter" target="_blank" rel="external nofollow noopener noreferrer">Rate Limit</a>。</p><p>除了过滤器链之外，还有一种过滤器叫<strong>监听器过滤器</strong>（Listener Filters），它会在过滤器链之前执行，用于操纵连接的<strong>元数据</strong>。这样做的目的是，无需更改 Envoy 的核心代码就可以方便地集成更多功能。例如，当监听的地址协议是 <code>UDP</code> 时，就可以指定 UDP 监听器过滤器。根据上面的分类，Envoy 过滤器的架构如下图所示：</p><p><img alt="img" data-src="https://cdn.jsdelivr.net/gh/yangchuansheng/imghosting/img/20200504224710.png"></p><h2 id="Request-Flow"><a href="#Request-Flow" class="headerlink" title="Request Flow"></a>Request Flow</h2><h3 id="Listener-TCP-Accept"><a href="#Listener-TCP-Accept" class="headerlink" title="Listener TCP Accept"></a>Listener TCP Accept</h3><p><img alt="Listener TCP Accept" data-src="https://www.envoyproxy.io/docs/envoy/latest/_images/lor-listeners.svg"></p><h3 id="Listener-filter-chains-and-network-filter-chain-matching"><a href="#Listener-filter-chains-and-network-filter-chain-matching" class="headerlink" title="Listener filter chains and network filter chain matching"></a>Listener filter chains and network filter chain matching</h3><p><img alt="Listener Filter Chains" data-src="https://www.envoyproxy.io/docs/envoy/latest/_images/lor-listener-filters.svg"></p><p><img alt="../_images/lor-filter-chain-match.svg" data-src="https://www.envoyproxy.io/docs/envoy/latest/_images/lor-filter-chain-match.svg"></p><h3 id="TLS-transport-socket-decryption"><a href="#TLS-transport-socket-decryption" class="headerlink" title="TLS transport socket decryption"></a>TLS transport socket decryption</h3><p><img alt="../_images/lor-transport-socket.svg" data-src="https://www.envoyproxy.io/docs/envoy/latest/_images/lor-transport-socket.svg"></p><h3 id="Network-filter-chain-processing"><a href="#Network-filter-chain-processing" class="headerlink" title="Network filter chain processing"></a>Network filter chain processing</h3><p><img alt="../_images/lor-network-filters.svg" data-src="https://www.envoyproxy.io/docs/envoy/latest/_images/lor-network-filters.svg"></p><p><img alt="../_images/lor-network-read.svg" data-src="https://www.envoyproxy.io/docs/envoy/latest/_images/lor-network-read.svg"></p><p><img alt="../_images/lor-network-write.svg" data-src="https://www.envoyproxy.io/docs/envoy/latest/_images/lor-network-write.svg"></p><h3 id="HTTP-2-codec-encoding"><a href="#HTTP-2-codec-encoding" class="headerlink" title="HTTP/2 codec encoding"></a>HTTP/2 codec encoding</h3><h3 id="TLS-transport-socket-encryption"><a href="#TLS-transport-socket-encryption" class="headerlink" title="TLS transport socket encryption"></a>TLS transport socket encryption</h3><p><img alt="../_images/lor-http-filters.svg" data-src="https://www.envoyproxy.io/docs/envoy/latest/_images/lor-http-filters.svg"></p><p><img alt="../_images/lor-http.svg" data-src="https://www.envoyproxy.io/docs/envoy/latest/_images/lor-http.svg"></p><p><img alt="../_images/lor-http-decode.svg" data-src="https://www.envoyproxy.io/docs/envoy/latest/_images/lor-http-decode.svg"></p><p><img alt="../_images/lor-http-encode.svg" data-src="https://www.envoyproxy.io/docs/envoy/latest/_images/lor-http-encode.svg"></p><p><img alt="../_images/lor-route-config.svg" data-src="https://www.envoyproxy.io/docs/envoy/latest/_images/lor-route-config.svg"></p><h3 id="Load-Balancing"><a href="#Load-Balancing" class="headerlink" title="Load Balancing"></a>Load Balancing</h3><p><img alt="../_images/lor-lb.svg" data-src="https://www.envoyproxy.io/docs/envoy/latest/_images/lor-lb.svg"></p><h3 id="Response-path-and-HTTP-lifecycle"><a href="#Response-path-and-HTTP-lifecycle" class="headerlink" title="Response path and HTTP lifecycle"></a>Response path and HTTP lifecycle</h3><p><img alt="../_images/lor-client.svg" data-src="https://www.envoyproxy.io/docs/envoy/latest/_images/lor-client.svg"></p><h3 id="Post-request-processing"><a href="#Post-request-processing" class="headerlink" title="Post-request processing"></a>Post-request processing</h3><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://developer.aliyun.com/article/606655" target="_blank" rel="external nofollow noopener noreferrer">https://developer.aliyun.com/article/606655</a></li><li><a href="https://www.cnblogs.com/popsuper1982/p/9841978.html" target="_blank" rel="external nofollow noopener noreferrer">https://www.cnblogs.com/popsuper1982/p/9841978.html</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;code&gt;Envoy&lt;/code&gt; 是一款由 Lyft 开源的高性能数据和服务代理软件，使用现代 C++ 开发，提供四层和七层网络代理能力。尽管在设计之初 &lt;code&gt;Envoy&lt;/code&gt;没有将性能作为最终的目标，而是更加强调模块化、易测试、易开发等特性，可它仍旧拥有足可媲美 Nginx 等经典代理软件的超高性能。在保证性能的同时，&lt;code&gt;Envoy&lt;/code&gt;也提供了强大的流量治理能力和可观察性。其独创的 xDS 协议则成为了构建 Service Mesh 通用数据面 API（UPDA）的基石。&lt;/p&gt;
    
    </summary>
    
    <content src="http://houmin.cc/https://cdn.jsdelivr.net/gh/yangchuansheng/imghosting/img/20200504160047.png" type="image" />
    
    
      <category term="术业专攻" scheme="http://houmin.cc/categories/%E6%9C%AF%E4%B8%9A%E4%B8%93%E6%94%BB/"/>
    
    
      <category term="网络" scheme="http://houmin.cc/tags/%E7%BD%91%E7%BB%9C/"/>
    
      <category term="envoy" scheme="http://houmin.cc/tags/envoy/"/>
    
  </entry>
  
  <entry>
    <title>【Service Mesh】Istio 流量控制</title>
    <link href="http://houmin.cc/posts/151719f0/"/>
    <id>http://houmin.cc/posts/151719f0/</id>
    <published>2020-11-24T08:47:28.000Z</published>
    <updated>2020-12-02T11:40:50.219Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>流量控制是指对系统流量的管控，包括了对网格入口的流量、网格出口的流量以及在网格内部微服务间相互调用流量的控制。在 <a href="../22cae0b8">Istio 入门</a> 中我们知道，Istio 架构在逻辑上分为 Control plane 和 Data plane，Control plane 负责整体管理和配置代理， Data plane 负责网格内所有微服务间的网络通信，同时还收集报告网络请求的遥测数据等。流量控制是在 Data plane 层实现。</p><a id="more"></a><p><img alt="Istio Architecture" data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-09-10_istio-arch.svg"></p><h2 id="路由和流量转移"><a href="#路由和流量转移" class="headerlink" title="路由和流量转移"></a>路由和流量转移</h2><p>Istio 为了控制服务请求，引入了服务版本（version）的概念，可以通过版本这一标签将服务进行区分。版本的设置是非常灵活的，以下是几种典型的设置方式：</p><ul><li>根据服务的迭代编号进行定义（如 v1、v2 版本）</li><li>根据部署环境进行定义（比如 dev、staging、production）</li><li>自定义的任何用于区分服务的某种标记</li></ul><p>通过版本标签，Istio 就可以定义灵活的路由规则来控制流量，上面提到的金丝雀发布这类应用场景就很容易实现了。</p><p>下图展示了使用服务版本实现路由分配的例子。服务版本定义了版本号（v1.5、v2.0-alpha）和环境（us-prod、us-staging）两种信息。服务 B 包含了 4 个 Pod，其中 3 个是部署在生产环境的 v1.5 版本，而 Pod4 是部署在预生产环境的 v2.0-alpha 版本。运维人员可以根据服务版本来指定路由规则，使 99% 的流量流向 v1.5 版本，而 1% 的流量进入 v2.0-alpha 版本。</p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-11-20_istio-routing.png"></p><p>除了上面介绍的服务间流量控制外，还能控制与网格边界交互的流量。可以在系统的入口和出口处部署 Sidecar 代理，让所有流入和流出的流量都由代理进行转发。负责入和出的代理就叫做入口网关和出口网关，它们把守着进入和流出网格的流量。下图展示了 Ingress 和 Egress 在请求流中的位置，有了他们俩，也就可以控制出入网格的流量了。</p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-11-20_istio-gateway.png"></p><p>Istio 还能设置流量策略。比如可以对连接池相关的属性进行设置，通过修改最大连接等参数，实现对请求负载的控制。还可以对负载均衡策略进行设置，在轮询、随机、最少访问等方式之间进行切换。还能设置异常探测策略，将满足异常条件的实例从负载均衡池中摘除，以保证服务的稳定性。</p><hr><p>Istio 的流量路由规则可以让您很容易的控制服务之间的流量和 API 调用。Istio 在服务层面提供了断路器，超时，重试等功能，通过这些功能可以简单地实现 A/B 测试，金丝雀发布，基于百分比的流量分割等，此外还提供了开箱即用的故障恢复功能，用于增加应用的健壮性，以应对服务故障或网络故障。这些功能都可以通过 Istio 的流量管理 API 添加流量配置来实现。</p><p>跟其他 Istio 配置一样，流量管理 API 也使用 CRD 指定。本小节主要介绍下面几个典型的流量管理 API 资源，以及这些 API 的功能和使用示例。</p><h3 id="VirtualService"><a href="#VirtualService" class="headerlink" title="VirtualService"></a>VirtualService</h3><p>VirtualService 由一组 <strong>路由规则</strong> 组成，描述了 <strong>用户请求的目标地址</strong> 到 <strong>服务网格中实际工作负载</strong> 之间的映射。在这个映射中，VirtualService提供了丰富的配置方式，可以为发送到这些 Workloads 的流量指定不同的路由规则。对应于具体的配置，用户请求的目标地址用 <code>hosts</code> 字段来表示，网格内的实际负载由每个 <code>route</code> 配置项中的 <code>destination</code> 字段指定。</p><pre class="mermaid">graph LRsubgraph VirtualServiceClientRequests -- DifferentTrafficRoutingRules --> DestinationWorkloadsHosts -- DifferentTrafficRoutingRules --> RouteDestinationend</pre><p>VirtualService 通过解耦 <strong>用户请求的目标地址</strong> 和 <strong>真实响应请求的目标工作负载</strong>，为服务提供了合适的统一抽象层，而由此演化设计的配置模型为管理这方面提供了一致的环境。对于原生 Kubernetes 而言，只有在 Ingress 处有这种路由规则的定义，对于集群内部不同Service的不同版本之间，并没有类似 VirtualService 的定义。</p><p>使用 VirtualService，可以为一个或多个主机名指定流量行为。在 VirtualService 中使用路由规则，告诉 Envoy如何发送 VirtualService 的流量到适当的目标。路由目标可以是相同服务的不同版本，或者是完全不同的服务。</p><p>一个典型的应用场景是将流量发送到被指定为服务子集的服务的不同版本。客户端将 VirtualService 视为一个单一实体，将请求发送至 VirtualService 主机，然后 Envoy 根据 VirtualService 规则把流量路由到不同的版本中。</p><p>这种方式可以方便地创建一种金丝雀的发布策略实现新版本流量的平滑比重升级。流量路由完全独立于实例部署，这意味着实现新版本服务的实例可以根据流量的负载来伸缩，完全不影响流量路由。相比之下，类似 Kubernetes 的容器调度平台仅支持基于部署中实例扩缩容比重的流量分发，那样会日趋复杂化。关于使用VirtualService实现金丝雀部署，可以参考 <a href="https://istio.io/latest/blog/2017/0.1-canary/" target="_blank" rel="external nofollow noopener noreferrer">Canary</a> 。</p><p>VirtualService 也提供了如下功能。</p><ul><li>通过单个 VirtualService 处理多个应用程序服务。例如，如果您的服务网格使用是 Kubernetes，您可以配置一个 VirtualService 来处理一个特定命名空间的所有服务。将单一的 VirtualService 映射为多个“真实”的服务特别有用，可以在不需要客户适应转换的情况下，将单体应用转换为微服务构建的复合应用系统。您的路由规则可以指定“请求到 <code>monolith.com</code> 的 URLs 跳转至 <code>microservice A</code> 中”。</li><li>和 Gateway  一起配置流量规则来控制入口和出口流量。</li></ul><p>在一些应用场景中，由于指定服务子集，需要配置 DestinationRule 来使用这些功能。在不同的对象中指定服务子集以及其他特定的目标策略可以帮助您在不同的 VirtualService 中清晰地复用这些功能。</p><p>下面的 VirtualService 根据是否来自于特定用户路由请求到不同的服务版本中（如果请求来自用户 <code>jason</code> ，则访问 <code>v2</code> 版本的 <code>reviews</code>，否则访问 <code>v3</code> 版本）：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1alpha3</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">VirtualService</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">reviews</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">reviews</span></span><br><span class="line">  <span class="attr">http:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">match:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">headers:</span></span><br><span class="line">        <span class="attr">end-user:</span></span><br><span class="line">          <span class="attr">exact:</span> <span class="string">jason</span></span><br><span class="line">    <span class="attr">route:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">destination:</span></span><br><span class="line">        <span class="attr">host:</span> <span class="string">reviews</span></span><br><span class="line">        <span class="attr">subset:</span> <span class="string">v2</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">route:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">destination:</span></span><br><span class="line">        <span class="attr">host:</span> <span class="string">reviews</span></span><br><span class="line">        <span class="attr">subset:</span> <span class="string">v3</span></span><br></pre></td></tr></table></figure><p>下面对这些字段依次解释：</p><h4 id="Hosts"><a href="#Hosts" class="headerlink" title="Hosts"></a>Hosts</h4><p>用来配置 Downstream 访问的可寻址地址，也就是用户请求的目标地址。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">hosts:</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">reviews</span></span><br></pre></td></tr></table></figure><ul><li>VirtualService 主机名可以是 IP 地址、 DNS 域名、完全限定域名（FQDN)</li><li>也可以是 依赖于平台的一个简称（例如 Kubernetes 服务的短名称）</li><li>也可以使用通配符 <code>*</code>前缀，创建一组匹配所有服务的路由规则</li><li>VirtualService 的 <code>hosts</code> 实际上不必是 Istio 服务注册的一部分，它只是虚拟的目标地址。这可以为没有路由到网格内部的虚拟主机建模。</li></ul><h4 id="路由规则"><a href="#路由规则" class="headerlink" title="路由规则"></a>路由规则</h4><p><code>http</code> 字段用来配置路由规则，通常情况下配置一组路由规则，当请求到来时，自上而下依次进行匹配，直到匹配成功后跳出匹配。它可以对请求的 uri、method、authority、headers、port、queryParams 以及是否对 uri 大小写敏感等进行配置。</p><blockquote><p>除了HTTP协议，也可以使用 <code>tcp</code> 和 <code>tls</code> 片段为 <a href="https://istio.io/latest/docs/reference/config/networking/virtual-service/#TCPRoute" target="_blank" rel="external nofollow noopener noreferrer">TCP</a> 和未终止的 <a href="https://istio.io/docs/reference/config/networking/virtual-service/#TLSRoute" target="_blank" rel="external nofollow noopener noreferrer">TLS</a> 流量设置路由规则</p></blockquote><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">http:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">match:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">headers:</span></span><br><span class="line">      <span class="attr">end-user:</span></span><br><span class="line">        <span class="attr">exact:</span> <span class="string">jason</span></span><br><span class="line">  <span class="attr">route:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">destination:</span></span><br><span class="line">      <span class="attr">host:</span> <span class="string">reviews</span></span><br><span class="line">      <span class="attr">subset:</span> <span class="string">v2</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">route:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">destination:</span></span><br><span class="line">      <span class="attr">host:</span> <span class="string">reviews</span></span><br><span class="line">      <span class="attr">subset:</span> <span class="string">v3</span></span><br></pre></td></tr></table></figure><p>我们推荐在每个 VirtualService 中配置一条默认「无条件的」或者基于权重的规则以确保 VirtualService 至少有一条匹配的路由。</p><h5 id="Destination"><a href="#Destination" class="headerlink" title="Destination"></a>Destination</h5><p>路由片段的 <code>destination</code> 字段指定符合匹配条件的流量目标地址。这里不像 VirtualService 的 <code>hosts</code>，Destination 的 <code>host</code> 必须是存在于 Istio 服务注册中心的实际目标地址，否则 Envoy 不知道该将请求发送到哪里。这个目标地址可以是代理的网格服务或者作为服务入口加入的非网格服务。下面的场景中我们运行在 Kubernetes 平台上，主机名是 Kubernetes 的服务名。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">route:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">destination:</span></span><br><span class="line">    <span class="attr">host:</span> <span class="string">reviews</span></span><br><span class="line">    <span class="attr">subset:</span> <span class="string">v2</span></span><br></pre></td></tr></table></figure><blockquote><figure class="highlight gams"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">*Note for Kubernetes users*: When short names are used (e.g. "reviews" instead of "reviews.default.svc.cluster.local"), Istio will interpret the short name based on the namespace of the rule, not the service. A rule in the "default" namespace containing a host "reviews will be interpreted as "reviews.default.svc.cluster.local", irrespective of the actual namespace associated with the reviews service. To avoid potential misconfiguration, it is recommended to always use fully qualified domain names over short names.</span></span><br></pre></td></tr></table></figure></blockquote><h5 id="Match"><a href="#Match" class="headerlink" title="Match"></a>Match</h5><p>路由规则是将特定流量子集路由到特定目标地址的强大工具。可以在流量端口、<code>header</code> 字段、 URL 等内容上设置匹配条件。例如，下面的VirtualService 使用户发送流量到两个独立的服务，ratings and reviews， 就好像它们是 <code>http://bookinfo.com/</code> 这个更大的 VirtualService 的一部分。VirtualService 规则根据请求的 URL 和指向适当服务的请求匹配流量。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1alpha3</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">VirtualService</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">bookinfo</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">bookinfo.com</span></span><br><span class="line">  <span class="attr">http:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">match:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">uri:</span></span><br><span class="line">        <span class="attr">prefix:</span> <span class="string">/reviews</span></span><br><span class="line">    <span class="attr">route:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">destination:</span></span><br><span class="line">        <span class="attr">host:</span> <span class="string">reviews</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">match:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">uri:</span></span><br><span class="line">        <span class="attr">prefix:</span> <span class="string">/ratings</span></span><br><span class="line">    <span class="attr">route:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">destination:</span></span><br><span class="line">        <span class="attr">host:</span> <span class="string">ratings</span></span><br></pre></td></tr></table></figure><p>对于匹配条件，您可以使用确定的值，一条前缀、或者一条正则表达式。</p><p>您可以使用 <code>AND</code> 向同一个 <code>match</code> 块添加多个匹配条件， 或者使用 <code>OR</code> 向同一个规则添加多个 <code>match</code> 块。对于任意给定的 VirtualService ，您可以配置多条路由规则。这可以使您的路由条件在一个单独的 VirtualService 中基于业务场景的复杂度来进行相应的配置。可以在 <a href="https://istio.io/docs/reference/config/networking/virtual-service/#HTTPMatchRequest" target="_blank" rel="external nofollow noopener noreferrer">HTTPMatchRequest 参考</a>中查看匹配条件字段和他们可能的值。</p><p>再者进一步使用匹配条件，您可以使用基于“权重”百分比分发流量。这在 A/B 测试和金丝雀部署中非常有用。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">reviews</span></span><br><span class="line">  <span class="attr">http:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">route:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">destination:</span></span><br><span class="line">        <span class="attr">host:</span> <span class="string">reviews</span></span><br><span class="line">        <span class="attr">subset:</span> <span class="string">v1</span></span><br><span class="line">      <span class="attr">weight:</span> <span class="number">75</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">destination:</span></span><br><span class="line">        <span class="attr">host:</span> <span class="string">reviews</span></span><br><span class="line">        <span class="attr">subset:</span> <span class="string">v2</span></span><br><span class="line">      <span class="attr">weight:</span> <span class="number">25</span></span><br></pre></td></tr></table></figure><p>您也可以使用路由规则在流量上执行一些操作，例如</p><ul><li>扩展或者删除 <code>headers</code></li><li>重写 URL</li><li>为调用这个目标地址设置重试策略</li></ul><h3 id="DestinationRule"><a href="#DestinationRule" class="headerlink" title="DestinationRule"></a>DestinationRule</h3><p><code>DestinationRule</code> 是 Istio 流量路由功能的重要组成部分。一个 <code>VirtualService</code> 可以看作是如何将流量分发到给定的目标地址，然后调用 <code>DestinationRule</code> 来配置分发到该目标地址的流量。<code>DestinationRule</code> 在 <code>VirtualService</code> 的路由规则之后起作用(即在 <code>VirtualService</code> 的 <code>match</code> -&gt; <code>route</code> -&gt; <code>destination</code> 之后起作用，此时流量已经分发到真实的 <code>Service</code> 上)，应用于真实的目标地址。</p><p>特别地，可以使用 <code>DestinationRule</code> 来指定命名的服务子集，例如根据版本对服务的实例进行分组，然后通过 <code>VirtualService</code> 的路由规则中的服务子集将控制流量分发到不同服务的实例中。</p><p><code>DestinationRule</code> 允许在调用完整的目标服务或特定的服务子集(如倾向使用的负载均衡模型，TLS 安全模型或断路器)时自定义 Envoy流量策略。Istio 默认会使用轮询策略，此外 Istio 也支持如下负载均衡模型，可以在 <code>DestinationRule</code> 中使用这些模型，将请求分发到特定的服务或服务子集。</p><ul><li>Random：将请求转发到一个随机的实例上</li><li>Weighted：按照指定的百分比将请求转发到实例上</li><li>Least requests：将请求转发到具有最少请求数目的实例上</li></ul><p>下面的 <code>DestinationRule</code> 使用不同的负载均衡策略为 my-svc 目的服务配置了3个不同的 Subset</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1alpha3</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">DestinationRule</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">my-destination-rule</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">host:</span> <span class="string">my-svc</span></span><br><span class="line">  <span class="attr">trafficPolicy:</span>     <span class="comment">#默认的负载均衡策略模型为随机</span></span><br><span class="line">    <span class="attr">loadBalancer:</span></span><br><span class="line">      <span class="attr">simple:</span> <span class="string">RANDOM</span></span><br><span class="line">  <span class="attr">subsets:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">v1</span>  <span class="comment">#subset1，将流量转发到具有标签 version:v1 的 deployment 对应的服务上</span></span><br><span class="line">    <span class="attr">labels:</span></span><br><span class="line">      <span class="attr">version:</span> <span class="string">v1</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">v2</span>  <span class="comment">#subset2，将流量转发到具有标签 version:v2 的 deployment 对应的服务上,指定负载均衡为轮询</span></span><br><span class="line">    <span class="attr">labels:</span></span><br><span class="line">      <span class="attr">version:</span> <span class="string">v2</span></span><br><span class="line">    <span class="attr">trafficPolicy:</span></span><br><span class="line">      <span class="attr">loadBalancer:</span></span><br><span class="line">        <span class="attr">simple:</span> <span class="string">ROUND_ROBIN</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">v3</span>   <span class="comment">#subset3，将流量转发到具有标签 version:v3 的 deployment 对应的服务上</span></span><br><span class="line">    <span class="attr">labels:</span></span><br><span class="line">      <span class="attr">version:</span> <span class="string">v3</span></span><br></pre></td></tr></table></figure><p>每个子集由一个或多个 <code>labels</code> 定义，对应 Kubernetes 中的对象(如 <code>Pod</code> )的 key/value 对。这些标签定义在 Kubernetes 服务的 deployment 的 metadata 中，用于标识不同的版本。</p><p>除了定义子集外，<code>DestinationRule</code> 还定义了该目的地中所有子集的默认流量策略，以及仅覆盖该子集的特定策略。默认的策略定义在 <code>subset</code> 字段之上，为 <code>v1</code> 和 <code>v3</code> 子集设置了随机负载均衡策略，在 <code>v2</code> 策略中使用了轮询负载均衡。</p><h3 id="Gateway"><a href="#Gateway" class="headerlink" title="Gateway"></a>Gateway</h3><p>Gateway 用于管理进出网格的流量，指定可以进入或离开网格的流量。Gateway 配置应用于网格边缘的独立的 Envoy代理上，而不是服务负载的 Envoy 代理上。</p><p>与其他控制进入系统的流量的机制(如 Kubernetes Ingress API)不同，Istio gateway 允许利用 Istio 的流量路由的强大功能和灵活性。Istio 的 gateway 资源仅允许配置 4-6 层的负载属性，如暴露的端口，TLS 配置等等，但结合 Istio 的 <code>VirtualService</code>，就可以像管理 Istio 网格中的其他数据面流量一样管理 Gateway 的流量。</p><p>Gateway 主要用于管理 Ingress 流量，但也可以配置 Egress Gateway。通过 Egress Gateway 可以配置流量离开网格的特定节点，限制哪些服务可以访问外部网络，或通过 Egress 安全控制来提高网格的安全性。Gateway 可以用于配置为一个纯粹的内部代理。</p><p>Istio (通过 <code>istio-ingressgateway</code> 和 <code>istio-egressgateway</code> 参数)提供了一些预配置的 Gateway 代理，<code>default</code> profile 下仅会部署 Ingress Gateway。Gateway 可以通过部署文件进行部署，也可以单独部署。</p><p>下面是 <code>default</code> profile 默认安装的 Ingress</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get gw</span><br><span class="line">NAME               AGE</span><br><span class="line">bookinfo-gateway   28h</span><br></pre></td></tr></table></figure><p>可以看到该 ingress 就是一个普通的 <code>Pod</code>，该 <code>Pod</code> 仅包含一个 Istio-proxy 容器</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get pod -n istio-system |grep ingress</span><br><span class="line">istio-ingressgateway-64f6f9d5c6-qrnw2 1/1 Running 0 4d20h</span><br></pre></td></tr></table></figure><p>下面是一个 Gateway 的例子，用于配置外部 HTTPS 的 ingress 流量：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1alpha3</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Gateway</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ext-host-gwy</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span>              <span class="comment">#指定 gateway 配置下发的代理，如具有标签 app: my-gateway-controller 的 pod</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">my-gateway-controller</span></span><br><span class="line">  <span class="attr">servers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span>                <span class="comment">#gateway pod 暴露的端口信息</span></span><br><span class="line">      <span class="attr">number:</span> <span class="number">443</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">https</span></span><br><span class="line">      <span class="attr">protocol:</span> <span class="string">HTTPS</span></span><br><span class="line">    <span class="attr">hosts:</span>                <span class="comment">#外部流量</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">ext-host.example.com</span></span><br><span class="line">    <span class="attr">tls:</span></span><br><span class="line">      <span class="attr">mode:</span> <span class="string">SIMPLE</span></span><br><span class="line">      <span class="attr">serverCertificate:</span> <span class="string">/tmp/tls.crt</span></span><br><span class="line">      <span class="attr">privateKey:</span> <span class="string">/tmp/tls.key</span></span><br></pre></td></tr></table></figure><p>上述 Gateway 配置允许来自 <code>ext-host.example.com</code> 流量进入网格的 443 端口，但没有指定该流量的路由。(此时流量只能进入网格，但没有指定处理该流量的服务，因此需要与 <code>VirtualService</code> 进行绑定)</p><p>为了为 Gateway 指定路由，需要通过 <code>VirtualService</code> 的 <code>Gateway</code> 字段，将 <code>Gateway</code> 绑定到一个 <code>VirtualService</code> 上，将来自 <code>ext-host.example.com</code> 流量引入一个 <code>VirtualService</code>，<code>hosts</code> 可以是通配符，表示引入匹配到的流量。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1alpha3</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">VirtualService</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">virtual-svc</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">ext-host.example.com</span></span><br><span class="line">  <span class="attr">gateways:</span>        <span class="comment">#将 gateway "ext-host-gwy" 绑定到 virtual service "virtual-svc"上</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">ext-host-gwy</span></span><br></pre></td></tr></table></figure><p>Egress Gateway 提供了对网格的出口流量进行统一管控的功能，在安装 Istio 时默认是不开启的。可以使用以下命令查看是否开启。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl get pod -l istio=egressgateway -n istio-system</span></span><br></pre></td></tr></table></figure><p>若没有开启，使用以下命令添加。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ istioctl manifest apply --<span class="built_in">set</span> values.global.istioNamespace=istio-system \</span><br><span class="line">    --<span class="built_in">set</span> values.gateways.istio-egressgateway.enabled=<span class="literal">true</span></span><br></pre></td></tr></table></figure><p>Egress Gateway 的一个简单示例如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1alpha3</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Gateway</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">istio-egressgateway</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">istio:</span> <span class="string">egressgateway</span></span><br><span class="line">  <span class="attr">servers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span></span><br><span class="line">      <span class="attr">number:</span> <span class="number">80</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">http</span></span><br><span class="line">      <span class="attr">protocol:</span> <span class="string">HTTP</span></span><br><span class="line">    <span class="attr">hosts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">edition.cnn.com</span></span><br></pre></td></tr></table></figure><p>可以看出，与 Ingress Gateway 不同，Egress Gateway 使用有 <code>istio: egressgateway</code> 标签的 Pod 来代理流量，实际上这也是一个 Envoy 代理。当网格内部需要访问 <code>edition.cnn.com</code> 这个地址时，流量将会统一先转发到 Egress Gateway 上，再由 Egress Gateway 将流量转发到 <code>edition.cnn.com</code> 上。</p><h3 id="ServiceEntry"><a href="#ServiceEntry" class="headerlink" title="ServiceEntry"></a>ServiceEntry</h3><p>Istio 支持对接 Kubernetes、Consul 等多种不同的注册中心，控制平面<code>Pilot</code>启动时，会从指定的注册中心获取 <code>Service Mesh</code> 集群的服务信息和实例列表，并将这些信息进行处理和转换，然后通过 xDS 下发给对应的数据平面，保证服务之间可以互相发现并正常访问。</p><p>同时，由于这些服务和实例信息都来源于服务网格内部，Istio 无法从注册中心直接获取网格外的服务，导致不利于网格内部与外部服务之间的通信和流量管理。为此，Istio 引入 ServiceEntry 实现对外通信和管理。</p><p>使用 ServiceEntry 可以将外部的服务条目添加到 Istio 内部的服务注册表中，以便让网格中的服务能够访问并路由到这些手动指定的服务。ServiceEntry 描述了服务的属性（DNS 名称、VIP、端口、协议、端点）。这些服务可能是位于网格外部（如，web APIs），也可能是处于网格内部但不属于平台服务注册表中的条目（如，需要和 Kubernetes 服务交互的一组虚拟机服务）。</p><h4 id="ServiceEntry-示例和属性介绍"><a href="#ServiceEntry-示例和属性介绍" class="headerlink" title="ServiceEntry 示例和属性介绍"></a>ServiceEntry 示例和属性介绍</h4><p>对于网格外部的服务，下面的 ServiceEntry 示例表示网格内部的应用通过 https 访问外部的 API。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1alpha3</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ServiceEntry</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">google</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">www.google.com</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">number:</span> <span class="number">443</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">https</span></span><br><span class="line">    <span class="attr">protocol:</span> <span class="string">HTTPS</span></span><br><span class="line">  <span class="attr">resolution:</span> <span class="string">DNS</span></span><br><span class="line">  <span class="attr">location:</span> <span class="string">MESH_EXTERNAL</span></span><br></pre></td></tr></table></figure><p>对于在网格内部但不属于平台服务注册表的服务，使用下面的示例可以将一组在非托管 VM 上运行的 MongoDB 实例添加到 Istio 的注册中心，以便可以将这些服务视为网格中的任何其他服务。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1alpha3</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ServiceEntry</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">external-svc-mongocluster</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">mymongodb.somedomain</span></span><br><span class="line">  <span class="attr">addresses:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="number">192.192</span><span class="number">.192</span><span class="number">.192</span><span class="string">/24</span> <span class="comment"># VIPs</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">number:</span> <span class="number">27018</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">mongodb</span></span><br><span class="line">    <span class="attr">protocol:</span> <span class="string">MONGO</span></span><br><span class="line">  <span class="attr">location:</span> <span class="string">MESH_INTERNAL</span></span><br><span class="line">  <span class="attr">resolution:</span> <span class="string">STATIC</span></span><br><span class="line">  <span class="attr">endpoints:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">address:</span> <span class="number">2.2</span><span class="number">.2</span><span class="number">.2</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">address:</span> <span class="number">3.3</span><span class="number">.3</span><span class="number">.3</span></span><br></pre></td></tr></table></figure><p>结合上面给出的示例，这里对 ServiceEntry 涉及的关键属性解释如下：</p><ul><li><code>hosts</code>: 表示与该 ServiceEntry 相关的主机名，可以是带有通配符前缀的 DNS 名称。</li><li><code>address</code>: 与服务相关的虚拟 IP 地址，可以是 CIDR 前缀的形式。</li><li><code>ports</code>: 和外部服务相关的端口，如果外部服务的 endpoints 是 Unix socket 地址，这里必须只有一个端口。</li><li><code>location</code>: 用于指定该服务属于网格内部（MESH_INTERNAL）还是外部（MESH_EXTERNAL）。</li><li><code>resolution</code>: 主机的服务发现模式，可以是 NONE、STATIC、DNS。</li><li><code>endpoints</code>: 与服务相关的一个或多个端点。</li><li><code>exportTo</code>: 用于控制 ServiceEntry 跨命名空间的可见性，这样就可以控制在一个命名空间下定义的资源对象是否可以被其他命名空间下的 <code>Sidecar</code>、Gateway 和 VirtualService 使用。目前支持两种选项，”.” 表示仅应用到当前命名空间，”*” 表示应用到所有命名空间。</li></ul><h4 id="使用-ServiceEntry-访问外部服务"><a href="#使用-ServiceEntry-访问外部服务" class="headerlink" title="使用 ServiceEntry 访问外部服务"></a>使用 ServiceEntry 访问外部服务</h4><p>Istio 提供了三种访问外部服务的方法：</p><ol><li>允许 <code>Sidecar</code> 将请求传递到未在网格内配置过的任何外部服务。使用这种方法时，无法监控对外部服务的访问，也不能利用 Istio 的流量控制功能。</li><li>配置 ServiceEntry 以提供对外部服务的受控访问。这是 Istio 官方推荐使用的方法。</li><li>对于特定范围的 IP，完全绕过 <code>Sidecar</code>。仅当出于性能或其他原因无法使用 <code>Sidecar</code> 配置外部访问时，才建议使用该配置方法。</li></ol><p>这里，我们重点讨论第 2 种方式，也就是使用 ServiceEntry 完成对网格外部服务的受控访问。</p><p>对于 <code>Sidecar</code> 对外部服务的处理方式，Istio 提供了两种选项:</p><ul><li><code>ALLOW_ANY</code>：默认值，表示 Istio 代理允许调用未知的外部服务。上面的第一种方法就使用了该配置项。</li><li><code>REGISTRY_ONLY</code>：Istio 代理会阻止任何没有在网格中定义的 HTTP 服务或 ServiceEntry 的主机。</li></ul><p>可以使用下面的命令查看当前所使用的模式:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get configmap istio -n istio-system -o yaml | grep -o <span class="string">"mode: ALLOW_ANY"</span></span><br><span class="line">mode: ALLOW_ANY</span><br></pre></td></tr></table></figure><p>如果当前使用的是 <code>ALLOW_ANY</code> 模式，可以使用下面的命令切换为 <code>REGISTRY_ONLY</code> 模式:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get configmap istio -n istio-system -o yaml | sed <span class="string">'s/mode: ALLOW_ANY/mode: REGISTRY_ONLY/g'</span> | kubectl replace -n istio-system -f -</span><br><span class="line">configmap <span class="string">"istio"</span> replaced</span><br></pre></td></tr></table></figure><p>在 <code>REGISTRY_ONLY</code> 模式下，需要使用 ServiceEntry 才能完成对外部服务的访问。当创建如下的 ServiceEntry 时，服务网格内部的应用就可以正常访问 httpbin.org 服务了。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1alpha3</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ServiceEntry</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">httpbin-ext</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">httpbin.org</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">number:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">http</span></span><br><span class="line">    <span class="attr">protocol:</span> <span class="string">HTTP</span></span><br><span class="line">  <span class="attr">resolution:</span> <span class="string">DNS</span></span><br><span class="line">  <span class="attr">location:</span> <span class="string">MESH_EXTERNAL</span></span><br></pre></td></tr></table></figure><h4 id="管理外部流量"><a href="#管理外部流量" class="headerlink" title="管理外部流量"></a>管理外部流量</h4><p>使用 ServiceEntry 可以使网格内部服务发现并访问外部服务，除此之外，还可以对这些到外部服务的流量进行管理。结合 VirtualService 为对应的 ServiceEntry 配置外部服务访问规则，如请求超时、故障注入等，实现对指定服务的受控访问。</p><p>下面的示例就是为外部服务 httpbin.org 设置了超时时间，当请求时间超过 3s 时，请求就会直接中断，避免因外部服务访问时延过高而影响内部服务的正常运行。由于外部服务的稳定性通常无法管控和监测，这种超时机制对内部服务的正常运行具有重要意义。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1alpha3</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">VirtualService</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">httpbin-ext</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">httpbin.org</span></span><br><span class="line">  <span class="attr">http:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">timeout:</span> <span class="string">3s</span></span><br><span class="line">    <span class="attr">route:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">destination:</span></span><br><span class="line">          <span class="attr">host:</span> <span class="string">httpbin.org</span></span><br><span class="line">        <span class="attr">weight:</span> <span class="number">100</span></span><br></pre></td></tr></table></figure><p>同样的，我们也可以为 ServiceEntry 设置故障注入规则，为系统测试提供基础。下面的示例表示为所有访问 <code>httpbin.org</code> 服务的请求注入一个403错误。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1alpha3</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">VirtualService</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"> <span class="attr">name:</span> <span class="string">httpbin-service</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"> <span class="attr">hosts:</span></span><br><span class="line"> <span class="bullet">-</span> <span class="string">httpbin.org</span></span><br><span class="line"> <span class="attr">http:</span></span><br><span class="line"> <span class="bullet">-</span> <span class="attr">route:</span></span><br><span class="line">   <span class="bullet">-</span> <span class="attr">destination:</span></span><br><span class="line">       <span class="attr">host:</span> <span class="string">httpbin.org</span></span><br><span class="line">   <span class="attr">fault:</span></span><br><span class="line">     <span class="attr">abort:</span></span><br><span class="line">       <span class="attr">percent:</span> <span class="number">100</span></span><br><span class="line">       <span class="attr">httpStatus:</span> <span class="number">403</span></span><br></pre></td></tr></table></figure><h3 id="Sidecar"><a href="#Sidecar" class="headerlink" title="Sidecar"></a>Sidecar</h3><p>在默认的情况下，Istio 中所有 Pod 中的 Envoy 代理都是可以被寻址的。然而在某些场景下，我们为了做资源隔离，希望只访问某些 Namespace 下的资源。这个时候，我们就可以使用 Sidecar配置来实现。下面是一个简单的示例：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1alpha3</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Sidecar</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">default</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">bookinfo</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">egress:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">hosts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">"./*"</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">"istio-system/*"</span></span><br></pre></td></tr></table></figure><p>该示例就规定了在命名空间为 bookinfo 下的所有服务仅可以访问本命名空间下的服务以及 <code>istio-system</code> 命名空间下的服务。</p><h2 id="弹性功能"><a href="#弹性功能" class="headerlink" title="弹性功能"></a>弹性功能</h2><p>除了最核心的路由和流量转移功能外，Istio 还提供了一定的弹性功能，目前支持超时、重试和熔断。</p><h3 id="Request-Timeouts"><a href="#Request-Timeouts" class="headerlink" title="Request Timeouts"></a>Request Timeouts</h3><p>如果程序请求长时间无法返回结果，则需要设置超时机制，超过设置的时间则返回错误信息。这样做既可以节约等待时消耗的资源，也可以避免由于级联错误引起的一系列问题。</p><p>设置超时的方式也有很多种，比如通过修改代码在应用程序侧设置请求超时时间，但是这样很不灵活，也容易出现遗漏的现象，而 Istio 则可以在基础设施层解决这一问题。在 Istio 里添加超时非常简单，只需要在路由配置里添加 <code>timeout</code> 这个关键字就可以实现。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1alpha3</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">VirtualService</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ratings</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">ratings</span></span><br><span class="line">  <span class="attr">http:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">route:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">destination:</span></span><br><span class="line">        <span class="attr">host:</span> <span class="string">ratings</span></span><br><span class="line">        <span class="attr">subset:</span> <span class="string">v1</span></span><br><span class="line">    <span class="attr">timeout:</span> <span class="string">10s</span></span><br></pre></td></tr></table></figure><h3 id="Retries"><a href="#Retries" class="headerlink" title="Retries"></a>Retries</h3><p>在网络环境不稳定的情况下，会出现暂时的网络不可达现象，这时需要重试机制，通过多次尝试来获取正确的返回信息。重试逻辑可以写业务代码中，比如 Bookinfo 应用中的<code>productpage</code>服务就存在硬编码重试，而 Istio 可以通过简单的配置来实现重试功能，让开发人员无需关注重试部分的代码实现，专心实现业务代码。在 Istio 里添加超时和重试都非常简单，只需要在路由配置里添 <code>retry</code> 这个关键字就可以实现。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1alpha3</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">VirtualService</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ratings</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">ratings</span></span><br><span class="line">  <span class="attr">http:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">route:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">destination:</span></span><br><span class="line">        <span class="attr">host:</span> <span class="string">ratings</span></span><br><span class="line">        <span class="attr">subset:</span> <span class="string">v1</span></span><br><span class="line">    <span class="attr">retries:</span></span><br><span class="line">      <span class="attr">attempts:</span> <span class="number">3</span></span><br><span class="line">      <span class="attr">perTryTimeout:</span> <span class="string">2s</span></span><br></pre></td></tr></table></figure><h3 id="Circuit-Breaking"><a href="#Circuit-Breaking" class="headerlink" title="Circuit Breaking"></a>Circuit Breaking</h3><p>熔断是一种非常有用的过载保护手段，可以避免服务的级联失败。在熔断器中，设置一个对服务中的单个主机调用的限制，例如并发连接的数量或对该主机调用失败的次数。一旦限制被触发，熔断器就会“跳闸”并停止连接到该主机。使用熔断模式可以快速失败而不必让客户端尝试连接到过载或有故障的主机。熔断适用于在负载均衡池中的“真实”网格目标地址，可以在 DestinationRule 中配置熔断器阈值，让配置适用于服务中的每个主机。</p><p>Istio 里面的熔断需要在自定义资源 <code>DestinationRule</code> 的 <code>TrafficPolicy</code> 里进行设置。下面的示例将 v1 子集的<code>reviews</code>服务工作负载的并发连接数限制为 100：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1alpha3</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">DestinationRule</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">reviews</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">host:</span> <span class="string">reviews</span></span><br><span class="line">  <span class="attr">subsets:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">v1</span></span><br><span class="line">    <span class="attr">labels:</span></span><br><span class="line">      <span class="attr">version:</span> <span class="string">v1</span></span><br><span class="line">    <span class="attr">trafficPolicy:</span></span><br><span class="line">      <span class="attr">connectionPool:</span></span><br><span class="line">        <span class="attr">tcp:</span></span><br><span class="line">          <span class="attr">maxConnections:</span> <span class="number">100</span></span><br></pre></td></tr></table></figure><h2 id="调试能力"><a href="#调试能力" class="headerlink" title="调试能力"></a>调试能力</h2><p>Istio 还提供了对流量进行调试的能力，包括故障注入和流量镜像。对流量进行调试可以让系统具有更好的容错能力，也方便我们在问题排查时通过调试来快速定位原因所在。</p><h3 id="Fault-Injection"><a href="#Fault-Injection" class="headerlink" title="Fault Injection"></a>Fault Injection</h3><p>在一个微服务架构的系统中，为了让系统达到较高的健壮性要求，通常需要对系统做定向错误测试。比如电商中的订单系统、支付系统等若出现故障那将是非常严重的生产事故，因此必须在系统设计前期就需要考虑多样性的异常故障并对每一种异常设计完善的恢复策略或优雅的回退策略，尽全力规避类似事故的发生，使得当系统发生故障时依然可以正常运作。而在这个过程中，服务故障模拟一直以来是一个非常繁杂的工作，于是在这样的背景下就衍生出了故障注入技术手段，故障注入是用来模拟上游服务请求响应异常行为的一种手段。通过人为模拟上游服务请求的一些故障信息来检测下游服务的故障策略是否能够承受这些故障并进行自我恢复。</p><p>Istio 提供了一种无侵入式的故障注入机制，让开发测试人员在不用调整服务程序的前提下，通过配置即可完成对服务的异常模拟。Istio 1.5 仅支持网络层的故障模拟，即支持模拟上游服务的处理时长、服务异常状态、自定义响应状态码等故障信息，暂不支持对于服务主机内存、CPU 等信息故障的模拟。他们都是通过配置上游主机的 VirtualService 来实现的。当我们在 VirtualService 中配置了故障注入时，上游服务的 Envoy代理在拦截到请求之后就会做出相应的响应。</p><p>目前，Istio 提供两种类型的故障注入，abort 类型与 delay 类型。</p><ul><li><strong>abort</strong>：非必配项，配置一个 Abort 类型的对象。用来注入请求异常类故障。简单的说，就是用来模拟上游服务对请求返回指定异常码时，当前的服务是否具备处理能力。它对应于 Envoy过滤器中的 <a href="https://www.envoyproxy.io/docs/envoy/latest/api-v2/config/filter/http/fault/v2/fault.proto#envoy-api-msg-config-filter-http-fault-v2-faultabort" target="_blank" rel="external nofollow noopener noreferrer">config.filter.http.fault.v2.FaultAbort</a> 配置项，当 VirtualService 资源应用时，Envoy将会该配置加载到过滤器中并处理接收到的流量。</li><li><strong>delay</strong>：非必配项，配置一个 Delay 类型的对象。用来注入延时类故障。通俗一点讲，就是人为模拟上游服务的响应时间，测试在高延迟的情况下，当前的服务是否具备容错容灾的能力。它对应于 Envoy过滤器中的 <a href="https://www.envoyproxy.io/docs/envoy/latest/api-v2/config/filter/fault/v2/fault.proto#envoy-api-msg-config-filter-fault-v2-faultdelay" target="_blank" rel="external nofollow noopener noreferrer">config.filter.fault.v2.FaultDelay</a> 配置型，同样也是在应用 Istio 的 VirtualService 资源时，Envoy将该配置加入到过滤器中。</li></ul><p>实际上，Istio 的故障注入正是基于 Envoy的 config.filter.http.fault.v2.HTTPFault 过滤器实现的，它的局限性也来自于 Envoy故障注入机制的局限性。对于 Envoy的 HttpFault 的详细介绍请参考 <a href="https://www.envoyproxy.io/docs/envoy/latest/api-v2/config/filter/http/fault/v2/fault.proto#envoy-api-msg-config-filter-http-fault-v2-httpfault" target="_blank" rel="external nofollow noopener noreferrer">Envoy 文档</a>。对比 Istio 故障注入的配置项与 Envoy故障注入的配置项，不难发现，Istio 简化了对于故障控制的手段，去掉了 Envoy中通过 HTTP header 控制故障注入的配置。</p><h4 id="HTTPFaultInjection-Abort"><a href="#HTTPFaultInjection-Abort" class="headerlink" title="HTTPFaultInjection.Abort"></a>HTTPFaultInjection.Abort</h4><ul><li><strong>httpStatus</strong>：必配项，是一个整型的值。表示注入 HTTP 请求的故障状态码。</li><li><strong>percentage</strong>：非必配项，是一个 Percent 类型的值。表示对多少请求进行故障注入。如果不指定该配置，那么所有请求都将会被注入故障。</li><li><strong>percent</strong>：已经废弃的一个配置，与 percentage 配置功能一样，已经被 percentage 代替。</li></ul><p>如下的配置表示对 <code>v1</code> 版本的 <code>ratings.prod.svc.cluster.local</code> 服务访问的时候进行故障注入，<code>0.1</code>表示有千分之一的请求被注入故障， <code>400</code> 表示故障为该请求的 HTTP 响应码为 <code>400</code> 。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1alpha3</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">VirtualService</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ratings-route</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">ratings.prod.svc.cluster.local</span></span><br><span class="line">  <span class="attr">http:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">route:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">destination:</span></span><br><span class="line">        <span class="attr">host:</span> <span class="string">ratings.prod.svc.cluster.local</span></span><br><span class="line">        <span class="attr">subset:</span> <span class="string">v1</span></span><br><span class="line">    <span class="attr">fault:</span></span><br><span class="line">      <span class="attr">abort:</span></span><br><span class="line">        <span class="attr">percentage:</span></span><br><span class="line">          <span class="attr">value:</span> <span class="number">0.1</span></span><br><span class="line">        <span class="attr">httpStatus:</span> <span class="number">400</span></span><br></pre></td></tr></table></figure><h4 id="HTTPFaultInjection-Delay"><a href="#HTTPFaultInjection-Delay" class="headerlink" title="HTTPFaultInjection.Delay"></a>HTTPFaultInjection.Delay</h4><ul><li><strong>fixedDelay</strong>：必配项，表示请求响应的模拟处理时间。格式为：<code>1h/1m/1s/1ms</code>， 不能小于 <code>1ms</code>。</li><li><strong>percentage</strong>：非必配项，是一个 Percent 类型的值。表示对多少请求进行故障注入。如果不指定该配置，那么所有请求都将会被注入故障。</li><li><strong>percent</strong>：已经废弃的一个配置，与 <code>percentage</code> 配置功能一样，已经被 <code>percentage</code> 代替。</li></ul><p>如下的配置表示对 <code>v1</code> 版本的 <code>reviews.prod.svc.cluster.local</code> 服务访问的时候进行延时故障注入，<code>0.1</code> 表示有千分之一的请求被注入故障，<code>5s</code> 表示<code>reviews.prod.svc.cluster.local</code> 延时 <code>5s</code>返回。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1alpha3</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">VirtualService</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">reviews-route</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">reviews.prod.svc.cluster.local</span></span><br><span class="line">  <span class="attr">http:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">match:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">sourceLabels:</span></span><br><span class="line">        <span class="attr">env:</span> <span class="string">prod</span></span><br><span class="line">    <span class="attr">route:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">destination:</span></span><br><span class="line">        <span class="attr">host:</span> <span class="string">reviews.prod.svc.cluster.local</span></span><br><span class="line">        <span class="attr">subset:</span> <span class="string">v1</span></span><br><span class="line">    <span class="attr">fault:</span></span><br><span class="line">      <span class="attr">delay:</span></span><br><span class="line">        <span class="attr">percentage:</span></span><br><span class="line">          <span class="attr">value:</span> <span class="number">0.1</span></span><br><span class="line">        <span class="attr">fixedDelay:</span> <span class="string">5s</span></span><br></pre></td></tr></table></figure><h3 id="Mirroring"><a href="#Mirroring" class="headerlink" title="Mirroring"></a>Mirroring</h3><p>流量镜像（Mirroring / traffic-shadow），也叫作影子流量，就是通过复制一份请求并把它发送到镜像服务，从而实现流量的复制功能。流量镜像的主要应用场景有以下几种：最主要的就是进行<strong>线上问题排查</strong>。</p><p>一般情况下，因为系统环境，特别是数据环境、用户使用习惯等问题，我们很难在开发环境中模拟出真实的生产环境中出现的棘手问题，同时生产环境也不能记录太过详细的日志，因此很难定位到问题。有了流量镜像，我们就可以把真实的请求发送到镜像服务，再打开 debug 日志来查看详细的信息。除此以外，还可以通过它来观察生产环境的请求处理能力，比如在镜像服务进行压力测试。也可以将复制的请求信息用于数据分析。流量镜像在 Istio 里实现起来也非常简单，只需要在路由配置中通添加<code>mirror</code>关键字即可。</p><h4 id="流量镜像能够为我们带来什么"><a href="#流量镜像能够为我们带来什么" class="headerlink" title="流量镜像能够为我们带来什么"></a>流量镜像能够为我们带来什么</h4><p>很多情况下，当我们对服务做了重构，或者我们对项目做了重大优化时，怎么样保证服务是健壮的呢？在传统的服务里，我们只能通过大量的测试，模拟在各种情况下服务的响应情况。虽然也有手工测试、自动化测试、压力测试等一系列手段去检测它，但是测试本身就是一个样本化的行为，即使测试人员再完善它的测试样例，无法全面的表现出线上服务的一个真实流量形态。往往当项目发布之后，总会出现一些意外，比如你服务里收到客户使用的某些数据库不认识的特殊符号，再比如用户在本该输入日期的输入框中输入了 “—” 字样的字符，又比如用户使用乱码替换你的 token 值批量恶意攻击服务等等，这样的情况屡见不鲜。数据的多样性，复杂性决定了开发人员在开发阶段根本是无法考虑周全的。</p><p>而流量镜像的设计，让这类问题得到了最大限度的解决。流量镜像讲究的不再是使用少量样本去评估一个服务的健壮性，而是在不影响线上坏境的前提下将线上流量持续的镜像到我们的预发布坏境中去，让重构后的服务在上线之前就结结实实地接受一波真实流量的冲击与考验，让所有的风险全部暴露在上线前夕，通过不断的暴露问题，解决问题让服务在上线前夕就拥有跟线上服务一样的健壮性。由于测试坏境使用的是真实流量，所以不管从流量的多样性，真实性，还是复杂性上都将能够得以展现，同时预发布服务也将表现出其最真实的处理能力和对异常的处理能力。运用这种模式，一方面，我们将不会再跟以前一样在发布服务前夕内心始终忐忑不安，只能祈祷上线之后不会出现问题。另一方面，当大量的流量流入重构服务之后，开发过程中难以评估的性能问题也将完完整整的暴露出来，此时开发人员将会考虑它服务的性能，测试人员将会更加完善他们的测试样例。通过暴露问题，解决问题，再暴露问题，再解决问题的方式循序渐进地完善预发布服务来增加我们上线的成功率。同时也变相的促进我们开发测试人员技能水平的提高。</p><p>当然，流量镜像的作用不仅仅只是解决上面这样的场景问题，我们可以根据它的特性，解决更多的问题。比如，假如我们在上线后突然发现一个线上问题，而这个问题在测试坏境中始终不能复现。那么这个时候我们就能利用它将异常流量镜像到一个分支服务中去，然后我们可以随意在这个分支服务上进行分析调试，这里所说的分支服务，可以是原服务的只用于问题分析而不处理正式业务的副本服务，也可以是一个只收集镜像流量的组件类服务。又比如突然需要收集某个时间段某些流量的特征数据做分析，像这种临时性的需求，使用流量镜像来处理非常合适，既不影响线上服务的正常运转，也达到了收集分析的目的。</p><h4 id="流量镜像的实现原理"><a href="#流量镜像的实现原理" class="headerlink" title="流量镜像的实现原理"></a>流量镜像的实现原理</h4><p>实际上在 Istio 中，服务间的通讯都是被 Envoy代理拦截并处理的， Istio 流量镜像的设计也是基于 Envoy特性实现的。它的流量转发如下图所示。可以看到，当流量进入到<code>Service A</code>时，因为在<code>Service A</code>的 Envoy代理上配置了流量镜像规则，那么它首先会将原始流量转发到<code>v1</code>版本的 <code>Service B</code>服务子集中去 。同时也会将相同的流量复制一份，异步地发送给<code>v2</code>版本的<code>Service B</code> 服务子集中去，可以明显的看到，<code>Service A</code> 发送完镜像流量之后并不关心它的响应情况。</p><p>在很多情况下，我们需要将真实的流量数据与镜像流量数据进行收集并分析，那么当我们收集完成后应该怎样区分哪些是真实流量，哪些是镜像流量呢？ 实际上，Envoy团队早就考虑到了这样的场景，他们为了区分镜像流量与真实流量，在镜像流量中修改了请求标头中 <code>host</code> 值来标识，它的修改规则是：在原始流量请求标头中的 <code>host</code> 属性值拼接上<code>“-shadow”</code> 字样作为镜像流量的 <code>host</code> 请求标头。</p><p>为了能够更清晰的对比出原始流量与镜像流量的区别，我们使用以下的一个示例来说明：</p><p>如下图所示，我们发起一个<code>http://istio.gateway.xxxx.tech/serviceB/request/info</code>的请求，请求首先进入了<code>istio-ingressgateway</code> ，它是一个 Istio 的 Gateway 资源类型的服务，它本身就是一个 Envoy代理。在这个例子里，就是它对流量进行了镜像处理。可以看到，它将流量转发给<code>v1</code>版本<code>Service B</code>服务子集的同时也复制了一份流量发送到了<code>v2</code>版本的<code>Service B</code>服务子集中去。</p><p><img alt="concepts-traffic-shadow-request" data-src="https://www.servicemesher.com/istio-handbook/images/concepts-traffic-shadow-request.png"></p><p>在上面的请求链中，请求标头数据有什么变化呢？下图收集了它们请求标头中的所有信息，可以明显的对比出正式流量与镜像流量请求标头中<code>host</code>属性的区别（部分相同的属性值过长，这里只截取了前半段）。从图中我们可以看出，首先就是host属性值的不同，而区别就是多了一个<code>“-shadow”</code>的后缀。再者发现<code>x-forwarded-for</code>属性也不相同，<code>x-forwarded-for</code>协议头的格式是：<code>x-forwarded-for: client1, proxy1, proxy2</code>， 当流量经过 Envoy代理时这个协议头将会把代理服务的 IP 添加进去。实例中<code>10.10.2.151</code>是我们云主机的 IP，而<code>10.10.2.121</code>是<code>isito-ingressgateway</code>所对应<code>Pod</code>的 IP 。从这里也能看到，镜像流量是由<code>istio-ingressgatway</code>发起的。除了这两个请求标头的不同，其他配置项是完全一样的。</p><p><img alt="concepts-traffic-shadow-header" data-src="https://www.servicemesher.com/istio-handbook/images/concepts-traffic-shadow-header.png"></p><h4 id="流量镜像的配置"><a href="#流量镜像的配置" class="headerlink" title="流量镜像的配置"></a>流量镜像的配置</h4><p>上面我们介绍了流量镜像的原理及使用场景，接下来我们再介绍下流量的镜像如何配置才能生效。在 Istio 架构里，镜像流量是借助于 VirtualService 这个资源中的 <code>HTTPRoute</code> 配置项的<code>mirror</code>与<code>mirrorPercent</code>这两项子配置项来实现的，这两个配置项的定义也是非常的简单。</p><ul><li><strong>mirror</strong>：配置一个 Destination 类型的对象，这里就是我们镜像流量转发的服务地址。具体的 <strong>VirtualService</strong> 配置与<strong>DestinationRule</strong> 对象配置属性请参考相关介绍页。</li><li><strong>mirrorPercent</strong>：配置一个数值，这个配置项用来指定有多少的原始流量将被转发到镜像流量服务中去，它的有效值为<code>0~100</code>，如果配置成<code>0</code>则表示不发送镜像流量。</li></ul><p>下面的例子就是我们在示例中使用到的<code>Service B</code>的镜像流量配置，其中，<code>mirror.host</code>配置项是配置一个域名或者在Istio 注册表中注册过的服务名称，可以看到，该配置指定了镜像流量需要发送的目标服务地址为<code>serviceB</code>。<code>mirror.subset</code>配置项配置一个<code>Service B</code>服务的服务子集名称 ，指定了要将镜像流量镜像到<code>v2</code>版本的<code>Service B</code>服务子集中去。<code>mirror_percent</code>配置将<code>100%</code>的真实流量进行镜像发送。所以下面的配置整体表示当流量到来时，将请求转发到<code>v1</code>版本的<code>service B</code>服务子集中，再以镜像的方式发送到<code>v2</code>版本的<code>service B</code>服务上一份，并将真实流量全部镜像。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1alpha3</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">VirtualService</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">serviceB</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">istio.gateway.xxxx.tech</span></span><br><span class="line">  <span class="attr">gateways:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">ingressgateway.istio-system.svc.cluster.local</span></span><br><span class="line">  <span class="attr">http:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">match:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">uri:</span></span><br><span class="line">        <span class="attr">prefix:</span> <span class="string">/serviceB</span></span><br><span class="line">    <span class="attr">rewrite:</span></span><br><span class="line">      <span class="attr">uri:</span> <span class="string">/</span></span><br><span class="line">    <span class="attr">route:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">destination:</span></span><br><span class="line">        <span class="attr">host:</span> <span class="string">serviceB</span></span><br><span class="line">        <span class="attr">subset:</span> <span class="string">v1</span></span><br><span class="line">    <span class="attr">mirror:</span></span><br><span class="line">      <span class="attr">host:</span> <span class="string">serviceB</span></span><br><span class="line">      <span class="attr">subset:</span> <span class="string">v2</span></span><br><span class="line">    <span class="attr">mirror_percent:</span> <span class="number">100</span></span><br></pre></td></tr></table></figure><p><code>service B</code> 服务对应的 DestinationRule 配置如下 ：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1alpha3</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">DestinationRule</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">serviceB</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">host:</span> <span class="string">serviceB</span></span><br><span class="line">  <span class="attr">subsets:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">v2</span></span><br><span class="line">    <span class="attr">labels:</span></span><br><span class="line">      <span class="attr">version:</span> <span class="string">v2</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">v1</span></span><br><span class="line">    <span class="attr">labels:</span></span><br><span class="line">      <span class="attr">version:</span> <span class="string">v1</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;流量控制是指对系统流量的管控，包括了对网格入口的流量、网格出口的流量以及在网格内部微服务间相互调用流量的控制。在 &lt;a href=&quot;../22cae0b8&quot;&gt;Istio 入门&lt;/a&gt; 中我们知道，Istio 架构在逻辑上分为 Control plane 和 Data plane，Control plane 负责整体管理和配置代理， Data plane 负责网格内所有微服务间的网络通信，同时还收集报告网络请求的遥测数据等。流量控制是在 Data plane 层实现。&lt;/p&gt;
    
    </summary>
    
    <content src="http://houmin.cc/https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-09-10_istio-bookinfo.svg" type="image" />
    
    
      <category term="术业专攻" scheme="http://houmin.cc/categories/%E6%9C%AF%E4%B8%9A%E4%B8%93%E6%94%BB/"/>
    
    
      <category term="网络" scheme="http://houmin.cc/tags/%E7%BD%91%E7%BB%9C/"/>
    
      <category term="envoy" scheme="http://houmin.cc/tags/envoy/"/>
    
      <category term="service mesh" scheme="http://houmin.cc/tags/service-mesh/"/>
    
      <category term="istio" scheme="http://houmin.cc/tags/istio/"/>
    
  </entry>
  
  <entry>
    <title>【Service Mesh】Istio 入门</title>
    <link href="http://houmin.cc/posts/22cae0b8/"/>
    <id>http://houmin.cc/posts/22cae0b8/</id>
    <published>2020-11-23T02:44:08.000Z</published>
    <updated>2020-11-27T02:46:29.502Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>Istio 是一个完全开源的服务网格，以透明的方式构建在现有的分布式应用中。它也是一个平台，拥有可以集成任何日志、遥测和策略系统的 API 接口。Istio 多样化的特性使你能够成功且高效地运行分布式微服务架构，并提供保护、连接和监控微服务的统一方法。</p><a id="more"></a><h2 id="核心功能"><a href="#核心功能" class="headerlink" title="核心功能"></a>核心功能</h2><h3 id="流量控制"><a href="#流量控制" class="headerlink" title="流量控制"></a>流量控制</h3><p>微服务应用最大的痛点就是处理服务间的通信，而这一问题的核心其实就是流量管理。首先我们来看看传统的微服务应用在没有 <a href="https://www.servicemesher.com/istio-handbook/GLOSSARY.html#service-mesh" target="_blank" rel="external nofollow noopener noreferrer">Service Mesh</a> 介入的情况下，是如何完成诸如金丝雀发布这样的路由功能的。我们假设不借助任何现成的第三方框架，一个最简单的实现方法，就是在服务间添加一个负载均衡（比如 Nginx）做代理，通过修改配置的权重来分配流量。这种方式使得对流量的管理和基础设施绑定在了一起，难以维护。</p><p>而使用 <a href="https://www.servicemesher.com/istio-handbook/GLOSSARY.html#istio" target="_blank" rel="external nofollow noopener noreferrer">Istio</a> 就可以轻松的实现各种维度的流量控制。下图是典型的金丝雀发布策略：根据权重把 5% 的流量路由给新版本，如果服务正常，再逐渐转移更多的流量到新版本。</p><p><a href="https://www.servicemesher.com/istio-handbook/GLOSSARY.html#istio" target="_blank" rel="external nofollow noopener noreferrer">Istio</a> 中的流量控制功能主要分为三个方面：</p><ul><li>请求路由和流量转移</li><li>弹性功能，包括熔断、超时、重试</li><li>调试能力，包括故障注入和流量镜像</li></ul><p>关于流量控制的更多内容，参考 <a href="../151719f0">Istio流量控制</a></p><h3 id="安全管理"><a href="#安全管理" class="headerlink" title="安全管理"></a>安全管理</h3><p>安全对于微服务这样的分布式系统来说至关重要。与单体应用在进程内进行通信不同，网络成为了服务间通信的纽带，这使得它对安全有了更迫切的需求。比如为了抵御外来攻击，我们需要对流量进行加密；为保证服务间通信的可靠性，需要使用mTLS的方式进行交互；为控制不同身份的访问，需要设置不同粒度的授权策略。作为一个服务网格，<a href="https://www.servicemesher.com/istio-handbook/GLOSSARY.html#istio" target="_blank" rel="external nofollow noopener noreferrer">Istio</a> 提供了一整套完整的安全解决方案。它可以以透明的方式，为我们的微服务应用添加安全策略。</p><p><a href="https://www.servicemesher.com/istio-handbook/GLOSSARY.html#istio" target="_blank" rel="external nofollow noopener noreferrer">Istio</a> 中的安全架构是由多个组件协同完成的。Citadel 是负责安全的主要组件，用于密钥和证书的管理；<a href="https://www.servicemesher.com/istio-handbook/GLOSSARY.html#pilot" target="_blank" rel="external nofollow noopener noreferrer">Pilot</a> 会将安全策略配置分发给 <a href="https://www.servicemesher.com/istio-handbook/GLOSSARY.html#envoy" target="_blank" rel="external nofollow noopener noreferrer">Envoy</a> 代理；<a href="https://www.servicemesher.com/istio-handbook/GLOSSARY.html#envoy" target="_blank" rel="external nofollow noopener noreferrer">Envoy</a> 执行安全策略来实现访问控制。下图展示了 <a href="https://www.servicemesher.com/istio-handbook/GLOSSARY.html#istio" target="_blank" rel="external nofollow noopener noreferrer">Istio</a> 的安全架构和运作流程。</p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-09-10_istio-secure-arch.svg"></p><p>关于安全管理的更多内容，参考 <a href="../">Istio安全管理</a></p><h3 id="可观测性"><a href="#可观测性" class="headerlink" title="可观测性"></a>可观测性</h3><p>面对复杂的应用环境和不断扩展的业务需求，即使再完备的测试也难以覆盖所有场景，无法保证服务不会出现故障。正因为如此，才需要“可观察性”来对服务的运行时状态进行监控、上报、分析，以提高服务可靠性。具有可观察性的系统，可以在服务出现故障时大大降低问题定位的难度，甚至可以在出现问题之前及时发现问题以降低风险。具体来说，可观察性可以：</p><ul><li>及时反馈异常或者风险使得开发人员可以及时关注、修复和解决问题（告警）；</li><li>出现问题时，能够帮助快速定位问题根源并解决问题，以减少服务损失（减损）；</li><li>收集并分析数据，以帮助开发人员不断调整和改善服务（持续优化）。</li></ul><p>而在微服务治理之中，随着服务数量大大增加，服务拓扑不断复杂化，可观察性更是至关重要。<a href="https://www.servicemesher.com/istio-handbook/GLOSSARY.html#istio" target="_blank" rel="external nofollow noopener noreferrer">Istio</a> 自然也不可能缺少对可观察性的支持。它会为所有的服务间通信生成详细的遥测数据，使得网格中每个服务请求都可以被观察和跟踪。开发人员可以凭此定位故障，维护和优化相关服务。而且，这一特性的引入无需侵入被观察的服务。</p><p><a href="https://www.servicemesher.com/istio-handbook/GLOSSARY.html#istio" target="_blank" rel="external nofollow noopener noreferrer">Istio</a> 一共提供了三种不同类型的数据从不同的角度支撑起其可观察性：</p><ul><li>指标（Metrics）</li><li>日志（Access Logs）</li><li>分布式追踪（Distributed Traces）</li></ul><p>关于可观测行的更多内容，参考 <a href="../">Istio可观测性</a></p><h2 id="架构解析"><a href="#架构解析" class="headerlink" title="架构解析"></a>架构解析</h2><p>Istio的架构由<strong>控制平面</strong>和<strong>数据平面</strong>两个部分组成。</p><ul><li>数据平面：由整个网格内的sidecar代理组成，每个sidecar代理会接管流入和流出服务的流量，并配合控制平面完成流量控制等方面的内容。</li><li>控制平面：负责控制和管理数据平面的sidecar代理，完成配置的分发、服务发现和授权鉴权等功能。</li></ul><p>控制平面是 Istio 在原有服务网格产品上，首次提出的架构，实现了对于数据平面的统一管理。</p><p><img alt="Istio Arch" data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-09-10_istio-arch.svg"></p><h3 id="控制平面"><a href="#控制平面" class="headerlink" title="控制平面"></a>控制平面</h3><h4 id="Pilot"><a href="#Pilot" class="headerlink" title="Pilot"></a>Pilot</h4><p><code>Pilot</code> 组件的主要功能是将路由规则等配置信息转换为 sidecar 可以识别的信息，并下发给数据平面。可以把它简单的理解为是一个<strong>配置分发器</strong>（dispatcher），并辅助 sidecar 完成流量控制相关的功能。它管理sidecar代理之间的路由流量规则，并配置故障恢复功能，如超时、重试和熔断。</p><p><img alt="Istio Pilot Arch" data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-09-10_istio-pilot-arch.svg"></p><p>上图显示了Pilot的基本架构，它主要由以下几个部分组成：</p><h5 id="Abstract-Model"><a href="#Abstract-Model" class="headerlink" title="Abstract Model"></a>Abstract Model</h5><p>为了实现对不同服务注册中心 （Kubernetes、consul） 的支持，<a href="https://www.servicemesher.com/istio-handbook/GLOSSARY.html#pilot" target="_blank" rel="external nofollow noopener noreferrer">Pilot</a> 需要对不同的输入来源的数据有一个统一的存储格式，也就是抽象模型。抽象模型中定义的关键成员包括 HostName（Service名称）、Ports（Service端口）、Address（Service ClusterIP）、Resolution （负载均衡策略） 等。</p><h5 id="Platform-Adapters"><a href="#Platform-Adapters" class="headerlink" title="Platform Adapters"></a>Platform Adapters</h5><p>借助平台适配器 Pilot 可以实现服务注册中心数据到抽象模型之间的数据转换。例如 Pilot 中的 Kubernetes 适配器通过 Kubernetes API 服务器得到 Kubernetes 中 Service 和 Pod 的相关信息，然后翻译为抽象模型提供给 Pilot 使用。通过平台适配器模式，Pilot 还可以从 Consul 等平台中获取服务信息，还可以开发适配器将其他提供服务发现的组件集成到 Pilot 中。</p><h5 id="xDS-API"><a href="#xDS-API" class="headerlink" title="xDS API"></a>xDS API</h5><p>Pilot 使用了一套起源于 Envoy 项目的标准数据面 API 来将服务信息和流量规则下发到数据面的 sidecar 中。这套标准数据面 API，也叫 xDS。Sidecar 通过 xDS API 可以动态获取 Listener （监听器）、Route （路由）、<a href="https://www.servicemesher.com/istio-handbook/GLOSSARY.html#cluster" target="_blank" rel="external nofollow noopener noreferrer">Cluster</a> （集群）及 Endpoint （集群成员）配置：</p><ul><li>LDS，Listener 发现服务：Listener 监听器控制 <a href="https://www.servicemesher.com/istio-handbook/GLOSSARY.html#sidecar" target="_blank" rel="external nofollow noopener noreferrer">sidecar</a> 启动端口监听（目前只支持 TCP 协议），并配置 L3/L4 层过滤器，当网络连接达到后，配置好的网络过滤器堆栈开始处理后续事件。</li><li>RDS，Router 发现服务：用于 HTTP 连接管理过滤器动态获取路由配置，路由配置包含 HTTP 头部修改（增加、删除 HTTP 头部键值），virtual hosts （虚拟主机），以及 virtual hosts 定义的各个路由条目。</li><li>CDS，Cluster发现服务：用于动态获取 Cluster 信息。</li><li>EDS，Endpoint 发现服务：用于动态维护端点信息，端点信息中还包括负载均衡权重、金丝雀状态等，基于这些信息，Sidecar 可以做出智能的负载均衡决策。</li></ul><h5 id="User-API"><a href="#User-API" class="headerlink" title="User API"></a>User API</h5><p>Pilot 还定义了一套用户 API， 用户 API 提供了面向业务的高层抽象，可以被运维人员理解和使用。</p><p>运维人员使用该 API 定义流量规则并下发到 Pilot，这些规则被 Pilot 翻译成数据面的配置，再通过标准数据面 API 分发到 sidecar 实例，可以在运行期对微服务的流量进行控制和调整。</p><p>通过运用不同的流量规则，可以对网格中微服务进行精细化的流量控制，如按版本分流、断路器、故障注入、灰度发布等。</p><p>关于 Pilot 的具体实现，可以参考 <a href="../">Istio Pilot 模块分析</a></p><h4 id="Citadel"><a href="#Citadel" class="headerlink" title="Citadel"></a>Citadel</h4><p><code>Citadel</code> 是 Istio 中专门负责安全的组件，内置有身份和证书管理功能，可以实现较为强大的授权和认证等操作，在1.5 版本之后取消了独立进程，作为一个模块被整合在 istiod 中。</p><p>总体来说，Istio 在安全架构方面主要包括以下内容：</p><ul><li>证书签发机构（CA）负责密钥和证书管理</li><li>API 服务器将安全配置分发给数据平面</li><li>客户端、服务端通过代理安全通信</li><li>Envoy 代理管理遥测和审计</li></ul><p>Istio 的身份标识模型使用一级服务标识来确定请求的来源，它可以灵活的标识终端用户、工作负载等。在平台层面，Istio 可以使用类似于服务名称来标识身份，或直接使用平台提供的服务标识。比如 Kubernetes 的 ServiceAccount，AWS IAM 用户、角色账户等。</p><p>在身份和证书管理方面，Istio 使用 X.509 证书，并支持密钥和证书的自动轮换。从 1.1 版本开始，Istio 开始支持安全发现服务器（SDS），随着不断的完善和增强，1.5 版本 SDS 已经成为默认开启的组件。Citadel 以前有两个功能：将证书以 Secret 的方式挂载到命名空间里；通过 SDS gRPC 接口与 nodeagent（已废弃）通信。目前 Citadel 只需要完成与 SDS 相关的工作，其他功能被移动到了 istiod 中。</p><p>关于Citadel的更多内容，参考 <a href="../">Istio安全管理</a></p><h4 id="Galley"><a href="#Galley" class="headerlink" title="Galley"></a>Galley</h4><p><code>Galley</code> 是 Istio 1.1 版本中新增加的组件，其目的是将 <code>Pilot</code> 和底层平台（如 Kubernetes）进行解耦。它分担了原本 <code>Pilot</code> 的一部分功能，主要负责配置的验证、提取和处理等功能。</p><h3 id="数据平面"><a href="#数据平面" class="headerlink" title="数据平面"></a>数据平面</h3><p>Istio 数据平面核心是以 sidecar 模式运行的智能代理。Sidecar 模式将数据平面核心组件部署到单独的流程或容器中，以提供隔离和封装。Sidecar 应用与父应用程序共享相同的生命周期，与父应用程序一起创建和退出。Sidecar 应用附加到父应用程序，并为应用程序提供额外的特性支持。</p><p>如下图所示，数据平面的 sidecar 代理可以调节和控制微服务之间所有的网络通信，每个服务 Pod 启动时会伴随启动 <code>istio-init</code> 和 proxy 容器。 </p><ul><li><code>istio-init</code> 容器主要功能是初始化 Pod 网络和对 Pod设置 iptable 规则，设置完成后自动结束。</li><li>Proxy 容器会启动两个服务：<code>istio-agent</code> 以及网络代理组件<ul><li><code>istio-agent</code>  的作用是同步管理数据，启动并管理网络代理服务进程，上报遥测数据</li><li>网络代理组件则根据管理策略完成流量管控、生成遥测数据。</li></ul></li></ul><p>数据平面真正触及到对网络数据包的相关操作，是上层控制平面策略的具体执行者。</p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-09-10_istio-data-plane-arch.png"></p><p>Envoy 是 Istio 中默认的数据平面 Sidecar 代理，关于 Sidecar 是如何实现自动注入和流量劫持，以及Sidecar的流量路由机制如何实现，更多可参考 <a href="../">Envoy系列文章</a> 。</p><h2 id="安装部署"><a href="#安装部署" class="headerlink" title="安装部署"></a>安装部署</h2><h3 id="下载安装"><a href="#下载安装" class="headerlink" title="下载安装"></a>下载安装</h3><p>这里介绍在 Kubernetes 环境下安装 Istio，在开始之前，你需要有一个 Kubernetes 运行环境。</p><p>从 Istio v1.7 版本开始，Istio官方推荐使用 istioctl 安装。下面是安装步骤：</p><ul><li>在 <a href="https://github.com/istio/istio/releases" target="_blank" rel="external nofollow noopener noreferrer">Istio release</a> 页面下载与操作系统匹配的安装包，并将其解压。这里可以直接用Istio提供的脚本：</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">$ curl -L https://raw.githubusercontent.com/istio/istio/release-1.7/release/downloadIstioCandidate.sh | sh -</span><br><span class="line">$  [root@VM-1-28-centos istio]<span class="comment"># ls </span></span><br><span class="line">istio-1.7.0  istio-1.7.0-linux-amd64.tar.gz</span><br><span class="line">$ [root@VM-1-28-centos istio]<span class="built_in">cd</span> istio-1.7.0</span><br><span class="line">$ [root@VM-1-28-centos istio-1.7.0]<span class="comment"># tree -L 2</span></span><br><span class="line">.</span><br><span class="line">├── bin</span><br><span class="line">│   └── istioctl</span><br><span class="line">├── LICENSE</span><br><span class="line">├── manifests</span><br><span class="line">│   ├── charts</span><br><span class="line">│   ├── deploy</span><br><span class="line">│   ├── examples</span><br><span class="line">│   └── profiles</span><br><span class="line">├── manifest.yaml</span><br><span class="line">├── README.md</span><br><span class="line">├── samples</span><br><span class="line">│   ├── addons</span><br><span class="line">│   ├── bookinfo</span><br><span class="line">│   ├── certs</span><br><span class="line">│   ├── cross-network-gateway</span><br><span class="line">│   ├── custom-bootstrap</span><br><span class="line">│   ├── external</span><br><span class="line">│   ├── fortio</span><br><span class="line">│   ├── health-check</span><br><span class="line">│   ├── helloworld</span><br><span class="line">│   ├── httpbin</span><br><span class="line">│   ├── https</span><br><span class="line">│   ├── kubernetes-blog</span><br><span class="line">│   ├── operator</span><br><span class="line">│   ├── rawvm</span><br><span class="line">│   ├── README.md</span><br><span class="line">│   ├── security</span><br><span class="line">│   ├── sleep</span><br><span class="line">│   ├── tcp-echo</span><br><span class="line">│   └── websockets</span><br><span class="line">└── tools</span><br><span class="line">    ├── certs</span><br><span class="line">    ├── convert_RbacConfig_to_ClusterRbacConfig.sh</span><br><span class="line">    ├── dump_kubernetes.sh</span><br><span class="line">    ├── _istioctl</span><br><span class="line">    └── istioctl.bash</span><br><span class="line"></span><br><span class="line">27 directories, 9 files</span><br></pre></td></tr></table></figure><p>安装目录内容： </p><div class="table-container"><table><thead><tr><th>目录</th><th>包含内容</th></tr></thead><tbody><tr><td><code>bin</code></td><td>包含 istioctl 的客户端文件</td></tr><tr><td><code>manifests</code></td><td>包含 各种部署的 manifests</td></tr><tr><td><code>samples</code></td><td>包含示例应用程序</td></tr><tr><td><code>tools</code></td><td>包含用于性能测试和在本地机器上进行测试的脚本</td></tr></tbody></table></div><ul><li>将<code>istioctl</code>客户端路径加入 <code>$PATH</code> 中，从而可以使用 istioctl 命令行工具</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:$(<span class="built_in">pwd</span>)/bin</span><br></pre></td></tr></table></figure><ul><li>安装 <code>demo</code> 配置</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ istioctl install --<span class="built_in">set</span> profile=demo</span><br><span class="line">✔ Istio core installed</span><br><span class="line">✔ Istiod installed</span><br><span class="line">✔ Egress gateways installed</span><br><span class="line">✔ Ingress gateways installed</span><br><span class="line">✔ Installation complete</span><br></pre></td></tr></table></figure><ul><li>添加一个Namespace Label，使得之后在部署你的应用的时候，istio会自动注入Envoy sidecar 代理</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl label namespace default istio-injection=enabled</span><br></pre></td></tr></table></figure><h3 id="部署-Bookinfo"><a href="#部署-Bookinfo" class="headerlink" title="部署 Bookinfo"></a>部署 Bookinfo</h3><p>Bookinfo 是 <a href="https://www.servicemesher.com/istio-handbook/GLOSSARY.html#istio" target="_blank" rel="external nofollow noopener noreferrer">Istio</a> 社区官方推荐的示例应用之一。它可以用来演示多种 <a href="https://www.servicemesher.com/istio-handbook/GLOSSARY.html#istio" target="_blank" rel="external nofollow noopener noreferrer">Istio</a> 的特性，并且它是一个异构的微服务应用。该应用由四个单独的微服务构成。 这个应用模仿了在线书店，可以展示书店中书籍的信息。例如页面上会显示一本书的描述，书籍的细节（ ISBN、页数等），以及关于这本书的一些评论。</p><p>Bookinfo 应用分为四个单独的微服务， 这些服务对 <a href="https://www.servicemesher.com/istio-handbook/GLOSSARY.html#istio" target="_blank" rel="external nofollow noopener noreferrer">Istio</a> 并无依赖，但是构成了一个有代表性的服务网格的例子：它由多个不同语言编写的服务构成，并且其中有一个应用会包含多个版本。</p><ul><li><code>productpage</code> 会调用 <code>details</code> 和 <code>reviews</code> 两个微服务，用来生成页面。</li><li><code>details</code> 中包含了书籍的信息。</li><li><code>reviews</code> 中包含了书籍相关的评论。它还会调用 <code>ratings</code> 微服务。</li><li><code>ratings</code> 中包含了由书籍评价组成的评级信息。</li></ul><p><code>reviews</code> 微服务有 3 个版本，可用来展示各服务之间的不同的调用链路：</p><ul><li>v1 版本不会调用 <code>ratings</code> 服务。</li><li>v2 版本会调用 <code>ratings</code> 服务，并使用 1 到 5 个黑色星形图标来显示评分信息。</li><li>v3 版本会调用 <code>ratings</code> 服务，并使用 1 到 5 个红色星形图标来显示评分信息。</li></ul><p>下图展示了这个应用的端到端架构：</p><p><img alt="Bookinfo Application without Istio" data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-09-10_istio-bookinfo-noistio.svg"></p><ul><li>部署示例应用程序</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl apply -f samples/bookinfo/platform/kube/bookinfo.yaml</span><br><span class="line">service/details created</span><br><span class="line">serviceaccount/bookinfo-details unchanged</span><br><span class="line">deployment.apps/details-v1 created</span><br><span class="line">service/ratings created</span><br><span class="line">serviceaccount/bookinfo-ratings unchanged</span><br><span class="line">deployment.apps/ratings-v1 created</span><br><span class="line">service/reviews created</span><br><span class="line">serviceaccount/bookinfo-reviews unchanged</span><br><span class="line">deployment.apps/reviews-v1 created</span><br><span class="line">deployment.apps/reviews-v2 created</span><br><span class="line">deployment.apps/reviews-v3 created</span><br><span class="line">service/productpage created</span><br><span class="line">serviceaccount/bookinfo-productpage unchanged</span><br><span class="line">deployment.apps/productpage-v1 created</span><br></pre></td></tr></table></figure><ul><li>之后应用起来，当每个Pod状态变为Ready的时候，sidecar也部署成功。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get svc</span><br><span class="line">NAME          TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)    AGE</span><br><span class="line">details       ClusterIP   172.18.252.45    &lt;none&gt;        9080/TCP   97s</span><br><span class="line">kubernetes    ClusterIP   172.18.252.1     &lt;none&gt;        443/TCP    51d</span><br><span class="line">productpage   ClusterIP   172.18.253.238   &lt;none&gt;        9080/TCP   97s</span><br><span class="line">ratings       ClusterIP   172.18.254.131   &lt;none&gt;        9080/TCP   97s</span><br><span class="line">reviews       ClusterIP   172.18.255.63    &lt;none&gt;        9080/TCP   97s</span><br><span class="line">$ kubectl get pods</span><br><span class="line">NAME                              READY   STATUS    RESTARTS   AGE</span><br><span class="line">details-v1-5974b67c8-z67st        2/2     Running   0          2m8s</span><br><span class="line">productpage-v1-797898bc54-frzdz   2/2     Running   0          2m8s</span><br><span class="line">ratings-v1-c6cdf8d98-xmhz8        2/2     Running   0          2m8s</span><br><span class="line">reviews-v1-8bdc65f7b-mjktx        2/2     Running   0          2m8s</span><br><span class="line">reviews-v2-868d77d678-4dzmn       2/2     Running   0          2m8s</span><br><span class="line">reviews-v3-6c9b646cb4-5tp9q       2/2     Running   0          2m8s</span><br></pre></td></tr></table></figure><ul><li>查看应用是否成功运行，通过给productpage发送请求，查看其返回</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl <span class="built_in">exec</span> <span class="string">"<span class="variable">$(kubectl get pod -l app=ratings -o jsonpath='&#123;.items[0].metadata.name&#125;')</span>"</span> -c ratings -- curl -s productpage:9080/productpage | grep -o <span class="string">"&lt;title&gt;.*&lt;/title&gt;"</span></span><br><span class="line">&lt;title&gt;Simple Bookstore App&lt;/title&gt;</span><br></pre></td></tr></table></figure><h3 id="集群外部访问应用"><a href="#集群外部访问应用" class="headerlink" title="集群外部访问应用"></a>集群外部访问应用</h3><p>到现在，Bookinfo 应用已经成功部署，我们在集群内部也已经可以访问，但是在集群外部还不能够访问。为了使得外部能够访问应用程序，我们需要创建一个<a href="https://istio.io/latest/docs/concepts/traffic-management/#gateways" target="_blank" rel="external nofollow noopener noreferrer">Istio Ingress Gateway</a>。</p><ul><li>将应用于istio gateway关联</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl apply -f samples/bookinfo/networking/bookinfo-gateway.yaml</span><br><span class="line">gateway.networking.istio.io/bookinfo-gateway created</span><br><span class="line">virtualservice.networking.istio.io/bookinfo created</span><br></pre></td></tr></table></figure><ul><li>确保配置上没有问题</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ istioctl analyze</span><br><span class="line">✔ No validation issues found when analyzing namespace: default.</span><br></pre></td></tr></table></figure><ul><li>确定Ingress的IP和Ports</li></ul><p>通过下面的命令来设置 <code>INGRESS_HOST</code> 和 <code>INGRESS_PORT</code>环境变量。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl get svc istio-ingressgateway -n istio-system</span><br><span class="line">NAME                   TYPE           CLUSTER-IP      EXTERNAL-IP      PORT(S)                                                                      AGE</span><br><span class="line">istio-ingressgateway   LoadBalancer   172.18.252.12   49.233.242.233   15021:32663/TCP,80:31968/TCP,443:31588/TCP,31400:32002/TCP,15443:30652/TCP   18m</span><br></pre></td></tr></table></figure><p>这里显示 <code>EXTERNAL_IP</code> 已经变设置，表明当前环境下有一个可以使用的外部负载均衡器。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">export</span> INGRESS_HOST=$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath=<span class="string">'&#123;.status.loadBalancer.ingress[0].ip&#125;'</span>)</span><br><span class="line">$ <span class="built_in">export</span> INGRESS_PORT=$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath=<span class="string">'&#123;.spec.ports[?(@.name=="http2")].port&#125;'</span>)</span><br><span class="line">$ <span class="built_in">export</span> SECURE_INGRESS_PORT=$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath=<span class="string">'&#123;.spec.ports[?(@.name=="https")].port&#125;'</span>)</span><br></pre></td></tr></table></figure><ul><li>设定GATEWAY_URL</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">export</span> GATEWAY_URL=<span class="variable">$INGRESS_HOST</span>:<span class="variable">$INGRESS_PORT</span></span><br><span class="line">$ <span class="built_in">echo</span> <span class="variable">$GATEWAY_URL</span></span><br><span class="line">49.233.242.233:80</span><br></pre></td></tr></table></figure><ul><li>确认外部访问是否成功：在浏览器直接访问 <code>http://&lt;GATE_WAYURL&gt;/productpage</code> 来访问Bookinfo应用</li></ul><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-09-10_istio-external-access.png"></p><h3 id="查看Dashboard"><a href="#查看Dashboard" class="headerlink" title="查看Dashboard"></a>查看Dashboard</h3><p>Istio集成了 <a href="https://istio.io/latest/docs/ops/integrations/" target="_blank" rel="external nofollow noopener noreferrer">一些</a> 遥测应用，他们可以帮助你对你的服务网格有直观的认识、展示网格的拓扑、分析网格的健康状态</p><ul><li>安装Kiali </li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl apply -f samples/addons</span><br><span class="line">$ <span class="keyword">while</span> ! kubectl <span class="built_in">wait</span> --<span class="keyword">for</span>=condition=available --timeout=600s deployment/kiali -n istio-system; <span class="keyword">do</span> sleep 1; <span class="keyword">done</span></span><br></pre></td></tr></table></figure><ul><li>访问Kiali</li></ul><p>官方教程指示使用 <code>istioctl dashboard kiali</code> 命令来打开浏览器访问 Kiali服务，但是我的 Kubernetes 集群在服务器上，这样显然不行，不要将 Kiali 服务暴露给外部。因为之前集群已经安装了 Traefik ，所以可以使用 Ingress来暴露。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Ingress</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">kiali</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">istio-system</span></span><br><span class="line">  <span class="attr">annotations:</span></span><br><span class="line">    <span class="attr">kubernetes.io/ingress.class:</span> <span class="string">traefik</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">http:</span></span><br><span class="line">      <span class="attr">paths:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/kiali</span></span><br><span class="line">        <span class="attr">backend:</span></span><br><span class="line">          <span class="attr">serviceName:</span> <span class="string">kiali</span></span><br><span class="line">          <span class="attr">servicePort:</span> <span class="number">20001</span></span><br></pre></td></tr></table></figure><p>在命令行创建Ingress，打开浏览器访问 <code>http://&lt;NodeIP&gt;:&lt;TraefikWebNodePort&gt;/kiali</code> 即可访问Kiali</p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-09-10_traefik-kiali.png"></p><p>在左侧导航栏点击Graph，选择default的命名空间，可以看到 <code>Bookinfo</code> 应用中各个服务间的关系：</p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-09-10_istio-kiali.png"></p><p>到此为止，你的Istio和相关的服务已经在集群中完好的部署，关于其具体功能演示，参照 <a href="../151719f0">Istio流量控制</a>。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://istio.io/latest/docs/setup/getting-started" target="_blank" rel="external nofollow noopener noreferrer">https://istio.io/latest/docs/setup/getting-started</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Istio 是一个完全开源的服务网格，以透明的方式构建在现有的分布式应用中。它也是一个平台，拥有可以集成任何日志、遥测和策略系统的 API 接口。Istio 多样化的特性使你能够成功且高效地运行分布式微服务架构，并提供保护、连接和监控微服务的统一方法。&lt;/p&gt;
    
    </summary>
    
    <content src="http://houmin.cc/https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-09-10_istio.png" type="image" />
    
    
      <category term="术业专攻" scheme="http://houmin.cc/categories/%E6%9C%AF%E4%B8%9A%E4%B8%93%E6%94%BB/"/>
    
    
      <category term="service mesh" scheme="http://houmin.cc/tags/service-mesh/"/>
    
      <category term="istio" scheme="http://houmin.cc/tags/istio/"/>
    
  </entry>
  
  <entry>
    <title>【Service Mesh】开篇</title>
    <link href="http://houmin.cc/posts/ac3e3d15/"/>
    <id>http://houmin.cc/posts/ac3e3d15/</id>
    <published>2020-11-22T06:24:34.000Z</published>
    <updated>2020-11-27T02:46:55.389Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><blockquote><p>Service Mesh 是一个<strong>基础设施层</strong>，用于处理<strong>服务到服务间</strong>的网络通信。<strong>云原生应用</strong>有着复杂的服务拓扑，Service Mesh负责在这些<strong>网络拓扑中实现请求的可靠传递</strong>。在实践中，Service Mesh通常实现为一组轻量级的<strong>网络代理</strong>，它们与应用程序部署在一起，但是<strong>对应用保持透明</strong>。</p></blockquote><p>本文作为 「Service Mesh」系列开篇，将理清 Service Mesh 的前世今生，通过对其概念与原理的理解，开始上手 Service Mesh的工作。与此同时，我们也会讨论 Service Mesh 在业界当前的应用现状，探讨其落地的难点与痛点。</p><a id="more"></a><h2 id="历史演进"><a href="#历史演进" class="headerlink" title="历史演进"></a>历史演进</h2><p>随着行业需求的推动，互联网服务从最早的仅有少数几台的大型服务器演变到成百上千的小型服务，服务架构也从最早期的单体式（Monolithic）到分布式（Distributed），再到微服务（Microservices）、容器化（Containerization）、容器编排（Container Orchestration），最后到服务网格（Service Mesh）、无服务器（Serverless）。</p><p>总结分布式系统的演进过程，我们可以看到一种通用的发展规律：</p><ul><li>首先是对每种情况提出临时解决方案</li><li>然后是更复杂的解决方案，类似于 library 以实现统一复用</li><li>随着对问题有更多的了解，开始将这些解决方案落实到 platform</li></ul><p>接下来我们会回顾从早期TCP/IP协议栈的广泛应用，到微服务时代从容器编排到服务网格的演进过程，并再次体会上述规律。</p><h3 id="计算机网络系统的演进"><a href="#计算机网络系统的演进" class="headerlink" title="计算机网络系统的演进"></a>计算机网络系统的演进</h3><p>从多台计算机开始通信以来，服务间通信是应用最为广泛的模式。以下图为例，ServiceA 和 ServiceB 可以是我们提供应用的服务端与客户端。在开发者开发这些服务的时候，需要借助底层的网络硬件和协议进行通信。这张图只是一个简化的师徒，省略了在代码操作的数据和通过线路发送接收的电信号之间转换的很多层。</p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-09-08_service-mesh-svc2svc.png"></p><p>更加具体一点，把底层的网络协议栈加入，我们会看到下图：</p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-09-08_service-mesh-svc2svc-stack.png"></p><p>从上世纪50年代起，上述的模型就一直在使用。最开始，由于计算机系统规模相对较小，每个节点之间的链路协议都是经过专门设计和维护的。随着计算机规模的迅速扩大，很多个小的网络系统开始连接起来。在这个过程中，不同主机间如何找到彼此，跨网络间如何路由转发，如何实现流量控制等问题，成了摆在网络系统设计人员面前亟需解决的难题。</p><p>为了实现各个网络节点的路由转发，屏蔽链路层协议，人们发明了IP网络协议。然而，IP网络协议还不能够解决流量控制的问题。这里的流量控制，值得是防止一台服务器发送过多的数据包，超出下游服务器的处理能力。在最开始，编写网络服务和应用程序的开发者来负责处理上述流量控制的问题。这就意味着在编写应用程序过程中，网络处理的逻辑和应用自身的业务逻辑被耦合在一起，如下图所示。</p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-09-08_service-mesh-flow-control.png"></p><p>然而，这种每个开发人员都要去考虑流量处理等传输层的问题太过复杂，程序开发的成本太高。随着技术的快速发展，流量处理和其他网络问题相关的解决方案被整合到网络协议栈，TCP/IP席卷了世界，成为互联网事实上的协议标准。流量控制等网络问题的代码仍在，但是你不再需要自己去开发与维护这段代码，而是直接调用系统提供的网络协议栈。</p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-09-08_service-mesh-tcp.png"></p><h3 id="微服务架构的演进"><a href="#微服务架构的演进" class="headerlink" title="微服务架构的演进"></a>微服务架构的演进</h3><p>确定于上世界80年代的TCP/IP网络协议栈和通用的网络模型对于互联网的发展发挥了巨大的作用，极大了促进了互联网应用的繁荣。网络应用的功能逐渐复杂起来，人们把所有的组件都集中在一个应用当中，这即是<code>单体应用 Monolithic</code>。单体应用基于相同技术栈开发、访问共享的数据库、共同部署运维和扩容。同时，组件之间的通信也趋于频繁和耦合，所有的交互都是以函数调用的形式来实现。</p><p>然而，随着互联网的迅猛发展，网络应用中需要添加越来越多的功能，应用的复杂度不断提升，参与软件开发的协作人数也越来越多，单体应用开始爆发出其固有局限性。在这种背景下，微服务的思潮降临，让软件开发重新变得小而美：</p><ul><li>单⼀职责：拆分后的单个微服务，通常只负责单个高内聚自闭环功能，因此很易于开发、理解和维护。</li><li>架构灵活：不同微服务应用之间在技术选型层面几乎是独立的，可以⾃由选择最适合的技术栈。</li><li>部署隔离：相比巨无霸单体应用，单个微服务应用的代码和产物体积大大减少，更容易持续集成和快速部署；同时，通过进程级别的隔离，也不再像单体应用一样只能同生共死，故障隔离效果显著提升。</li><li>独⽴扩展：单体应用时代，某个模块如果存在资源瓶颈（e.g. CPU/内存），只能跟随整个应用一起扩容，白白浪费很多资源。微服务化后，扩展的粒度细化到了微服务级别，可以更精确地按需独立扩展。</li></ul><p>然而，微服务也不是银弹，在微服务落地的过程中，也产生了很多的问题，其中主要的问题就是服务间通信：</p><ul><li><p><strong>如何找到服务的提供⽅？</strong></p><p>微服务通讯必须走远程过程调用（HTTP/REST本质上也属于RPC），当其中一个应用需要消费另一个应用的服务时，无法再像单体应用一样通过简单的进程内机制（e.g. Spring的依赖注入）就能获取到服务实例；你甚至都不知道有没有这个服务方。</p></li><li><p><strong>如何保证远程调⽤的可靠性?</strong></p><p>既然是RPC，那必然要走IP网络，而我们都知道网络（相比计算和存储）是软件世界里最不可靠的东西。虽然有TCP这种可靠传输协议，但频繁丢包、交换机故障甚至电缆被挖断也常有发生；即使网络是好的，如果对方机器宕机了，或者进程负载过高不响应呢？</p></li><li><p><strong>如何降低服务调⽤的延迟？</strong></p><p>网络不只是不可靠，还有延迟的问题。虽然相同系统内的微服务应用通常都部署在一起，同机房内调用延迟很小；但对于较复杂的业务链路，很可能一次业务访问就会包括数十次RPC调用，累积起来的延迟就很可观了。</p></li><li><p><strong>如何保证服务调⽤的安全性？</strong></p><p>网络不只是不可靠和有延迟，还是不安全的。互联网时代，你永远不知道屏幕对面坐的是人还是狗；同样，微服务间通讯时，如果直接走裸的通讯协议，你也永远不知道对端是否真的就是自己人，或者传输的机密信息是否有被中间人偷听。</p></li></ul><h4 id="服务通信：耦合业务逻辑"><a href="#服务通信：耦合业务逻辑" class="headerlink" title="服务通信：耦合业务逻辑"></a>服务通信：耦合业务逻辑</h4><p>就像历史总是会重演，为了解决上述微服务引入的问题，最早需要工程师独立去完成对应的服务，在业务逻辑中实现下列逻辑：</p><ul><li>服务发现（Service Discovery）：解决“我想调用你，如何找到你”的问题。</li><li>服务熔断（Circuit Breaker）：缓解服务之间依赖的不可靠问题。</li><li>负载均衡（Load Balancing）：通过均匀分配流量，让请求处理更加及时。</li><li>安全通讯：包括协议加密（TLS）、身份认证（证书/签名）、访问鉴权（RBAC）等</li></ul><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-09-08_service-mesh-micro-service.png"></p><p>然而，随着分布式程度的增加，这些服务的复杂度也越来越高，一些问题不得不考虑：</p><ul><li>重复造轮子：需要编写和维护⼤量非功能性代码，如何集中精力专注业务创新?</li><li>与业务耦合：服务通讯逻辑与业务代码逻辑混在一起，动不动还会遇到点匪夷所思的分布式bug。</li></ul><h4 id="服务通信：独立Library"><a href="#服务通信：独立Library" class="headerlink" title="服务通信：独立Library"></a>服务通信：独立Library</h4><p>为了解决重复造轮子的问题，集成了服务通信中各种问题的Library开始变得十分流行，包括 Apache Dubbo（手动置顶）、Spring Cloud、Netflix OSS、gRPC 等等。</p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-09-08_service-mesh-micro-service-lib.png"></p><p>这些可复用的类库和框架，确确实实带来了质量和效率上的大幅提升，但是也存在着下列问题：</p><ul><li>并非完全透明：程序员们仍然需要正确理解和使⽤这些库，上手成本和出错概率依然很高。</li><li>限制技术选择：使用这些技术后，应用很容易就会被对应的语⾔和框架强绑定（vendor-lock）。</li><li>维护成本高：库版本升级，需要牵连应⽤一起重新构建和部署；麻烦不说，还要祈祷别出故障。</li></ul><h4 id="服务通信：Sidecar"><a href="#服务通信：Sidecar" class="headerlink" title="服务通信：Sidecar"></a>服务通信：Sidecar</h4><p>像网络协议栈发展的过程一样，将大规模分布式服务所需要的功能剥离出来集成到底层平台是一个众望所归的选择。人们通过应用层的协议(例如HTTP)写出了很多复杂的应用程序和服务，甚至不用考虑TCP是如何控制数据包在网络上传输的。这就是我们微服务所需要的，从事服务开发的工程师们可以专注于业务逻辑的开发，避免浪费时间去编写服务基础设施代码或者管理这些库和框架。</p><p>在这个想法下，我们可以得到类似于如下的图：</p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-09-08_service-mesh-protocol.png"></p><p>不幸的是，更改协议栈来增加微服务的功能不是一个可行的方案，许多开发者是通过一组代理来实现此功能。这里的设计思想是<strong>服务不需要和下游服务直连，所有的流量都通过该代理透明的来实现对应的功能</strong>。这里的透明代理，通过一种叫做 <code>Sidecar</code> 的模式来运行，Sidecar将上述类库和框架要干的事情从应用中彻底剥离了出来，并统一下沉到了基础设施层，这其中的典型代表就是 Linkerd 和 Envoy。</p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-09-08_service-mesh-sidecar.png"></p><h4 id="服务通信：Service-Mesh"><a href="#服务通信：Service-Mesh" class="headerlink" title="服务通信：Service Mesh"></a>服务通信：Service Mesh</h4><p>在这种模型中，每个服务都会有一个配套的代理SideCar。考虑到服务之间的通信仅仅通过SideCar代理，我们最终得到如下的部署图：</p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-09-08_service-mesh-data.png"></p><p>Buoyant的CEO William Morgan ，发现了各个SideCar代理之间互联组成了一个网状网络，<strong>2017初，William为这个网状的平台起了一个<a href="https://buoyant.io/2017/04/25/whats-a-service-mesh-and-why-do-i-need-one/" target="_blank" rel="external nofollow noopener noreferrer">“Service Mesh”的定义</a></strong>。</p><blockquote><p>Service Mesh是一个用于服务和服务之间通信的专用基础设施层。它负责服务请求能够在复杂的服务拓扑(组成了云原生应用)中可靠的进行投递。在实践中，Serivce Mesh的典型实现是作为轻量级网络代理阵列，部署在应用程序旁边，不需要业务进程感知到。</p></blockquote><p>William关于Service Mesh的定义中，最有说服力的一点是，他不再将SideCar代理视为一个独立组件，而是承认了<strong>它们组成的网络像它们自身一样是有价值的</strong></p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-09-08_service-mesh-data2.png"></p><p>随着很多公司将它们的微服务部署到更复杂的系统运行环境中，例如Kubernetes和Mesos，人们开始使用这些平台提供的工具来实现合适的Serivce Mesh的想法。它们将独立的SideCar代理从独立的工作环境中转移到一个适当的，有集中的控制面。</p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-09-08_service-mesh-control.png"></p><p>看下我们的鸟瞰图，服务之间的流量仍然是通过SideCar代理来进行转发，但是控制平面知道每个SideCar实例。控制平面能够让代理实现例如访问控制，指标收集等需要协作完成的事情。Istio是这个模型的典型实现。</p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-09-08_service-mesh-control2.png"> </p><h2 id="主流实现"><a href="#主流实现" class="headerlink" title="主流实现"></a>主流实现</h2><p>Service Mesh 的主流实现包括：</p><ul><li>Linkerd：背后公司是Buoyant，开发语⾔使用Scala，2016年1⽉15日初次发布，2017年1⽉23日加入CNCF。</li><li>Envoy：背后公司是Lyft，开发语言使用C++ 11，2016年9月13日初次发布，2017年9⽉14日加⼊CNCF。</li><li>Istio：背后公司是Google和IBM，开发语言使用Go，2017年5⽉月10日初次发布。</li><li>Conduit：背后公司也是Buoyant，开发语言使用Rust和Go，2017年12月5日初次发布，现在已经加入了 <code>Linkerd</code> 项目。</li></ul><h3 id="Linkerd"><a href="#Linkerd" class="headerlink" title="Linkerd"></a>Linkerd</h3><p>现在（2020.09.08） <code>Linkerd</code> 已经发展到 2.8 版本，由控制面和数据面组成，详情可以参考 <a href="https://linkerd.io/2/reference/architecture/" target="_blank" rel="external nofollow noopener noreferrer">这里</a></p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-09-08_linkerd-control-plane.png"></p><h3 id="Envoy"><a href="#Envoy" class="headerlink" title="Envoy"></a>Envoy</h3><p>Envoy是一个高性能的Service Mesh软件，现在主要被用于数据面作为 Sidecar 代理，详情可以参考 <a href="../7beb34d2/">这里</a></p><p><img alt data-src="https://cdn.jsdelivr.net/gh/yangchuansheng/imghosting/img/20200504160047.png"></p><h3 id="Istio"><a href="#Istio" class="headerlink" title="Istio"></a>Istio</h3><p>Istio是第二代 Service Mesh，第一次提出控制面的概念，详情可以参考 <a href="../22cae0b8/">这里</a></p><p><img alt="Istio Arch" data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-09-10_istio-arch.svg"></p><h3 id="NginMesh"><a href="#NginMesh" class="headerlink" title="NginMesh"></a>NginMesh</h3><p>Service Mesh 最基础的功能毕竟是 sidecar proxy. 提到 proxy 怎么能够少了 nginx? 我想nginx自己也是这么想的吧 毫不意外，nginx也推出了其 service mesh 的开源实现：nginMesh.</p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-09-08_nginx-sidecar.png"></p><p>不过，与 William Morgan 的死磕策略不同，nginMesh 从一开始就没有想过要做一套完整的第二代Service Mesh 开源方案，而是直接宣布兼容Istio, 作为Istio的 sidecar proxy. 由于 nginx 在反向代理方面广泛的使用，以及运维技术的相对成熟，nginMesh在sidecar proxy领域应该会有一席之地。</p><h2 id="对比Kubernetes原生架构"><a href="#对比Kubernetes原生架构" class="headerlink" title="对比Kubernetes原生架构"></a>对比Kubernetes原生架构</h2><h3 id="Kube-proxy-vs-Sidecar"><a href="#Kube-proxy-vs-Sidecar" class="headerlink" title="Kube-proxy vs Sidecar"></a>Kube-proxy vs Sidecar</h3><p>下图展示的是 Kubernetes 与 Service Mesh 中的的服务访问关系：</p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-09-08_k8s-vs-service-mesh.png"></p><ul><li>Kubernetes 集群的每个节点都部署了一个 <code>kube-proxy</code> 组件，该组件会与 Kubernetes API Server 通信，获取集群中的 <code>Service</code> 信息，然后设置 iptables 规则，直接将对某个 <code>Service</code> 的请求发送到对应的 Endpoint（属于同一组 <code>Service</code> 的 <code>Pod</code>）上。</li><li>Kube-proxy 实现了流量在 Kubernetes <code>Service</code> 多个 <code>Pod</code> 实例间的负载均衡，但是如何对这些 <code>Service</code> 间的流量做细粒度的控制，比如按照百分比划分流量到不同的应用版本（这些应用都属于同一个 <code>Service</code>，但位于不同的 deployment 上），做金丝雀发布（灰度发布）和蓝绿发布？Kubernetes 社区给出了 <a href="https://kubernetes.io/docs/concepts/cluster-administration/manage-deployment/#canary-deployments" target="_blank" rel="external nofollow noopener noreferrer">使用 Deployment 做金丝雀发布的方法</a>，该方法本质上就是通过修改 <code>Pod</code> 的 label 来将不同的 <code>Pod</code> 划归到 Deployment 的 <code>Service</code> 上。</li></ul><p><code>kube-proxy</code> 的设置都是全局生效的，无法对每个服务做细粒度的控制，而 <code>Service Mesh</code> 通过 <code>Sidecar</code> proxy 的方式将 Kubernetes 中对流量的控制从 <code>Service</code> 一层抽离出来，可以做更多的扩展。</p><h3 id="Ingress-vs-Gateway"><a href="#Ingress-vs-Gateway" class="headerlink" title="Ingress vs Gateway"></a>Ingress vs Gateway</h3><p> <code>kube-proxy</code> 只能路由 Kubernetes 集群内部的流量，而我们知道 Kubernetes 集群的 <code>Pod</code> 位于 CNI 创建的外网络中，集群外部是无法直接与其通信的，因此 Kubernetes 中创建了 Ingress 这个资源对象，它由位于 Kubernetes 边缘节点（这样的节点可以是很多个也可以是一组）的 Ingress controller 驱动，负责管理 <strong>南北向流量</strong>，Ingress 必须对接各种 Ingress Controller 才能使用，比如 <a href="https://github.com/kubernetes/ingress-nginx" target="_blank" rel="external nofollow noopener noreferrer">nginx ingress controller</a>、<a href="https://traefik.io/" target="_blank" rel="external nofollow noopener noreferrer">traefik</a>。</p><ul><li>Ingress 只适用于 HTTP 流量，使用方式也很简单，只能对 <code>Service</code>、port、HTTP 路径等有限字段匹配来路由流量，这导致它无法路由如 MySQL、Redis 和各种私有 RPC 等 TCP 流量。</li><li>要想直接路由南北向的流量，只能使用 <code>Service</code> 的 LoadBalancer 或 NodePort，前者需要云厂商支持，后者需要进行额外的端口管理。</li><li>有些 Ingress controller 支持暴露 TCP 和 UDP 服务，但是只能使用 <code>Service</code> 来暴露，Ingress 本身是不支持的，例如 <a href="https://kubernetes.github.io/ingress-nginx/user-guide/exposing-tcp-udp-services/" target="_blank" rel="external nofollow noopener noreferrer">nginx ingress controller</a>，服务暴露的端口是通过创建 ConfigMap 的方式来配置的。</li></ul><p><code>Istio</code> Gateway 的功能与 Kubernetes Ingress 类似，都是负责集群的南北向流量。<code>Istio</code> <code>Gateway</code> 描述的负载均衡器用于承载进出网格边缘的连接。该规范中描述了一系列开放端口和这些端口所使用的协议、负载均衡的 SNI 配置等内容。Gateway 是一种 CRD 扩展，它同时复用了 <code>Sidecar</code> proxy 的能力，详细配置请参考 <a href="https://istio.io/docs/reference/config/networking/gateway/" target="_blank" rel="external nofollow noopener noreferrer">Istio 官网</a>。</p><h2 id="落地问题"><a href="#落地问题" class="headerlink" title="落地问题"></a>落地问题</h2><p>服务网格的出现带来的变革：</p><p>第一，<strong>微服务治理与业务逻辑的解耦</strong>。服务网格把 SDK 中的<strong>大部分</strong>能力从应用中剥离出来，拆解为独立进程，以 Sidecar 的模式进行部署。服务网格通过将服务通信及相关管控功能从业务程序中分离并下沉到基础设施层，使其和业务系统完全解耦，使开发人员更加专注于业务本身。</p><blockquote><p>注意，这里提到了一个词“大部分”，SDK 中往往还需要保留<strong>协议编解码</strong>的逻辑，甚至在某些场景下还需要一个轻量级的 SDK 来实现细粒度的治理与监控策略。例如，要想实现方法级别的调用链追踪，服务网格则需要业务应用实现 trace ID 的传递，而这部分实现逻辑也可以通过轻量级的 SDK 实现。因此，从代码层面来讲，服务网格并非是零侵入的。</p></blockquote><p>第二，<strong>异构系统的统一治理</strong>。随着新技术的发展和人员更替，在同一家公司中往往会出现不同语言、不同框架的应用和服务，为了能够统一管控这些服务，以往的做法是为每种语言、每种框架都开发一套完整的 SDK，维护成本非常之高，而且给公司的中间件团队带来了很大的挑战。有了服务网格之后，通过将主体的服务治理能力下沉到基础设施，多语言的支持就轻松很多了。只需要提供一个非常轻量级的 SDK，甚至很多情况下都不需要一个单独的 SDK，就可以方便地实现多语言、多协议的统一流量管控、监控等需求。</p><p>此外，服务网格相对于传统微服务框架，还拥有三大技术优势：</p><ul><li>可观察性。因为服务网格是一个专用的基础设施层，所有的服务间通信都要通过它，所以它在技术堆栈中处于独特的位置，以便在服务调用级别上提供统一的遥测指标。这意味着，所有服务都被监控为“黑盒”。服务网格捕获诸如来源、目的地、协议、URL、状态码、延迟、持续时间等线路数据。这本质上等同于 web 服务器日志可以提供的数据，但是服务网格可以为所有服务捕获这些数据，而不仅仅是单个服务的 web 层。需要指出的是，收集数据仅仅是解决微服务应用程序中可观察性问题的一部分。存储与分析这些数据则需要额外能力的机制的补充，然后作用于警报或实例自动伸缩等。</li><li>流量控制。通过 <code>Service Mesh</code>，可以为服务提供智能路由（蓝绿部署、金丝雀发布、A/B test）、超时重试、熔断、故障注入、流量镜像等各种控制能力。而以上这些往往是传统微服务框架不具备，但是对系统来说至关重要的功能。例如，服务网格承载了微服务之间的通信流量，因此可以在网格中通过规则进行故障注入，模拟部分微服务出现故障的情况，对整个应用的健壮性进行测试。由于服务网格的设计目的是有效地将来源请求调用连接到其最优目标服务实例，所以这些流量控制特性是“面向目的地的”。这正是服务网格流量控制能力的一大特点。</li><li>安全。在某种程度上，单体架构应用受其单地址空间的保护。然而，一旦单体架构应用被分解为多个微服务，网络就会成为一个重要的攻击面。更多的服务意味着更多的网络流量，这对黑客来说意味着更多的机会来攻击信息流。而服务网格恰恰提供了保护网络调用的能力和基础设施。服务网格的安全相关的好处主要体现在以下三个核心领域：服务的认证、服务间通讯的加密、安全相关策略的强制执行。</li></ul><p>服务网格带来了巨大变革并且拥有其强大的技术优势，被称为第二代“微服务架构”。然而就像之前说的软件开发没有银弹，传统微服务架构有许多痛点，而服务网格也不例外，也有它的局限性。</p><ul><li>增加了复杂度。服务网格将 <code>Sidecar</code> 代理和其它组件引入到已经很复杂的分布式环境中，会极大地增加整体链路和操作运维的复杂性。</li><li>运维人员需要更专业。在容器编排器（如 Kubernetes）上添加 <code>Istio</code> 之类的服务网格，通常需要运维人员成为这两种技术的专家，以便充分使用二者的功能以及定位环境中遇到的问题。</li><li>延迟。从链路层面来讲，服务网格是一种侵入性的、复杂的技术，可以为系统调用增加显著的延迟。这个延迟是毫秒级别的，但是在特殊业务场景下，这个延迟可能也是难以容忍的。</li><li>平台的适配。服务网格的侵入性迫使开发人员和运维人员适应高度自治的平台并遵守平台的规则。</li></ul><h2 id="展望未来"><a href="#展望未来" class="headerlink" title="展望未来"></a>展望未来</h2><p>展望未来，Kubernetes 正在爆炸式发展，它已经成为企业绿地应用的容器编排的首选。如果说 Kubernetes 已经彻底赢得了市场，并且基于 Kubernetes 的应用程序的规模和复杂性持续增加，那么就会有一个临界点，而服务网格则将是有效管理这些应用程序所必需的。随着服务网格技术的持续发展，其实现产品（如 <code>Istio</code>）的架构与功能的不断优化，服务网格将完全取代传统微服务架构，成为大小企业微服务化和上云改造的首选架构。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://philcalcado.com/2017/08/03/pattern_service_mesh.html" target="_blank" rel="external nofollow noopener noreferrer">https://philcalcado.com/2017/08/03/pattern_service_mesh.html</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;Service Mesh 是一个&lt;strong&gt;基础设施层&lt;/strong&gt;，用于处理&lt;strong&gt;服务到服务间&lt;/strong&gt;的网络通信。&lt;strong&gt;云原生应用&lt;/strong&gt;有着复杂的服务拓扑，Service Mesh负责在这些&lt;strong&gt;网络拓扑中实现请求的可靠传递&lt;/strong&gt;。在实践中，Service Mesh通常实现为一组轻量级的&lt;strong&gt;网络代理&lt;/strong&gt;，它们与应用程序部署在一起，但是&lt;strong&gt;对应用保持透明&lt;/strong&gt;。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;本文作为 「Service Mesh」系列开篇，将理清 Service Mesh 的前世今生，通过对其概念与原理的理解，开始上手 Service Mesh的工作。与此同时，我们也会讨论 Service Mesh 在业界当前的应用现状，探讨其落地的难点与痛点。&lt;/p&gt;
    
    </summary>
    
    <content src="http://houmin.cc/https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-09-08_service-mesh.png" type="image" />
    
    
      <category term="术业专攻" scheme="http://houmin.cc/categories/%E6%9C%AF%E4%B8%9A%E4%B8%93%E6%94%BB/"/>
    
    
      <category term="service" scheme="http://houmin.cc/tags/service/"/>
    
      <category term="service mesh" scheme="http://houmin.cc/tags/service-mesh/"/>
    
      <category term="sidecar" scheme="http://houmin.cc/tags/sidecar/"/>
    
  </entry>
  
  <entry>
    <title>めぐる季节</title>
    <link href="http://houmin.cc/posts/b0b2b640/"/>
    <id>http://houmin.cc/posts/b0b2b640/</id>
    <published>2020-11-21T11:23:16.000Z</published>
    <updated>2020-11-26T13:36:14.191Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>经过立冬后的一夜冬雨，北京城满地黄叶堆积，下班路上被冻进口袋的双手真真切地告诉我：冬天真的来了。经过一周的工作，今年冬天的初雪如约而至，这里是2020年「朝花夕拾」第二十五期 <code>めぐる季节</code>，在季节转换间我们继续。</p>    <div id="aplayer-hSdnTkcd" class="aplayer aplayer-tag-marker meting-tag-marker" data-id="445063" data-server="netease" data-type="song" data-mode="circulation" data-autoplay="false" data-mutex="true" data-listmaxheight="340px" data-preload="auto" data-theme="#555"></div><a id="more"></a><h2 id="记录"><a href="#记录" class="headerlink" title="记录"></a>记录</h2><p>又是一年的初雪，本来想着今天去城内好好拍照的，想着在家吃完火锅再去，结果吃完雪已经停了，「小雪」真的名不虚传。很可惜，二十四节气的小雪这次搁置，下次这种机会一定要提前准备，有备无患。毕竟，你在北京呆的时间也没有多少时间了，要抓住每一次机会。</p><p>按照惯例，我们继续每周的数据总结，首先是 <code>RescueTime</code>：</p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-11-21_rescue-time.png"></p><ul><li>精力分散的时间里面，依然是企业微信消耗的时间占比最多。大家都知道工作时间被碎片化是一件非常难受的事情，好不容易进入某项工作的 <code>context</code>，又被企业微信/钉钉等工具打扰，上下文切换耗时太长。相比之下，还是更喜欢邮件一点，因为大家也不期待你能够及时回复，在一段时间内你可以专注你自己的事情。想到一个改进措施，每天花固定的时间来解决需要企业微信来进行沟通相关的事情，比如<code>11:30</code>、<code>5:30</code> 那会，所有要沟通的事情统一解决，下周看看效果。</li><li>相比于上周，这个周末的分散时间好多了，因为周末在学习GPU相关的内容，这也导致这篇「朝花夕拾」晚了四天</li><li>漫无目的刷手机的情况还存在，在改善中，手机知乎就不应该存在，知乎是碰到问题去搜索的，现在推送质量太差，平时阅读可以靠微信公众号和RSS订阅，这周入手了Kindle，是天然的RSS阅读器</li></ul><p>谷歌日历的每天总结还是没跟上，IFFT在印象笔记上的每日总结推送还在继续，下周加上这个维度的总结监测。接下来是Forest专注时间观察，现在对于 <code>Forest</code> 的使用还是太随意化了，每次要专注的时候有时候会忘记种树，还有的时候会去用手机。</p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-11-21_forest.jpg"></p><p>接下来是跑步数据，相比上周的只有一次跑步，这周一周三次跑步算得上一种进步了，但是真正的跑步习惯还没形成，跑步的时候也算不得轻松自在一路坚持下来，下周要继续。毕竟体脂还是有点高的，坚持减肥感受一下自己能够瘦到什么地步。</p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-11-21_running.jpg"></p><p>睡眠数据还没有进入统计，争取下周前能够把这套数据系统搭建起来，不论是购买新的硬件还是基于当前硬件挖数据。</p><h2 id="世界"><a href="#世界" class="headerlink" title="世界"></a>世界</h2><h3 id="区域全面经济合作协定"><a href="#区域全面经济合作协定" class="headerlink" title="区域全面经济合作协定"></a>区域全面经济合作协定</h3><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-11-15-rcep.jpg"></p><h3 id="华为出售荣耀"><a href="#华为出售荣耀" class="headerlink" title="华为出售荣耀"></a>华为出售荣耀</h3><h3 id="信用债"><a href="#信用债" class="headerlink" title="信用债"></a>信用债</h3><h3 id="蛋壳公寓暴雷"><a href="#蛋壳公寓暴雷" class="headerlink" title="蛋壳公寓暴雷"></a>蛋壳公寓暴雷</h3><h2 id="回归"><a href="#回归" class="headerlink" title="回归"></a>回归</h2>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;经过立冬后的一夜冬雨，北京城满地黄叶堆积，下班路上被冻进口袋的双手真真切地告诉我：冬天真的来了。经过一周的工作，今年冬天的初雪如约而至，这里是2020年「朝花夕拾」第二十五期 &lt;code&gt;めぐる季节&lt;/code&gt;，在季节转换间我们继续。&lt;/p&gt;

    &lt;div id=&quot;aplayer-hSdnTkcd&quot; class=&quot;aplayer aplayer-tag-marker meting-tag-marker&quot; data-id=&quot;445063&quot; data-server=&quot;netease&quot; data-type=&quot;song&quot; data-mode=&quot;circulation&quot; data-autoplay=&quot;false&quot; data-mutex=&quot;true&quot; data-listmaxheight=&quot;340px&quot; data-preload=&quot;auto&quot; data-theme=&quot;#555&quot;&gt;&lt;/div&gt;
    
    </summary>
    
    <content src="http://houmin.cc/https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-11-21_snow.png" type="image" />
    
    
      <category term="朝花夕拾" scheme="http://houmin.cc/categories/%E6%9C%9D%E8%8A%B1%E5%A4%95%E6%8B%BE/"/>
    
    
      <category term="小雪" scheme="http://houmin.cc/tags/%E5%B0%8F%E9%9B%AA/"/>
    
      <category term="RECP" scheme="http://houmin.cc/tags/RECP/"/>
    
  </entry>
  
  <entry>
    <title>【异构计算】GPU 虚拟化</title>
    <link href="http://houmin.cc/posts/6e1a1f6e/"/>
    <id>http://houmin.cc/posts/6e1a1f6e/</id>
    <published>2020-11-20T13:01:09.000Z</published>
    <updated>2021-01-07T09:26:49.007Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2 id="A-survey-of-GPU-sharing-for-DL"><a href="#A-survey-of-GPU-sharing-for-DL" class="headerlink" title="A survey of GPU sharing for DL"></a><strong>A survey of GPU sharing for DL</strong></h2><p>当前机器学习训练中，使用GPU提供算力已经非常普遍，对于GPU-based AI system的研究也如火如荼。在这些研究中，以提高资源利用率为主要目标的GPU共享(GPU sharing)是当下研究的热点之一。GPU共享涉及到的技术面较广，包括GPU架构（计算，存储等），Cuda，IO（内存，显存），机器学习框架（Tf，Pytorch），集群&amp;调度，ML/DL算法特性，通信（单机内和多机间），逆向工程等等，是一个自上而下的工作。本篇文章希望能提供一个对GPU共享工作的分享，希望能和相关领域的研究者们共同讨论。限于笔者能力有限，可能会出现一些错漏，希望能多多指正，感谢。</p><p>GPU共享，是指在同一张GPU卡上同时运行多个任务。优势在于：（1）集群中可以运行更多任务，减少抢占。（2）资源利用率（GPU/显存/e.t.c.）提高；GPU共享后，总利用率接近运行任务利用率之和，减少了资源浪费。（3）可以增强公平性，因为多个任务可以同时开始享受资源；也可以单独保证某一个任务的QoS。（4）减少任务排队时间。（5）总任务结束时间下降；假设两个任务结束时间分别是x,y，通过GPU共享，两个任务全部结束的时间小于x+y。</p><p>想要实现GPU共享，需要完成的主要工作有：（1）资源隔离，是指共享组件有能力限制任务占据算力（线程/SM）及显存的比例，更进一步地，可以限制总线带宽。（2）并行模式，主要指时间片模式和MPS模式。</p><a id="more"></a><h2 id="资源隔离"><a href="#资源隔离" class="headerlink" title="资源隔离"></a><strong>资源隔离</strong></h2><p>资源隔离是指共享组件有能力限制任务占据算力/显存的比例。限制的方法就是劫持调用。图一是在Nvidia GPU上，机器学习自上而下的视图。由于Cuda和Driver不开源，因此资源隔离层一般处在用户态。在内核态做隔离的困难较大，但也有一些工作。顺带一提，Intel的Driver是开源的，在driver层的共享和热迁移方面有一些上海交大和Intel合作的工作。</p><p><img alt="img" data-src="https://pic2.zhimg.com/80/v2-c56d1458a16fb2ecb05231676bedaebd_1440w.jpg"></p><p>图一/使用Nvidia GPU机器学习自上而下视图</p><p>来自腾讯的Gaia(ISPA’18)[1]共享层在Cuda driver API之上，它通过劫持对Cuda driver API的调用来做到资源隔离。劫持的调用如图二所示。具体实现方式也较为直接，在调用相应API时检查：（1）对于显存，一旦该任务申请显存后占用的显存大小大于config中的设置，就报错。（2）对于计算资源，存在硬隔离和软隔离两种方式，共同点是当任务使用的GPU SM利用率超出资源上限，则暂缓下发API调用。不同点是如果有资源空闲，软隔离允许任务超过设置，动态计算资源上限。而硬隔离则不允许超出设置量。该项目代码开源在[2]。实测即使只跑一个任务也会有较大JCT影响，可能是因为对资源的限制及守护程序的资源占用问题。KubeShare（HPDC ‘20）[3]的在资源隔离方面也是类似的方案。</p><p><img alt="img" data-src="https://pic1.zhimg.com/80/v2-a57553b87051e3f808f3e469f3066544_1440w.jpg">图二/ Gaia限制的CUDA driver API</p><p>发了44篇论文（截止2020年3月）的rCuda[4]和Gaia有相似之处，他们都是在Cuda driver API之上，通过劫持调用来做资源隔离。不同的是，rCuda除了资源隔离，最主要的目标是支持池化。池化简单来讲就是使用远程访问的形式使用GPU资源，任务使用本机的CPU和另一台机器的GPU，两者通过网络进行通信。也是因为这个原因，共享模块需要将CPU和GPU的调用分开。然而正常情况下混合编译的程序会插入一些没有开源的Cuda API，因此需要使用作者提供的cuda，分别编译程序的CPU和GPU部分。图三显示了rCuda的架构。如果使用该产品，用户需要重新编译，对用户有一定的影响。该项目代码不开源。另外vCUDA（TC ‘12）[5]和qCUDA(CloudCom ‘19)[18]也采用了和rCuda相似的技术。</p><p><img alt="img" data-src="https://pic4.zhimg.com/80/v2-77bf2f39619f86b12615dff7b4c94ef3_1440w.jpg">图三/rCuda架构</p><p>GPUShare（IPDPSW’ 16）[6]也是劫持的方式，但不同的是,它采用预测执行时间的方式来实现计算资源的公平性。作者认为比切换周期还小的短kernel不会影响公平使用，因此只限制了较大的kernel。</p><p>来自阿里的cGPU[7]，其共享模块在Nvidia driver层之上，也就是内核态。由于是在公有云使用，相对于用户态的共享会更加安全。它也是通过劫持对driver的调用完成资源隔离的，通过设置任务占用时间片长度来分配任务占用算力，但不清楚使用何种方式精准地控制上下文切换的时间。值得一提的是，由于Nvidia driver是不开源的，因此需要一些逆向工程才可以获得driver的相关method的name和ioctl参数的结构。该方案在使用上对用户可以做到无感知，当然JCT是有影响的。代码没有开源，也没有论文。图四是cGPU的架构图。</p><p><img alt="img" data-src="https://pic2.zhimg.com/80/v2-115ed2529ef08b23dda03531a761e2b1_1440w.jpg">图四/cgpu架构图</p><p>来自Nvidia的vGPU[8]其共享模块在Nvidia driver里面。vGPU通过vfio-mdev提供了一个隔离性非常高的的硬件环境，主要面向的是虚拟机产品，无法动态调整资源比例。来自Nvidia的产品当然没有开源。图五是vGPU的架构图。</p><p><img alt="img" data-src="https://pic1.zhimg.com/80/v2-08f7028ee011a1ae2304f3fd5c03e290_1440w.jpg">图五/vGPU架构图</p><p>Fractional GPU（RTAS’ 19）[9]是一篇基于MPS的资源隔离方案。其共享模块在Nvidia driver里面。该方案的隔离非常硬，核心就是绑定。在计算隔离方面，它通过给任务绑定一定比例的可使用SM，就可以天然地实现计算隔离。MPS的计算隔离是通过限制任务的thread数，相较于Fractional GPU会限制地更加不准确。在显存隔离方面，作者深入地研究Nvidia GPU内存架构（包括一些逆向工程）图六是Fractional GPU通过逆向得到的Nvidia GPU GTX 970的存储体系架构。通过页面着色（Page Coloring）来完成显存隔离。页面着色的思想也是将特定的物理页分配给GPU SM分区，以限制分区间互相抢占的问题。该隔离方案整体上来说有一定损耗，而且只能使用规定好的资源比例，不能够灵活地检测和使用全部空闲资源。另外使用该方案需要修改用户代码。代码开源在[10]。</p><p><img alt="img" data-src="https://pic4.zhimg.com/80/v2-704741168c4809f59f00579a11f2c1c7_1440w.jpg">图六/Fractional GPU通过逆向得到的Nvidia GPU GTX 970的存储体系架构</p><p>Mig（ MULTI-INSTANCE GPU）[21]是今年A100机器支持的资源隔离方案，Nvidia在最底层硬件上对资源进行了隔离，可以完全地做到计算/通信/配置/错误的隔离。它将SM和显存均匀地分给GPU instance，最多支持将SM分7份（一份14个），显存分8份（1份5GB）。顺带一提A100有SM108个，剩下的10个将无法用上。它可选的配置也是有限制的，如图七所示。</p><p><img alt="img" data-src="https://pic4.zhimg.com/80/v2-df195268fb6b385bc75745e30b667f4b_1440w.jpg"></p><p><img alt="img" data-src="https://pic3.zhimg.com/80/v2-94da48314185157753a32c54d93557ee_1440w.jpg">图七/Mig GPU Instance配置</p><h2 id="并行模式"><a href="#并行模式" class="headerlink" title="并行模式"></a><strong>并行模式</strong></h2><p>并行模式指任务是以何种方式在同一个GPU上运行的。目前有两种方式：（1）分时复用。指划分时间片，让不同的任务占据一个独立的时间片，需要进行上下文切换。在这种模式下，任务实际上是并发的，而不是并行的，因为同一时间只有一个任务在跑。（2）合并共享。指将多个任务合并成一个上下文，因此可以同时跑多个任务，是真正意义上的并行。在生产环境中，更多使用分时复用的方式。</p><p><strong>分时复用</strong></p><p>分时复用的模式大家都较为熟悉，CPU程序的时间片共享已经非常常见和易用，但在GPU领域还有一些工作要做。</p><p>如果在Nvidia GPU上直接启动两个任务，使用的就是时间片共享的方式。但该模式存在多任务干扰问题：即使两个机器学习任务的GPU利用率和显存利用率之和远小于1，单个任务的JCT也会高出很多。究其原因，是因为计算碰撞，通信碰撞，以及GPU的上下文切换较慢。计算碰撞很好理解，如果切换给另一个任务的时候，本任务正好在做CPU计算/IO/通信，而需要GPU计算时，时间片就切回给本任务，那么就不会有JCT的影响。但两个任务往往同时需要使用GPU资源。通信碰撞，是指任务同时需要使用显存带宽，在主机内存和设备显存之间传输数据。GPU上下文切换慢，是相对CPU而言的。CPU上下文切换的速度是微秒级别，而GPU的切换在毫秒级别。在此处也会有一定的损耗。图八是分时复用模式的常见架构。</p><p><img alt="img" data-src="https://pic3.zhimg.com/80/v2-2acd31e4bdba1acf7725da192939eb02_1440w.jpg">图八/分时复用架构图</p><p>上文提到的Gaia，KubeShare，rCuda，vCuda，qCuda，cGPU，vGPU均为分时复用的模式。由于上文所述的问题，他们的单个任务完成时间（JCT）都会受到较大的影响。V100测试环境下，两个任务同时运行，其JCT是单个任务运行时的1.4倍以上。因此在生产环境下，我们需要考虑如何减少任务之间互相影响的问题。上述方案都没有考虑机器学习的特性，只要共享层接收到kernel下发，检查没有超过设置上限，就会继续向下传递。另外也限制任务显存的使用不能超过设置上限，不具备弹性。因此针对特定的生产场景，有一些工作结合机器学习任务的特性，进行了资源的限制及优化。</p><p><strong>服务质量（QoS）保障</strong></p><p>在生产环境的GPU集群中常会有两类任务，代称为高优先级任务和低优先级任务。高优任务是时间敏感的，在它需要资源时需要立刻提供给它。而低优任务是时间不敏感的，当集群有资源没被使用时，就可以安排它填充资源缝隙以提高集群利用率。因此共享模块需要优先保障高优先级任务的JCT不受影响，以限制低优任务资源占用的方式。</p><p>Baymax（ASPLOS ‘16）[11]通过任务重排序保障了高优任务的QoS。Baymax作者认为多任务之间的性能干扰通常是由排队延迟和PCI-e带宽争用引起的。也就是说，当高优任务需要计算或IO通信时，如果有低优的任务排在它前面，高优任务就需要等待，因此QoS无法保障。针对这两点Baymax分别做了一些限制：（1）在排队延迟方面，Baymax利用KNN/LR模型来预测持续时间。然后Baymax对发给GPU的请求进行重新排序。简单来说，就是共享模块预测了每个请求的执行时间，当它认为发下去的请求GPU还没执行完时，新下发的请求就先进入队列里。同时将位于队列中的任务重排序，当需要下发请求时，先下发队列中的高优任务请求。（2）在PCI-e带宽争用方面，Baymax限制了并发数据传输任务的数量。Baymax作者在第二年发表了Prophet（ASPLOS ‘17）[12]，用于预测多任务共置时QoS的影响程度。在论文最后提到的实验中，表示如果预测到多个任务不会影响QoS，就将其共置，但此处共置使用的是MPS，也就是没有使用分时复用的模式了。在该研究中，预测是核心。预测准确性是否能适应复杂的生产环境，预测的机器负载是否较大，还暂不清楚。</p><p>来自阿里的AntMan（OSDI ‘20）[13]也认为排队延迟和带宽争用是干扰的原因，不同的是，它从DL模型的特点切入，来区分切换的时机。</p><p>在算力限制方面，AntMan通过限制低优任务的kernel launch保证了高优任务的QoS。图九是AntMan算力共享机制的对比。AntMan算力调度最小单元，在论文中描述似乎有些模糊，应该是Op（Operator），AntMan“会持续分析GPU运算符的执行时间“，并在空隙时插入另一个任务的Op。但如何持续分析，论文中并没有详细描述。在显存隔离方面，AntMan没有限制显存的大小，而是尽力让两个任务都能运行在机器上。但两个或多个任务的显存申请量可能会造成显存溢出，因此AntMan做了很多显存方面的工作。首先需要了解任务在显存中保存的内容：首先是模型，该数据是大小稳定的，当它在显存中时，iteration才可以开始计算。论文中表示90%的任务模型使用500mb以内的显存。其次是iteration开始时申请的临时显存，这部分显存理论上来说，在iteration结束后就会释放。但使用的机器学习框架有缓存机制，申请的显存不会退回，该特性保障了速度，但牺牲了共享的可能性。因此AntMan做了一些显存方面最核心的机制是，当显存放不下时，就转到内存上。在此处论文还做了很多工作，不再尽述。</p><p>论文描述称AntMan可以规避总线带宽争用问题，但似乎从机制上来说无法避免。除此之外，按照Op为粒度进行算力隔离是否会需要大量调度负载也是一个疑问，另外Op执行时间的差异性较大，尤其是开启XLA之后，这也可能带来一些不确定性。该方案需要修改机器学习框架（Tensorflow和Pytorch），对用户有一定的影响。代码开源在[20]，目前还是WIP项目（截止2020/11/18），核心部分（local-coordinator）还没能开源。</p><p><img alt="img" data-src="https://pic3.zhimg.com/80/v2-953ef97814735d35dc1dcc7cfdab7c9e_1440w.jpg">图九/AntMan算力共享机制的对比</p><p>如果最小调度单元是iteration，则会更加简单。首先需要了解一下DL训练的特征：训练时的最小迭代是一个iteration，分为四个过程：IO，进行数据读取存储以及一些临时变量的申请等；前向，在此过程中会有密集的GPU kernel。NLP任务在此处也会有CPU负载。后向，计算梯度更新，需要下发GPU kernel；更新，如果非一机一卡的任务，会有通信的过程。之后更新合并后的梯度，需要一小段GPU时间。可以看出前向后向和通信之后的更新过程，是需要使用GPU的，通信和IO不需要。因此可以在此处插入一些来自其他任务的kernel，同时还可以保证被插入任务的QoS。更简单的方式是，通过在iteration前后插入另一个任务的iteration来完成共享。当然这样就无法考虑通信的空隙，可以被理解是一种tradeoff。另外也因为iteration是最小调度单元，避免了计算资源和显存带宽争用问题。另外，如果不考虑高优任务，实现一个退化版本，贪心地放置iteration而不加以限制。可以更简单地提高集群利用率，也可以让任务的JCT/排队时间减小。</p><p><strong>针对推理的上下文切换</strong></p><p>在上文中描述了分时复用的三个问题，其中上下文切换是一个耗时点。来自字节跳动的PipeSwitch（OSDI ‘20）[14]针对推理场景的上下文切换进行了优化。具体生产场景是这样的：训练推理任务共享一张卡，大多数时候训练使用资源。当推理请求下发，上下文需要立刻切换到推理任务。如果模型数据已经在显存中，切换会很快，但生产环境中模型一般较大，训练和推理的模型不能同时加载到显存中，当切换到推理时，需要先传输整个模型，因此速度较慢。</p><p>在该场景下，GPU上下文切换的开销有：（1）任务清理，指释放显存。（2）任务初始化，指启动进程，初始化Cuda context等。（3）Malloc。（4）模型传输，从内存传到显存。</p><p>在模型传输方面，PipeSwitch作者观察到，和训练不同的是推理只有前向过程，因此只需要知道上一层的输出及本层的参数就可以开始计算本层。目前的加载方式是，将模型数据全部加载到显存后，才会开始进行计算，但实际上如果对IO和计算做pipeline，只加载一层就开始计算该层，就会加快整体速度。当然直接使用层为最小粒度可能会带来较大开销，因此进行了grouping合并操作。图十显示了pipeline的对比。在任务清理和初始化方面，设置了一些常驻进程来避免开销。最后在Malloc方面也使用了统一的内存管理来降低开销。可以说做的非常全面。由于需要获知层级结构，因此需要对Pytorch框架进行修改，对用户有一定影响。代码开源在[19].</p><p><img alt="img" data-src="https://pic1.zhimg.com/80/v2-81a828e00f810669c93b4499fd9e8720_1440w.jpg">图十/PipeSwitch pipeline的对比</p><p><strong>合并共享</strong></p><p>合并共享是指，多个任务合并成一个上下文，因此可以共享GPU资源，同时发送kernel到GPU上，也共同使用显存。最具有代表性的是Nvidia的MPS[15]。该模式的好处是显而易见的，当任务使用的资源可以同时被满足时，其JCT就基本没有影响，性能可以说是最好的。可以充分利用GPU资源。但坏处也是致命的：错误会互相影响，如果一个任务错误退出（包括被kill），如果该任务正在执行kernel，那么和该任务共同share IPC和UVM的任务也会一同出错退出。目前还没有工作能够解决这一问题，Nvidia官方也推荐使用MPS的任务需要能够接受错误影响，比如MPI程序。因此无法在生产场景上大规模使用。另外，有报告称其不能支持所有DL框架的所有版本。</p><p>在资源隔离方面，MPS没有显存隔离，可以通过限制同时下发的thread数粗略地限制计算资源。它位于Nvidia Driver之上。图十一是MPS的架构图。</p><p><img alt="img" data-src="https://pic2.zhimg.com/80/v2-9ac1476ec711db7c87c479674e8278f9_1440w.jpg">图十一/MPS架构图</p><p>Salus（MLSys ‘20）[16]也采取了合并共享的方式，作者通过Adaptor将GPU请求合并到同一个context下，去掉了上下文切换。当然，和MPS一样会发生错误传播，论文中也没有要解决这一问题，因此无法在生产环境中使用。但笔者认为这篇论文中更大的价值在显存和调度方面，它的很多见解在AntMan和PipeSwitch中也有体现。调度方面，以iteration为最小粒度，并且诠释了原因：使用kernel为粒度，可以进一步利用资源，但会增加调度服务的开销。因此折中选择了iteration，可以实现性能最大化。显存方面，一些观察和AntMan是一致的：显存变化具有周期性；永久性显存（模型）较小，只要模型在显存中就可以开始计算；临时性显存在iteration结束后就应该释放。也描述了机器学习框架缓存机制的死锁问题。不过Salus实现上需要两个任务所需的显存都放到GPU显存里，没有置换的操作。论文中也提到了推理场景下的切换问题：切换后理论上模型传输时间比推理延迟本身长几倍。除此之外论文中也有一些其他的观察点，值得一看。图十二展示了Salus架构。该项目代码开源在[17]。Salus也需要修改DL框架。作者也开源了修改后的tensorflow代码。</p><p><img alt="img" data-src="https://pic2.zhimg.com/80/v2-28340c2c8607d60d527beeb4128483fd_1440w.jpg">图十二/Salus架构图</p><p>如果在合并共享模块之上做分时复用，应可以绕过硬件的限制，精准地控制时间片和切换的时机，也可以去除上下文切换的开销。但在这种情况下是否还会有错误影响，还需要进一步验证。</p><h2 id="场景展望"><a href="#场景展望" class="headerlink" title="场景展望"></a><strong>场景展望</strong></h2><p>目前GPU共享已经逐渐开始进入工业落地的阶段了，若需要更好地满足用户对使用场景的期待，除了更高的性能，笔者认为以下几点也需要注意。</p><ul><li>能够提供稳定的服务，运维便捷。比如MPS的错误影响是不能被接受的，另外对于带有预测的实现，也需要更高的稳定性。共享工作负载尽量降低。</li><li>更低的JCT时延，最好具有保障部分任务QoS的能力。对于一个已有的GPU集群进行改造时，需要尽量减少对已有的用户和任务的影响。</li><li>不打扰用户，尽量不对用户的代码和框架等做修改，另外也需要考虑框架和其他库的更新问题。</li></ul><hr><h2 id="GPU-虚拟化方案"><a href="#GPU-虚拟化方案" class="headerlink" title="GPU 虚拟化方案"></a>GPU 虚拟化方案</h2><h3 id="Nvidia-vGPU"><a href="#Nvidia-vGPU" class="headerlink" title="Nvidia vGPU"></a>Nvidia vGPU</h3><p>NVIDIA Virtual GPU允许多虚拟机能够同时直接访问单个物理GPU的能力，只需要在虚拟机上装上与宿主机相同的驱动设备。通过这种方式，NVIDIA vGPU给多个虚拟机非并行化图形性能，以及应用的兼容性，在不同负载间来共享一个GPU。</p><p><img alt="Diagram showing the high-level architecture of NVIDIA vGPU" data-src="https://docs.nvidia.com/grid/latest/grid-vgpu-user-guide/graphics/architecture-grid-vgpu.png"></p><p>NVIDIA在vGPU技术上提供了2种模式，GPU passthrough和Bare-Metal Deployment。GPU passthrough模式相当于独占，不允许虚拟机之间共享设备，Bare-Metal相当于共享模式。GRID技术的Bare-Metal通过vfio-mdev提供了一个隔离性非常高的的硬件环境（不是模拟简单的模拟硬件），这个虚拟化技术并不会对性能有很大的伤害，对多租户需要强隔离的平台是一个很好的选择。</p><p>但是这个技术目前来看主要针对的是<a href="https://docs.nvidia.com/grid/latest/grid-vgpu-user-guide/index.html#grid-vgpu-introduction" target="_blank" rel="external nofollow noopener noreferrer">虚拟机平台</a>，在技术特性方面也有明确写出<a href="https://docs.nvidia.com/grid/latest/grid-vgpu-user-guide/index.html#features-grid-vgpu" target="_blank" rel="external nofollow noopener noreferrer">某些功能不支持</a>，其次NVIDIA GRID技术需要购买NVIDIA公司的软件授权才能使用，这个授权费相当昂贵。</p><h4 id="Time-Sliced-Nvidia-vGPU-Internel-Architecture"><a href="#Time-Sliced-Nvidia-vGPU-Internel-Architecture" class="headerlink" title="Time-Sliced Nvidia vGPU Internel Architecture"></a>Time-Sliced Nvidia vGPU Internel Architecture</h4><p>通过分时复用实现对于 GPU 的共享：</p><p><img alt="Diagram showing the internal architecture of a time-sliced NVIDIA vGPU" data-src="https://docs.nvidia.com/grid/latest/grid-vgpu-user-guide/graphics/architecture-grid-vgpu-internal.png"></p><h4 id="Since-11-1-MIG-Backend-Nvidia-vGPU-Internal-Architecture"><a href="#Since-11-1-MIG-Backend-Nvidia-vGPU-Internal-Architecture" class="headerlink" title="Since 11.1 MIG-Backend Nvidia vGPU Internal Architecture"></a>Since 11.1 MIG-Backend Nvidia vGPU Internal Architecture</h4><p>Multi-Instance-GPU</p><p><img alt="Diagram showing the internal architecture of a MIG-backed NVIDIA vGPU" data-src="https://docs.nvidia.com/grid/latest/grid-vgpu-user-guide/graphics/architecture-grid-vgpu-mig-backed-internal.png"></p><h3 id="Nvidia-MPS"><a href="#Nvidia-MPS" class="headerlink" title="Nvidia MPS"></a>Nvidia MPS</h3><p>NVIDIA MPS技术NVIDIA对GPU共享的最早的一种支持模式，通过MPS server和MPS client就可以让多个GPU任务共享GPU的计算能力。对于容器平台，这种共享GPU的方式是一种可行性的选择。</p><p>不过，这种指令代理技术有一个<a href="https://docs.nvidia.com/deploy/pdf/CUDA_Multi_Process_Service_Overview.pdf" target="_blank" rel="external nofollow noopener noreferrer">弊端</a>，就是如果MPS Server挂掉或者其他MPS client端造成的非正常性退出，会导致处于同一个MPS server下的所有MPS client都受到影响，这种影响对于提供共享服务的平台来说是灾难性的。</p><h3 id="Gaia-vCUDA"><a href="#Gaia-vCUDA" class="headerlink" title="Gaia vCUDA"></a>Gaia vCUDA</h3><p>它通过劫持对Cuda driver API的调用来做到资源隔离。劫持的调用如图二所示。具体实现方式也较为直接，在调用相应API时检查：（1）对于显存，一旦该任务申请显存后占用的显存大小大于config中的设置，就报错。（2）对于计算资源，存在硬隔离和软隔离两种方式，共同点是当任务使用的GPU SM利用率超出资源上限，则暂缓下发API调用。不同点是如果有资源空闲，软隔离允许任务超过设置，动态计算资源上限。而硬隔离则不允许超出设置量。该项目代码开源在[2]。实测即使只跑一个任务也会有较大JCT影响，可能是因为对资源的限制及守护程序的资源占用问题。</p><p>vCUDA的系统架构与NVIDIA的GRID架构类似，采用一个Manager来管理GPU，Manager负责配置容器的GPU计算能力和显存资源，做到使用者无法使用多余申请的显存，GPU的平均使用率不会大幅超出申请值。vCUDA的设计采用零入侵设计，用户的程序无需重新编译就可以运行在GaiaStack平台进行GPU共享。</p><p><img alt="img" data-src="http://km.oa.com/files/photos/pictures/201812/1544621216_79_w462_h389.png"></p><p>vCUDA使用修改后cuda library来达到资源控制，vCUDA分别修改了计算操作，显存操作和信息获取3个方面的API。</p><p><img alt data-src="https://pic1.zhimg.com/80/v2-a57553b87051e3f808f3e469f3066544_720w.jpg"></p><h3 id="Alibaba-cGPU"><a href="#Alibaba-cGPU" class="headerlink" title="Alibaba cGPU"></a>Alibaba cGPU</h3><p>来自阿里的cGPU[7]，其共享模块在Nvidia driver层之上，也就是内核态。由于是在公有云使用，相对于用户态的共享会更加安全。它也是通过劫持对driver的调用完成资源隔离的，通过设置任务占用时间片长度来分配任务占用算力，但不清楚使用何种方式精准地控制上下文切换的时间。值得一提的是，由于Nvidia driver是不开源的，因此需要一些逆向工程才可以获得driver的相关method的name和ioctl参数的结构。该方案在使用上对用户可以做到无感知，当然JCT是有影响的。代码没有开源，也没有论文。图四是cGPU的架构图。</p><p><img alt data-src="https://pic2.zhimg.com/80/v2-115ed2529ef08b23dda03531a761e2b1_720w.jpg"></p><h3 id="Alibaba-AntMan"><a href="#Alibaba-AntMan" class="headerlink" title="Alibaba AntMan"></a>Alibaba AntMan</h3><p>来自阿里的AntMan（OSDI ‘20）[13]也认为排队延迟和带宽争用是干扰的原因，不同的是，它从DL模型的特点切入，来区分切换的时机。</p><p>在算力限制方面，AntMan通过限制低优任务的kernel launch保证了高优任务的QoS。图九是AntMan算力共享机制的对比。AntMan算力调度最小单元，在论文中描述似乎有些模糊，应该是Op（Operator），AntMan“会持续分析GPU运算符的执行时间“，并在空隙时插入另一个任务的Op。但如何持续分析，论文中并没有详细描述。在显存隔离方面，AntMan没有限制显存的大小，而是尽力让两个任务都能运行在机器上。但两个或多个任务的显存申请量可能会造成显存溢出，因此AntMan做了很多显存方面的工作。首先需要了解任务在显存中保存的内容：首先是模型，该数据是大小稳定的，当它在显存中时，iteration才可以开始计算。论文中表示90%的任务模型使用500mb以内的显存。其次是iteration开始时申请的临时显存，这部分显存理论上来说，在iteration结束后就会释放。但使用的机器学习框架有缓存机制，申请的显存不会退回，该特性保障了速度，但牺牲了共享的可能性。因此AntMan做了一些显存方面最核心的机制是，当显存放不下时，就转到内存上。在此处论文还做了很多工作，不再尽述。</p><p>论文描述称AntMan可以规避总线带宽争用问题，但似乎从机制上来说无法避免。除此之外，按照Op为粒度进行算力隔离是否会需要大量调度负载也是一个疑问，另外Op执行时间的差异性较大，尤其是开启XLA之后，这也可能带来一些不确定性。该方案需要修改机器学习框架（Tensorflow和Pytorch），对用户有一定的影响。代码开源在[20]，目前还是WIP项目（截止2020/11/18），核心部分（local-coordinator）还没能开源。</p><p><img alt="AntMan算力共享机制的对比" data-src="https://pic3.zhimg.com/80/v2-953ef97814735d35dc1dcc7cfdab7c9e_720w.jpg"></p><p>如果最小调度单元是iteration，则会更加简单。首先需要了解一下DL训练的特征：训练时的最小迭代是一个iteration，分为四个过程：IO，进行数据读取存储以及一些临时变量的申请等；前向，在此过程中会有密集的GPU kernel。NLP任务在此处也会有CPU负载。后向，计算梯度更新，需要下发GPU kernel；更新，如果非一机一卡的任务，会有通信的过程。之后更新合并后的梯度，需要一小段GPU时间。可以看出前向后向和通信之后的更新过程，是需要使用GPU的，通信和IO不需要。因此可以在此处插入一些来自其他任务的kernel，同时还可以保证被插入任务的QoS。更简单的方式是，通过在iteration前后插入另一个任务的iteration来完成共享。当然这样就无法考虑通信的空隙，可以被理解是一种tradeoff。另外也因为iteration是最小调度单元，避免了计算资源和显存带宽争用问题。另外，如果不考虑高优任务，实现一个退化版本，贪心地放置iteration而不加以限制。可以更简单地提高集群利用率，也可以让任务的JCT/排队时间减小。</p><h3 id="ByteDance-PipeSwitch"><a href="#ByteDance-PipeSwitch" class="headerlink" title="ByteDance PipeSwitch"></a>ByteDance PipeSwitch</h3><p>在上文中描述了分时复用的三个问题，其中上下文切换是一个耗时点。来自字节跳动的PipeSwitch（OSDI ‘20）[14]针对推理场景的上下文切换进行了优化。具体生产场景是这样的：训练推理任务共享一张卡，大多数时候训练使用资源。当推理请求下发，上下文需要立刻切换到推理任务。如果模型数据已经在显存中，切换会很快，但生产环境中模型一般较大，训练和推理的模型不能同时加载到显存中，当切换到推理时，需要先传输整个模型，因此速度较慢。</p><p>在该场景下，GPU上下文切换的开销有：（1）任务清理，指释放显存。（2）任务初始化，指启动进程，初始化Cuda context等。（3）Malloc。（4）模型传输，从内存传到显存。</p><p>在模型传输方面，PipeSwitch作者观察到，和训练不同的是推理只有前向过程，因此只需要知道上一层的输出及本层的参数就可以开始计算本层。目前的加载方式是，将模型数据全部加载到显存后，才会开始进行计算，但实际上如果对IO和计算做pipeline，只加载一层就开始计算该层，就会加快整体速度。当然直接使用层为最小粒度可能会带来较大开销，因此进行了grouping合并操作。图十显示了pipeline的对比。在任务清理和初始化方面，设置了一些常驻进程来避免开销。最后在Malloc方面也使用了统一的内存管理来降低开销。可以说做的非常全面。由于需要获知层级结构，因此需要对Pytorch框架进行修改，对用户有一定影响。代码开源在[19].</p><p><img alt="img" data-src="https://pic1.zhimg.com/80/v2-81a828e00f810669c93b4499fd9e8720_720w.jpg"></p><h2 id="GPU-并行模式"><a href="#GPU-并行模式" class="headerlink" title="GPU 并行模式"></a>GPU 并行模式</h2><p>并行模式指任务是以何种方式在同一个GPU上运行的。目前有两种方式：</p><ul><li>分时复用：指划分时间片，让不同的任务占据一个独立的时间片，需要进行上下文切换。在这种模式下，任务实际上是并发的，而不是并行的，因为同一时间只有一个任务在跑。</li><li>合并共享：指将多个任务合并成一个上下文，因此可以同时跑多个任务，是真正意义上的并行。在生产环境中，更多使用分时复用的方式。</li></ul><h3 id="分时复用"><a href="#分时复用" class="headerlink" title="分时复用"></a>分时复用</h3><p>分时复用的模式大家都较为熟悉，CPU程序的时间片共享已经非常常见和易用，但在GPU领域还有一些工作要做。如果在Nvidia GPU上直接启动两个任务，使用的就是时间片共享的方式。但该模式存在多任务干扰问题：即使两个机器学习任务的GPU利用率和显存利用率之和远小于1，单个任务的JCT(单个任务完成时间)也会高出很多。</p><p>究其原因，是因为计算碰撞，通信碰撞，以及GPU的上下文切换较慢。</p><ul><li>计算碰撞很好理解，如果切换给另一个任务的时候，本任务正好在做CPU计算/IO/通信，而需要GPU计算时，时间片就切回给本任务，那么就不会有JCT的影响。但两个任务往往同时需要使用GPU资源。</li><li>通信碰撞，是指任务同时需要使用显存带宽，在主机内存和设备显存之间传输数据。</li><li>GPU上下文切换慢，是相对CPU而言的。CPU上下文切换的速度是微秒级别，而GPU的切换在毫秒级别。在此处也会有一定的损耗。</li></ul><p>图八是分时复用模式的常见架构：</p><p><img alt="media/image3.png" data-src="https://docs.nvidia.com/deploy/mps/topics/media/image3.png"></p><p>上文提到的Gaia，KubeShare，rCuda，vCuda，qCuda，cGPU，vGPU均为分时复用的模式。由于上文所述的问题，他们的单个任务完成时间（JCT）都会受到较大的影响。V100测试环境下，两个任务同时运行，其JCT是单个任务运行时的1.4倍以上。因此在生产环境下，我们需要考虑如何减少任务之间互相影响的问题。上述方案都没有考虑机器学习的特性，只要共享层接收到kernel下发，检查没有超过设置上限，就会继续向下传递。另外也限制任务显存的使用不能超过设置上限，不具备弹性。因此针对特定的生产场景，有一些工作结合机器学习任务的特性，进行了资源的限制及优化。</p><h3 id="QoS-保障"><a href="#QoS-保障" class="headerlink" title="QoS 保障"></a>QoS 保障</h3><h3 id="合并共享"><a href="#合并共享" class="headerlink" title="合并共享"></a>合并共享</h3><p>合并共享是指，多个任务合并成一个上下文，因此可以共享GPU资源，同时发送kernel到GPU上，也共同使用显存。最具有代表性的是Nvidia的MPS[15]。该模式的好处是显而易见的，当任务使用的资源可以同时被满足时，其JCT就基本没有影响，性能可以说是最好的。可以充分利用GPU资源。但坏处也是致命的：错误会互相影响，如果一个任务错误退出（包括被kill），如果该任务正在执行kernel，那么和该任务共同share IPC和UVM的任务也会一同出错退出。目前还没有工作能够解决这一问题，Nvidia官方也推荐使用MPS的任务需要能够接受错误影响，比如MPI程序。因此无法在生产场景上大规模使用。另外，有报告称其不能支持所有DL框架的所有版本。</p><p>在资源隔离方面，MPS没有显存隔离，可以通过限制同时下发的thread数粗略地限制计算资源。它位于Nvidia Driver之上</p><p><img alt="media/image4.png" data-src="https://docs.nvidia.com/deploy/mps/topics/media/image4.png"></p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://zhuanlan.zhihu.com/p/285994980" target="_blank" rel="external nofollow noopener noreferrer">https://zhuanlan.zhihu.com/p/285994980</a></li><li><a href="https://docs.nvidia.com/grid/latest/grid-vgpu-user-guide/index.html" target="_blank" rel="external nofollow noopener noreferrer">Nvidia vGPU</a></li><li><a href="https://docs.nvidia.com/deploy/mps/index.html" target="_blank" rel="external nofollow noopener noreferrer">Nvidia MPS</a></li><li><a href="https://zhuanlan.zhihu.com/p/285994980" target="_blank" rel="external nofollow noopener noreferrer">针对深度学习的GPU共享</a></li><li><a href="http://km.oa.com/group/37641/articles/show/418533" target="_blank" rel="external nofollow noopener noreferrer">http://km.oa.com/group/37641/articles/show/418533</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;A-survey-of-GPU-sharing-for-DL&quot;&gt;&lt;a href=&quot;#A-survey-of-GPU-sharing-for-DL&quot; class=&quot;headerlink&quot; title=&quot;A survey of GPU sharing for DL&quot;&gt;&lt;/a&gt;&lt;strong&gt;A survey of GPU sharing for DL&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;当前机器学习训练中，使用GPU提供算力已经非常普遍，对于GPU-based AI system的研究也如火如荼。在这些研究中，以提高资源利用率为主要目标的GPU共享(GPU sharing)是当下研究的热点之一。GPU共享涉及到的技术面较广，包括GPU架构（计算，存储等），Cuda，IO（内存，显存），机器学习框架（Tf，Pytorch），集群&amp;amp;调度，ML/DL算法特性，通信（单机内和多机间），逆向工程等等，是一个自上而下的工作。本篇文章希望能提供一个对GPU共享工作的分享，希望能和相关领域的研究者们共同讨论。限于笔者能力有限，可能会出现一些错漏，希望能多多指正，感谢。&lt;/p&gt;
&lt;p&gt;GPU共享，是指在同一张GPU卡上同时运行多个任务。优势在于：（1）集群中可以运行更多任务，减少抢占。（2）资源利用率（GPU/显存/e.t.c.）提高；GPU共享后，总利用率接近运行任务利用率之和，减少了资源浪费。（3）可以增强公平性，因为多个任务可以同时开始享受资源；也可以单独保证某一个任务的QoS。（4）减少任务排队时间。（5）总任务结束时间下降；假设两个任务结束时间分别是x,y，通过GPU共享，两个任务全部结束的时间小于x+y。&lt;/p&gt;
&lt;p&gt;想要实现GPU共享，需要完成的主要工作有：（1）资源隔离，是指共享组件有能力限制任务占据算力（线程/SM）及显存的比例，更进一步地，可以限制总线带宽。（2）并行模式，主要指时间片模式和MPS模式。&lt;/p&gt;
    
    </summary>
    
    <content src="http://houmin.cc/https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2019-10-18_city.jpg" type="image" />
    
    
      <category term="术业专攻" scheme="http://houmin.cc/categories/%E6%9C%AF%E4%B8%9A%E4%B8%93%E6%94%BB/"/>
    
    
      <category term="虚拟化" scheme="http://houmin.cc/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
      <category term="GPU" scheme="http://houmin.cc/tags/GPU/"/>
    
      <category term="资源隔离" scheme="http://houmin.cc/tags/%E8%B5%84%E6%BA%90%E9%9A%94%E7%A6%BB/"/>
    
      <category term="深度学习" scheme="http://houmin.cc/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>【异构计算】NVIDIA GPU MIG</title>
    <link href="http://houmin.cc/posts/4e8612ed/"/>
    <id>http://houmin.cc/posts/4e8612ed/</id>
    <published>2020-11-19T09:03:47.000Z</published>
    <updated>2021-01-14T10:40:22.828Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>MIG，也就是 <code>Multi-Instance GPU</code> 是 NVIDIA 在 <code>NVIDIA GTC 2020</code> 发布的最新 Ampere 架构的 <code>NVIDIA A100 GPU</code> 推出的新特性。当配置为 MIG 运行状态时，A100 可以通过分出最多 7 个核心来帮助供应商提高 GPU 服务器的利用率，无需额外投入。MIG 提供了一种多用户使用隔离的GPU资源、提高GPU资源使用率的新的方式，特别适合于云服务提供商的多租户场景，保证一个租户的运行不干扰另一个租户。本文将介绍 MIG 的新特性和使用方法，以及在容器和 k8s 中使用 MIG 的方案。 </p><a id="more"></a><h2 id="MIG-技术简介"><a href="#MIG-技术简介" class="headerlink" title="MIG 技术简介"></a>MIG 技术简介</h2><p>随着深度学习的广泛应用，使用GPU加速训练和推理越来越普遍。然而，高昂的GPU价格在这里成为了不可忽视的成本，有时候单个GPU并没有得到充分的利用，在多租户之间如何能够共享GPU并且互不干扰成为了一个重要课题，尤其是在云服务环境使用GPU的场景下。针对这个问题，有很多种解决方案，分别是软件级虚拟化GPU和硬件级虚拟化GPU，而 MIG 即是硬件级虚拟化GPU的一种方式：</p><blockquote><p>Data center managers aim to keep resource utilization high, so an ideal data center accelerator doesn’t just go big- it also efficiently accelerates many smaller workloads.</p></blockquote><p><strong>MIG主要技术特点</strong></p><ol><li>每个GI独立的SM，完全隔离的显存（包括隔离的显存，L2cache，独立的DMA控制器等），从而可以保证每个GI的QoS</li><li>支持虚拟机，容器，进程层面的使用</li></ol><p>首先看一下传统GPU的内部架构，<strong>MIG的目的是使虚拟的每个GPU实例都拥有上面类似的架构。</strong></p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2021-01-14_nvidia-gpu.png"></p><h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a><strong>基本概念</strong></h3><p>MIG对资源的划分可以分为两级，分别是GPU Instance、Compute Instance</p><h4 id="GPU-Instance"><a href="#GPU-Instance" class="headerlink" title="GPU Instance"></a>GPU Instance</h4><p>MIG功能可以将单个GPU划分为多个GPU分区，称为 <code>GPU Insance</code>。创建GPU实例可以认为是将一个大GPU拆分为多个较小的GPU，每个GPU实例都具有专用的计算和内存资源。</p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2021-01-04_nvidia-mig-compare.png"></p><p>每个GPU实例的行为就像一个较小的，功能齐全的独立GPU，其中包括：</p><ul><li>预定义数量的GPC</li><li>SMs</li><li>L2 Cache</li><li>Frame buffer</li></ul><p>注意：在MIG操作模式下，每个GPU实例中的单个GPC启用了7个TPC（14个SM），这使所有GPU切片具有相同的一致计算性能。</p><ul><li><strong>GPU Engine</strong>：一个 GPU Engine 是 GPU 中执行工作的组件，常用的GPU Engine 如下，每个Engine都能够被独立地调度和为不同 GPU Context 执行工作<ul><li><strong>Compute/Graphics engine</strong> that executes the compute instructions</li><li>the copy engine (<strong>CE</strong>) that is responsible for performing DMAs</li><li><strong>NVDEC</strong> for video decoding</li><li><strong>NVENC</strong> for encoding</li></ul></li><li><strong>GPU Memory Slice</strong>：一个 GPU Memory Slice 是 A100 GPU Memory 的一个最小片段，包括对应的 <code>memory controllers</code> 和 <code>cache</code>，粗略来说一个 GPU Memory Slice 大致是总的GPU Memory资源的 1/8，包括memory的 capacity 和 bandwidth。</li><li><p><strong>GPU SM Slice</strong>：一个 GPU SM Slice 是 A100 GPU SMs 的一个最小片段，粗略来说一个 GPU SM Slice 大致是总的GPU SM资源的 1/7</p></li><li><p><strong>GPU Slice</strong>：一个 GPU Slice 是 A100 GPU 中集合一个 <code>GPU Memory Slice</code> 和 一个 <code>GPU SM Slice</code> 的最小片段</p></li><li><strong>GPU Instance</strong>：一个 GPU Instance 是 GPU Slices 和 GPU Engines (DMAs, NVDECs, etc.)的结合</li></ul><h4 id="Compute-Instance"><a href="#Compute-Instance" class="headerlink" title="Compute Instance"></a>Compute Instance</h4><p>一个 GPU Instance 可以被划分为多个 Compute Instance，多个Compute Instance之间共享Memory和Engine，它包含了原来GPU Instance里面 <code>GPU SM slices</code> 和 <code>GPU Engines</code> 的一个子集(DMAs, NVDECs, etc.)：</p><ul><li>默认情况下，将在每个GPU实例下创建一个 Compute Instances，从而公开GPU实例中可用的所有GPU计算资源。</li><li>可以将GPU实例细分为多个较小的 Compute Instances，以进一步拆分其计算资源。</li></ul><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2021-01-14_nvidia-compute-instance.png"></p><h3 id="架构对比"><a href="#架构对比" class="headerlink" title="架构对比"></a>架构对比</h3><p>pre-A100 GPU每个用户独占SM、Frame Buffer、L2 Cache。</p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2021-01-14_csp-multi-user-today.png"></p><p>A100 MIG将GPU进行物理切割，每个虚拟GPU instance具有独立的SM、L2 Cache、DRAM。</p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2021-01-14_csp-mig.png"></p><p>下面是MIG 配置多个独立的GPU Compute workloads。每个GPC分配固定的CE和DEC。A100中有5个decoder。</p><p>当1个GPU instance中包含2个Compute instance时，2个Compute instance共享CE、DEC和L2、Frame Buffer。</p><ul><li>GPC：Graphics Processor Cluster</li><li>TPC：Texture Processor Cluster</li></ul><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2021-01-14_nvidia-mig-partition.png"></p><p>Compute instance使多个上下文可以在GPU实例上同时运行。</p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2021-01-14_nvidia-mig.png"></p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2021-01-13_nvidia-mig.png"></p><h3 id="MIG-隔离"><a href="#MIG-隔离" class="headerlink" title="MIG 隔离"></a>MIG 隔离</h3><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2021-01-14_mig-isolation.png"></p><p><strong>和上一代Volta MPS技术的对比</strong></p><blockquote><p>MPS was designed for sharing the GPU among applications from <strong>a single user</strong>, but not for multi-user or <strong>multi-tenant use</strong> cases.</p></blockquote><p>解决了MPS存在的memory system resources were shared across all the applications问题，同时继承了Volta MPS所有功能</p><div class="table-container"><table><thead><tr><th style="text-align:left">对比项</th><th style="text-align:left">MPS</th><th style="text-align:left">MIG</th></tr></thead><tbody><tr><td style="text-align:left">Partition Type</td><td style="text-align:left">Logical</td><td style="text-align:left">Physical</td></tr><tr><td style="text-align:left">Max Partitions</td><td style="text-align:left">48</td><td style="text-align:left">7</td></tr><tr><td style="text-align:left">SM Performance Isolation</td><td style="text-align:left">Yes (by percentage, not partitioning)</td><td style="text-align:left">Yes</td></tr><tr><td style="text-align:left">Memory Protection</td><td style="text-align:left">Yes</td><td style="text-align:left">Yes</td></tr><tr><td style="text-align:left">Memory Bandwidth QoS</td><td style="text-align:left">No</td><td style="text-align:left">Yes</td></tr><tr><td style="text-align:left">Error Isolation</td><td style="text-align:left">No</td><td style="text-align:left">Yes</td></tr><tr><td style="text-align:left">Cross-Partition Interop</td><td style="text-align:left">IPC</td><td style="text-align:left">Limited IPC</td></tr><tr><td style="text-align:left">Reconfigure</td><td style="text-align:left">Process Launch</td><td style="text-align:left">When Idle</td></tr></tbody></table></div><h3 id="GPU-Partitioning"><a href="#GPU-Partitioning" class="headerlink" title="GPU Partitioning"></a>GPU Partitioning</h3><p>每个 GI 包括的资源不是随意定义的，NVIDIA 提供了 一系列的 <code>GPU Instance Profiles</code>，用户在创建 GI 时必须按照这个 Profile 来切割。我们知道，A100 总共有 8 个 GPU Memory Slice 和 7 个 SM Slice，那么切分总共有5种 Profile：</p><div class="table-container"><table><thead><tr><th>Profile Name</th><th>Fraction of Memory</th><th>Fraction of SMs</th><th>Hardware Units</th><th>Number of Instances Available</th></tr></thead><tbody><tr><td>MIG 1g.5gb</td><td>1/8</td><td>1/7</td><td>0 NVDECs</td><td>7</td></tr><tr><td>MIG 2g.10gb</td><td>2/8</td><td>2/7</td><td>1 NVDECs</td><td>3</td></tr><tr><td>MIG 3g.20gb</td><td>4/8</td><td>3/7</td><td>2 NVDECs</td><td>2</td></tr><tr><td>MIG 4g.20gb</td><td>4/8</td><td>4/7</td><td>2 NVDECs</td><td>1</td></tr><tr><td>MIG 7g.40gb</td><td>Full</td><td>7/7</td><td>5 NVDECs</td><td>1</td></tr></tbody></table></div><p>注意：这里对于 <code>A100-SXM4-40GB</code> 总的 Memory大小是40GB，所以最小单位是 <code>1g.5gb</code>，如果对于 <code>A100-SXM4-80GB</code>，则最小单位是 <code>1g.10gb</code>。</p><p>也就是说，这几种 Profile 确定了 A100 GPU 可以被切分的方式，如下图，所有可以切分的方式只是下图从左到右选择不同的Profile，并且两个Profile上下不重叠。唯一的例外是，现在 NVIDIA 不支持 (4 memory, 4 compute) 和 (4 memory, 3 compute) 的组合：</p><p><img alt data-src="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/graphics/gpu-instances-combo-pic.png"></p><p>下图就是组合的一种方式：A100 GPU 被切割成了3个GPU Instance，分别的大小是</p><ul><li>4 memory，4 compute</li><li>2 memory，2 compute</li><li>1 memory，1 compute</li></ul><p><img alt="Example Configuration of GPU Instances." data-src="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/graphics/gpu-instances-example-pic.png"></p><p>下图也是组合的一种可能：</p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2021-01-14_mig-profile0.png"></p><p>前面提到， 硬件上 NVIDIA 不支持 (4 memory, 4 compute) 和 (4 memory, 3 compute) 的组合，但是支持两个  (4 memory, 3 compute) 的组合，这里左边的一个  (4 memory, 3 compute) 是将  (4 memory, 4 compute) 示例化为一个  (4 memory, 3 compute)。如下图就将 A100 切分成两个 GPU Instance，每个GPU Instance都有 (4 memory, 3 compute)</p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2021-01-14_mig-profile1.png"></p><p>或者切分成3个GPU Instance：</p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2021-01-14_mig-profile2.png"></p><p>也可以切分成下面这种4个GPU Instance：</p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2021-01-14_mig-profile3.png"></p><p>总的来说，一共有 18 种切分方法：</p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-01-14_mig-profiles.png"></p><p>注意，下图中的两种切分并不相同，因为每个切分的Instance 的 <code>physical layout</code> 也很重要：</p><p><img alt="Placement of GPU Instances." data-src="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/graphics/gpu-instances-placement-pic.png"></p><h2 id="MIG-技术使用"><a href="#MIG-技术使用" class="headerlink" title="MIG 技术使用"></a>MIG 技术使用</h2><p>具体到A100卡，实际实现有两个型号，分别是</p><ul><li>GA100 Full GPU with 128 SMs</li><li>A100 Tensor Core GPU with 108 SMs</li></ul><p>本次调研中使用的卡是108 SM版本</p><h3 id="驱动安装"><a href="#驱动安装" class="headerlink" title="驱动安装"></a>驱动安装</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">$ nvidia-smi</span><br><span class="line">Wed Jan 13 11:42:34 2021</span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| NVIDIA-SMI 460.27.04    Driver Version: 460.27.04    CUDA Version: 11.2     |</span><br><span class="line">|-------------------------------+----------------------+----------------------+</span><br><span class="line">| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |</span><br><span class="line">| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |</span><br><span class="line">|                               |                      |               MIG M. |</span><br><span class="line">|===============================+======================+======================|</span><br><span class="line">|   0  A100-SXM4-40GB      Off  | 00000000:00:08.0 Off |                    0 |</span><br><span class="line">| N/A   26C    P0    43W / 400W |      0MiB / 40536MiB |      0%      Default |</span><br><span class="line">|                               |                      |             Disabled |</span><br><span class="line">+-------------------------------+----------------------+----------------------+</span><br><span class="line"></span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| Processes:                                                                  |</span><br><span class="line">|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |</span><br><span class="line">|        ID   ID                                                   Usage      |</span><br><span class="line">|=============================================================================|</span><br><span class="line">|  No running processes found                                                 |</span><br><span class="line">+-----------------------------------------------------------------------------+</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ tree /dev/</span><br><span class="line">├── nvidia0</span><br><span class="line">├── nvidia-caps</span><br><span class="line">│   ├── nvidia-cap1</span><br><span class="line">│   └── nvidia-cap2</span><br><span class="line">├── nvidiactl</span><br><span class="line">├── nvidia-modeset</span><br><span class="line">├── nvidia-uvm</span><br><span class="line">├── nvidia-uvm-tools</span><br></pre></td></tr></table></figure><h3 id="开启MIG支持"><a href="#开启MIG支持" class="headerlink" title="开启MIG支持"></a>开启MIG支持</h3><p>查询是否开启MIG</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ nvidia-smi -i 0 --query-gpu=pci.bus_id,mig.mode.current --format=csv</span><br><span class="line">pci.bus_id, mig.mode.current</span><br><span class="line">00000000:00:08.0, Disabled</span><br></pre></td></tr></table></figure><p>对于指定卡开启mig，只有在卡空闲时才能更改mig enable 设置</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ nvidia-smi -i 0 -mig 1</span><br><span class="line">Warning: MIG mode is <span class="keyword">in</span> pending <span class="built_in">enable</span> state <span class="keyword">for</span> GPU 00000000:00:08.0:In use by another client</span><br><span class="line">00000000:00:08.0 is currently being used by one or more other processes (e.g. CUDA application or a monitoring application such as another instance of nvidia-smi). Please first <span class="built_in">kill</span> all processes using the device and retry the <span class="built_in">command</span> or reboot the system to make MIG mode effective.</span><br><span class="line">All <span class="keyword">done</span>.</span><br></pre></td></tr></table></figure><blockquote><p>If you are using MIG inside a VM with GPU passthrough, then you may need to reboot the VM to allow the GPU to be in MIG mode as in some cases, GPU reset is not allowed via the hypervisor for security reasons. This can be seen in the following example:</p></blockquote><p>重启之后</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ nvidia-smi -i 0 --query-gpu=pci.bus_id,mig.mode.current --format=csv</span><br><span class="line">pci.bus_id, mig.mode.current</span><br><span class="line">00000000:00:08.0, Enabled</span><br></pre></td></tr></table></figure><h3 id="查询可分配-GI-信息"><a href="#查询可分配-GI-信息" class="headerlink" title="查询可分配 GI 信息"></a>查询可分配 GI 信息</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># nvidia-smi mig -lgip</span></span><br><span class="line">+--------------------------------------------------------------------------+</span><br><span class="line">| GPU instance profiles:                                                   |</span><br><span class="line">| GPU   Name          ID    Instances   Memory     P2P    SM    DEC   ENC  |</span><br><span class="line">|                           Free/Total   GiB              CE    JPEG  OFA  |</span><br><span class="line">|==========================================================================|</span><br><span class="line">|   0  MIG 1g.5gb     19     7/7        4.75       No     14     0     0   |</span><br><span class="line">|                                                          1     0     0   |</span><br><span class="line">+--------------------------------------------------------------------------+</span><br><span class="line">|   0  MIG 2g.10gb    14     3/3        9.75       No     28     1     0   |</span><br><span class="line">|                                                          2     0     0   |</span><br><span class="line">+--------------------------------------------------------------------------+</span><br><span class="line">|   0  MIG 3g.20gb     9     2/2        19.62      No     42     2     0   |</span><br><span class="line">|                                                          3     0     0   |</span><br><span class="line">+--------------------------------------------------------------------------+</span><br><span class="line">|   0  MIG 4g.20gb     5     1/1        19.62      No     56     2     0   |</span><br><span class="line">|                                                          4     0     0   |</span><br><span class="line">+--------------------------------------------------------------------------+</span><br><span class="line">|   0  MIG 7g.40gb     0     1/1        39.50      No     98     5     0   |</span><br><span class="line">|                                                          7     1     1   |</span><br><span class="line">+--------------------------------------------------------------------------+</span><br></pre></td></tr></table></figure><h3 id="查询-GI-placements"><a href="#查询-GI-placements" class="headerlink" title="查询 GI placements"></a>查询 GI placements</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># nvidia-smi mig -lgipp</span></span><br><span class="line">GPU  0 Profile ID 19 Placements: &#123;0,1,2,3,4,5,6&#125;:1</span><br><span class="line">GPU  0 Profile ID 14 Placements: &#123;0,2,4&#125;:2</span><br><span class="line">GPU  0 Profile ID  9 Placements: &#123;0,4&#125;:4</span><br><span class="line">GPU  0 Profile ID  5 Placement : &#123;0&#125;:4</span><br><span class="line">GPU  0 Profile ID  0 Placement : &#123;0&#125;:8</span><br></pre></td></tr></table></figure><h3 id="创建-GPU-Instances"><a href="#创建-GPU-Instances" class="headerlink" title="创建 GPU Instances"></a>创建 GPU Instances</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># nvidia-smi mig -cgi 9,14,19</span></span><br><span class="line">Successfully created GPU instance ID  2 on GPU  0 using profile MIG 3g.20gb (ID  9)</span><br><span class="line">Successfully created GPU instance ID  3 on GPU  0 using profile MIG 2g.10gb (ID 14)</span><br><span class="line">Successfully created GPU instance ID  9 on GPU  0 using profile MIG 1g.5gb (ID 19)</span><br></pre></td></tr></table></figure><h3 id="查询-GPU-Instance"><a href="#查询-GPU-Instance" class="headerlink" title="查询 GPU Instance"></a>查询 GPU Instance</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># nvidia-smi mig -lgi</span></span><br><span class="line">+----------------------------------------------------+</span><br><span class="line">| GPU instances:                                     |</span><br><span class="line">| GPU   Name          Profile  Instance   Placement  |</span><br><span class="line">|                       ID       ID       Start:Size |</span><br><span class="line">|====================================================|</span><br><span class="line">|   0  MIG 1g.5gb       19        9          2:1     |</span><br><span class="line">+----------------------------------------------------+</span><br><span class="line">|   0  MIG 2g.10gb      14        3          0:2     |</span><br><span class="line">+----------------------------------------------------+</span><br><span class="line">|   0  MIG 3g.20gb       9        2          4:4     |</span><br><span class="line">+----------------------------------------------------+</span><br></pre></td></tr></table></figure><h3 id="创建-Compute-Instance"><a href="#创建-Compute-Instance" class="headerlink" title="创建 Compute Instance"></a>创建 Compute Instance</h3><p>创建CI前，首先需要查询对应的GI支持Profile列表，可以发现上文创建的ID为2的GI可以进一步分为3种类型的CI</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># nvidia-smi mig -lcip -gi 2</span></span><br><span class="line">+--------------------------------------------------------------------------------------+</span><br><span class="line">| Compute instance profiles:                                                           |</span><br><span class="line">| GPU     GPU       Name             Profile  Instances   Exclusive       Shared       |</span><br><span class="line">|       Instance                       ID     Free/Total     SM       DEC   ENC   OFA  |</span><br><span class="line">|         ID                                                          CE    JPEG       |</span><br><span class="line">|======================================================================================|</span><br><span class="line">|   0      2       MIG 1c.3g.20gb       0      3/3           14        2     0     0   |</span><br><span class="line">|                                                                      3     0         |</span><br><span class="line">+--------------------------------------------------------------------------------------+</span><br><span class="line">|   0      2       MIG 2c.3g.20gb       1      1/1           28        2     0     0   |</span><br><span class="line">|                                                                      3     0         |</span><br><span class="line">+--------------------------------------------------------------------------------------+</span><br><span class="line">|   0      2       MIG 3g.20gb          2*     1/1           42        2     0     0   |</span><br><span class="line">|                                                                      3     0         |</span><br><span class="line">+--------------------------------------------------------------------------------------+</span><br><span class="line"></span><br><span class="line"><span class="comment"># nvidia-smi mig -lcip -gi 3</span></span><br><span class="line">+--------------------------------------------------------------------------------------+</span><br><span class="line">| Compute instance profiles:                                                           |</span><br><span class="line">| GPU     GPU       Name             Profile  Instances   Exclusive       Shared       |</span><br><span class="line">|       Instance                       ID     Free/Total     SM       DEC   ENC   OFA  |</span><br><span class="line">|         ID                                                          CE    JPEG       |</span><br><span class="line">|======================================================================================|</span><br><span class="line">|   0      3       MIG 1c.2g.10gb       0      2/2           14        1     0     0   |</span><br><span class="line">|                                                                      2     0         |</span><br><span class="line">+--------------------------------------------------------------------------------------+</span><br><span class="line">|   0      3       MIG 2g.10gb          1*     1/1           28        1     0     0   |</span><br><span class="line">|                                                                      2     0         |</span><br><span class="line">+--------------------------------------------------------------------------------------+</span><br></pre></td></tr></table></figure><p>然后进一步将ID为2的GI划分为两个CI，Profile分别是1c.3g.20gb，2c.3g.20gb，具体命令如下</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># nvidia-smi mig -cci 0,1 -gi 2</span></span><br><span class="line">Successfully created compute instance ID  0 on GPU  0 GPU instance ID  2 using profile MIG 1c.3g.20gb (ID  0)</span><br><span class="line">Successfully created compute instance ID  1 on GPU  0 GPU instance ID  2 using profile MIG 2c.3g.20gb (ID  1)</span><br></pre></td></tr></table></figure><h3 id="查询-Compute-Instance"><a href="#查询-Compute-Instance" class="headerlink" title="查询 Compute Instance"></a>查询 Compute Instance</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># nvidia-smi mig -lci -gi 2</span></span><br><span class="line">+--------------------------------------------------------------------+</span><br><span class="line">| Compute instances:                                                 |</span><br><span class="line">| GPU     GPU       Name             Profile   Instance   Placement  |</span><br><span class="line">|       Instance                       ID        ID       Start:Size |</span><br><span class="line">|         ID                                                         |</span><br><span class="line">|====================================================================|</span><br><span class="line">|   0      2       MIG 1c.3g.20gb       0         0          0:1     |</span><br><span class="line">+--------------------------------------------------------------------+</span><br><span class="line">|   0      2       MIG 2c.3g.20gb       1         1          1:2     |</span><br><span class="line">+--------------------------------------------------------------------+</span><br></pre></td></tr></table></figure><p>执行 <code>nvidia-smi</code> 也可以看到如下输出</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># nvidia-smi</span></span><br><span class="line">Wed Jan 13 12:04:54 2021</span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| NVIDIA-SMI 460.27.04    Driver Version: 460.27.04    CUDA Version: 11.2     |</span><br><span class="line">|-------------------------------+----------------------+----------------------+</span><br><span class="line">| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |</span><br><span class="line">| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |</span><br><span class="line">|                               |                      |               MIG M. |</span><br><span class="line">|===============================+======================+======================|</span><br><span class="line">|   0  A100-SXM4-40GB      On   | 00000000:00:08.0 Off |                   On |</span><br><span class="line">| N/A   26C    P0    43W / 400W |     11MiB / 40536MiB |     N/A      Default |</span><br><span class="line">|                               |                      |              Enabled |</span><br><span class="line">+-------------------------------+----------------------+----------------------+</span><br><span class="line"></span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| MIG devices:                                                                |</span><br><span class="line">+------------------+----------------------+-----------+-----------------------+</span><br><span class="line">| GPU  GI  CI  MIG |         Memory-Usage |        Vol|         Shared        |</span><br><span class="line">|      ID  ID  Dev |           BAR1-Usage | SM     Unc| CE  ENC  DEC  OFA  JPG|</span><br><span class="line">|                  |                      |        ECC|                       |</span><br><span class="line">|==================+======================+===========+=======================|</span><br><span class="line">|  0    2   0   0  |      5MiB / 20096MiB | 14      0 |  3   0    2    0    0 |</span><br><span class="line">|                  |      0MiB / 32767MiB |           |                       |</span><br><span class="line">+------------------+                      +-----------+-----------------------+</span><br><span class="line">|  0    2   1   1  |                      | 28      0 |  3   0    2    0    0 |</span><br><span class="line">|                  |                      |           |                       |</span><br><span class="line">+------------------+----------------------+-----------+-----------------------+</span><br><span class="line"></span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| Processes:                                                                  |</span><br><span class="line">|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |</span><br><span class="line">|        ID   ID                                                   Usage      |</span><br><span class="line">|=============================================================================|</span><br><span class="line">|  No running processes found                                                 |</span><br><span class="line">+-----------------------------------------------------------------------------+</span><br></pre></td></tr></table></figure><p>执行<code>nvidia-smi -L</code> 可以列出每个设备的UUID，供后续计算时使用</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># nvidia-smi -L</span></span><br><span class="line">GPU 0: A100-SXM4-40GB (UUID: GPU-ed92375c-b61c-7a27-2611-bc72ad3ea181)</span><br><span class="line">  MIG 1c.3g.20gb Device 0: (UUID: MIG-GPU-ed92375c-b61c-7a27-2611-bc72ad3ea181/2/0)</span><br><span class="line">  MIG 2c.3g.20gb Device 1: (UUID: MIG-GPU-ed92375c-b61c-7a27-2611-bc72ad3ea181/2/1)</span><br></pre></td></tr></table></figure><h3 id="删除-CPU-Instance"><a href="#删除-CPU-Instance" class="headerlink" title="删除 CPU Instance"></a>删除 CPU Instance</h3><p>可以使用如下命令删除gi实例1上的ci实例0</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvidia-smi mig -dci -ci 0 -gi 1</span><br></pre></td></tr></table></figure><h2 id="使用-MIG"><a href="#使用-MIG" class="headerlink" title="使用 MIG"></a>使用 MIG</h2><h3 id="Bare-Metal"><a href="#Bare-Metal" class="headerlink" title="Bare-Metal"></a>Bare-Metal</h3><p>暂时没有拿到 bare metal 的 A100 机器，TODO</p><h3 id="Container"><a href="#Container" class="headerlink" title="Container"></a>Container</h3><h4 id="前置条件"><a href="#前置条件" class="headerlink" title="前置条件"></a>前置条件</h4><ul><li>安装Docker</li><li>安装NVIDIA Container Toolkit：<ul><li>Nvidia-docker2 版本推荐在 v2.5.0 以上</li></ul></li></ul><h4 id="运行容器"><a href="#运行容器" class="headerlink" title="运行容器"></a>运行容器</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># docker run --runtime=nvidia -e NVIDIA_VISIBLE_DEVICES=MIG-GPU-ed92375c-b61c-7a27-2611-bc72ad3ea181/2/1 nvidia/cuda nvidia-smi</span></span><br><span class="line">docker: Error response from daemon: OCI runtime create failed: container_linux.go:349: starting container process caused <span class="string">"process_linux.go:449: container init caused \"process_linux.go:432: running prestart hook 0 caused \\\"error running hook: exit status 1, stdout: , stderr: exec command: [/usr/bin/nvidia-container-cli --load-kmods configure --ldconfig=@/sbin/ldconfig --device=MIG-GPU-ed92375c-b61c-7a27-2611-bc72ad3ea181/2/1 --compute --utility --require=cuda&gt;=11.1 brand=tesla,driver&gt;=418,driver&lt;419 brand=tesla,driver&gt;=440,driver&lt;441 brand=tesla,driver&gt;=450,driver&lt;451 --pid=11936 /var/lib/docker/overlay2/5ee3e036c29f6cd488a3ad1ab1c55a47e595ffff530075853396745de546e4a8/merged]\\\\nnvidia-container-cli: device error: unknown device id: MIG-GPU-ed92375c-b61c-7a27-2611-bc72ad3ea181/2/1\\\\n\\\"\""</span>: unknown.</span><br><span class="line">ERRO[0000] error waiting <span class="keyword">for</span> container: context canceled</span><br></pre></td></tr></table></figure><p>怀疑是 NVIDIA Docker Toolkit 版本太老</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># /usr/bin/nvidia-container-runtime -v</span></span><br><span class="line">runc version 1.0.0-rc10</span><br><span class="line">commit: dc9208a3303feef5b3839f4323d9beb36df0a9dd</span><br><span class="line">spec: 1.0.1-dev</span><br></pre></td></tr></table></figure><p>安装新版本的 NVIDIA Docker Toolkit</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">Dependencies Resolved</span><br><span class="line"></span><br><span class="line">==========================================================================================================================================================================</span><br><span class="line"> Package                                       Arch                       Version                                      Repository                                    Size</span><br><span class="line">==========================================================================================================================================================================</span><br><span class="line">Installing:</span><br><span class="line"> nvidia-docker2                                noarch                     2.5.0-1                                      nvidia-docker                                8.4 k</span><br><span class="line">Installing <span class="keyword">for</span> dependencies:</span><br><span class="line"> container-selinux                             noarch                     2:2.119.1-1.c57a6f9.tl2                      tlinux                                        39 k</span><br><span class="line"> containerd.io                                 x86_64                     1.2.5-3.1.el7                                tlinux                                        22 M</span><br><span class="line"> docker-ce                                     x86_64                     3:18.09.5-3.el7                              tlinux                                        19 M</span><br><span class="line"> docker-ce-cli                                 x86_64                     1:18.09.5-3.el7                              tlinux                                        14 M</span><br><span class="line">Updating <span class="keyword">for</span> dependencies:</span><br><span class="line"> libnvidia-container-tools                     x86_64                     1.3.1-1                                      libnvidia-container                           42 k</span><br><span class="line"> libnvidia-container1                          x86_64                     1.3.1-1                                      libnvidia-container                           86 k</span><br><span class="line"> nvidia-container-runtime                      x86_64                     3.4.0-1                                      nvidia-container-runtime                     693 k</span><br><span class="line"> nvidia-container-toolkit                      x86_64                     1.4.0-2                                      nvidia-container-runtime                     819 k</span><br></pre></td></tr></table></figure><p>环境配置好后，即可通过 <code>docker</code> 运行容器使用GPU：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">$ docker run --runtime=nvidia -e NVIDIA_VISIBLE_DEVICES=MIG-GPU-61148488-f8ba-c817-b2e8-18f59e2b66b1/2/0 nvidia/cuda nvidia-smi</span><br><span class="line">Wed Jan 13 11:30:19 2021</span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| NVIDIA-SMI 460.27.04    Driver Version: 460.27.04    CUDA Version: 11.2     |</span><br><span class="line">|-------------------------------+----------------------+----------------------+</span><br><span class="line">| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |</span><br><span class="line">| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |</span><br><span class="line">|                               |                      |               MIG M. |</span><br><span class="line">|===============================+======================+======================|</span><br><span class="line">|   0  A100-SXM4-40GB      On   | 00000000:00:08.0 Off |                   On |</span><br><span class="line">| N/A   26C    P0    42W / 400W |                  N/A |     N/A      Default |</span><br><span class="line">|                               |                      |              Enabled |</span><br><span class="line">+-------------------------------+----------------------+----------------------+</span><br><span class="line"></span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| MIG devices:                                                                |</span><br><span class="line">+------------------+----------------------+-----------+-----------------------+</span><br><span class="line">| GPU  GI  CI  MIG |         Memory-Usage |        Vol|         Shared        |</span><br><span class="line">|      ID  ID  Dev |           BAR1-Usage | SM     Unc| CE  ENC  DEC  OFA  JPG|</span><br><span class="line">|                  |                      |        ECC|                       |</span><br><span class="line">|==================+======================+===========+=======================|</span><br><span class="line">|  0    2   0   0  |      5MiB / 20096MiB | 14      0 |  3   0    2    0    0 |</span><br><span class="line">|                  |      0MiB / 32767MiB |           |                       |</span><br><span class="line">+------------------+----------------------+-----------+-----------------------+</span><br><span class="line"></span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| Processes:                                                                  |</span><br><span class="line">|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |</span><br><span class="line">|        ID   ID                                                   Usage      |</span><br><span class="line">|=============================================================================|</span><br><span class="line">|  No running processes found                                                 |</span><br><span class="line">+-----------------------------------------------------------------------------+</span><br></pre></td></tr></table></figure><h3 id="Kubernetes"><a href="#Kubernetes" class="headerlink" title="Kubernetes"></a>Kubernetes</h3><h4 id="前置依赖"><a href="#前置依赖" class="headerlink" title="前置依赖"></a>前置依赖</h4><ul><li>NVIDIA R450+ datacenter driver: 450.80.02+</li><li>NVIDIA Container Toolkit (nvidia-docker2): v2.5.0+</li><li>NVIDIA k8s-device-plugin: v0.7.0+</li><li>NVIDIA gpu-feature-discovery: v0.2.0+</li></ul><h4 id="None"><a href="#None" class="headerlink" title="None"></a>None</h4><p>确认 Node 上的 MIG 特性开启，此时没有创建任何GI：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">Thu Jan 14 16:35:34 2021</span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| NVIDIA-SMI 460.27.04    Driver Version: 460.27.04    CUDA Version: 11.2     |</span><br><span class="line">|-------------------------------+----------------------+----------------------+</span><br><span class="line">| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |</span><br><span class="line">| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |</span><br><span class="line">|                               |                      |               MIG M. |</span><br><span class="line">|===============================+======================+======================|</span><br><span class="line">|   0  A100-SXM4-40GB      On   | 00000000:00:08.0 Off |                   On |</span><br><span class="line">| N/A   26C    P0    43W / 400W |      0MiB / 40536MiB |     N/A      Default |</span><br><span class="line">|                               |                      |              Enabled |</span><br><span class="line">+-------------------------------+----------------------+----------------------+</span><br><span class="line"></span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| MIG devices:                                                                |</span><br><span class="line">+------------------+----------------------+-----------+-----------------------+</span><br><span class="line">| GPU  GI  CI  MIG |         Memory-Usage |        Vol|         Shared        |</span><br><span class="line">|      ID  ID  Dev |           BAR1-Usage | SM     Unc| CE  ENC  DEC  OFA  JPG|</span><br><span class="line">|                  |                      |        ECC|                       |</span><br><span class="line">|==================+======================+===========+=======================|</span><br><span class="line">|  No MIG devices found                                                       |</span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line"></span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| Processes:                                                                  |</span><br><span class="line">|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |</span><br><span class="line">|        ID   ID                                                   Usage      |</span><br><span class="line">|=============================================================================|</span><br><span class="line">|  No running processes found                                                 |</span><br><span class="line">+-----------------------------------------------------------------------------+</span><br></pre></td></tr></table></figure><p>启动 <code>Device Plugin</code>，此时 <code>mig-strategy</code> 是 <code>none</code>：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">DaemonSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nvidia-device-plugin-daemonset</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">nvidia-device-plugin-ds</span></span><br><span class="line">  <span class="attr">updateStrategy:</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">RollingUpdate</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="comment"># This annotation is deprecated. Kept here for backward compatibility</span></span><br><span class="line">      <span class="comment"># See https://kubernetes.io/docs/tasks/administer-cluster/guaranteed-scheduling-critical-addon-pods/</span></span><br><span class="line">      <span class="attr">annotations:</span></span><br><span class="line">        <span class="attr">scheduler.alpha.kubernetes.io/critical-pod:</span> <span class="string">""</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">nvidia-device-plugin-ds</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">tolerations:</span></span><br><span class="line">      <span class="comment"># This toleration is deprecated. Kept here for backward compatibility</span></span><br><span class="line">      <span class="comment"># See https://kubernetes.io/docs/tasks/administer-cluster/guaranteed-scheduling-critical-addon-pods/</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">CriticalAddonsOnly</span></span><br><span class="line">        <span class="attr">operator:</span> <span class="string">Exists</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">nvidia.com/gpu</span></span><br><span class="line">        <span class="attr">operator:</span> <span class="string">Exists</span></span><br><span class="line">        <span class="attr">effect:</span> <span class="string">NoSchedule</span></span><br><span class="line">      <span class="comment"># Mark this pod as a critical add-on; when enabled, the critical add-on</span></span><br><span class="line">      <span class="comment"># scheduler reserves resources for critical add-on pods so that they can</span></span><br><span class="line">      <span class="comment"># be rescheduled after a failure.</span></span><br><span class="line">      <span class="comment"># See https://kubernetes.io/docs/tasks/administer-cluster/guaranteed-scheduling-critical-addon-pods/</span></span><br><span class="line">      <span class="attr">priorityClassName:</span> <span class="string">"system-node-critical"</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">nvidia/k8s-device-plugin:v0.7.0</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">nvidia-device-plugin-ctr</span></span><br><span class="line">        <span class="attr">args:</span> <span class="string">["--fail-on-init-error=false"]</span></span><br><span class="line">        <span class="attr">securityContext:</span></span><br><span class="line">          <span class="attr">allowPrivilegeEscalation:</span> <span class="literal">false</span></span><br><span class="line">          <span class="attr">capabilities:</span></span><br><span class="line">            <span class="attr">drop:</span> <span class="string">["ALL"]</span></span><br><span class="line">        <span class="attr">volumeMounts:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">device-plugin</span></span><br><span class="line">            <span class="attr">mountPath:</span> <span class="string">/var/lib/kubelet/device-plugins</span></span><br><span class="line">      <span class="attr">volumes:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">device-plugin</span></span><br><span class="line">          <span class="attr">hostPath:</span></span><br><span class="line">            <span class="attr">path:</span> <span class="string">/var/lib/kubelet/device-plugins</span></span><br></pre></td></tr></table></figure><p>可以看到 <code>Node</code> 上可以用 <code>nvidia.com/gpu</code> 资源数目：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">Capacity:</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line">  <span class="attr">nvidia.com/gpu:</span>          <span class="number">1</span></span><br><span class="line"><span class="attr">Allocatable:</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line">  <span class="attr">nvidia.com/gpu:</span>          <span class="number">1</span></span><br></pre></td></tr></table></figure><p>部署 <code>Pod</code>：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl run -it --rm \</span><br><span class="line">   --image=nvidia/cuda \</span><br><span class="line">   --restart=Never \</span><br><span class="line">   --limits=nvidia.com/gpu=1 \</span><br><span class="line">GPU 0: A100-SXM4-40GB (UUID: GPU-ed92375c-b61c-7a27-2611-bc72ad3ea181)</span><br><span class="line">pod <span class="string">"mig-none-example"</span> deleted</span><br></pre></td></tr></table></figure><h4 id="Single"><a href="#Single" class="headerlink" title="Single"></a>Single</h4><p> 确认 Node 上的MIG特性开启后，创建大小相同的7个GI，每个GI对应着一个CI：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">$ nvidia-smi mig -cgi 19,19,19,19,19,19,19 -C</span><br><span class="line">Successfully created GPU instance ID 13 on GPU  0 using profile MIG 1g.5gb (ID 19)</span><br><span class="line">Successfully created compute instance ID  0 on GPU  0 GPU instance ID 13 using profile MIG 1g.5gb (ID  0)</span><br><span class="line">Successfully created GPU instance ID 11 on GPU  0 using profile MIG 1g.5gb (ID 19)</span><br><span class="line">Successfully created compute instance ID  0 on GPU  0 GPU instance ID 11 using profile MIG 1g.5gb (ID  0)</span><br><span class="line">Successfully created GPU instance ID 12 on GPU  0 using profile MIG 1g.5gb (ID 19)</span><br><span class="line">Successfully created compute instance ID  0 on GPU  0 GPU instance ID 12 using profile MIG 1g.5gb (ID  0)</span><br><span class="line">Successfully created GPU instance ID  7 on GPU  0 using profile MIG 1g.5gb (ID 19)</span><br><span class="line">Successfully created compute instance ID  0 on GPU  0 GPU instance ID  7 using profile MIG 1g.5gb (ID  0)</span><br><span class="line">Successfully created GPU instance ID  8 on GPU  0 using profile MIG 1g.5gb (ID 19)</span><br><span class="line">Successfully created compute instance ID  0 on GPU  0 GPU instance ID  8 using profile MIG 1g.5gb (ID  0)</span><br><span class="line">Successfully created GPU instance ID  9 on GPU  0 using profile MIG 1g.5gb (ID 19)</span><br><span class="line">Successfully created compute instance ID  0 on GPU  0 GPU instance ID  9 using profile MIG 1g.5gb (ID  0)</span><br><span class="line">Successfully created GPU instance ID 10 on GPU  0 using profile MIG 1g.5gb (ID 19)</span><br><span class="line">Successfully created compute instance ID  0 on GPU  0 GPU instance ID 10 using profile MIG 1g.5gb (ID  0)</span><br><span class="line">$ nvidia-smi -L</span><br><span class="line">GPU 0: A100-SXM4-40GB (UUID: GPU-ed92375c-b61c-7a27-2611-bc72ad3ea181)</span><br><span class="line">  MIG 1g.5gb Device 0: (UUID: MIG-GPU-ed92375c-b61c-7a27-2611-bc72ad3ea181/7/0)</span><br><span class="line">  MIG 1g.5gb Device 1: (UUID: MIG-GPU-ed92375c-b61c-7a27-2611-bc72ad3ea181/8/0)</span><br><span class="line">  MIG 1g.5gb Device 2: (UUID: MIG-GPU-ed92375c-b61c-7a27-2611-bc72ad3ea181/9/0)</span><br><span class="line">  MIG 1g.5gb Device 3: (UUID: MIG-GPU-ed92375c-b61c-7a27-2611-bc72ad3ea181/10/0)</span><br><span class="line">  MIG 1g.5gb Device 4: (UUID: MIG-GPU-ed92375c-b61c-7a27-2611-bc72ad3ea181/11/0)</span><br><span class="line">  MIG 1g.5gb Device 5: (UUID: MIG-GPU-ed92375c-b61c-7a27-2611-bc72ad3ea181/12/0)</span><br><span class="line">  MIG 1g.5gb Device 6: (UUID: MIG-GPU-ed92375c-b61c-7a27-2611-bc72ad3ea181/13/0)</span><br></pre></td></tr></table></figure><p>部署 <code>Device Plugin</code>：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">DaemonSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nvidia-device-plugin-daemonset</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">nvidia-device-plugin-ds</span></span><br><span class="line">  <span class="attr">updateStrategy:</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">RollingUpdate</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="comment"># This annotation is deprecated. Kept here for backward compatibility</span></span><br><span class="line">      <span class="comment"># See https://kubernetes.io/docs/tasks/administer-cluster/guaranteed-scheduling-critical-addon-pods/</span></span><br><span class="line">      <span class="attr">annotations:</span></span><br><span class="line">        <span class="attr">scheduler.alpha.kubernetes.io/critical-pod:</span> <span class="string">""</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">nvidia-device-plugin-ds</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">tolerations:</span></span><br><span class="line">      <span class="comment"># This toleration is deprecated. Kept here for backward compatibility</span></span><br><span class="line">      <span class="comment"># See https://kubernetes.io/docs/tasks/administer-cluster/guaranteed-scheduling-critical-addon-pods/</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">CriticalAddonsOnly</span></span><br><span class="line">        <span class="attr">operator:</span> <span class="string">Exists</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">nvidia.com/gpu</span></span><br><span class="line">        <span class="attr">operator:</span> <span class="string">Exists</span></span><br><span class="line">        <span class="attr">effect:</span> <span class="string">NoSchedule</span></span><br><span class="line">      <span class="comment"># Mark this pod as a critical add-on; when enabled, the critical add-on</span></span><br><span class="line">      <span class="comment"># scheduler reserves resources for critical add-on pods so that they can</span></span><br><span class="line">      <span class="comment"># be rescheduled after a failure.</span></span><br><span class="line">      <span class="comment"># See https://kubernetes.io/docs/tasks/administer-cluster/guaranteed-scheduling-critical-addon-pods/</span></span><br><span class="line">      <span class="attr">priorityClassName:</span> <span class="string">"system-node-critical"</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">nvidia/k8s-device-plugin:v0.7.0</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">nvidia-device-plugin-ctr</span></span><br><span class="line">        <span class="attr">args:</span> <span class="string">["--fail-on-init-error=false",</span> <span class="string">"--mig-strategy=single"</span><span class="string">]</span></span><br><span class="line">        <span class="attr">securityContext:</span></span><br><span class="line">          <span class="attr">allowPrivilegeEscalation:</span> <span class="literal">false</span></span><br><span class="line">          <span class="attr">capabilities:</span></span><br><span class="line">            <span class="attr">drop:</span> <span class="string">["ALL"]</span></span><br><span class="line">        <span class="attr">volumeMounts:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">device-plugin</span></span><br><span class="line">            <span class="attr">mountPath:</span> <span class="string">/var/lib/kubelet/device-plugins</span></span><br><span class="line">      <span class="attr">volumes:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">device-plugin</span></span><br><span class="line">          <span class="attr">hostPath:</span></span><br><span class="line">            <span class="attr">path:</span> <span class="string">/var/lib/kubelet/device-plugins</span></span><br></pre></td></tr></table></figure><p>这时候可以看到 Node 上面的标记 <code>nvidia.com/gpu</code> 变成了 7 个：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">Capacity:</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line">  <span class="attr">nvidia.com/gpu:</span>          <span class="number">7</span></span><br><span class="line"><span class="attr">Allocatable:</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line">  <span class="attr">nvidia.com/gpu:</span>          <span class="number">7</span></span><br></pre></td></tr></table></figure><p>部署 <code>discovery</code></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">DaemonSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">gpu-feature-discovery</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/name:</span> <span class="string">gpu-feature-discovery</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/version:</span> <span class="number">0.2</span><span class="number">.0</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/part-of:</span> <span class="string">nvidia-gpu</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app.kubernetes.io/name:</span> <span class="string">gpu-feature-discovery</span></span><br><span class="line">      <span class="attr">app.kubernetes.io/part-of:</span> <span class="string">nvidia-gpu</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app.kubernetes.io/name:</span> <span class="string">gpu-feature-discovery</span></span><br><span class="line">        <span class="attr">app.kubernetes.io/version:</span> <span class="number">0.2</span><span class="number">.0</span></span><br><span class="line">        <span class="attr">app.kubernetes.io/part-of:</span> <span class="string">nvidia-gpu</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">nvidia/gpu-feature-discovery:v0.2.0</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">gpu-feature-discovery</span></span><br><span class="line">          <span class="attr">args:</span> <span class="string">["--mig-strategy=single"]</span></span><br><span class="line">          <span class="attr">volumeMounts:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">output-dir</span></span><br><span class="line">              <span class="attr">mountPath:</span> <span class="string">"/etc/kubernetes/node-feature-discovery/features.d"</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">dmi-product-name</span></span><br><span class="line">              <span class="attr">mountPath:</span> <span class="string">"/sys/class/dmi/id/product_name"</span></span><br><span class="line">          <span class="attr">env:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">NVIDIA_MIG_MONITOR_DEVICES</span></span><br><span class="line">              <span class="attr">value:</span> <span class="string">all</span></span><br><span class="line">          <span class="attr">securityContext:</span></span><br><span class="line">            <span class="attr">privileged:</span> <span class="literal">true</span></span><br><span class="line">      <span class="attr">nodeSelector:</span></span><br><span class="line">        <span class="attr">feature.node.kubernetes.io/pci-10de.present:</span> <span class="string">"true"</span> <span class="comment"># NVIDIA vendor ID</span></span><br><span class="line">      <span class="attr">volumes:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">output-dir</span></span><br><span class="line">          <span class="attr">hostPath:</span></span><br><span class="line">            <span class="attr">path:</span> <span class="string">"/etc/kubernetes/node-feature-discovery/features.d"</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">dmi-product-name</span></span><br><span class="line">          <span class="attr">hostPath:</span></span><br><span class="line">            <span class="attr">path:</span> <span class="string">"/sys/class/dmi/id/product_name"</span></span><br></pre></td></tr></table></figure><p>运行 Pod 申请GPU：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">$  <span class="keyword">for</span> i <span class="keyword">in</span> $(seq 7); <span class="keyword">do</span></span><br><span class="line">   kubectl run \</span><br><span class="line">      --image=nvidia/cuda:11.0-base \</span><br><span class="line">      --restart=Never \</span><br><span class="line">      --limits=nvidia.com/gpu=1 \</span><br><span class="line">      mig-single-example-<span class="variable">$&#123;i&#125;</span> -- bash -c <span class="string">"nvidia-smi -L; sleep infinity"</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line">pod/mig-single-example-1 created</span><br><span class="line">pod/mig-single-example-2 created</span><br><span class="line">pod/mig-single-example-3 created</span><br><span class="line">pod/mig-single-example-4 created</span><br><span class="line">pod/mig-single-example-5 created</span><br><span class="line">pod/mig-single-example-6 created</span><br><span class="line">pod/mig-single-example-7 created</span><br><span class="line"></span><br><span class="line">$ <span class="keyword">for</span> i <span class="keyword">in</span> $(seq 7); <span class="keyword">do</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"mig-single-example-<span class="variable">$&#123;i&#125;</span>"</span>;</span><br><span class="line">kubectl logs mig-single-example-<span class="variable">$&#123;i&#125;</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">""</span>;</span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line">mig-single-example-1</span><br><span class="line">GPU 0: A100-SXM4-40GB (UUID: GPU-ed92375c-b61c-7a27-2611-bc72ad3ea181)</span><br><span class="line">  MIG 1g.5gb Device 0: (UUID: MIG-GPU-ed92375c-b61c-7a27-2611-bc72ad3ea181/11/0)</span><br><span class="line"></span><br><span class="line">mig-single-example-2</span><br><span class="line">GPU 0: A100-SXM4-40GB (UUID: GPU-ed92375c-b61c-7a27-2611-bc72ad3ea181)</span><br><span class="line">  MIG 1g.5gb Device 0: (UUID: MIG-GPU-ed92375c-b61c-7a27-2611-bc72ad3ea181/7/0)</span><br><span class="line"></span><br><span class="line">mig-single-example-3</span><br><span class="line">GPU 0: A100-SXM4-40GB (UUID: GPU-ed92375c-b61c-7a27-2611-bc72ad3ea181)</span><br><span class="line">  MIG 1g.5gb Device 0: (UUID: MIG-GPU-ed92375c-b61c-7a27-2611-bc72ad3ea181/8/0)</span><br><span class="line">  </span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">$ <span class="keyword">for</span> i <span class="keyword">in</span> $(seq 7); <span class="keyword">do</span></span><br><span class="line">kubectl delete pod mig-single-example-<span class="variable">$&#123;i&#125;</span>;</span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line">pod <span class="string">"mig-single-example-1"</span> deleted</span><br><span class="line">pod <span class="string">"mig-single-example-2"</span> deleted</span><br><span class="line">...</span><br></pre></td></tr></table></figure><h4 id="Mixed"><a href="#Mixed" class="headerlink" title="Mixed"></a>Mixed</h4><p> 确认 Node 上的MIG特性开启后，创建不同大小的3个GI，每个GI对应着一个CI：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">$ nvidia-smi mig -cgi 9,14,19 -C</span><br><span class="line">Successfully created GPU instance ID  2 on GPU  0 using profile MIG 3g.20gb (ID  9)</span><br><span class="line">Successfully created compute instance ID  0 on GPU  0 GPU instance ID  2 using profile MIG 3g.20gb (ID  2)</span><br><span class="line">Successfully created GPU instance ID  3 on GPU  0 using profile MIG 2g.10gb (ID 14)</span><br><span class="line">Successfully created compute instance ID  0 on GPU  0 GPU instance ID  3 using profile MIG 2g.10gb (ID  1)</span><br><span class="line">Successfully created GPU instance ID  9 on GPU  0 using profile MIG 1g.5gb (ID 19)</span><br><span class="line">Successfully created compute instance ID  0 on GPU  0 GPU instance ID  9 using profile MIG 1g.5gb (ID  0)</span><br><span class="line">$ nvidia-smi -L</span><br><span class="line">GPU 0: A100-SXM4-40GB (UUID: GPU-61148488-f8ba-c817-b2e8-18f59e2b66b1)</span><br><span class="line">  MIG 3g.20gb Device 0: (UUID: MIG-GPU-61148488-f8ba-c817-b2e8-18f59e2b66b1/2/0)</span><br><span class="line">  MIG 2g.10gb Device 1: (UUID: MIG-GPU-61148488-f8ba-c817-b2e8-18f59e2b66b1/3/0)</span><br><span class="line">  MIG 1g.5gb Device 2: (UUID: MIG-GPU-61148488-f8ba-c817-b2e8-18f59e2b66b1/9/0)</span><br></pre></td></tr></table></figure><p>启动 <code>Device Plugin</code> ：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">DaemonSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nvidia-device-plugin-daemonset</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">nvidia-device-plugin-ds</span></span><br><span class="line">  <span class="attr">updateStrategy:</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">RollingUpdate</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="comment"># This annotation is deprecated. Kept here for backward compatibility</span></span><br><span class="line">      <span class="comment"># See https://kubernetes.io/docs/tasks/administer-cluster/guaranteed-scheduling-critical-addon-pods/</span></span><br><span class="line">      <span class="attr">annotations:</span></span><br><span class="line">        <span class="attr">scheduler.alpha.kubernetes.io/critical-pod:</span> <span class="string">""</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">nvidia-device-plugin-ds</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">tolerations:</span></span><br><span class="line">      <span class="comment"># This toleration is deprecated. Kept here for backward compatibility</span></span><br><span class="line">      <span class="comment"># See https://kubernetes.io/docs/tasks/administer-cluster/guaranteed-scheduling-critical-addon-pods/</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">CriticalAddonsOnly</span></span><br><span class="line">        <span class="attr">operator:</span> <span class="string">Exists</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">nvidia.com/gpu</span></span><br><span class="line">        <span class="attr">operator:</span> <span class="string">Exists</span></span><br><span class="line">        <span class="attr">effect:</span> <span class="string">NoSchedule</span></span><br><span class="line">      <span class="comment"># Mark this pod as a critical add-on; when enabled, the critical add-on</span></span><br><span class="line">      <span class="comment"># scheduler reserves resources for critical add-on pods so that they can</span></span><br><span class="line">      <span class="comment"># be rescheduled after a failure.</span></span><br><span class="line">      <span class="comment"># See https://kubernetes.io/docs/tasks/administer-cluster/guaranteed-scheduling-critical-addon-pods/</span></span><br><span class="line">      <span class="attr">priorityClassName:</span> <span class="string">"system-node-critical"</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">nvidia/k8s-device-plugin:v0.7.0</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">nvidia-device-plugin-ctr</span></span><br><span class="line">        <span class="attr">args:</span> <span class="string">["--fail-on-init-error=false",</span> <span class="string">"--mig-strategy=mixed"</span><span class="string">]</span></span><br><span class="line">        <span class="attr">securityContext:</span></span><br><span class="line">          <span class="attr">allowPrivilegeEscalation:</span> <span class="literal">false</span></span><br><span class="line">          <span class="attr">capabilities:</span></span><br><span class="line">            <span class="attr">drop:</span> <span class="string">["ALL"]</span></span><br><span class="line">        <span class="attr">volumeMounts:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">device-plugin</span></span><br><span class="line">            <span class="attr">mountPath:</span> <span class="string">/var/lib/kubelet/device-plugins</span></span><br><span class="line">      <span class="attr">volumes:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">device-plugin</span></span><br><span class="line">          <span class="attr">hostPath:</span></span><br><span class="line">            <span class="attr">path:</span> <span class="string">/var/lib/kubelet/device-plugins</span></span><br></pre></td></tr></table></figure><p>启动 <code>Device Plugin</code> 之后，可以看到 Node 上的有MIG的<code>resource type</code>：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">Capacity:</span><br><span class="line">...</span><br><span class="line">  nvidia.com/gpu:          0</span><br><span class="line">  nvidia.com/mig-1g.5gb:   1</span><br><span class="line">  nvidia.com/mig-2g.10gb:  1</span><br><span class="line">  nvidia.com/mig-3g.20gb:  1</span><br><span class="line">  pods:                    61</span><br><span class="line">Allocatable:</span><br><span class="line">...</span><br><span class="line">  nvidia.com/gpu:          0</span><br><span class="line">  nvidia.com/mig-1g.5gb:   1</span><br><span class="line">  nvidia.com/mig-2g.10gb:  1</span><br><span class="line">  nvidia.com/mig-3g.20gb:  1</span><br><span class="line">  pods:                    61</span><br></pre></td></tr></table></figure><p>这时候启动 <code>gpu-feature-discovery</code>，启动策略是 <code>mixed</code>：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">DaemonSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">gpu-feature-discovery</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/name:</span> <span class="string">gpu-feature-discovery</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/version:</span> <span class="number">0.2</span><span class="number">.0</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/part-of:</span> <span class="string">nvidia-gpu</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app.kubernetes.io/name:</span> <span class="string">gpu-feature-discovery</span></span><br><span class="line">      <span class="attr">app.kubernetes.io/part-of:</span> <span class="string">nvidia-gpu</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app.kubernetes.io/name:</span> <span class="string">gpu-feature-discovery</span></span><br><span class="line">        <span class="attr">app.kubernetes.io/version:</span> <span class="number">0.2</span><span class="number">.0</span></span><br><span class="line">        <span class="attr">app.kubernetes.io/part-of:</span> <span class="string">nvidia-gpu</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">nvidia/gpu-feature-discovery:v0.2.0</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">gpu-feature-discovery</span></span><br><span class="line">          <span class="attr">args:</span> <span class="string">["--mig-strategy=mixed"]</span></span><br><span class="line">          <span class="attr">volumeMounts:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">output-dir</span></span><br><span class="line">              <span class="attr">mountPath:</span> <span class="string">"/etc/kubernetes/node-feature-discovery/features.d"</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">dmi-product-name</span></span><br><span class="line">              <span class="attr">mountPath:</span> <span class="string">"/sys/class/dmi/id/product_name"</span></span><br><span class="line">          <span class="attr">env:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">NVIDIA_MIG_MONITOR_DEVICES</span></span><br><span class="line">              <span class="attr">value:</span> <span class="string">all</span></span><br><span class="line">          <span class="attr">securityContext:</span></span><br><span class="line">            <span class="attr">privileged:</span> <span class="literal">true</span></span><br><span class="line">      <span class="comment">#nodeSelector:</span></span><br><span class="line">      <span class="comment">#  feature.node.kubernetes.io/pci-10de.present: "true" # NVIDIA vendor ID</span></span><br><span class="line">      <span class="attr">volumes:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">output-dir</span></span><br><span class="line">          <span class="attr">hostPath:</span></span><br><span class="line">            <span class="attr">path:</span> <span class="string">"/etc/kubernetes/node-feature-discovery/features.d"</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">dmi-product-name</span></span><br><span class="line">          <span class="attr">hostPath:</span></span><br><span class="line">            <span class="attr">path:</span> <span class="string">"/sys/class/dmi/id/product_name"</span></span><br></pre></td></tr></table></figure><p>这时候查看 Node 的 label，可以看到 MIG 相关的 label 已经打上 ？</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get node -o json | \</span><br><span class="line">   jq <span class="string">'.items[0].metadata.labels | with_entries(select(.key | startswith("nvidia.com")))'</span></span><br><span class="line">&#123;&#125;</span><br></pre></td></tr></table></figure><p>使用 <code>kubectl</code> 启动 Pod：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl run -it --rm \</span><br><span class="line">   --image=nvidia/cuda:11.0-base \</span><br><span class="line">   --restart=Never \</span><br><span class="line">   --limits=nvidia.com/mig-1g.5gb=1 \</span><br><span class="line">   mig-mixed-example -- nvidia-smi -L</span><br><span class="line">GPU 0: A100-SXM4-40GB (UUID: GPU-ed92375c-b61c-7a27-2611-bc72ad3ea181)</span><br><span class="line">  MIG 1g.5gb Device 0: (UUID: MIG-GPU-ed92375c-b61c-7a27-2611-bc72ad3ea181/9/0)</span><br><span class="line">pod <span class="string">"mig-mixed-example"</span> deleted</span><br></pre></td></tr></table></figure><h4 id="当前TKE的问题"><a href="#当前TKE的问题" class="headerlink" title="当前TKE的问题"></a>当前TKE的问题</h4><ul><li>驱动版本 和 Nvidia-container-toolkit 版本 较老，需要更新</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># TKE GPU Node查看到 Driver 信息</span></span><br><span class="line">$ nvidia-smi -a</span><br><span class="line">Driver Version                      : 418.67</span><br><span class="line">CUDA Version                        : 10.1</span><br><span class="line"></span><br><span class="line"><span class="comment"># Nvidia Container Toolkit 版本</span></span><br><span class="line">nvidia-container-runtime-3.1.0-1</span><br><span class="line">nvidia-container-toolkit-1.0.1-2</span><br><span class="line">libnvidia-container-tools-1.0.2-1</span><br><span class="line">libnvidia-container1-1.0.2-1</span><br><span class="line"></span><br><span class="line"><span class="comment"># NVIDIA Device Plugin 版本较老</span></span><br><span class="line">nvidia/k8s-device-plugin:1.10</span><br><span class="line"></span><br><span class="line">应该用 NVIDIA k8s-device-plugin: v0.7.0+</span><br></pre></td></tr></table></figure><ul><li>VM 中使用 MIG，开启MIG特性需要重启VM</li></ul><blockquote><p> If you are using MIG inside a VM with GPU passthrough, then you may <strong>need to reboot the VM</strong> to allow the GPU to be in MIG mode as in some cases, GPU reset is not allowed via the hypervisor for security reasons. This can be seen in the following example:</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ sudo nvidia-smi -i 0 -mig 1</span><br><span class="line">Warning: MIG mode is <span class="keyword">in</span> pending <span class="built_in">enable</span> state <span class="keyword">for</span> GPU 00000000:00:03.0:Not Supported</span><br><span class="line">Reboot the system or try nvidia-smi --gpu-reset to make MIG mode effective on GPU 00000000:00:03.0</span><br><span class="line">All <span class="keyword">done</span>.</span><br><span class="line"></span><br><span class="line">$ sudo nvidia-smi --gpu-reset</span><br><span class="line">Resetting GPU 00000000:00:03.0 is not supported.</span><br></pre></td></tr></table></figure><h2 id="划分MIG后的性能对比"><a href="#划分MIG后的性能对比" class="headerlink" title="划分MIG后的性能对比"></a>划分MIG后的性能对比</h2><h3 id="整块卡的性能"><a href="#整块卡的性能" class="headerlink" title="整块卡的性能"></a>整块卡的性能</h3><div class="table-container"><table><thead><tr><th style="text-align:left">测试项目</th><th style="text-align:left">实测性能</th><th style="text-align:left">官方标准性能</th></tr></thead><tbody><tr><td style="text-align:left">FP32MAD</td><td style="text-align:left">19.436TF</td><td style="text-align:left">19.5 TF</td></tr><tr><td style="text-align:left">FP64MAD</td><td style="text-align:left">9.690TF</td><td style="text-align:left">9.7 TF</td></tr><tr><td style="text-align:left">int32mad</td><td style="text-align:left">19.446TF</td><td style="text-align:left">-</td></tr><tr><td style="text-align:left">int32add</td><td style="text-align:left">18.906TF</td><td style="text-align:left">-</td></tr><tr><td style="text-align:left">FP32GEMMTensor (矩阵大小满足最佳性能要求)</td><td style="text-align:left">158.426TF</td><td style="text-align:left">156 TF</td></tr><tr><td style="text-align:left">FP32GEMMTensor (不满足最佳性能要求)</td><td style="text-align:left">68.054 TF</td><td style="text-align:left">-</td></tr><tr><td style="text-align:left">FP32GEMM</td><td style="text-align:left">19.047 TF</td><td style="text-align:left">-</td></tr></tbody></table></div><p><strong>备注</strong></p><ol><li>GEMM 需要在cuda 11.0 下重编，才能达到以上效果</li><li>满足最佳性能要求是的GEMM大小参数 9000 <em> 6000 </em> 6000</li><li>不满足最佳性能要求的GEMM大小参数 8997 <em> 5998 </em> 5998</li></ol><h3 id="MIG卡的性能"><a href="#MIG卡的性能" class="headerlink" title="MIG卡的性能"></a>MIG卡的性能</h3><p>为了测试各个CI和GI的性能，对3g.20gb GI进行进一步划分，分为 2c.3g.20gb, 1c.3g.20gb，另外两个GI不做进一步划分，直接在GI基础上创建CI。</p><p>至此一块GPU卡被分为四个CI分别是</p><ul><li>MIG 1c.3g.20gb</li><li>MIG 2c.3g.20gb</li><li>MIG 2g.10gb</li><li>MIG 1g.5gb</li></ul><h4 id="各CI串行执行"><a href="#各CI串行执行" class="headerlink" title="各CI串行执行"></a>各CI串行执行</h4><p><strong>MIG 1c.3g.20gb</strong></p><div class="table-container"><table><thead><tr><th style="text-align:left">测试项目</th><th style="text-align:left">实测性能(OPS)</th></tr></thead><tbody><tr><td style="text-align:left">FP32MAD</td><td style="text-align:left">2.523 T</td></tr><tr><td style="text-align:left">FP64MAD</td><td style="text-align:left">1.261 T</td></tr><tr><td style="text-align:left">INT32MAD</td><td style="text-align:left">2.524 T</td></tr><tr><td style="text-align:left">INT32ADD</td><td style="text-align:left">2.455 T</td></tr><tr><td style="text-align:left">FP32GEMMTensor (矩阵大小满足最佳性能要求)</td><td style="text-align:left">23.081 T</td></tr><tr><td style="text-align:left">FP32GEMMTensor (不满足最佳性能要求)</td><td style="text-align:left">8.940 T</td></tr><tr><td style="text-align:left">FP32GEMM</td><td style="text-align:left">2.476 T</td></tr></tbody></table></div><p><strong>MIG 2c.3g.20gb</strong></p><div class="table-container"><table><thead><tr><th style="text-align:left">测试项目</th><th style="text-align:left">实测性能(OPS)</th></tr></thead><tbody><tr><td style="text-align:left">FP32MAD</td><td style="text-align:left">5.046 T</td></tr><tr><td style="text-align:left">FP64MAD</td><td style="text-align:left">2.521 T</td></tr><tr><td style="text-align:left">INT32MAD</td><td style="text-align:left">5.049 T</td></tr><tr><td style="text-align:left">INT32ADD</td><td style="text-align:left">4.908 T</td></tr><tr><td style="text-align:left">FP32GEMMTensor (矩阵大小满足最佳性能要求)</td><td style="text-align:left">44.941 T</td></tr><tr><td style="text-align:left">FP32GEMMTensor (不满足最佳性能要求)</td><td style="text-align:left">18.920 T</td></tr><tr><td style="text-align:left">FP32GEMM</td><td style="text-align:left">4.909 T</td></tr></tbody></table></div><p><strong>MIG 2g.10gb</strong></p><div class="table-container"><table><thead><tr><th style="text-align:left">测试项目</th><th style="text-align:left">实测性能(OPS)</th></tr></thead><tbody><tr><td style="text-align:left">FP32MAD</td><td style="text-align:left">5.046 T</td></tr><tr><td style="text-align:left">FP64MAD</td><td style="text-align:left">2.521 T</td></tr><tr><td style="text-align:left">INT32MAD</td><td style="text-align:left">5.049 T</td></tr><tr><td style="text-align:left">INT32ADD</td><td style="text-align:left">4.908 T</td></tr><tr><td style="text-align:left">FP32GEMMTensor (矩阵大小满足最佳性能要求)</td><td style="text-align:left">40.151 T</td></tr><tr><td style="text-align:left">FP32GEMMTensor (不满足最佳性能要求)</td><td style="text-align:left">17.514 T</td></tr><tr><td style="text-align:left">FP32GEMM</td><td style="text-align:left">4.909 T</td></tr></tbody></table></div><p><strong>MIG 1g.5gb</strong></p><div class="table-container"><table><thead><tr><th style="text-align:left">测试项目</th><th style="text-align:left">实测性能(OPS)</th></tr></thead><tbody><tr><td style="text-align:left">FP32MAD</td><td style="text-align:left">2.523 T</td></tr><tr><td style="text-align:left">FP64MAD</td><td style="text-align:left">1.261 T</td></tr><tr><td style="text-align:left">INT32MAD</td><td style="text-align:left">2.524 T</td></tr><tr><td style="text-align:left">INT32ADD</td><td style="text-align:left">2.454 T</td></tr><tr><td style="text-align:left">FP32GEMMTensor (矩阵大小满足最佳性能要求)</td><td style="text-align:left">16.453 T</td></tr><tr><td style="text-align:left">FP32GEMMTensor (不满足最佳性能要求)</td><td style="text-align:left">8.261 T</td></tr><tr><td style="text-align:left">FP32GEMM</td><td style="text-align:left">2.476T</td></tr></tbody></table></div><p><strong>备注</strong></p><p>在串行执行FP32MAD任务时，1c.3g.20gb，1g.5gb的测试任务时保持在14.3%，2c.3g.20gb，2g.10gb的测试任务时保持在28.6%附近</p><h4 id="各CI并行执行"><a href="#各CI并行执行" class="headerlink" title="各CI并行执行"></a>各CI并行执行</h4><p>统一执行FP32MAD</p><div class="table-container"><table><thead><tr><th style="text-align:left">测试项目</th><th style="text-align:left">实测性能(OPS)</th></tr></thead><tbody><tr><td style="text-align:left">1c.3g.20gb</td><td style="text-align:left">2.523 T</td></tr><tr><td style="text-align:left">2c.3g.20gb</td><td style="text-align:left">5.044 T</td></tr><tr><td style="text-align:left">2g.10gb</td><td style="text-align:left">5.046 T</td></tr><tr><td style="text-align:left">1g.5gb</td><td style="text-align:left">2.523 T</td></tr></tbody></table></div><p>统一执行FP32GEMMTensor</p><div class="table-container"><table><thead><tr><th style="text-align:left">测试项目</th><th style="text-align:left">实测性能(OPS)</th></tr></thead><tbody><tr><td style="text-align:left">1c.3g.20gb</td><td style="text-align:left">20.450 T</td></tr><tr><td style="text-align:left">2c.3g.20gb</td><td style="text-align:left">41.194 T</td></tr><tr><td style="text-align:left">2g.10gb</td><td style="text-align:left">39.773 T</td></tr><tr><td style="text-align:left">1g.5gb</td><td style="text-align:left">16.336 T</td></tr></tbody></table></div><p><strong>备注</strong></p><p>在并行执行FP32MAD任务时，SmActivity,SmOccupancy,FP32Activity三项监控指标保持在85.7%附近</p><p>分别执行不同类型的计算</p><div class="table-container"><table><thead><tr><th style="text-align:left">测试项目</th><th style="text-align:left">实测性能(OPS)</th></tr></thead><tbody><tr><td style="text-align:left">1c.3g.20gb FP32MAD</td><td style="text-align:left">2.523 T</td></tr><tr><td style="text-align:left">2c.3g.20gb FP64MAD</td><td style="text-align:left">2.521 T</td></tr><tr><td style="text-align:left">2g.10gb INT32MAD</td><td style="text-align:left">5.048 T</td></tr><tr><td style="text-align:left">1g.5gb INT32ADD</td><td style="text-align:left">2.454 T</td></tr></tbody></table></div><p><strong>备注</strong></p><p>在并行执行不同计算任务时，SmActivity,SmOccupancy,FP64Activity,FP32Activity分别为85.7%, 78.1%, 28.5%, 57.0%</p><p>根据测试结果，验证了CI，GI隔离的有效性，具体结论如下</p><ol><li>对比各个MIG上任务串行执行，以及并行执行的性能数据，可以有效验证CI，GI隔离的有效性</li><li>划分CI，GI存在一定的性能损失，1g.5gb 上测得的性能并不等与整张卡的1/7，从整张卡的维度来看，存在10%的性能损失。考虑原因，A100 卡总共有108 SMs，但是分为7个MIG实例后，每个MIG实例只有14个SM 14*7 = 98 SMs，有10个SM将无法使用，这10个SM的浪费就是产生性能损失的源头。</li><li>对比2c.3g.20gb 2g.10gb可以发现在2c.3g.20gb（一个GI上软隔离的CI）Tensor计算性能比 2c.3g.20gb（完全隔离的GI)更好一些，同时对比所有CI同时执行FP32GemmTensor，可以发现同一个GI上的CI同时执行GEMM（相比FP32MAD，有一定的显存读写）时，两个CI的计算性能比单独执行时会有所下降，更接近单独GI的性能。即说明2c.3g.20gb性能强于2g.10gb，是由于CI隔离不完全导致的。</li></ol><h3 id="A100卡可以为后续工作带来的价值"><a href="#A100卡可以为后续工作带来的价值" class="headerlink" title="A100卡可以为后续工作带来的价值"></a>A100卡可以为后续工作带来的价值</h3><ol><li>每个MIG实例的完整隔离，可以支持多种虚拟化场景，包括虚拟机，容器</li><li>最小实例的基础计算能力，大约为T4卡的三分之一，P4卡的一半，计算能力适中，内存带宽1,555 GB/s 相比于P4卡 192 GB/s，T4 320+ GB/s，带宽足够充裕，不会成为瓶颈</li><li>存在离线计算和在线推理使用同一种GPU的可能性，打通离线，在线两个GPU资源池<ul><li>T4卡的具体性能指标 16G显存，SM 40, 8 TensorCores/SM, 64 INT32Cores/SM, 64 FP32Cores/SM,</li><li>A100卡的具体性能指标 40G显存，SM 108, 4 Third-generation Tensor Cores/SM, 64 FP32 CUDA Cores/SM,</li></ul></li></ol><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html" target="_blank" rel="external nofollow noopener noreferrer">NVIDIA Multi-Instance GPU User Guide</a></li><li><a href="https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/nvidia-ampere-architecture-whitepaper.pdf" target="_blank" rel="external nofollow noopener noreferrer">NVIDIA Ampere Architecture WhitePaper</a></li><li><a href="https://docs.google.com/document/d/1Dxx5MwG_GiBeKOuMNwv4QbO8OqA7XFdzn7fzzI7AQDg" target="_blank" rel="external nofollow noopener noreferrer">Design Document: Challenges Supporting MIG in Kubernetes</a></li><li><a href="https://docs.nvidia.com/datacenter/cloud-native/kubernetes/mig-k8s.html" target="_blank" rel="external nofollow noopener noreferrer">User Guide: MIG Support in Kubernetes</a></li><li><a href="https://github.com/NVIDIA/k8s-device-plugin/issues/180" target="_blank" rel="external nofollow noopener noreferrer">Github Issue: k8s device plugin Supporting MIG</a></li><li><a href="https://docs.google.com/document/d/1mdgMQ8g7WmaI_XVVRrCvHPFPOMCm5LQD5JefgAh6N8g" target="_blank" rel="external nofollow noopener noreferrer">PoC: Supporting MIG in Kubernetes</a></li><li><a href="https://docs.google.com/document/d/1bshSIcWNYRZGfywgwRHa07C0qRyOYKxWYxClbeJM-WM" target="_blank" rel="external nofollow noopener noreferrer">Steps to Enable MIG Support in Kubernetes</a></li><li><a href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html" target="_blank" rel="external nofollow noopener noreferrer">Install NVIDIA Container Toolkit Guide</a></li><li><a href="https://developer.nvidia.com/zh-cn/blog/nvidia-ampere-architecture-in-depth/" target="_blank" rel="external nofollow noopener noreferrer">深度了解 NVIDIA Ampere 架构</a></li><li><a href="https://blog.csdn.net/han2529386161/article/details/106411138" target="_blank" rel="external nofollow noopener noreferrer">NVIDIA GPU A100 Ampere 架构深度解析</a></li><li><a href="https://help.didiyun.com/hc/kb/article/1414838/" target="_blank" rel="external nofollow noopener noreferrer">https://help.didiyun.com/hc/kb/article/1414838/</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;MIG，也就是 &lt;code&gt;Multi-Instance GPU&lt;/code&gt; 是 NVIDIA 在 &lt;code&gt;NVIDIA GTC 2020&lt;/code&gt; 发布的最新 Ampere 架构的 &lt;code&gt;NVIDIA A100 GPU&lt;/code&gt; 推出的新特性。当配置为 MIG 运行状态时，A100 可以通过分出最多 7 个核心来帮助供应商提高 GPU 服务器的利用率，无需额外投入。MIG 提供了一种多用户使用隔离的GPU资源、提高GPU资源使用率的新的方式，特别适合于云服务提供商的多租户场景，保证一个租户的运行不干扰另一个租户。本文将介绍 MIG 的新特性和使用方法，以及在容器和 k8s 中使用 MIG 的方案。 &lt;/p&gt;
    
    </summary>
    
    <content src="http://houmin.cc/https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-12-16_gpu-mig-overview.jpg" type="image" />
    
    
      <category term="术业专攻" scheme="http://houmin.cc/categories/%E6%9C%AF%E4%B8%9A%E4%B8%93%E6%94%BB/"/>
    
    
      <category term="虚拟化" scheme="http://houmin.cc/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
      <category term="GPU" scheme="http://houmin.cc/tags/GPU/"/>
    
      <category term="MIG" scheme="http://houmin.cc/tags/MIG/"/>
    
  </entry>
  
  <entry>
    <title>【异构计算】GPU 共享</title>
    <link href="http://houmin.cc/posts/cf391335/"/>
    <id>http://houmin.cc/posts/cf391335/</id>
    <published>2020-11-18T03:11:07.000Z</published>
    <updated>2021-01-07T09:25:34.737Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>原生的 k8s 基于 <code>Device Plugin</code> 和 <code>Extended Resource</code> 机制实现了在容器中使用GPU，但是只支持GPU的独占使用，不允许在Pod间共享GPU，这大大降低了对集群中GPU的利用率。为了在集群层面共享GPU，我们需要实现GPU资源的隔离与调度，本文将依次介绍阿里的 <a href="https://github.com/AliyunContainerService/gpushare-scheduler-extender" target="_blank" rel="external nofollow noopener noreferrer">GPUShare</a> 与腾讯的 <a href="https://github.com/tkestack/gpu-manager" target="_blank" rel="external nofollow noopener noreferrer">GPUManager</a>，分析其实现机制。</p><a id="more"></a><h2 id="阿里GPUShare"><a href="#阿里GPUShare" class="headerlink" title="阿里GPUShare"></a>阿里GPUShare</h2><p>阿里的 <a href="https://github.com/AliyunContainerService/gpushare-scheduler-extender" target="_blank" rel="external nofollow noopener noreferrer">GPUShare</a> 基于 <a href="https://github.com/NVIDIA/nvidia-docker" target="_blank" rel="external nofollow noopener noreferrer">Nvidia Docker2</a> 和他们的 <a href="https://docs.google.com/document/d/1ZgKH_K4SEfdiE_OfxQ836s4yQWxZfSjS288Tq9YIWCA/edit#heading=h.r88v2xgacqr" target="_blank" rel="external nofollow noopener noreferrer">gpu sharing design</a> 设计而实现的，为了使用阿里的GPUShare，首先需要配置Node上的 Docker Runtime 并安装 <code>NVIDIA Docker 2</code>，具体过程可以参考 <a href="../574111db">在Docker中使用GPU</a>。</p><h3 id="架构设计"><a href="#架构设计" class="headerlink" title="架构设计"></a>架构设计</h3><h4 id="假设条件"><a href="#假设条件" class="headerlink" title="假设条件"></a>假设条件</h4><ul><li>尽管GPU可以从 CUDA Cores 和 GPU Memory 两个维度来衡量GPU的能力，<strong>在推理的场景，我们可以假定CUDA core的数量和GPU  Memory的大小是成比例的</strong></li><li>在模型开发和推理的场景下，<strong>用户申请的GPU资源不超过1个GPU，也就是说 resource limit 是 一个GPU</strong></li><li>每个Node上所有卡的GPU Memory相同，这样可以通过 <code>gpuTotalMemory</code> 和 <code>gpuTotalCount</code> 算出Node上每张卡的GPU Memory</li></ul><h4 id="设计原则"><a href="#设计原则" class="headerlink" title="设计原则"></a>设计原则</h4><ul><li><p>设计里定义了两种 <code>Extended Resource</code>：</p><ul><li><code>aliyun.com/gpu-mem</code>： 单位从 <code>number of GPUs</code> 变更为 <code>amount of GPU memory in MiB</code>，如果一个Node有多个GPU设备，这里计算的是总的GPU Memory</li><li><code>aliyun.com/gpu-count</code>：对应于Node上的GPU 设备的数目</li></ul></li><li>基于k8s原生的Scheduler Extender、Extended Resource、DevicePlugin机制来实现</li><li>这个方案只实现GPU的共享，不实现算力和显存的隔离，如果想实现隔离，在阿里云可以搭配 <a href="https://www.alibabacloud.com/help/zh/doc-detail/163994.htm" target="_blank" rel="external nofollow noopener noreferrer">cGPU</a> 一起使用</li></ul><h4 id="核心组件"><a href="#核心组件" class="headerlink" title="核心组件"></a>核心组件</h4><p>下图是整个设计的核心组件：</p><ul><li>GPU Share Scheduler Extender：基于k8s scheduler extender机制，作用于调度过程的<code>Filter</code>和<code>Bind</code>阶段，用于决定某个Node上的一个GPU设备是否可以提供足够的GPU Memory，并将GPU分配的结果记录到Pod Spec 的 Annotation中</li><li>GPU Share Device Plugin：基于k8s device plugin机制，根据GPU Share Scheduler Extender记录在Pod Spec的Annotation，实现GPU 设备的 Allocation。</li></ul><p><img alt="GPU Share Design" data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-11-21_aliyun-gpu-share.jpg"></p><h3 id="具体过程"><a href="#具体过程" class="headerlink" title="具体过程"></a>具体过程</h3><h4 id="设备资源报告"><a href="#设备资源报告" class="headerlink" title="设备资源报告"></a>设备资源报告</h4><p><code>GPU Share Device Plugin</code> 基于 <code>nvml</code> 库来查询每个Node上GPU设备的数目和每个GPU设备的GPU Memory。</p><p>这些资源状况被通过 <code>ListAndWatch()</code> 汇报给 Kubelet，然后 kubelet 会上报给 APIServer，这时候执行 <code>kubectl get node</code> 可以看到在 <code>status</code> 看到相关的<code>Extended Resource</code>字段：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Node</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="number">10.0</span><span class="number">.0</span><span class="number">.4</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">gpushare:</span> <span class="string">"true"</span></span><br><span class="line">    <span class="string">...</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">podCIDR:</span> <span class="number">172.16</span><span class="number">.1</span><span class="number">.0</span><span class="string">/26</span></span><br><span class="line">  <span class="attr">podCIDRs:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="number">172.16</span><span class="number">.1</span><span class="number">.0</span><span class="string">/26</span></span><br><span class="line">  <span class="attr">providerID:</span> <span class="string">qcloud:///800002/ins-hsmsc4x9</span></span><br><span class="line"><span class="attr">status:</span></span><br><span class="line">  <span class="string">...</span></span><br><span class="line">  <span class="attr">allocatable:</span></span><br><span class="line">    <span class="attr">aliyun.com/gpu-count:</span> <span class="string">"1"</span></span><br><span class="line">    <span class="attr">aliyun.com/gpu-mem:</span> <span class="string">"22"</span></span><br><span class="line">    <span class="attr">cpu:</span> <span class="string">5926m</span></span><br><span class="line">    <span class="attr">ephemeral-storage:</span> <span class="string">"47438316671"</span></span><br><span class="line">    <span class="attr">hugepages-2Mi:</span> <span class="string">"0"</span></span><br><span class="line">    <span class="attr">memory:</span> <span class="string">54222084Ki</span></span><br><span class="line">    <span class="string">...</span></span><br><span class="line">  <span class="attr">capacity:</span></span><br><span class="line">    <span class="attr">aliyun.com/gpu-count:</span> <span class="string">"1"</span></span><br><span class="line">    <span class="attr">aliyun.com/gpu-mem:</span> <span class="string">"22"</span></span><br><span class="line">    <span class="attr">cpu:</span> <span class="string">"6"</span></span><br><span class="line">    <span class="attr">ephemeral-storage:</span> <span class="string">51473868Ki</span></span><br><span class="line">    <span class="attr">hugepages-2Mi:</span> <span class="string">"0"</span></span><br><span class="line">    <span class="attr">memory:</span> <span class="string">57448708Ki</span></span><br><span class="line">    <span class="string">...</span></span><br></pre></td></tr></table></figure><h4 id="调度插件扩展"><a href="#调度插件扩展" class="headerlink" title="调度插件扩展"></a>调度插件扩展</h4><p>用户申请GPU的时候，在 Extended Resource 中只填写 <code>gpu-mem</code>，下面部署一个单机版的Tensorflow：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span> </span><br><span class="line">  <span class="attr">name:</span> <span class="string">tensorflow</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">k8s-app:</span> <span class="string">tensorflow</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">k8s-app:</span> <span class="string">tensorflow</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">k8s-app:</span> <span class="string">tensorflow</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">tensorflow</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">tensorflow/tensorflow:2.2.1-gpu-py3-jupyter</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">8888</span></span><br><span class="line">        <span class="attr">resources:</span></span><br><span class="line">          <span class="attr">limits:</span></span><br><span class="line">            <span class="attr">cpu:</span> <span class="number">4</span></span><br><span class="line">            <span class="attr">memory:</span> <span class="string">2Gi</span></span><br><span class="line">            <span class="attr">aliyun.com/gpu-mem:</span> <span class="number">3</span></span><br><span class="line">          <span class="attr">requests:</span></span><br><span class="line">            <span class="attr">cpu:</span> <span class="number">2</span></span><br><span class="line">            <span class="attr">memory:</span> <span class="string">1Gi</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">jupyter-service</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">NodePort</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">8888</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">tensorflow</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">k8s-app:</span> <span class="string">tensorflow</span></span><br></pre></td></tr></table></figure><h5 id="Filter"><a href="#Filter" class="headerlink" title="Filter"></a>Filter</h5><p>当kube-scheduler运行完所有的Filter函数后，就会调用 <code>GPU Share Extender</code> 的 Filter 函数。在原生的过滤中，kube-scheduler会计算是否有足够的Extended Resource（算的是总共的GPU Memory），但是不能知道是否某个GPU设备有足够的资源，这时候就需要调度器插件来实现。以下图为例：</p><ul><li>用户申请了8138MiB的GPU Memory，对于原生调度器，N1节点只剩下  (16276 * 2 - 16276 - 12207 = 4069) 的GPU资源，不满足 Extended Resource可用的条件，N1节点被过滤掉</li><li>接下来的N2节点和N3节点剩余的总的资源数都有8138MiB，那么该选择哪一个呢</li><li>在 <code>GPU Share Extender</code> 的过滤中，他需要找到有单个GPU能够满足用户申请的资源，当检查到N2节点的时候，发现虽然总的GPU Memory有8138MiB，但是每个GPU设备都只剩4096MiB了，不能满足单设备8138的需求，所以N2被过滤掉</li><li>扫描到N3节点，发现GPU0满足8138MiB的需求，符合要求</li></ul><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-11-21_aliyun-gpu-share-filter.jpg"></p><blockquote><p><strong>这里有一个问题：当一个Node上有多张卡的时候，Scheduler Extender是如何知道每张卡当前可用的Capacity的呢？</strong></p></blockquote><p>我们看一下Extender在 Filter 阶段执行的函数，对于要创建的Pod，当前Node检查自己拥有的所有可用GPU，一旦有一个GPU的可用显存大于申请的显存，那么当前Node是可以被调度的。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// check if the pod can be allocated on the node</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(n *NodeInfo)</span> <span class="title">Assume</span><span class="params">(pod *v1.Pod)</span> <span class="params">(allocatable <span class="keyword">bool</span>)</span></span> &#123;</span><br><span class="line">allocatable = <span class="literal">false</span></span><br><span class="line"></span><br><span class="line">n.rwmu.RLock()</span><br><span class="line"><span class="keyword">defer</span> n.rwmu.RUnlock()</span><br><span class="line"></span><br><span class="line">availableGPUs := n.getAvailableGPUs()</span><br><span class="line">reqGPU := <span class="keyword">uint</span>(utils.GetGPUMemoryFromPodResource(pod))</span><br><span class="line">log.Printf(<span class="string">"debug: AvailableGPUs: %v in node %s"</span>, availableGPUs, n.name)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(availableGPUs) &gt; <span class="number">0</span> &#123;</span><br><span class="line"><span class="keyword">for</span> devID := <span class="number">0</span>; devID &lt; <span class="built_in">len</span>(n.devs); devID++ &#123;</span><br><span class="line">availableGPU, ok := availableGPUs[devID]</span><br><span class="line"><span class="keyword">if</span> ok &#123;</span><br><span class="line"><span class="keyword">if</span> availableGPU &gt;= reqGPU &#123;</span><br><span class="line">allocatable = <span class="literal">true</span></span><br><span class="line"><span class="keyword">break</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> allocatable</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>接下来的一个问题是，每个Node可用的GPU显存是如何得到的呢？我们进入到 <code>getAvailableGPUs</code> 继续看：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(n *NodeInfo)</span> <span class="title">getAvailableGPUs</span><span class="params">()</span> <span class="params">(availableGPUs <span class="keyword">map</span>[<span class="keyword">int</span>]<span class="keyword">uint</span>)</span></span> &#123;</span><br><span class="line">allGPUs := n.getAllGPUs()</span><br><span class="line">usedGPUs := n.getUsedGPUs()</span><br><span class="line">unhealthyGPUs := n.getUnhealthyGPUs()</span><br><span class="line">availableGPUs = <span class="keyword">map</span>[<span class="keyword">int</span>]<span class="keyword">uint</span>&#123;&#125;</span><br><span class="line"><span class="keyword">for</span> id, totalGPUMem := <span class="keyword">range</span> allGPUs &#123;</span><br><span class="line"><span class="keyword">if</span> usedGPUMem, found := usedGPUs[id]; found &#123;</span><br><span class="line">availableGPUs[id] = totalGPUMem - usedGPUMem</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">log.Printf(<span class="string">"info: available GPU list %v before removing unhealty GPUs"</span>, availableGPUs)</span><br><span class="line"><span class="keyword">for</span> id, _ := <span class="keyword">range</span> unhealthyGPUs &#123;</span><br><span class="line">log.Printf(<span class="string">"info: delete dev %d from availble GPU list"</span>, id)</span><br><span class="line"><span class="built_in">delete</span>(availableGPUs, id)</span><br><span class="line">&#125;</span><br><span class="line">log.Printf(<span class="string">"info: available GPU list %v after removing unhealty GPUs"</span>, availableGPUs)</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> availableGPUs</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里可以看到，<code>Scheduler Extender</code> 内部维护了当前Node上所有的GPU显存状态和已经用了的GPU显存状态信息：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// device index: gpu memory</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(n *NodeInfo)</span> <span class="title">getUsedGPUs</span><span class="params">()</span> <span class="params">(usedGPUs <span class="keyword">map</span>[<span class="keyword">int</span>]<span class="keyword">uint</span>)</span></span> &#123;</span><br><span class="line">usedGPUs = <span class="keyword">map</span>[<span class="keyword">int</span>]<span class="keyword">uint</span>&#123;&#125;</span><br><span class="line"><span class="keyword">for</span> _, dev := <span class="keyword">range</span> n.devs &#123;</span><br><span class="line">usedGPUs[dev.idx] = dev.GetUsedGPUMemory()</span><br><span class="line">&#125;</span><br><span class="line">log.Printf(<span class="string">"info: getUsedGPUs: %v in node %s, and devs %v"</span>, usedGPUs, n.name, n.devs)</span><br><span class="line"><span class="keyword">return</span> usedGPUs</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// device index: gpu memory</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(n *NodeInfo)</span> <span class="title">getAllGPUs</span><span class="params">()</span> <span class="params">(allGPUs <span class="keyword">map</span>[<span class="keyword">int</span>]<span class="keyword">uint</span>)</span></span> &#123;</span><br><span class="line">allGPUs = <span class="keyword">map</span>[<span class="keyword">int</span>]<span class="keyword">uint</span>&#123;&#125;</span><br><span class="line"><span class="keyword">for</span> _, dev := <span class="keyword">range</span> n.devs &#123;</span><br><span class="line">allGPUs[dev.idx] = dev.totalGPUMem</span><br><span class="line">&#125;</span><br><span class="line">log.Printf(<span class="string">"info: getAllGPUs: %v in node %s, and dev %v"</span>, allGPUs, n.name, n.devs)</span><br><span class="line"><span class="keyword">return</span> allGPUs</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>关于 <code>GetUsedGPUMemory</code>，是<code>Scheduler Extender</code> 内部维护的 <code>DeviceInfo</code> 所记录的，这里的 <code>d.podMap</code> 会在每次Extender执行 <code>Bind</code> 的时候，将对应的Pod添加到对应的Node上的 <code>DeviceInfo</code>中：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(d *DeviceInfo)</span> <span class="title">GetUsedGPUMemory</span><span class="params">()</span> <span class="params">(gpuMem <span class="keyword">uint</span>)</span></span> &#123;</span><br><span class="line">log.Printf(<span class="string">"debug: GetUsedGPUMemory() podMap %v, and its address is %p"</span>, d.podMap, d)</span><br><span class="line">d.rwmu.RLock()</span><br><span class="line"><span class="keyword">defer</span> d.rwmu.RUnlock()</span><br><span class="line"><span class="keyword">for</span> _, pod := <span class="keyword">range</span> d.podMap &#123;</span><br><span class="line"><span class="keyword">if</span> pod.Status.Phase == v1.PodSucceeded || pod.Status.Phase == v1.PodFailed &#123;</span><br><span class="line">log.Printf(<span class="string">"debug: skip the pod %s in ns %s due to its status is %s"</span>, pod.Name, pod.Namespace, pod.Status.Phase)</span><br><span class="line"><span class="keyword">continue</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// gpuMem += utils.GetGPUMemoryFromPodEnv(pod)</span></span><br><span class="line">gpuMem += utils.GetGPUMemoryFromPodAnnotation(pod)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> gpuMem</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>再总结总结，本质上是 <code>Scheduler Extender</code> 维护了一个 <code>devs</code> 这么一个数据结构，使得它可以知道当前Node上每个GPU设备的显存状态。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// NodeInfo is node level aggregated information.</span></span><br><span class="line"><span class="keyword">type</span> NodeInfo <span class="keyword">struct</span> &#123;</span><br><span class="line">name           <span class="keyword">string</span></span><br><span class="line">node           *v1.Node</span><br><span class="line">devs           <span class="keyword">map</span>[<span class="keyword">int</span>]*DeviceInfo</span><br><span class="line">gpuCount       <span class="keyword">int</span></span><br><span class="line">gpuTotalMemory <span class="keyword">int</span></span><br><span class="line">rwmu           *sync.RWMutex</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>那么问题来了，我们通过ApiServer，只能知道对应Node上的 <code>gpuCount</code> 和 <code>gpuTotalMemory</code>，而不知道每张卡各自的显存的。这个 <code>devs</code> 是怎么初始化得到每张卡的显存信息呢的呢？继续看代码：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Create Node Level</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">NewNodeInfo</span><span class="params">(node *v1.Node)</span> *<span class="title">NodeInfo</span></span> &#123;</span><br><span class="line">log.Printf(<span class="string">"debug: NewNodeInfo() creates nodeInfo for %s"</span>, node.Name)</span><br><span class="line"></span><br><span class="line">devMap := <span class="keyword">map</span>[<span class="keyword">int</span>]*DeviceInfo&#123;&#125;</span><br><span class="line"><span class="keyword">for</span> i := <span class="number">0</span>; i &lt; utils.GetGPUCountInNode(node); i++ &#123;</span><br><span class="line">devMap[i] = newDeviceInfo(i, <span class="keyword">uint</span>(utils.GetTotalGPUMemory(node)/utils.GetGPUCountInNode(node)))</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(devMap) == <span class="number">0</span> &#123;</span><br><span class="line">log.Printf(<span class="string">"warn: node %s with nodeinfo %v has no devices"</span>,</span><br><span class="line">node.Name,</span><br><span class="line">node)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> &amp;NodeInfo&#123;</span><br><span class="line">name:           node.Name,</span><br><span class="line">node:           node,</span><br><span class="line">devs:           devMap,</span><br><span class="line">gpuCount:       utils.GetGPUCountInNode(node),</span><br><span class="line">gpuTotalMemory: utils.GetTotalGPUMemory(node),</span><br><span class="line">rwmu:           <span class="built_in">new</span>(sync.RWMutex),</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看到，<strong>这里在初始化的时候，默认设定每张GPU卡的显存大小一样，通过平均得到每张卡的心存信息。</strong></p><h5 id="Bind"><a href="#Bind" class="headerlink" title="Bind"></a>Bind</h5><ul><li>当调度器发现有Node符合要求，这时候会把Pod和Node Bind到一起，<code>GPU Share Extender</code> 需要做两件事情：<ul><li>根据 <code>binpack</code> 原则找到Node上对应的GPU设备，并将 GPU Device ID记录到 Pod的 Annotation中 <code>ALIYUN_GPU_ID</code>。他也会将Pod使用的GPU Memory记录到Pod Annotation中：<code>ALIYUN_COM_GPU_MEM_POD</code> 和 <code>ALIYUN_COM_GPU_MEM_ASSUME_TIME</code></li><li>Bind the Node and Pod with kubernetes API</li></ul></li><li>如果没有找到合适的Node符合要求，那么就不会做Bind操作</li></ul><p>以下图为例，N1中有4个GPU，其中GPU0（12207），GPU1（8138）、GPU2（4069）和GPU3（16276）, GPU2因为资源不够被过滤掉，剩下的3个GPU根据 Binpack 原则，我们选用GPU1（图里面 Annotation错了，不是0，而是1）</p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-11-21_aliyun-gpu-share-bind.jpg"></p><p>我们看一看在找GPU设备的时候是如何操作的，可以看到这里通过 <code>candidateGPUMemory &gt; availableGPU</code> 这里实现了 <code>binpack</code>。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// allocate the GPU ID to the pod</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(n *NodeInfo)</span> <span class="title">allocateGPUID</span><span class="params">(pod *v1.Pod)</span> <span class="params">(candidateDevID <span class="keyword">int</span>, found <span class="keyword">bool</span>)</span></span> &#123;</span><br><span class="line"></span><br><span class="line">reqGPU := <span class="keyword">uint</span>(<span class="number">0</span>)</span><br><span class="line">found = <span class="literal">false</span></span><br><span class="line">candidateDevID = <span class="number">-1</span></span><br><span class="line">candidateGPUMemory := <span class="keyword">uint</span>(<span class="number">0</span>)</span><br><span class="line">availableGPUs := n.getAvailableGPUs()</span><br><span class="line"></span><br><span class="line">reqGPU = <span class="keyword">uint</span>(utils.GetGPUMemoryFromPodResource(pod))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> reqGPU &gt; <span class="keyword">uint</span>(<span class="number">0</span>) &#123;</span><br><span class="line">log.Printf(<span class="string">"info: reqGPU for pod %s in ns %s: %d"</span>, pod.Name, pod.Namespace, reqGPU)</span><br><span class="line">log.Printf(<span class="string">"info: AvailableGPUs: %v in node %s"</span>, availableGPUs, n.name)</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(availableGPUs) &gt; <span class="number">0</span> &#123;</span><br><span class="line"><span class="keyword">for</span> devID := <span class="number">0</span>; devID &lt; <span class="built_in">len</span>(n.devs); devID++ &#123;</span><br><span class="line">availableGPU, ok := availableGPUs[devID]</span><br><span class="line"><span class="keyword">if</span> ok &#123;</span><br><span class="line"><span class="keyword">if</span> availableGPU &gt;= reqGPU &#123;</span><br><span class="line"><span class="keyword">if</span> candidateDevID == <span class="number">-1</span> || candidateGPUMemory &gt; availableGPU &#123;</span><br><span class="line">candidateDevID = devID</span><br><span class="line">candidateGPUMemory = availableGPU</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">found = <span class="literal">true</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> found &#123;</span><br><span class="line">log.Printf(<span class="string">"info: Find candidate dev id %d for pod %s in ns %s successfully."</span>,</span><br><span class="line">candidateDevID,</span><br><span class="line">pod.Name,</span><br><span class="line">pod.Namespace)</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">log.Printf(<span class="string">"warn: Failed to find available GPUs %d for the pod %s in the namespace %s"</span>,</span><br><span class="line">reqGPU,</span><br><span class="line">pod.Name,</span><br><span class="line">pod.Namespace)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> candidateDevID, found</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="Kubelet创建Pod"><a href="#Kubelet创建Pod" class="headerlink" title="Kubelet创建Pod"></a>Kubelet创建Pod</h4><p>接下来由Kubelet在创建container前调用 <code>GPU Share Device Plugin</code> 的 <code>Allocate</code> 函数，参数是申请的GPU Memory的数量。</p><p>Pod运行成功后，执行 <code>kubectl get pod</code> 可以看到：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">annotations:</span></span><br><span class="line">    <span class="attr">ALIYUN_COM_GPU_MEM_ASSIGNED:</span> <span class="string">"true"</span></span><br><span class="line">    <span class="attr">ALIYUN_COM_GPU_MEM_ASSUME_TIME:</span> <span class="string">"1606125285243248618"</span></span><br><span class="line">    <span class="attr">ALIYUN_COM_GPU_MEM_DEV:</span> <span class="string">"22"</span></span><br><span class="line">    <span class="attr">ALIYUN_COM_GPU_MEM_IDX:</span> <span class="string">"0"</span></span><br><span class="line">    <span class="attr">ALIYUN_COM_GPU_MEM_POD:</span> <span class="string">"3"</span></span><br><span class="line">  <span class="string">...</span></span><br></pre></td></tr></table></figure><ul><li><p>Device Plugin 从 k8s apiserver 拿到所有Pending的Pod中属于GPU Share的Pod，并且按照 AssumedTimestamp排序</p></li><li><p>选择符合Allocation传入的GPU Memory的Pod，如果有多个，选择最早的那个Pod</p></li><li><p>标记 <code>ALIYUN_COM_GPU_MEM_ASSIGNED</code> 为 True</p></li><li><p>把 DeviceID 作为下NVIDIA_VISIBLE_DEVICES环境变量告诉 Nvidia Docker2，并且创建容器</p></li></ul><p><img alt data-src="https://github.com/AliyunContainerService/gpushare-scheduler-extender/raw/master/docs/designs/sequence.jpg"></p><blockquote><p><strong>这里问题是device plugin的allocate接口参数是什么，是否包含pod信息，是否包含pod annotation？</strong></p></blockquote><p>查看 Device Plugin 的代码，这一个申请的GPU Memory的数量让我很疑惑，为何要这么算？</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> _, req := <span class="keyword">range</span> reqs.ContainerRequests &#123;</span><br><span class="line">podReqGPU += <span class="keyword">uint</span>(<span class="built_in">len</span>(req.DevicesIDs))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>继续看 <code>Device Plugin</code> 的 <code>DeviceIDs</code> 是如何生成的。这里调用了 <code>nvml library</code> 可以探测到本Node上拥有的GPU有多少个，每个显存是多少。接下来 <code>Device Plugin</code> 会创建一系列的 <code>FakeDeviceID</code>，并将这个DeviceIDs返回给 Kubelet，这就解释了为什么要通过上面的方法计算申请的 GPU Memory，这里的Memory以MiB为单位。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">getDevices</span><span class="params">()</span> <span class="params">([]*pluginapi.Device, <span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">uint</span>)</span></span> &#123;</span><br><span class="line">n, err := nvml.GetDeviceCount()</span><br><span class="line">check(err)</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> devs []*pluginapi.Device</span><br><span class="line">realDevNames := <span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">uint</span>&#123;&#125;</span><br><span class="line"><span class="keyword">for</span> i := <span class="keyword">uint</span>(<span class="number">0</span>); i &lt; n; i++ &#123;</span><br><span class="line">d, err := nvml.NewDevice(i)</span><br><span class="line">check(err)</span><br><span class="line"><span class="comment">// realDevNames = append(realDevNames, d.UUID)</span></span><br><span class="line"><span class="keyword">var</span> id <span class="keyword">uint</span></span><br><span class="line">log.Infof(<span class="string">"Deivce %s's Path is %s"</span>, d.UUID, d.Path)</span><br><span class="line">_, err = fmt.Sscanf(d.Path, <span class="string">"/dev/nvidia%d"</span>, &amp;id)</span><br><span class="line">check(err)</span><br><span class="line">realDevNames[d.UUID] = id</span><br><span class="line"><span class="comment">// var KiB uint64 = 1024</span></span><br><span class="line">log.Infof(<span class="string">"# device Memory: %d"</span>, <span class="keyword">uint</span>(*d.Memory))</span><br><span class="line"><span class="keyword">if</span> getGPUMemory() == <span class="keyword">uint</span>(<span class="number">0</span>) &#123;</span><br><span class="line">setGPUMemory(<span class="keyword">uint</span>(*d.Memory))</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span> j := <span class="keyword">uint</span>(<span class="number">0</span>); j &lt; getGPUMemory(); j++ &#123;</span><br><span class="line">fakeID := generateFakeDeviceID(d.UUID, j)</span><br><span class="line"><span class="keyword">if</span> j == <span class="number">0</span> &#123;</span><br><span class="line">log.Infoln(<span class="string">"# Add first device ID: "</span> + fakeID)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> j == getGPUMemory()<span class="number">-1</span> &#123;</span><br><span class="line">log.Infoln(<span class="string">"# Add last device ID: "</span> + fakeID)</span><br><span class="line">&#125;</span><br><span class="line">devs = <span class="built_in">append</span>(devs, &amp;pluginapi.Device&#123;</span><br><span class="line">ID:     fakeID,</span><br><span class="line">Health: pluginapi.Healthy,</span><br><span class="line">&#125;)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> devs, realDevNames</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们看一下 <code>Device Plugin</code> 是如何找到对应的Pod的，可以看到一旦碰到有Pod申请的GPU显存与Kubelet传入的显存大小一致，那么则找到对应的Pod了。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">pods, err := getCandidatePods()</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">   log.Infof(<span class="string">"invalid allocation requst: Failed to find candidate pods due to %v"</span>, err)</span><br><span class="line">   <span class="keyword">return</span> buildErrResponse(reqs, podReqGPU), <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> _, pod := <span class="keyword">range</span> pods &#123;</span><br><span class="line">   <span class="keyword">if</span> getGPUMemoryFromPodResource(pod) == podReqGPU &#123;</span><br><span class="line">      log.Infof(<span class="string">"Found Assumed GPU shared Pod %s in ns %s with GPU Memory %d"</span>,</span><br><span class="line">         pod.Name,</span><br><span class="line">         pod.Namespace,</span><br><span class="line">         podReqGPU)</span><br><span class="line">      assumePod = pod</span><br><span class="line">      found = <span class="literal">true</span></span><br><span class="line">      <span class="keyword">break</span></span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里的 <code>getCandidatePods</code>就是List所有Pending的Pod中 Assume Memory的，并且按照时间排序：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// pick up the gpushare pod with assigned status is false, and</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">getCandidatePods</span><span class="params">()</span> <span class="params">([]*v1.Pod, error)</span></span> &#123;</span><br><span class="line">candidatePods := []*v1.Pod&#123;&#125;</span><br><span class="line">allPods, err := getPendingPodsInNode()</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> candidatePods, err</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span> _, pod := <span class="keyword">range</span> allPods &#123;</span><br><span class="line">current := pod</span><br><span class="line"><span class="keyword">if</span> isGPUMemoryAssumedPod(&amp;current) &#123;</span><br><span class="line">candidatePods = <span class="built_in">append</span>(candidatePods, &amp;current)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">  ...</span><br><span class="line"><span class="keyword">return</span> makePodOrderdByAge(candidatePods), <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p><strong>那么这里有一个问题：如果在同一个Node有两个Pod <poda, podb>，都申请了相同的GPU显存大小，比如3G，那么kubelet是在创建容器的时候，是如何保证两个Pod不混淆的呢？混淆会有问题吗，kubelet建Pod的时候到底是怎么搞的？是谁触发了kubelet创建容器？</poda,></strong></p></blockquote><hr><h2 id="腾讯GPUManager"><a href="#腾讯GPUManager" class="headerlink" title="腾讯GPUManager"></a>腾讯GPUManager</h2><p>GPU Manager 提供一个 All-in-One 的 GPU 管理器，基于 Kubernetes DevicePlugin 插件系统实现，该管理器提供了分配并共享 GPU、GPU 指标查询、容器运行前的 GPU 相关设备准备等功能，支持用户在 Kubernetes 集群中使用 GPU 设备。</p><ul><li><strong>拓扑分配</strong>：提供基于 GPU 拓扑分配功能，当用户分配超过1张 GPU 卡的应用，可以选择拓扑连接最快的方式分配 GPU 设备。</li><li><strong>GPU 共享</strong>：允许用户提交小于1张卡资源的任务，并提供 QoS 保证。</li><li><strong>应用 GPU 指标的查询</strong>：用户可以访问主机端口（默认为 5678）的 <code>/metrics</code> 路径，可以为 Prometheus 提供 GPU 指标的收集功能，访问 <code>/usage</code> 路径可以进行可读性的容器状况查询。</li></ul><h3 id="架构设计-1"><a href="#架构设计-1" class="headerlink" title="架构设计"></a>架构设计</h3><h4 id="设计原则-1"><a href="#设计原则-1" class="headerlink" title="设计原则"></a>设计原则</h4><ul><li><p>设计里定义了两种 <code>Extended Resource</code>：</p><ul><li><code>tencent.com/vcuda-core</code> ： <code>vcuda-core</code>对应的是使用率，单张卡有100个core</li><li><code>tencent.com/vcuda-memory</code> ：<code>vcuda-memory</code> 是显存，每个单位是256MB的显存</li><li>如果申请的资源为50%利用率，7680MB显存，<code>tencent.com/vcuda-core</code> 填写50，<code>tencent.com/vcuda-memory</code> 填写成30</li><li>同样支持原来的独占卡的方式，只需要在core的地方填写100的整数倍，memory值填写大于0的任意值</li></ul></li><li>基于k8s原生的Scheduler Extender、Extended Resource、DevicePlugin机制来实现</li><li>这个方案同时实现GPU的共享与算力和显存的隔离，类似于阿里云 <a href="https://www.alibabacloud.com/help/zh/doc-detail/163994.htm" target="_blank" rel="external nofollow noopener noreferrer">cGPU</a> 加上GPUShare 一起使用</li></ul><h4 id="核心组件-1"><a href="#核心组件-1" class="headerlink" title="核心组件"></a>核心组件</h4><p>GaiaGPU的实现主要分为两个部分：Kubernetes 部分 和 vCUDA 部分</p><ul><li>Kubernetes部分基于 Kubernetes 的 Extended Resources、Device Plugin 和 Scheduler Extender机制，实现了下面两个项目<ul><li><a href="https://github.com/tkestack/gpu-manager" target="_blank" rel="external nofollow noopener noreferrer">GPU Manager </a>：实现为一个 Device Plugin，与 NVIDIA 的 <a href="https://github.com/NVIDIA/k8s-device-plugin" target="_blank" rel="external nofollow noopener noreferrer">k8s-device-plugin</a> 相比，不需要额外配置 <code>nvidia-docker2</code>，使用的是原生的 <code>runc</code></li><li><a href="https://github.com/tkestack/gpu-admission" target="_blank" rel="external nofollow noopener noreferrer">GPU Admission</a>：实现为一个Scheduler Extender，注意这里的Extender在论文中没有提到，下图中的GPU Scheduler实现的是topology的选卡，属于现在GPU Manager项目的一部分，与这里的调度器插件无关</li></ul></li><li>vCUDA 部分通过 <a href="https://github.com/tkestack/vcuda-controller" target="_blank" rel="external nofollow noopener noreferrer">vcuda-controller</a> 来实现，作为 NVIDIA 的 CUDA 库的封装</li></ul><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-11-22_gaia-gpu-manager.png"></p><h3 id="具体过程-1"><a href="#具体过程-1" class="headerlink" title="具体过程"></a>具体过程</h3><h4 id="设备资源上报"><a href="#设备资源上报" class="headerlink" title="设备资源上报"></a>设备资源上报</h4><ul><li>与阿里的 <a href="https://github.com/AliyunContainerService/gpushare-scheduler-extender" target="_blank" rel="external nofollow noopener noreferrer">GPUShare</a> 一样，GPU Manager 在 <code>ListAndWatch</code> 返回给Kubelet的也不是实际的GPU设备，而是 <code>a list of vGPUs</code>，</li><li>GPU被虚拟化为两个资源维度，memory 和 computing resource<ul><li>memory：以256M内存作为单位，每个memory unit叫做 <code>vmemory</code> device</li><li>computing resource：将一个物理GPU划分为100个 <code>vprocessor</code> devices，每个 <code>vprocessor</code> 占有 1%的GPU利用率</li></ul></li><li>用户申请具有GPU的Pod资源Manifest如下：</li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">vcuda</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">restartPolicy:</span> <span class="string">Never</span></span><br><span class="line">  <span class="attr">hostNetwork:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">tensorflow</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">vcuda-test</span></span><br><span class="line">    <span class="attr">command:</span> <span class="string">['/usr/local/nvidia/bin/nvidia-smi']</span></span><br><span class="line">    <span class="attr">resources:</span></span><br><span class="line">      <span class="attr">requests:</span></span><br><span class="line">        <span class="attr">tencent.com/vcuda-core:</span> <span class="number">50</span></span><br><span class="line">        <span class="attr">tencent.com/vcuda-memory:</span> <span class="number">30</span></span><br><span class="line">      <span class="attr">limits:</span></span><br><span class="line">        <span class="attr">tencent.com/vcuda-core:</span> <span class="number">50</span></span><br><span class="line">        <span class="attr">tencent.com/vcuda-memory:</span> <span class="number">3</span></span><br></pre></td></tr></table></figure><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-11-22_gaia-device-plugin.png"></p><p> 下面看具体代码，首先是向 <code>kubelet</code> 注册：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(m *managerImpl)</span> <span class="title">RegisterToKubelet</span><span class="params">()</span> <span class="title">error</span></span> &#123;</span><br><span class="line">socketFile := filepath.Join(m.config.DevicePluginPath, types.KubeletSocket)</span><br><span class="line">dialOptions := []grpc.DialOption&#123;grpc.WithInsecure(), grpc.WithDialer(utils.UnixDial), grpc.WithBlock(), grpc.WithTimeout(time.Second * <span class="number">5</span>)&#125;</span><br><span class="line"></span><br><span class="line">conn, err := grpc.Dial(socketFile, dialOptions...)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> err</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">defer</span> conn.Close()</span><br><span class="line"></span><br><span class="line">client := pluginapi.NewRegistrationClient(conn)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> _, srv := <span class="keyword">range</span> m.bundleServer &#123;</span><br><span class="line">req := &amp;pluginapi.RegisterRequest&#123;</span><br><span class="line">Version:      pluginapi.Version,</span><br><span class="line">Endpoint:     path.Base(srv.SocketName()),</span><br><span class="line">ResourceName: srv.ResourceName(),</span><br><span class="line">Options:      &amp;pluginapi.DevicePluginOptions&#123;PreStartRequired: <span class="literal">true</span>&#125;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">glog.V(<span class="number">2</span>).Infof(<span class="string">"Register to kubelet with endpoint %s"</span>, req.Endpoint)</span><br><span class="line">_, err = client.Register(context.Background(), req)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> err</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里有一个 <code>m.bundleServer</code>，分别是 <code>vcore</code> 和 <code>vmemory</code> 的 gRPC Server。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(m *managerImpl)</span> <span class="title">setupGRPCService</span><span class="params">()</span></span> &#123;</span><br><span class="line">vcoreServer := newVcoreServer(m)</span><br><span class="line">vmemoryServer := newVmemoryServer(m)</span><br><span class="line"></span><br><span class="line">m.bundleServer[types.VCoreAnnotation] = vcoreServer</span><br><span class="line">m.bundleServer[types.VMemoryAnnotation] = vmemoryServer</span><br><span class="line"></span><br><span class="line">displayapi.RegisterGPUDisplayServer(m.srv, m)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>接下来看 <code>ListAndWatch</code> 的实现，对于两种资源，它会去检查 <code>capacity()</code>里面包含对应 <code>resourceName</code> 的：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//ListAndWatchWithResourceName send devices for request resource back to server</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(ta *NvidiaTopoAllocator)</span> <span class="title">ListAndWatchWithResourceName</span><span class="params">(resourceName <span class="keyword">string</span>, e *pluginapi.Empty, s pluginapi.DevicePlugin_ListAndWatchServer)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">devs := <span class="built_in">make</span>([]*pluginapi.Device, <span class="number">0</span>)</span><br><span class="line"><span class="keyword">for</span> _, dev := <span class="keyword">range</span> ta.capacity() &#123;</span><br><span class="line"><span class="keyword">if</span> strings.HasPrefix(dev.ID, resourceName) &#123;</span><br><span class="line">devs = <span class="built_in">append</span>(devs, dev)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">s.Send(&amp;pluginapi.ListAndWatchResponse&#123;Devices: devs&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">// We don't send unhealthy state</span></span><br><span class="line"><span class="keyword">for</span> &#123;</span><br><span class="line">time.Sleep(time.Second)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">glog.V(<span class="number">2</span>).Infof(<span class="string">"ListAndWatch %s exit"</span>, resourceName)</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>那么这里的 <code>ta.capicity()</code> 是如何得到的呢？这里维护了一个拓扑树，树根是物理的Host，树叶是物理的GPU。这里根据树叶上GPU的数目和总的显存大小，构建了 <code>vcore</code> 设备 和 <code>vmemory</code> 设备，命名以各自的资源名为前缀。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(ta *NvidiaTopoAllocator)</span> <span class="title">capacity</span><span class="params">()</span> <span class="params">(devs []*pluginapi.Device)</span></span> &#123;</span><br><span class="line"><span class="keyword">var</span> (</span><br><span class="line">gpuDevices, memoryDevices []*pluginapi.Device</span><br><span class="line">totalMemory               <span class="keyword">int64</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">nodes := ta.tree.Leaves()</span><br><span class="line"><span class="keyword">for</span> i := <span class="keyword">range</span> nodes &#123;</span><br><span class="line">totalMemory += <span class="keyword">int64</span>(nodes[i].Meta.TotalMemory)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">totalCores := <span class="built_in">len</span>(nodes) * nvtree.HundredCore</span><br><span class="line">gpuDevices = <span class="built_in">make</span>([]*pluginapi.Device, totalCores)</span><br><span class="line"><span class="keyword">for</span> i := <span class="number">0</span>; i &lt; totalCores; i++ &#123;</span><br><span class="line">gpuDevices[i] = &amp;pluginapi.Device&#123;</span><br><span class="line">ID:     fmt.Sprintf(<span class="string">"%s-%d"</span>, types.VCoreAnnotation, i),</span><br><span class="line">Health: pluginapi.Healthy,</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">totalMemoryBlocks := totalMemory / types.MemoryBlockSize</span><br><span class="line">memoryDevices = <span class="built_in">make</span>([]*pluginapi.Device, totalMemoryBlocks)</span><br><span class="line"><span class="keyword">for</span> i := <span class="keyword">int64</span>(<span class="number">0</span>); i &lt; totalMemoryBlocks; i++ &#123;</span><br><span class="line">memoryDevices[i] = &amp;pluginapi.Device&#123;</span><br><span class="line">ID:     fmt.Sprintf(<span class="string">"%s-%d-%d"</span>, types.VMemoryAnnotation, types.MemoryBlockSize, i),</span><br><span class="line">Health: pluginapi.Healthy,</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">devs = <span class="built_in">append</span>(devs, gpuDevices...)</span><br><span class="line">devs = <span class="built_in">append</span>(devs, memoryDevices...)</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="调度插件扩展-1"><a href="#调度插件扩展-1" class="headerlink" title="调度插件扩展"></a>调度插件扩展</h4><h5 id="细粒度Quota准入"><a href="#细粒度Quota准入" class="headerlink" title="细粒度Quota准入"></a>细粒度Quota准入</h5><p><code>GPU Quota Admission</code> 作为调度器插件，实现了更细粒度的quota调度准入维度。用户通过配置一个 <code>ConfigMap</code>，对每个 <code>Namespace</code>可用的GPU卡的配额做规划，同时也定义了资源池，这样在调度的时候就可以实现按照资源池及GPU型号进行策略调度。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"A"</span>: &#123;</span><br><span class="line">    <span class="attr">"pool"</span>: [<span class="string">"public"</span>], <span class="comment">// Pods in namespace 'A' could use pool 'public'</span></span><br><span class="line">    <span class="attr">"quota"</span>: &#123;</span><br><span class="line">      <span class="attr">"M40"</span>: <span class="number">2</span>,</span><br><span class="line">      <span class="attr">"P100"</span>: <span class="number">3</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"B"</span>: &#123;</span><br><span class="line">    <span class="attr">"pool"</span>: [ <span class="string">"wx"</span> ], <span class="comment">// Pods in namespace 'B' could use pool 'wx'</span></span><br><span class="line">    <span class="attr">"quota"</span>: &#123;</span><br><span class="line">      <span class="attr">"M40"</span>: <span class="number">8</span>,</span><br><span class="line">      <span class="attr">"P100"</span>: <span class="number">2</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>具体在调度的时候，对每一个Pod，根据Namespace可以筛选出一系列含有GPU的Pods，然后当前Namespace下，对于某种GPU Model（比如P100），计算已经使用了的GPU大小，根据 <code>ConfigMap</code> 定义的配额，找到没超出。通过这个，得到所有没超出Quota的Models。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> NamespaceQuota <span class="keyword">struct</span> &#123;</span><br><span class="line">Quota <span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">int</span> <span class="string">`json:"quota"`</span></span><br><span class="line">Pool []<span class="keyword">string</span> <span class="string">`json:"pool"`</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(gpuFilter *GPUFilter)</span> <span class="title">filterGPUModel</span><span class="params">(pod *corev1.Pod, namespaceQuota NamespaceQuota)</span> <span class="params">([]<span class="keyword">string</span>, error)</span></span> &#123;</span><br><span class="line"><span class="keyword">var</span> filteredGPUModels []<span class="keyword">string</span></span><br><span class="line"><span class="keyword">for</span> gpuModel, limit := <span class="keyword">range</span> namespaceQuota.Quota &#123;</span><br><span class="line">limit = limit * VirtualGPUTimes</span><br><span class="line">  nodeSelector, err := metav1.LabelSelectorAsSelector(&amp;metav1.LabelSelector&#123;</span><br><span class="line">MatchLabels: <span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">string</span>&#123;gpuFilter.conf.GPUModelLabel: gpuModel&#125;&#125;)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">&#125;</span><br><span class="line">pods, err := gpuFilter.listPodsOnNodes(nodeSelector, pod.Namespace)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">&#125;</span><br><span class="line">gpuUsed := calculateGPUUsage(<span class="built_in">append</span>(pods, pod))</span><br><span class="line"><span class="keyword">if</span> gpuUsed &lt;= limit &#123;</span><br><span class="line">filteredGPUModels = <span class="built_in">append</span>(filteredGPUModels, gpuModel)</span><br><span class="line">&#125;</span><br><span class="line">glog.V(<span class="number">4</span>).Infof(<span class="string">"Pods in namespace %s will use %d %s GPU cards after adding this pod, quota is %d"</span>,</span><br><span class="line">pod.Namespace, gpuUsed, gpuModel, limit)</span><br><span class="line">&#125;</span><br><span class="line">glog.V(<span class="number">4</span>).Infof(<span class="string">"These GPU models could be used by pod %s: %+v"</span>, pod.Name, filteredGPUModels)</span><br><span class="line"><span class="keyword">return</span> filteredGPUModels, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>接下来在 Filter阶段，根据上面的可用 <code>GPU Models</code> 和定义的 <code>Quota Pool</code>，</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(gpuFilter *GPUFilter)</span> <span class="title">filterNodes</span><span class="params">(nodes []corev1.Node, gpuModels, pools []<span class="keyword">string</span>)</span> <span class="params">(filteredNodes []corev1.Node, failedNodesMap schedulerapi.FailedNodesMap, err error)</span></span> &#123;</span><br><span class="line"><span class="keyword">var</span> gpuModelSelector, poolSelector labels.Selector</span><br><span class="line"></span><br><span class="line">glog.V(<span class="number">4</span>).Infof(<span class="string">"Filter nodes with gpuModels(%+v) and pools(%+v)"</span>, gpuModels, pools)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(gpuModels) != <span class="number">0</span> &#123;</span><br><span class="line">gpuModelSelector, err = metav1.LabelSelectorAsSelector(&amp;metav1.LabelSelector&#123;</span><br><span class="line">MatchExpressions: []metav1.LabelSelectorRequirement&#123;&#123;</span><br><span class="line">Key:      gpuFilter.conf.GPUModelLabel,</span><br><span class="line">Operator: metav1.LabelSelectorOpIn,</span><br><span class="line">Values:   gpuModels,</span><br><span class="line">&#125;&#125;&#125;)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, <span class="literal">nil</span>, err</span><br><span class="line">&#125;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">gpuModelSelector = labels.Nothing()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// If pool is empty, it means that pod could use every pool, it is OK to leave it as a empty selector.</span></span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(pools) != <span class="number">0</span> &#123;</span><br><span class="line">poolSelector, err = metav1.LabelSelectorAsSelector(&amp;metav1.LabelSelector&#123;</span><br><span class="line">MatchExpressions: []metav1.LabelSelectorRequirement&#123;&#123;</span><br><span class="line">Key:      gpuFilter.conf.GPUPoolLabel,</span><br><span class="line">Operator: metav1.LabelSelectorOpIn,</span><br><span class="line">Values:   pools,</span><br><span class="line">&#125;&#125;&#125;)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, <span class="literal">nil</span>, err</span><br><span class="line">&#125;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">poolSelector = labels.Everything()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">failedNodesMap = schedulerapi.FailedNodesMap&#123;&#125;</span><br><span class="line"><span class="keyword">for</span> _, node := <span class="keyword">range</span> nodes &#123;</span><br><span class="line"><span class="keyword">if</span> gpuModelSelector.Matches(labels.Set(node.Labels)) &amp;&amp; poolSelector.Matches(labels.Set(node.Labels)) &#123;</span><br><span class="line">filteredNodes = <span class="built_in">append</span>(filteredNodes, node)</span><br><span class="line">glog.V(<span class="number">5</span>).Infof(<span class="string">"Add %s to filteredNodes"</span>, node.Name)</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">failedNodesMap[node.Name] = <span class="string">"ExceedsGPUQuota"</span></span><br><span class="line">glog.V(<span class="number">5</span>).Infof(<span class="string">"Add %s to failedNodesMap"</span>, node.Name)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> filteredNodes, failedNodesMap, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>到这一步，也就是实现了细粒度的Quota调度准入控制。</p><h5 id="避免GPU碎片化"><a href="#避免GPU碎片化" class="headerlink" title="避免GPU碎片化"></a>避免GPU碎片化</h5><p>为此我们增加了GPU predicate controller来尽可能的降低系统默认调度策略带来的碎片化问题。</p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-11-19_gpu-manager-predicate.png"></p><p>我们看看它是如何实现的，首先在 <code>deviceFilter</code>的入口里面，拿到当前Node上存在的所有Pod：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">pods, err := gpuFilter.ListPodsOnNode(node)</span><br><span class="line">...</span><br><span class="line">nodeInfo := device.NewNodeInfo(node, pods)</span><br><span class="line">alloc := algorithm.NewAllocator(nodeInfo)</span><br><span class="line">newPod, err := alloc.Allocate(pod)</span><br></pre></td></tr></table></figure><p>接下来构建一个 <code>NodeInfo</code> 结构体，里面包含有当前Node的所有信息，这里记录了Node上所有的GPU显存和GPU设备数目。这个是通过Node Status里面两个扩展资源计算出来的。<strong>GPU Manager 方案也是认为每台机器上的GPU的不同卡的显存大小是相同的，这样可以算出每张卡的显存大小</strong>。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> NodeInfo <span class="keyword">struct</span> &#123;</span><br><span class="line">name        <span class="keyword">string</span></span><br><span class="line">node        *v1.Node</span><br><span class="line">devs        <span class="keyword">map</span>[<span class="keyword">int</span>]*DeviceInfo</span><br><span class="line">deviceCount <span class="keyword">int</span></span><br><span class="line">totalMemory <span class="keyword">uint</span></span><br><span class="line">usedCore    <span class="keyword">uint</span></span><br><span class="line">usedMemory  <span class="keyword">uint</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>NodeInfo</code> 里面还有一个 <code>DeviceInfo</code> 的map，用于记录每张卡的使用情况。这里在初始化这个 <code>NodeInfo</code> 数据结构的时候也会根据传入的 <code>pods</code> 信息更新 <code>DeviceInfo</code> 的设备使用情况。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> DeviceInfo <span class="keyword">struct</span> &#123;</span><br><span class="line">id          <span class="keyword">int</span></span><br><span class="line">totalMemory <span class="keyword">uint</span></span><br><span class="line">usedMemory  <span class="keyword">uint</span></span><br><span class="line">usedCore    <span class="keyword">uint</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>接下来就是每个 <code>Allocate</code> 函数的实现，对于Pod里面的每一个容器，都会分配得到一个 <code>devIDs</code> 列表，然后得到对Pod打上Annotation：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(alloc *allocator)</span> <span class="title">Allocate</span><span class="params">(pod *v1.Pod)</span> <span class="params">(*v1.Pod, error)</span></span> &#123;</span><br><span class="line">newPod := pod.DeepCopy()</span><br><span class="line"><span class="keyword">for</span> i, c := <span class="keyword">range</span> newPod.Spec.Containers &#123;</span><br><span class="line"><span class="keyword">if</span> !util.IsGPURequiredContainer(&amp;c) &#123;</span><br><span class="line"><span class="keyword">continue</span></span><br><span class="line">&#125;</span><br><span class="line">devIDs := []<span class="keyword">string</span>&#123;&#125;</span><br><span class="line">devs, err := alloc.AllocateOne(&amp;c)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">glog.Infof(<span class="string">"failed to allocate for pod %s(%s)"</span>, newPod.Name, c.Name)</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span> _, dev := <span class="keyword">range</span> devs &#123;</span><br><span class="line">devIDs = <span class="built_in">append</span>(devIDs, strconv.Itoa(dev.GetID()))</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> newPod.Annotations == <span class="literal">nil</span> &#123;</span><br><span class="line">newPod.Annotations = <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">string</span>)</span><br><span class="line">&#125;</span><br><span class="line">newPod.Annotations[util.PredicateGPUIndexPrefix+strconv.Itoa(i)] = strings.Join(devIDs, <span class="string">","</span>)</span><br><span class="line">&#125;</span><br><span class="line">newPod.Annotations[util.GPUAssigned] = <span class="string">"false"</span></span><br><span class="line">newPod.Annotations[util.PredicateTimeAnnotation] = fmt.Sprintf(<span class="string">"%d"</span>, time.Now().UnixNano())</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> newPod, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>接下来的问题就是，这里的 <code>AllocateOne</code> 是如何实现的呢？对于每个容器，根据其申请的GPU资源，可以分为GPU是共享模式还是独占模式，然后调用 <code>Evaluate</code>去得到 <code>devs</code>。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(alloc *allocator)</span> <span class="title">AllocateOne</span><span class="params">(container *v1.Container)</span> <span class="params">([]*device.DeviceInfo, error)</span></span> &#123;</span><br><span class="line"><span class="keyword">var</span> (</span><br><span class="line">devs           []*device.DeviceInfo</span><br><span class="line">sharedMode     <span class="keyword">bool</span></span><br><span class="line">vcore, vmemory <span class="keyword">uint</span></span><br><span class="line">)</span><br><span class="line">node := alloc.nodeInfo.GetNode()</span><br><span class="line">nodeTotalMemory := util.GetCapacityOfNode(node, util.VMemoryAnnotation)</span><br><span class="line">deviceCount := util.GetGPUDeviceCountOfNode(node)</span><br><span class="line">deviceTotalMemory := <span class="keyword">uint</span>(nodeTotalMemory / deviceCount)</span><br><span class="line">needCores := util.GetGPUResourceOfContainer(container, util.VCoreAnnotation)</span><br><span class="line">needMemory := util.GetGPUResourceOfContainer(container, util.VMemoryAnnotation)</span><br><span class="line"></span><br><span class="line"><span class="keyword">switch</span> &#123;</span><br><span class="line"><span class="keyword">case</span> needCores &lt; util.HundredCore:</span><br><span class="line">eval := NewShareMode(alloc.nodeInfo)</span><br><span class="line">devs = eval.Evaluate(needCores, needMemory)</span><br><span class="line">sharedMode = <span class="literal">true</span></span><br><span class="line"><span class="keyword">default</span>:</span><br><span class="line">eval := NewExclusiveMode(alloc.nodeInfo)</span><br><span class="line">devs = eval.Evaluate(needCores, needMemory)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(devs) == <span class="number">0</span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, fmt.Errorf(<span class="string">"failed to allocate for container %s"</span>, container.Name)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> sharedMode &#123;</span><br><span class="line">vcore = needCores</span><br><span class="line">vmemory = needMemory</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">vcore = util.HundredCore</span><br><span class="line">vmemory = deviceTotalMemory</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span> _, dev := <span class="keyword">range</span> devs &#123;</span><br><span class="line">err := alloc.nodeInfo.AddUsedResources(dev.GetID(), vcore, vmemory)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">glog.Infof(<span class="string">"failed to update used resource for node %s dev %d due to %v"</span>, node.Name, dev.GetID(), err)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> devs, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>以共享模式为例，这里拿到当前Node的所有 <code>Device</code>，分别根据最少可用的<code>cores</code>和可用的<code>memory</code>来排序，如果有满足用户需要的设备，则加入到 <code>devs</code> 里面，最后将这个 <code>list</code> 返回给用户。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(al *shareMode)</span> <span class="title">Evaluate</span><span class="params">(cores <span class="keyword">uint</span>, memory <span class="keyword">uint</span>)</span> []*<span class="title">device</span>.<span class="title">DeviceInfo</span></span> &#123;</span><br><span class="line"><span class="keyword">var</span> (</span><br><span class="line">devs        []*device.DeviceInfo</span><br><span class="line">deviceCount = al.node.GetDeviceCount()</span><br><span class="line">tmpStore    = <span class="built_in">make</span>([]*device.DeviceInfo, deviceCount)</span><br><span class="line">sorter      = shareModeSort(device.ByAllocatableCores, device.ByAllocatableMemory, device.ByID)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i := <span class="number">0</span>; i &lt; deviceCount; i++ &#123;</span><br><span class="line">tmpStore[i] = al.node.GetDeviceMap()[i]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">sorter.Sort(tmpStore)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> _, dev := <span class="keyword">range</span> tmpStore &#123;</span><br><span class="line"><span class="keyword">if</span> dev.AllocatableCores() &gt;= cores &amp;&amp; dev.AllocatableMemory() &gt;= memory &#123;</span><br><span class="line">glog.V(<span class="number">4</span>).Infof(<span class="string">"Pick up %d , cores: %d, memory: %d"</span>, dev.GetID(), dev.AllocatableCores(), dev.AllocatableMemory())</span><br><span class="line">devs = <span class="built_in">append</span>(devs, dev)</span><br><span class="line"><span class="keyword">break</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> devs</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看到这里在调度过程中，选择最先满足的那个，一旦满足则跳出选择。这是因为这里的 <code>devs</code> 已经按照最少可用的资源来匹配了，通过这种方式可以减少碎片化。</p><h4 id="Kubelet创建Pod-1"><a href="#Kubelet创建Pod-1" class="headerlink" title="Kubelet创建Pod"></a>Kubelet创建Pod</h4><p>用户创建Pod之后，经过调度找到对应的Node，这时候Kubelet向DevicePlugin执行Allocate函数。因为Kubelet看到的是虚拟的Devices，这里需要有一个从虚拟Device到实际GPU Device的映射，这里就是上图中GPU Manager做的事情，然后发送一个Request给GPU Scheduler，根据拓扑关系选择最合适的GPU，然后GPU Manager将 AllocateResponse返回给Kubelet。</p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-11-22_gaia-device-plugin.png"></p><p>我们先看 <code>Allocate</code> 的实现，这段代码比较长，但是实现的逻辑也不难：</p><ul><li>Allocate传入的参数是 <code>deviceIDs</code> 这样里一个List，<strong>里面只有 <code>vcore</code> 这种设备</strong> （代码是这样的，需要进一步看一看 kubelet）</li><li>Pod可能有多个Container，这里每次只处理一个容器<ul><li>如果还有未处理的Pod，先解决未处理Pod中的容器</li><li>否则从当前Node上的Pod遍历，选择与用户申请的 <code>vcore</code> 相同的容器</li></ul></li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(ta *NvidiaTopoAllocator)</span> <span class="title">Allocate</span><span class="params">(_ context.Context, reqs *pluginapi.AllocateRequest)</span> <span class="params">(*pluginapi.AllocateResponse, error)</span></span> &#123;</span><br><span class="line">ta.Lock()</span><br><span class="line"><span class="keyword">defer</span> ta.Unlock()</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> (</span><br><span class="line">reqCount           <span class="keyword">uint</span></span><br><span class="line">candidatePod       *v1.Pod</span><br><span class="line">candidateContainer *v1.Container</span><br><span class="line">found              <span class="keyword">bool</span></span><br><span class="line">)</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(reqs.ContainerRequests) &lt; <span class="number">1</span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, fmt.Errorf(<span class="string">"empty container request"</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// k8s send allocate request for one container at a time</span></span><br><span class="line">req := reqs.ContainerRequests[<span class="number">0</span>]</span><br><span class="line">resps := &amp;pluginapi.AllocateResponse&#123;&#125;</span><br><span class="line">reqCount = <span class="keyword">uint</span>(<span class="built_in">len</span>(req.DevicesIDs))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> ta.unfinishedPod != <span class="literal">nil</span> &#123;</span><br><span class="line">candidatePod = ta.unfinishedPod</span><br><span class="line">cache := ta.allocatedPod.GetCache(<span class="keyword">string</span>(candidatePod.UID))</span><br><span class="line"><span class="keyword">for</span> i, c := <span class="keyword">range</span> candidatePod.Spec.Containers &#123;</span><br><span class="line"><span class="keyword">if</span> _, ok := cache[c.Name]; ok &#123;</span><br><span class="line"><span class="keyword">continue</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> !utils.IsGPURequiredContainer(&amp;c) &#123;</span><br><span class="line"><span class="keyword">continue</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> reqCount != utils.GetGPUResourceOfContainer(&amp;candidatePod.Spec.Containers[i], types.VCoreAnnotation) &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, fmt.Errorf(msg)</span><br><span class="line">&#125;</span><br><span class="line">candidateContainer = &amp;candidatePod.Spec.Containers[i]</span><br><span class="line">found = <span class="literal">true</span></span><br><span class="line"><span class="keyword">break</span></span><br><span class="line">&#125;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">pods, err := getCandidatePods(ta.k8sClient, ta.config.Hostname)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">msg := fmt.Sprintf(<span class="string">"Failed to find candidate pods due to %v"</span>, err)</span><br><span class="line">glog.Infof(msg)</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, fmt.Errorf(msg)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> _, pod := <span class="keyword">range</span> pods &#123;</span><br><span class="line"><span class="keyword">if</span> found &#123;</span><br><span class="line"><span class="keyword">break</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span> i, c := <span class="keyword">range</span> pod.Spec.Containers &#123;</span><br><span class="line"><span class="keyword">if</span> !utils.IsGPURequiredContainer(&amp;c) &#123;</span><br><span class="line"><span class="keyword">continue</span></span><br><span class="line">&#125;</span><br><span class="line">podCache := ta.allocatedPod.GetCache(<span class="keyword">string</span>(pod.UID))</span><br><span class="line"><span class="keyword">if</span> podCache != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">if</span> _, ok := podCache[c.Name]; ok &#123;</span><br><span class="line">glog.Infof(<span class="string">"container %s of pod %s has been allocate, continue to next"</span>, c.Name, pod.UID)</span><br><span class="line"><span class="keyword">continue</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> utils.GetGPUResourceOfContainer(&amp;pod.Spec.Containers[i], types.VCoreAnnotation) == reqCount &#123;</span><br><span class="line">glog.Infof(<span class="string">"Found candidate Pod %s(%s) with device count %d"</span>, pod.UID, c.Name, reqCount)</span><br><span class="line">candidatePod = pod</span><br><span class="line">candidateContainer = &amp;pod.Spec.Containers[i]</span><br><span class="line">found = <span class="literal">true</span></span><br><span class="line"><span class="keyword">break</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>找到这样的一个容器之后，拿到容器申请的 <code>vmemory</code>，每一个虚拟的 <code>vmemory</code> 作为一个设备加入到 <code>req.DevicesIDs</code> 中，继续调用 <code>allocateOne</code>:</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> found &#123;</span><br><span class="line"><span class="comment">// get vmemory info from container spec</span></span><br><span class="line">vmemory := utils.GetGPUResourceOfContainer(candidateContainer, types.VMemoryAnnotation)</span><br><span class="line"><span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="keyword">int</span>(vmemory); i++ &#123;</span><br><span class="line">req.DevicesIDs = <span class="built_in">append</span>(req.DevicesIDs, types.VMemoryAnnotation)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">resp, err := ta.allocateOne(candidatePod, candidateContainer, req)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">glog.Errorf(err.Error())</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">&#125;</span><br><span class="line">resps.ContainerResponses = <span class="built_in">append</span>(resps.ContainerResponses, resp)</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">msg := fmt.Sprintf(<span class="string">"candidate pod not found for request %v, allocation failed"</span>, reqs)</span><br><span class="line">glog.Infof(msg)</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, fmt.Errorf(msg)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> resps, ni</span><br></pre></td></tr></table></figure><p>具体的 <code>Allocate</code> 实现在 <code>allocateOne</code> 里面，根据Pod计算出其申请的 <code>needCores</code> 和 <code>needMemory</code> 之后，根据三种情况有不同的分配策略。注意这里还是在拓扑树上面操作，拓扑树树根是物理的Host，树叶是物理的GPU</p><ul><li>申请的资源超过一张卡，这时候分配的策略是尽可能减少卡之间的通信开销</li><li>申请的资源等于一张卡，这时候的分配策略是尽可能减少拓扑树里面产生没有兄弟节点的叶节点</li><li>申请的资源小于一张卡，这时候的分配策略是尽可能减少卡资源的碎片化</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">switch</span> &#123;</span><br><span class="line"><span class="keyword">case</span> needCores &gt; nvtree.HundredCore:</span><br><span class="line">eval, ok := ta.evaluators[<span class="string">"link"</span>]</span><br><span class="line"><span class="comment">// 这种场景下needCores must be multiple of nvtree.HundredCore</span></span><br><span class="line">nodes = eval.Evaluate(needCores, <span class="number">0</span>)</span><br><span class="line"><span class="keyword">case</span> needCores == nvtree.HundredCore:</span><br><span class="line">eval, ok := ta.evaluators[<span class="string">"fragment"</span>]</span><br><span class="line">nodes = eval.Evaluate(needCores, <span class="number">0</span>)</span><br><span class="line"><span class="keyword">default</span>:</span><br><span class="line"><span class="comment">// evaluate in share mode</span></span><br><span class="line">shareMode = <span class="literal">true</span></span><br><span class="line">eval, ok := ta.evaluators[<span class="string">"share"</span>]</span><br><span class="line">nodes = eval.Evaluate(needCores, needMemory)</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>这里的 <code>Evaluate</code> 返回的是 <code>NvidiaNode</code> 这样的 GPU 节点，通过这个结构可以构建一个拓扑树：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//NvidiaNode represents a node of Nvidia GPU</span></span><br><span class="line"><span class="keyword">type</span> NvidiaNode <span class="keyword">struct</span> &#123;</span><br><span class="line">Meta            DeviceMeta</span><br><span class="line">AllocatableMeta SchedulerCache</span><br><span class="line"></span><br><span class="line">Parent   *NvidiaNode</span><br><span class="line">Children []*NvidiaNode</span><br><span class="line">Mask     <span class="keyword">uint32</span></span><br><span class="line"></span><br><span class="line">pendingReset <span class="keyword">bool</span></span><br><span class="line">vchildren    <span class="keyword">map</span>[<span class="keyword">int</span>]*NvidiaNode</span><br><span class="line">ntype        nvml.GpuTopologyLevel</span><br><span class="line">tree         *NvidiaTree</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>关于这里具体的分配算法此处就不再详述了，抓住主脉络。</p><p>接下来构建 <code>pluginapi.ContainerAllocateResponse</code>，这里会分别设置环境变量，挂载的目录，找到的设备，以及<code>Annotation</code>：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ctntResp := &amp;pluginapi.ContainerAllocateResponse&#123;</span><br><span class="line">Envs:        <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">string</span>),</span><br><span class="line">Mounts:      <span class="built_in">make</span>([]*pluginapi.Mount, <span class="number">0</span>),</span><br><span class="line">Devices:     <span class="built_in">make</span>([]*pluginapi.DeviceSpec, <span class="number">0</span>),</span><br><span class="line">Annotations: <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">string</span>),</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>首先是 <code>Devices</code> 字段：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">allocatedDevices := sets.NewString()</span><br><span class="line">deviceList := <span class="built_in">make</span>([]<span class="keyword">string</span>, <span class="number">0</span>)</span><br><span class="line"><span class="keyword">for</span> _, n := <span class="keyword">range</span> nodes &#123;</span><br><span class="line">name := n.MinorName()</span><br><span class="line">glog.V(<span class="number">2</span>).Infof(<span class="string">"Allocate %s for %s(%s), Meta (%d:%d)"</span>, name, pod.UID, container.Name, n.Meta.ID, n.Meta.MinorID)</span><br><span class="line"></span><br><span class="line">ctntResp.Annotations[types.VCoreAnnotation] = fmt.Sprintf(<span class="string">"%d"</span>, needCores)</span><br><span class="line">ctntResp.Annotations[types.VMemoryAnnotation] = fmt.Sprintf(<span class="string">"%d"</span>, needMemory)</span><br><span class="line"></span><br><span class="line">ctntResp.Devices = <span class="built_in">append</span>(ctntResp.Devices, &amp;pluginapi.DeviceSpec&#123;</span><br><span class="line">ContainerPath: name,</span><br><span class="line">HostPath:      name,</span><br><span class="line">Permissions:   <span class="string">"rwm"</span>,</span><br><span class="line">&#125;)</span><br><span class="line">deviceList = <span class="built_in">append</span>(deviceList, n.Meta.UUID)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> !allocated &#123;</span><br><span class="line">ta.tree.MarkOccupied(n, needCores, needMemory)</span><br><span class="line">&#125;</span><br><span class="line">allocatedDevices.Insert(name)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里还有一些控制设备：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Append control device</span></span><br><span class="line">ctntResp.Devices = <span class="built_in">append</span>(ctntResp.Devices, &amp;pluginapi.DeviceSpec&#123;</span><br><span class="line">ContainerPath: types.NvidiaCtlDevice,</span><br><span class="line">HostPath:      types.NvidiaCtlDevice,</span><br><span class="line">Permissions:   <span class="string">"rwm"</span>,</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line">ctntResp.Devices = <span class="built_in">append</span>(ctntResp.Devices, &amp;pluginapi.DeviceSpec&#123;</span><br><span class="line">ContainerPath: types.NvidiaUVMDevice,</span><br><span class="line">HostPath:      types.NvidiaUVMDevice,</span><br><span class="line">Permissions:   <span class="string">"rwm"</span>,</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">// Append default device</span></span><br><span class="line"><span class="keyword">if</span> cfg, found := ta.extraConfig[<span class="string">"default"</span>]; found &#123;</span><br><span class="line"><span class="keyword">for</span> _, dev := <span class="keyword">range</span> cfg.Devices &#123;</span><br><span class="line">ctntResp.Devices = <span class="built_in">append</span>(ctntResp.Devices, &amp;pluginapi.DeviceSpec&#123;</span><br><span class="line">ContainerPath: dev,</span><br><span class="line">HostPath:      dev,</span><br><span class="line">Permissions:   <span class="string">"rwm"</span>,</span><br><span class="line">&#125;)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>接着是 <code>Annotations</code> 字段：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">ctntResp.Annotations[types.VDeviceAnnotation] = vDeviceAnnotationStr(nodes)</span><br><span class="line"><span class="keyword">if</span> !allocated &#123;</span><br><span class="line">ta.allocatedPod.Insert(<span class="keyword">string</span>(pod.UID), container.Name, &amp;cache.Info&#123;</span><br><span class="line">Devices: allocatedDevices.UnsortedList(),</span><br><span class="line">Cores:   needCores,</span><br><span class="line">Memory:  needMemory,</span><br><span class="line">&#125;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后是 <code>Envs</code> 字段</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// LD_LIBRARY_PATH</span></span><br><span class="line">ctntResp.Envs[<span class="string">"LD_LIBRARY_PATH"</span>] = <span class="string">"/usr/local/nvidia/lib64"</span></span><br><span class="line"><span class="keyword">for</span> _, env := <span class="keyword">range</span> container.Env &#123;</span><br><span class="line"><span class="keyword">if</span> env.Name == <span class="string">"compat32"</span> &amp;&amp; strings.ToLower(env.Value) == <span class="string">"true"</span> &#123;</span><br><span class="line">ctntResp.Envs[<span class="string">"LD_LIBRARY_PATH"</span>] = <span class="string">"/usr/local/nvidia/lib"</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// NVIDIA_VISIBLE_DEVICES</span></span><br><span class="line">ctntResp.Envs[<span class="string">"NVIDIA_VISIBLE_DEVICES"</span>] = strings.Join(deviceList, <span class="string">","</span>)</span><br></pre></td></tr></table></figure><p>最后是 <code>Mounts</code> 字段，这里给GPU容器配置一个volume挂载点来提供CUDA Library以及配置环境变量<code>LD_LIBRARY_PATH</code> 告诉应用哪里去找到 <code>CUDA Library</code>。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> shareMode &#123;</span><br><span class="line">ctntResp.Mounts = <span class="built_in">append</span>(ctntResp.Mounts, &amp;pluginapi.Mount&#123;</span><br><span class="line">ContainerPath: <span class="string">"/usr/local/nvidia"</span>,</span><br><span class="line">HostPath:      types.DriverLibraryPath,</span><br><span class="line">ReadOnly:      <span class="literal">true</span>,</span><br><span class="line">&#125;)</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">ctntResp.Mounts = <span class="built_in">append</span>(ctntResp.Mounts, &amp;pluginapi.Mount&#123;</span><br><span class="line">ContainerPath: <span class="string">"/usr/local/nvidia"</span>,</span><br><span class="line">HostPath:      types.DriverOriginLibraryPath,</span><br><span class="line">ReadOnly:      <span class="literal">true</span>,</span><br><span class="line">&#125;)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">ctntResp.Mounts = <span class="built_in">append</span>(ctntResp.Mounts, &amp;pluginapi.Mount&#123;</span><br><span class="line">ContainerPath: types.VCUDA_MOUNTPOINT,</span><br><span class="line">HostPath:      filepath.Join(ta.config.VirtualManagerPath, <span class="keyword">string</span>(pod.UID)),</span><br><span class="line">ReadOnly:      <span class="literal">true</span>,</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><h4 id="vGPU-Manager"><a href="#vGPU-Manager" class="headerlink" title="vGPU Manager"></a>vGPU Manager</h4><p><code>vGPU Manager</code> 作为 <code>GPU Manager</code> 这个 <code>DaemonSet</code> 的一部分，负责下发容器配置和监控容器分配的vGPU。上一步在拓扑分配器确定好每个容器的资源配置之后，<code>vGPU Manager</code> 负责为每个容器在 host 上创建一个独立的目录，这个目录以容器的名称命名，并且会被包括在 <code>AllocateResponse</code> 中返回给 kubelet，对就是上面那段代码做的事情。</p><p><code>vGPU Manager</code> 会维护一个使用了GPU的并且仍然活着的容器列表，还会去周期性的检查他们。一旦有容器挂掉，就会将这个容器移出列表并且删去目录。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//                Host                     |                Container</span></span><br><span class="line"><span class="comment">//                                         |</span></span><br><span class="line"><span class="comment">//                                         |</span></span><br><span class="line"><span class="comment">//  .-----------.                          |</span></span><br><span class="line"><span class="comment">//  | allocator |----------.               |             ___________</span></span><br><span class="line"><span class="comment">//  '-----------'   PodUID |               |             \          \</span></span><br><span class="line"><span class="comment">//                         v               |              ) User App )--------.</span></span><br><span class="line"><span class="comment">//                .-----------------.      |             /__________/         |</span></span><br><span class="line"><span class="comment">//     .----------| virtual-manager |      |                                  |</span></span><br><span class="line"><span class="comment">//     |          '-----------------'      |                                  |</span></span><br><span class="line"><span class="comment">// $VirtualManagerPath/PodUID              |                                  |</span></span><br><span class="line"><span class="comment">//     |                                   |       read /proc/self/cgroup     |</span></span><br><span class="line"><span class="comment">//     |  .------------------.             |       to get PodUID, ContainerID |</span></span><br><span class="line"><span class="comment">//     '-&gt;| create directory |------.      |                                  |</span></span><br><span class="line"><span class="comment">//        '------------------'      |      |                                  |</span></span><br><span class="line"><span class="comment">//                                  |      |                                  |</span></span><br><span class="line"><span class="comment">//                 .----------------'      |       .----------------------.   |</span></span><br><span class="line"><span class="comment">//                 |                       |       | fork call gpu-client |&lt;--'</span></span><br><span class="line"><span class="comment">//                 |                       |       '----------------------'</span></span><br><span class="line"><span class="comment">//                 v                       |                   |</span></span><br><span class="line"><span class="comment">//    .------------------------.           |                   |</span></span><br><span class="line"><span class="comment">//   ( wait for client register )&lt;-------PodUID, ContainerID---'</span></span><br><span class="line"><span class="comment">//    '------------------------'           |</span></span><br><span class="line"><span class="comment">//                 |                       |</span></span><br><span class="line"><span class="comment">//                 v                       |</span></span><br><span class="line"><span class="comment">//   .--------------------------.          |</span></span><br><span class="line"><span class="comment">//   | locate pod and container |          |</span></span><br><span class="line"><span class="comment">//   '--------------------------'          |</span></span><br><span class="line"><span class="comment">//                 |                       |</span></span><br><span class="line"><span class="comment">//                 v                       |</span></span><br><span class="line"><span class="comment">//   .---------------------------.         |</span></span><br><span class="line"><span class="comment">//   | write down configure and  |         |</span></span><br><span class="line"><span class="comment">//   | pid file with containerID |         |</span></span><br><span class="line"><span class="comment">//   | as name                   |         |</span></span><br><span class="line"><span class="comment">//   '---------------------------'         |</span></span><br><span class="line"><span class="comment">//                                         |</span></span><br><span class="line"><span class="comment">//                                         |</span></span><br><span class="line"><span class="comment">//                                         v</span></span><br></pre></td></tr></table></figure><h3 id="vGPU-Library"><a href="#vGPU-Library" class="headerlink" title="vGPU Library"></a>vGPU Library</h3><p>论文中的 <code>vGPU Library</code>，具体实现为 <a href="https://github.com/tkestack/vcuda-controller" target="_blank" rel="external nofollow noopener noreferrer">vcuda-controller</a> ，它运行在容器中用于管理部署在容器中的GPU资源。这个 <code>vGPU Library</code> 本质上就是自己封装了 <code>CUDA Library</code>，劫持了 <code>memory-related</code> API 和 <code>computing-related</code> API，下表显示了劫持的API。</p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-11-22_gaia-vcuda.png"></p><p><code>vCUDA</code> 在调用相应API时检查：</p><ul><li>对于显存，一旦该任务申请显存后占用的显存大小大于config中的设置，就报错。</li><li>对于计算资源，存在硬隔离和软隔离两种方式<ul><li>共同点是当任务使用的GPU SM利用率超出资源上限，则暂缓下发API调用。</li><li>不同点是如果有资源空闲，软隔离允许任务超过设置，动态计算资源上限。而硬隔离则不允许超出设置量。</li></ul></li></ul><p>这里对于其具体实现按下不表。</p><p>一个令人疑惑的问题是，在GPU Manager中，用户的容器是如何能够使用这个动态库的呢？具体有两个问题：</p><ul><li>这个库从哪里来？<ul><li><code>GPU Manager</code> 作为 <code>DaemonSet</code> 会在其Image中将我们自定义的库打包进去，然后挂载到Node上的一个目录。</li></ul></li><li>容器中的应用是如何感知到的？<ul><li>这里主要是通过在创建容器的时候，设置 <code>LD_LIBRARY_PATH</code> ，将其指向这个自定义的动态库的地址。</li></ul></li></ul><h3 id="资源监控统计"><a href="#资源监控统计" class="headerlink" title="资源监控统计"></a>资源监控统计</h3><p>这部分代码还没有看。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://github.com/AliyunContainerService/gpushare-scheduler-extender/blob/master/docs/designs/designs.md" target="_blank" rel="external nofollow noopener noreferrer">阿里GPUShare设计文档</a></li><li><a href="https://www.alibabacloud.com/help/zh/doc-detail/163994.htm" target="_blank" rel="external nofollow noopener noreferrer">阿里共享调度使用文档</a></li><li><a href="https://ieeexplore.ieee.org/document/8672318" target="_blank" rel="external nofollow noopener noreferrer">Gaia GPUManager论文</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;原生的 k8s 基于 &lt;code&gt;Device Plugin&lt;/code&gt; 和 &lt;code&gt;Extended Resource&lt;/code&gt; 机制实现了在容器中使用GPU，但是只支持GPU的独占使用，不允许在Pod间共享GPU，这大大降低了对集群中GPU的利用率。为了在集群层面共享GPU，我们需要实现GPU资源的隔离与调度，本文将依次介绍阿里的 &lt;a href=&quot;https://github.com/AliyunContainerService/gpushare-scheduler-extender&quot; target=&quot;_blank&quot; rel=&quot;external nofollow noopener noreferrer&quot;&gt;GPUShare&lt;/a&gt; 与腾讯的 &lt;a href=&quot;https://github.com/tkestack/gpu-manager&quot; target=&quot;_blank&quot; rel=&quot;external nofollow noopener noreferrer&quot;&gt;GPUManager&lt;/a&gt;，分析其实现机制。&lt;/p&gt;
    
    </summary>
    
    <content src="http://houmin.cc/https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-11-21_aliyun-gpu-share.jpg" type="image" />
    
    
      <category term="术业专攻" scheme="http://houmin.cc/categories/%E6%9C%AF%E4%B8%9A%E4%B8%93%E6%94%BB/"/>
    
    
      <category term="k8s" scheme="http://houmin.cc/tags/k8s/"/>
    
      <category term="GPU" scheme="http://houmin.cc/tags/GPU/"/>
    
      <category term="资源隔离" scheme="http://houmin.cc/tags/%E8%B5%84%E6%BA%90%E9%9A%94%E7%A6%BB/"/>
    
      <category term="scheduler extender" scheme="http://houmin.cc/tags/scheduler-extender/"/>
    
      <category term="device plugin" scheme="http://houmin.cc/tags/device-plugin/"/>
    
  </entry>
  
  <entry>
    <title>【异构计算】在Docker中使用GPU</title>
    <link href="http://houmin.cc/posts/574111db/"/>
    <id>http://houmin.cc/posts/574111db/</id>
    <published>2020-11-17T12:45:00.000Z</published>
    <updated>2021-01-07T09:25:44.208Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>我们在 <a href="https://houmin.cc/posts/5004f8e5/">GPU 与 CUDA 编程入门</a> 这篇博客中初步介绍了如何Linux上使用GPU的方法，随着容器和k8s的迅猛发展，人们对于在容器中使用GPU的需求越发强烈。本文将基于前文，继续介绍如何在容器中使用GPU，进一步地，介绍在Kubernetes中如何调度GPU，并以Tensorflow为例，介绍如何基于Docker搭建部署了GPU的深度学习开发环境。</p><a id="more"></a><h2 id="NVIDIA-Container-Toolkit"><a href="#NVIDIA-Container-Toolkit" class="headerlink" title="NVIDIA Container Toolkit"></a>NVIDIA Container Toolkit</h2><h3 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h3><p>容器最早是用于无缝部署基于CPU的应用，它们对于硬件和平台是无感知的，但是显然这种使用场景对于GPU并不适用。对于不同的GPU，需要机器安装不同的硬件驱动，这极大限制了在容器中使用GPU。为了解决这个问题，最早的一种使用方法是在容器中完全重新安装一次NVIDIA驱动，然后将在容器启动的时候将GPU以字符设备 <code>/dev/nvidia0</code> 的方式传递给容器。然而这种方法要求容器中安装的驱动版本与Host上的驱动版本完全一致，同一个Docker Image不能在各个机器上复用，这极大的限制了容器的扩展性。</p><p>为了解决上述问题，容器必须对于 NVIDIA 驱动是无感知的，基于此 NVIDIA 推出了 <a href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/overview.html" target="_blank" rel="external nofollow noopener noreferrer">NVIDIA Container Toolkit</a>：</p><p><img alt="nvidia-gpu-docker" data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-11-22_nvidia-gpu-docker.png"></p><p>如上图所示， NVIDIA 将原来 CUDA 应用依赖的API环境划分为两个部分：</p><ul><li>驱动级API：由<code>libcuda.so.major.minor</code>动态库和内核module提供支持，图中表示为CUDA Driver<ul><li>驱动级API属于底层API，每当NVIDIA公司释放出某一个版本的驱动时，如果你要升级主机上的驱动，那么内核模块和<code>libcuda.so.major.minor</code>这2个文件就必须同时升级到同一个版本，这样原有的程序才能正常工作,</li><li>不同版本的驱动不能同时存在于宿主机上</li></ul></li><li>非驱动级API：由动态库<code>libcublas.so</code>等用户空间级别的API组成，图中表示为CUDA Toolkit<ul><li>非驱动级API的版本号是以Toolkit自身的版本号来管理, 比如cuda-10，cuda-11</li><li>不同版本的Toolkit可以同时运行在相同的宿主机上</li><li>非驱动级API算是对驱动级API的一种更高级的封装,最终还是要调用驱动级API来实现功能</li></ul></li></ul><p>为了让使用GPU的容器更具可扩展性，关于非驱动级的API被 NVIDIA 打包进了  <a href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/overview.html" target="_blank" rel="external nofollow noopener noreferrer">NVIDIA Container Toolkit</a>，因此在容器中使用GPU之前，每个机器需要先安装好NVIDIA驱动，之后配置好 NVIDIA Container Toolkit之后，就可以在容器中方便使用GPU了。</p><h3 id="整体架构"><a href="#整体架构" class="headerlink" title="整体架构"></a>整体架构</h3><p>NVIDIA 的容器工具包本质是使用一个<code>nvidia-runc</code>的方式来提供GPU容器的创建, 在用户创建出来的OCI spec上补上几个hook函数，来达到GPU设备运行的准备工作。具体包括以下几个组件，从上到下展示如图：</p><ul><li><code>nvidia-docker2</code></li><li><code>nvidia-container-runtime</code></li><li><code>nvidia-container-toolkit</code></li><li><code>libnvidia-container</code></li></ul><p><img alt data-src="https://docs.nvidia.com/datacenter/cloud-native/_images/nvidia-docker-arch.png"></p><p>下面对这几个组件依次介绍：</p><h4 id="libnvidia-container"><a href="#libnvidia-container" class="headerlink" title="libnvidia-container"></a><code>libnvidia-container</code></h4><p>This component provides a library and a simple CLI utility to automatically configure GNU/Linux containers leveraging NVIDIA GPUs. The implementation relies on kernel primitives and is designed to be agnostic of the container runtime.</p><p><code>libnvidia-container</code> provides a well-defined API and a wrapper CLI (called <code>nvidia-container-cli</code>) that different runtimes can invoke to inject NVIDIA GPU support into their containers.</p><h4 id="nvidia-container-toolkit"><a href="#nvidia-container-toolkit" class="headerlink" title="nvidia-container-toolkit"></a><code>nvidia-container-toolkit</code></h4><p>This component includes a script that implements the interface required by a <code>runC</code> <code>prestart</code> hook. This script is invoked by <code>runC</code> after a container has been created, but before it has been started, and is given access to the <code>config.json</code> associated with the container (e.g. this <a href="https://github.com/opencontainers/runtime-spec/blob/master/config.md#configuration-schema-example=" target="_blank" rel="external nofollow noopener noreferrer">config.json</a> ). It then takes information contained in the <code>config.json</code> and uses it to invoke the <code>libnvidia-container</code> CLI with an appropriate set of flags. One of the most important flags being which specific GPU devices should be injected into the container.</p><p>Note that the previous name of this component was <code>nvidia-container-runtime-hook</code>. <code>nvidia-container-runtime-hook</code> is now simply a symlink to <code>nvidia-container-toolkit</code> on the system.</p><h4 id="nvidia-container-runtime"><a href="#nvidia-container-runtime" class="headerlink" title="nvidia-container-runtime"></a><code>nvidia-container-runtime</code></h4><p>This component used to be a complete fork of <code>runC</code> with NVIDIA specific code injected into it. Since 2019, it is a thin wrapper around the native <code>runC</code> installed on the host system. <code>nvidia-container-runtime</code> takes a <code>runC</code> spec as input, injects the <code>nvidia-container-toolkit</code> script as a <code>prestart</code> hook into it, and then calls out to the native <code>runC</code>, passing it the modified <code>runC</code> spec with that hook set. It’s important to note that this component is not necessarily specific to docker (but it is specific to <code>runC</code>).</p><p>When the package is installed, the Docker <code>daemon.json</code> is updated to point to the binary as can be seen below:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">/etc/docker/daemon.json</span><br><span class="line">&#123;</span><br><span class="line"><span class="string">"default-runtime"</span>: <span class="string">"nvidia"</span>,</span><br><span class="line"><span class="string">"runtimes"</span>: &#123;</span><br><span class="line">    <span class="string">"nvidia"</span>: &#123;</span><br><span class="line">        <span class="string">"path"</span>: <span class="string">"/usr/bin/nvidia-container-runtime"</span>,</span><br><span class="line">        <span class="string">"runtimeArgs"</span>: []</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="nvidia-docker2"><a href="#nvidia-docker2" class="headerlink" title="nvidia-docker2"></a><code>nvidia-docker2</code></h4><p>This package is the only docker-specific package of the hierarchy. It takes the script associated with the <code>nvidia-container-runtime</code> and installs it into docker’s <code>/etc/docker/daemon.json</code> file. This then allows you to run (for example) <code>docker run --runtime=nvidia ...</code> to automatically add GPU support to your containers. It also installs a wrapper script around the native docker CLI called <code>nvidia-docker</code> which lets you invoke docker without needing to specify <code>--runtime=nvidia</code> every single time. It also lets you set an environment variable on the host (<code>NV_GPU</code>) to specify which GPUs should be injected into a container.</p><h3 id="部署验证"><a href="#部署验证" class="headerlink" title="部署验证"></a>部署验证</h3><p>这里仍然基于腾讯云的 CentOS 7机器为例演示如何在安装配置 <code>NVIDIA Container Toolkit</code>，对于更多的平台可以参考其<a href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html" target="_blank" rel="external nofollow noopener noreferrer">官方文档</a>。</p><h4 id="安装-Docker-CE"><a href="#安装-Docker-CE" class="headerlink" title="安装 Docker CE"></a>安装 Docker CE</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ curl https://get.docker.com | sh \</span><br><span class="line">  &amp;&amp; sudo systemctl start docker \</span><br><span class="line">  &amp;&amp; sudo systemctl <span class="built_in">enable</span> docker</span><br></pre></td></tr></table></figure><h4 id="安装-NVIDIA-Container-Toolkit"><a href="#安装-NVIDIA-Container-Toolkit" class="headerlink" title="安装 NVIDIA Container Toolkit"></a>安装 NVIDIA Container Toolkit</h4><p>Setup the <code>stable</code> repository and the GPG key:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ distribution=$(. /etc/os-release;<span class="built_in">echo</span> <span class="variable">$ID</span><span class="variable">$VERSION_ID</span>) \</span><br><span class="line">   &amp;&amp; curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add - \</span><br><span class="line">   &amp;&amp; curl -s -L https://nvidia.github.io/nvidia-docker/<span class="variable">$distribution</span>/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list</span><br></pre></td></tr></table></figure><p>Install the <code>nvidia-docker2</code> package (and dependencies) after updating the package listing:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-get update</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-get install -y nvidia-docker2</span><br></pre></td></tr></table></figure><p>Restart the Docker daemon to complete the installation after setting the default runtime:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo systemctl restart docker</span><br></pre></td></tr></table></figure><p>At this point, a working setup can be tested by running a base CUDA container:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker run --rm --gpus all nvidia/cuda:11.0-base nvidia-smi</span><br></pre></td></tr></table></figure><p>This should result in a console output shown below:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| NVIDIA-SMI 450.51.06    Driver Version: 450.51.06    CUDA Version: 11.0     |</span><br><span class="line">|-------------------------------+----------------------+----------------------+</span><br><span class="line">| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |</span><br><span class="line">| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |</span><br><span class="line">|                               |                      |               MIG M. |</span><br><span class="line">|===============================+======================+======================|</span><br><span class="line">|   0  Tesla T4            On   | 00000000:00:1E.0 Off |                    0 |</span><br><span class="line">| N/A   34C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |</span><br><span class="line">|                               |                      |                  N/A |</span><br><span class="line">+-------------------------------+----------------------+----------------------+</span><br><span class="line"></span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| Processes:                                                                  |</span><br><span class="line">|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |</span><br><span class="line">|        ID   ID                                                   Usage      |</span><br><span class="line">|=============================================================================|</span><br><span class="line">|  No running processes found                                                 |</span><br><span class="line">+-----------------------------------------------------------------------------+</span><br></pre></td></tr></table></figure><h4 id="配置-NVIDIA-Runtime"><a href="#配置-NVIDIA-Runtime" class="headerlink" title="配置 NVIDIA Runtime"></a>配置 NVIDIA Runtime</h4><p>To register the <code>nvidia</code> runtime, use the method below that is best suited to your environment. You might need to merge the new argument with your existing configuration. Three options are available:</p><h4 id="Systemd-drop-in-file"><a href="#Systemd-drop-in-file" class="headerlink" title="Systemd drop-in file"></a>Systemd drop-in file</h4><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo mkdir -p <span class="regexp">/etc/</span>systemd<span class="regexp">/system/</span>docker.service.d</span><br></pre></td></tr></table></figure><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ sudo tee <span class="regexp">/etc/</span>systemd<span class="regexp">/system/</span>docker.service.d/override.conf &lt;&lt;EOF</span><br><span class="line">[Service]</span><br><span class="line">ExecStart=</span><br><span class="line">ExecStart=<span class="regexp">/usr/</span>bin<span class="regexp">/dockerd --host=fd:/</span><span class="regexp">/ --add-runtime=nvidia=/</span>usr<span class="regexp">/bin/</span>nvidia-container-runtime</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ sudo systemctl daemon-reload \</span><br><span class="line">  &amp;&amp; sudo systemctl restart docker</span><br></pre></td></tr></table></figure><h4 id="Daemon-configuration-file"><a href="#Daemon-configuration-file" class="headerlink" title="Daemon configuration file"></a>Daemon configuration file</h4><p>The <code>nvidia</code> runtime can also be registered with Docker using the <code>daemon.json</code> configuration file:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ sudo tee /etc/docker/daemon.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">"runtimes"</span>: &#123;</span><br><span class="line">        <span class="string">"nvidia"</span>: &#123;</span><br><span class="line">            <span class="string">"path"</span>: <span class="string">"/usr/bin/nvidia-container-runtime"</span>,</span><br><span class="line">            <span class="string">"runtimeArgs"</span>: []</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo pkill -SIGHUP dockerd</span><br></pre></td></tr></table></figure><p>You can optionally reconfigure the default runtime by adding the following to <code>/etc/docker/daemon.json</code>:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"default-runtime"</span>: <span class="string">"nvidia"</span></span><br></pre></td></tr></table></figure><h4 id="Command-Line"><a href="#Command-Line" class="headerlink" title="Command Line"></a>Command Line</h4><p>Use <code>dockerd</code> to add the <code>nvidia</code> runtime:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo dockerd --add-runtime=nvidia=/usr/bin/nvidia-container-runtime [...]</span><br></pre></td></tr></table></figure><h2 id="在k8s中管理GPU"><a href="#在k8s中管理GPU" class="headerlink" title="在k8s中管理GPU"></a>在k8s中管理GPU</h2><p>为了在 k8s 中管理和使用GPU，我们除了需要配置 <code>NVIDIA Container Toolkit</code>，还需要安装NVIDIA推出的 <a href="https://github.com/NVIDIA/k8s-device-plugin" target="_blank" rel="external nofollow noopener noreferrer">NVIDIA/k8s-device-plugin</a>，具体安装可以参考 <a href="../3f069334">我的这篇博文</a>。上面的步骤加起来显得还是有些繁琐，如果你直接使用腾讯云 TKE 的话，在集群添加装有GPU的Node时候，就会自动帮你安装配置好  <code>NVIDIA Container Toolkit</code> 和  <code>NVIDIA/k8s-device-plugin</code>，十分方便。接下来我们以Tensorflow为例，演示在 k8s 环境运行有GPU的Tensorflow。</p><h3 id="单机版Tensorflow"><a href="#单机版Tensorflow" class="headerlink" title="单机版Tensorflow"></a>单机版Tensorflow</h3><p>首先是单机版的Tensorflow，执行 <code>kubectl apply -f tensorflow.yaml</code>来运行 <code>Jupiter Notebook</code>。</p><figure class="highlight yaml"><figcaption><span>tensorflow.yaml</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span> </span><br><span class="line">  <span class="attr">name:</span> <span class="string">tensorflow</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">k8s-app:</span> <span class="string">tensorflow</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">k8s-app:</span> <span class="string">tensorflow</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">k8s-app:</span> <span class="string">tensorflow</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">tensorflow</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">tensorflow/tensorflow:2.2.1-gpu-py3-jupyter</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">8888</span></span><br><span class="line">        <span class="attr">resources:</span></span><br><span class="line">          <span class="attr">limits:</span></span><br><span class="line">            <span class="attr">cpu:</span> <span class="number">4</span></span><br><span class="line">            <span class="attr">memory:</span> <span class="string">2Gi</span></span><br><span class="line">          <span class="attr">requests:</span></span><br><span class="line">            <span class="attr">cpu:</span> <span class="number">2</span></span><br><span class="line">            <span class="attr">memory:</span> <span class="string">1Gi</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">jupyter-service</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">NodePort</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">8888</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">tensorflow</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">k8s-app:</span> <span class="string">tensorflow</span></span><br></pre></td></tr></table></figure><p>我们看到容器很快运行起来，根据 <code>http:&lt;nodeIP&gt;:&lt;nodePort&gt;</code> 可以访问到 <code>Jupiter Notebook</code>，但是显示需要token：</p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-11-22_tensorflow-jupiter.png"></p><p>查看 <code>Tensorflow</code> 日志，可以获得 token：<code>aa06c9f12d80adac1a6288b97bf8030522cecc92202dbb20</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">[root@VM-1-14-centos single]<span class="comment"># kubectl get pods</span></span><br><span class="line">NAME                          READY   STATUS    RESTARTS   AGE</span><br><span class="line">tensorflow-6cbc85744b-c567p   1/1     Running   0          7m37s</span><br><span class="line">[root@VM-1-14-centos single]<span class="comment"># kubectl logs tensorflow-6cbc85744b-c567p</span></span><br><span class="line"></span><br><span class="line">________                               _______________</span><br><span class="line">___  __/__________________________________  ____/__  /________      __</span><br><span class="line">__  /  _  _ \_  __ \_  ___/  __ \_  ___/_  /_   __  /_  __ \_ | /| / /</span><br><span class="line">_  /   /  __/  / / /(__  )/ /_/ /  /   _  __/   _  / / /_/ /_ |/ |/ /</span><br><span class="line">/_/    \___//_/ /_//____/ \____//_/    /_/      /_/  \____/____/|__/</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">WARNING: You are running this container as root, <span class="built_in">which</span> can cause new files <span class="keyword">in</span></span><br><span class="line">mounted volumes to be created as the root user on your host machine.</span><br><span class="line"></span><br><span class="line">To avoid this, run the container by specifying your user<span class="string">'s userid:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">$ docker run -u $(id -u):$(id -g) args...</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[I 04:47:52.083 NotebookApp] Writing notebook server cookie secret to /root/.local/share/jupyter/runtime/notebook_cookie_secret</span></span><br><span class="line"><span class="string">[I 04:47:52.315 NotebookApp] Serving notebooks from local directory: /tf</span></span><br><span class="line"><span class="string">[I 04:47:52.315 NotebookApp] Jupyter Notebook 6.1.4 is running at:</span></span><br><span class="line"><span class="string">[I 04:47:52.315 NotebookApp] http://tensorflow-6cbc85744b-c567p:8888/?token=aa06c9f12d80adac1a6288b97bf8030522cecc92202dbb20</span></span><br><span class="line"><span class="string">[I 04:47:52.315 NotebookApp]  or http://127.0.0.1:8888/?token=aa06c9f12d80adac1a6288b97bf8030522cecc92202dbb20</span></span><br><span class="line"><span class="string">[I 04:47:52.315 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).</span></span><br><span class="line"><span class="string">[C 04:47:52.319 NotebookApp]</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    To access the notebook, open this file in a browser:</span></span><br><span class="line"><span class="string">        file:///root/.local/share/jupyter/runtime/nbserver-1-open.html</span></span><br><span class="line"><span class="string">    Or copy and paste one of these URLs:</span></span><br><span class="line"><span class="string">        http://tensorflow-6cbc85744b-c567p:8888/?token=aa06c9f12d80adac1a6288b97bf8030522cecc92202dbb20</span></span><br><span class="line"><span class="string">     or http://127.0.0.1:8888/?token=aa06c9f12d80adac1a6288b97bf8030522cecc92202dbb20</span></span><br><span class="line"><span class="string">[I 04:49:28.692 NotebookApp] 302 GET / (172.16.0.193) 0.57ms</span></span><br><span class="line"><span class="string">[I 04:49:28.700 NotebookApp] 302 GET /tree? (172.16.0.193) 0.67ms</span></span><br></pre></td></tr></table></figure><p>登陆之后即可看到 <code>Jupiter Notebook</code>：</p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-11-22_tensorflow-jupiter.png"></p><p>新建Notebook，运行命令如下：</p><p><img alt data-src="https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-11-22_tensorflow-gpu.png"></p><p>可以看到，TensorFlow 支持在GPU上的运算</p><ul><li><code>&quot;/device:GPU:0&quot;</code>：TensorFlow 可见的机器上第一个 GPU 的速记表示法。</li><li><code>&quot;/job:localhost/replica:0/task:0/device:GPU:0&quot;</code>：TensorFlow 可见的机器上第一个 GPU 的完全限定名称。</li></ul><h3 id="分布式Tensorflow"><a href="#分布式Tensorflow" class="headerlink" title="分布式Tensorflow"></a>分布式Tensorflow</h3><p>整体架构：</p><p>这个架构图是分布式tensorflow的实战图，其中有</p><ul><li>两个参数服务</li><li>多个worker服务</li><li>还有个shuffle和抽样的服务</li></ul><p>shuffle就是对样根据其标签进行混排，然后对外提供batch抽样服务（可以是有放回和无放回，抽样是一门科学，详情可以参考抽样技术一书），每个batch的抽样是由每个worker去触发，worker拿到抽样的数据样本ID后就去基于kubernetes构建的分布式数据库里边提取该batchSize的样本数据，进行训练计算，由于分布式的tensorflow能够保证异步梯度下降算法，所以每次训练batch数据的时候都会基于最新的参数迭代，然而，更新参数操作就是两个参数服务做的，架构中模型（参数）的存储在NFS中，这样以来，参数服务与worker就可以共享参数了，最后说明一下，我们训练的所有数据都是存储在分布式数据库中（数据库的选型可以根据具体的场景而定）。为什么需要一个shuffle和抽样的服务，因为当数据量很大的时候，我们如果对所有的样本数据进行shuffle和抽样计算的话会浪费很大的资源，因此需要一个这样的服务专门提取数据的（id，label）来进行混排和抽样，这里如果（id, label）的数据量也很大的时候我们可以考虑基于spark 来分布式的进行shuffle和抽样，目前spark2.3已经原生支持kubernetes调度</p><p><img alt data-src="https://upload-images.jianshu.io/upload_images/3521279-7ab3727232db8073.png"></p><p>首先是 <code>Parameter Server</code>：</p><figure class="highlight yaml"><figcaption><span>tf-ps.yaml</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span> </span><br><span class="line">  <span class="attr">name:</span> <span class="string">tensorflow-ps</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">tensorflow-ps</span></span><br><span class="line">        <span class="attr">role:</span> <span class="string">ps</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">ps</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">tensorflow/tensorflow:2.2.1-gpu-py3-jupyter</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">2222</span></span><br><span class="line">        <span class="attr">resources:</span></span><br><span class="line">          <span class="attr">limits:</span></span><br><span class="line">            <span class="attr">cpu:</span> <span class="number">4</span></span><br><span class="line">            <span class="attr">memory:</span> <span class="string">2Gi</span></span><br><span class="line">          <span class="attr">requests:</span></span><br><span class="line">            <span class="attr">cpu:</span> <span class="number">2</span></span><br><span class="line">            <span class="attr">memory:</span> <span class="string">1Gi</span></span><br><span class="line">        <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/datanfs</span></span><br><span class="line">          <span class="attr">readOnly:</span> <span class="literal">false</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">nfs</span></span><br><span class="line">      <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nfs</span></span><br><span class="line">        <span class="attr">nfs:</span></span><br><span class="line">          <span class="attr">server:</span> <span class="string">你的nfs服务地址</span></span><br><span class="line">          <span class="attr">path:</span> <span class="string">"/data/nfs"</span>   </span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">tensorflow-ps-service</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">tensorflow-ps</span></span><br><span class="line">    <span class="attr">role:</span> <span class="string">service</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">2222</span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">2222</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">tensorflow-ps</span></span><br></pre></td></tr></table></figure><p>然后是 <code>Worker</code>：</p><figure class="highlight yaml"><figcaption><span>tf-worker.yaml</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">tensorflow-worker</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">3</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">tensorflow-worker</span></span><br><span class="line">        <span class="attr">role:</span> <span class="string">worker</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">worker</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">tensorflow/tensorflow:2.2.1-gpu-py3-jupyter</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">2222</span></span><br><span class="line">        <span class="attr">resources:</span></span><br><span class="line">          <span class="attr">limits:</span></span><br><span class="line">            <span class="attr">cpu:</span> <span class="number">4</span></span><br><span class="line">            <span class="attr">memory:</span> <span class="string">2Gi</span></span><br><span class="line">          <span class="attr">requests:</span></span><br><span class="line">            <span class="attr">cpu:</span> <span class="number">2</span></span><br><span class="line">            <span class="attr">memory:</span> <span class="string">1Gi</span></span><br><span class="line">        <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/datanfs</span></span><br><span class="line">          <span class="attr">readOnly:</span> <span class="literal">false</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">nfs</span></span><br><span class="line">      <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nfs</span></span><br><span class="line">        <span class="attr">nfs:</span></span><br><span class="line">          <span class="attr">server:</span> <span class="string">你的nfs服务地址</span></span><br><span class="line">          <span class="attr">path:</span> <span class="string">"/data/nfs"</span>   </span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">tensorflow-wk-service</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">tensorflow-worker</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">2222</span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">2222</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">tensorflow-worker</span></span><br></pre></td></tr></table></figure><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://cloud.tencent.com/developer/article/1005137" target="_blank" rel="external nofollow noopener noreferrer">https://cloud.tencent.com/developer/article/1005137</a></li><li><a href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/overview.html" target="_blank" rel="external nofollow noopener noreferrer">NVIDIA Container Toolkit</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;我们在 &lt;a href=&quot;https://houmin.cc/posts/5004f8e5/&quot;&gt;GPU 与 CUDA 编程入门&lt;/a&gt; 这篇博客中初步介绍了如何Linux上使用GPU的方法，随着容器和k8s的迅猛发展，人们对于在容器中使用GPU的需求越发强烈。本文将基于前文，继续介绍如何在容器中使用GPU，进一步地，介绍在Kubernetes中如何调度GPU，并以Tensorflow为例，介绍如何基于Docker搭建部署了GPU的深度学习开发环境。&lt;/p&gt;
    
    </summary>
    
    <content src="http://houmin.cc/https://cosmos-1251905798.cos.ap-beijing.myqcloud.com/blog/2020-11-22_nvidia-gpu-docker.png" type="image" />
    
    
      <category term="术业专攻" scheme="http://houmin.cc/categories/%E6%9C%AF%E4%B8%9A%E4%B8%93%E6%94%BB/"/>
    
    
      <category term="container" scheme="http://houmin.cc/tags/container/"/>
    
      <category term="docker" scheme="http://houmin.cc/tags/docker/"/>
    
      <category term="k8s" scheme="http://houmin.cc/tags/k8s/"/>
    
      <category term="GPU" scheme="http://houmin.cc/tags/GPU/"/>
    
      <category term="Nvidia" scheme="http://houmin.cc/tags/Nvidia/"/>
    
      <category term="tensorflow" scheme="http://houmin.cc/tags/tensorflow/"/>
    
  </entry>
  
</feed>
